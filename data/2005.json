{"abstract":{"entropy":6.901827406718996,"topics":["genetic algorithm, blind separation, search algorithm, web search, planning domain, global routing, fitness functions, widely used, markov decision, evolutionary algorithm, search, genetic gas, space-time block, genetic programming, local search, planning, partially observable, separation bss, source separation, software engineering","recent years, natural language, arc consistency, neural networks, data mining, data, scene understanding, play role, systems, applications data, mobile need, data stream, multi-agent systems, sensor networks, rdf ontologies, materialized views, resource allocation, model-based diagnosis, management data, language generation","speech recognition, presents novel, presents based, wide range, ultra wideband, signature scheme, ultra uwb, proposes, wavelet transform, noisy speech, power consumption, path delay, speech, describes speech, delay fault, motion estimation, register file, timing synchronization, proposes novel, based adaptive","presents algorithm, constraint satisfaction, particle swarm, machine learning, genetic programming, evolutionary algorithm, genetic algorithm, learning, optimization problem, presents approach, presents model, constraint problem, evolutionary optimization, solving problem, learning classifier, particle pso, problem, classifier systems, presents analysis, petri nets","markov decision, markov model, markov mdps, decision mdps, graph edge, decision making, decision problem, study problem, decision, markov, methods, graph, tree, study, finding, functions, investigate, relational, branch, deals","blind separation, global routing, consider problem, use algorithm, distribution algorithm, evolutionary computation, source separation, separation bss, blind bss, differential evolution, blind source, bayesian networks, source bss, presents model, address problem, paper algorithm, algorithm model, paper problem, paper, estimation distribution","arc consistency, self-interested agents, consider agents, problem agents, agents, knowledge, agents coalitions, computational complexity, negotiation agents, consider problem, systems agents, problem knowledge, order, computing, knowledge agents, major, complexity, requires, investigate, user","recent years, systems, play role, multi-agent systems, model-based diagnosis, xml repositories, growing interest, communication systems, years seen, increasingly important, become important, increase important, large number, recent systems, important, research, wireless communication, systems increasingly, recent research, software systems","systems based, paper scheme, proposes novel, presents based, based, based adaptive, based code, letter code, presents adaptive, proposes based, paper based, proposes methodology, scheme, proposes adaptive, systems adaptive, adaptive algorithm, novel improving, algorithm based, technique based, describes based","proposes synthesis, motion video, path delay, motion estimation, delay fault, vector quantization, remove noise, simd synthesis, reduction noise, circuit input, reduce noise, design circuit, technique, circuit, estimation video, presents estimation, proposes technique, video coding, noise, proposes cmos","constraint satisfaction, optimization problem, particle swarm, problem, constraint problem, solving problem, particle pso, algorithm problem, satisfaction problem, petri nets, scheduling problem, swarm optimization, swarm pso, particle optimization, quantified boolean, constraint, swarm algorithm, optimization pso, combinatorial auctions, quantified constraint","presents approach, approach problem, hybrid systems, hybrid algorithm, evolutionary problem, novel approach, approach, problem given, approach evolutionary, approach algorithm, approach systems, presents novel, textual given, describes approach, problem identifying, approach based, text systems, evolutionary computation, sequence problem, presents synchronous"],"ranking":[["57376|GECCO|2005|An empirical study of the robustness of two module clustering fitness functions|Two of the attractions of search-based software engineering (SBSE) derive from the nature of the fitness functions used to guide the search. These have proved to be highly robust (for a variety of different search algorithms) and have yielded insight into the nature of the search space itself, shedding light upon the software engineering problem in hand.This paper aims to exploit these two benefits of SBSE in the context of search based module clustering. The paper presents empirical results which compare the robustness of two fitness functions used for software module clustering one (MQ) used exclusively for module clustering. The other is EVM, a clustering fitness function previously applied to time series and gene expression data.The results show that both metrics are relatively robust in the presence of noise, with EVM being the more robust of the two. The results may also yield some interesting insights into the nature of software graphs.|Mark Harman,Stephen Swift,Kiarash Mahdavi","57268|GECCO|2005|Efficient credit assignment through evaluation function decomposition|Evolutionary methods are powerful tools in discovering solutions for difficult continuous tasks. When such a solution is encoded over multiple genes, a genetic algorithm faces the difficult credit assignment problem of evaluating how a single gene in a chromosome contributes to the full solution. Typically a single evaluation function is used for the entire chromosome, implicitly giving each gene in the chromosome the same evaluation. This method is inefficient because a gene will get credit for the contribution of all the other genes as well. Accurately measuring the fitness of individual genes in such a large search space requires many trials. This paper instead proposes turning this single complex search problem into a multi-agent search problem, where each agent has the simpler task of discovering a suitable gene. Gene-specific evaluation functions can then be created that have better theoretical properties than a single evaluation function over all genes. This method is tested in the difficult double-pole balancing problem, showing that agents using gene-specific evaluation functions can create a successful control policy in % fewer trials than the best existing genetic algorithms. The method is extended to more distributed problems, achieving % performance gains over tradition methods in the multi-rover domain.|Adrian K. Agogino,Kagan Tumer,Risto Miikkulainen","65397|AAAI|2005|Scheduling Engineering Works for the MTR Corporation in Hong Kong|This paper describes a Hong Kong MTR Corporation subway project to enhance and extend the current Web-based Engineering Works and Traffic Information Management System (ETMS) with an intelligent \"AI Engine.\" The challenge is to be able to fully and accurately encapsulate all the necessary domain and operation knowledge on subway engineering works and to be able to apply this knowledge in an efficient manner for both validation as well as scheduling. Since engineering works can only be performed a few hours each night, it is crucially important that the \"AI Engine\" maximizes the number of jobs done while ensuring operational safety and resource availability. Previously, all constraintresource checking and scheduling decisions were made manually. The new AI approach streamlines the entire planning, scheduling and rescheduling process and extends the ETMS with intelligent abilities to () automatically detect potential conflicts as work requests are entered, () check all approved work schedules for any conflicts before execution, () generate weekly operational schedules, () repair schedules after changes and () generate quarterly schedules for planning. The AI Engine uses a rule representation combined with heuristic search and a genetic algorithm for scheduling. An iterative repair algorithm was used for dynamic rescheduling.|Andy Hon Wai Chun,Dennis Wai Ming Yeung,Garbbie Pui Shan Lam,Daniel Lai,Richard Keefe,Jerome Lam,Helena Chan","42556|IEICE Transations|2005|Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain|This paper overviews a total solution for frequency-domain blind source separation (BSS) of convolutive mixtures of audio signals, especially speech. Frequency-domain BSS performs independent component analysis (ICA) in each frequency bin, and this is more efficient than time-domain BSS. We describe a sophisticated total solution for frequency-domain BSS, including permutation, scaling, circularity, and complex activation function solutions. Experimental results of   ,   ,   ,   , and    (moving sources), (sources  microphones) in a room are promising.|Shoji Makino,Hiroshi Sawada,Ryo Mukai,Shoko Araki","57275|GECCO|2005|Intelligent exploration for genetic algorithms using self-organizing maps in evolutionary computation|Exploration vs. exploitation is a well known issue in Evolutionary Algorithms. Accordingly, an unbalanced search can lead to premature convergence. GASOM, a novel Genetic Algorithm, addresses this problem by intelligent exploration techniques. The approach uses Self-Organizing Maps to mine data from the evolution process. The information obtained is successfully utilized to enhance the search strategy and confront genetic drift. This way, local optima are avoided and exploratory power is maintained. The evaluation of GASOM on well known problems shows that it effectively prevents premature convergence and seeks the global optimum. Particularly on deceptive and misleading functions it showed outstanding performance. Additionally, representing the search history by the Self-Organizing Map provides a visually pleasing insight into the state and course of evolution.|Heni Ben Amor,Achim Rettinger","16267|IJCAI|2005|Conditional Planning in the Discrete Belief Space|Probabilistic planning with observability restrictions, as formalized for example as partially observable Markov decision processes (POMDP), has a wide range of applications, but it is computationally extremely difficult. For POMDPs, the most general decision problems about existence of policies satisfying certain properties are undecidable. We consider a computationally easier form of planning that ignores exact probabilities, and give an algorithm for a class of planning problems with partial observability. We show that the basic backup step in the algorithm is NP-complete. Then we proceed to give an algorithm for the backup step, and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.|Jussi Rintanen","42438|IEICE Transations|2005|Separation of Sound Sources Propagated in the Same Direction|This paper describes a method for separating a target sound from other noise arriving in a single direction when the target cannot, therefore, be separated by directivity control. Microphones are arranged in a line toward the sources to form null sensitivity points at given distances from the microphones. The null points exclude non-target sound sources on the basis of weighting coefficients for microphone outputs determined by blind source separation. The separation problem is thereby simplified to instantaneous separation by adjustment of the time-delays for microphone outputs. The system uses a direct (i.e. non-iterative) algorithm for blind separation based on second-order statistics, assuming that all sources are non-stationary signals. Simulations show that the -microphone system can separate a target sound with separability of more than  dB for the -source problem, and  dB for the -source problem when the other sources are adjacent.|Akio Ando,Masakazu Iwaki,Kazuho Ono,Koichi Kurozumi","42618|IEICE Transations|2005|Subband-Based Blind Separation for Convolutive Mixtures of Speech|We propose utilizing subband-based blind source separation (BSS) for convolutive mixtures of speech. This is motivated by the drawback of frequency-domain BSS, i.e., when a long frame with a fixed long frame-shift is used to cover reverberation, the number of samples in each frequency decreases and the separation performance is degraded. In subband BSS, () by using a moderate number of subbands, a sufficient number of samples can be held in each subband, and () by using FIR filters in each subband, we can manage long reverberation. We confirm that subband BSS achieves better performance than frequency-domain BSS. Moreover, subband BSS allows us to select a separation method suited to each subband. Using this advantage, we propose efficient separation procedures that consider the frequency characteristics of room reverberation and speech signals () by using longer unmixing filters in low frequency bands and () by adopting an overlap-blockshift in BSS's batch adaptation in low frequency bands. Consequently, frequency-dependent subband processing is successfully realized with the proposed subband BSS.|Shoko Araki,Shoji Makino,Robert Aichner,Tsuyoki Nishikawa,Hiroshi Saruwatari","42498|IEICE Transations|2005|Blind Separation of Speech by Fixed-Point ICA with Source Adaptive Negentropy Approximation|This paper presents a study on the blind separation of a convoluted mixture of speech signals using Frequency Domain Independent Component Analysis (FDICA) algorithm based on the negentropy maximization of Time Frequency Series of Speech (TFSS). The comparative studies on the negentropy approximation of TFSS using generalized Higher Order Statistics (HOS) of different nonquadratic, nonlinear functions are presented. A new nonlinear function based on the statistical modeling of TFSS by exponential power functions has also been proposed. The estimation of standard error and bias, obtained using the sequential delete-one jackknifing method, in the approximation of negentropy of TFSS by different nonlinear functions along with their signal separation performance indicate the superlative power of the exponential-power-based nonlinear function. The proposed nonlinear function has been found to speed-up convergence with slight improvement in the separation quality under reverberant conditions.|Rajkishore Prasad,Hiroshi Saruwatari,Kiyohiro Shikano","57390|GECCO|2005|The blob code is competitive with edge-sets in genetic algorithms for the minimum routing cost spanning tree problem|Among the many codings of spanning trees for evolutionary search are those based on bijections between Prfer strings---strings of n- vertex labels---and spanning trees on the labeled vertices. One of these bijections, called the Blob Code, showed promise as an evolutionary coding, but EAs that use it to represent spanning trees have not performed well. Here, a genetic algorithm that represents spanning trees via the Blob Code is faster than, and returns results competitive with those of, a GA that encodes spanning trees as edge-sets on Euclidean instances of the minimum routing cost spanning tree problem. On instances whose edge weights have been chosen at random, the Blob-coded GA maintains its time advantage, but its results are inferior to those of the edge-set-coded GA, and both GAs are hard pressed to keep up with a simple stochastic hill-climber on all the test instances.|Bryant A. Julstrom"],["80587|VLDB|2005|Temporal Management of RFID Data|RFID technology can be used to significantly improve the efficiency of business processes by providing the capability of automatic identification and data capture. This technology poses many new challenges on current data management systems. RFID data are time-dependent, dynamically changing, in large volumes, and carry implicit semantics. RFID data management systems need to effectively support such large scale temporal data created by RFID applications. These systems need to have an explicit temporal data model for RFID data to support tracking and monitoring queries. In addition, they need to have an automatic method to transform the primitive observations from RFID readers into derived data used in RFID-enabled applications. In this paper, we present an integrated RFID data management system -- Siemens RFID Middleware -- based on an expressive temporal data model for RFID data. Our system enables semantic RFID data filtering and automatic data transformation based on declarative rules, provides powerful query support of RFID object tracking and monitoring, and can be adapted to different RFID-enabled applications.|Fusheng Wang,Peiya Liu","80579|VLDB|2005|Robust Real-time Query Processing with QStream|Processing data streams with Quality-of-Service (QoS) guarantees is an emerging area in existing streaming applications. Although it is possible to negotiate the result quality and to reserve the required processing resources in advance, it remains a challenge to adapt the DSMS to data stream characteristics which are not known in advance or are difficult to obtain. Within this paper we present the second generation of our QStream DSMS which addresses the above challenge by using a real-time capable operating system environment for resource reservation and by applying an adaptation mechanism if the data stream characteristics change spontaneously.|Sven Schmidt,Thomas Legler,Sebastian Sch√§r,Wolfgang Lehner","42659|IEICE Transations|2005|Autonomous Configuration in Wireless Sensor Networks|Because of the large scale of wireless sensor networks, the configuration needs to be done autonomously. In this paper, we present Scalable Data Collection (SDC) protocol, a tree-based protocol for collecting data over multi-hop, wireless sensor networks. The design of the protocol aims to satisfy the requirements of sensor networks that every sensor transmits sensed data to a sink node periodically or spontaneously. The sink nodes construct the tree by broadcasting a solicit packet to discover the child nodes. The sensor receiving this packet decides on an appropriate parent to which it will attach, it then broadcasts the same packet to discover its child nodes. Through this process, the tree is created autonomously without any flooding of the routing packets. SDC avoids periodic updating of routing information but the tree need to be reconstructed upon node failures or adding of new nodes. The states required on each sensor are constant and independent of network size, therefore SDC scales better than the existing protocols. Moreover, each sensor can make forwarding decisions regardless of the knowledge on geographical information. We evaluated the performance of SDC by using the ns- simulator and comparing with Directed Diffusion, DSR, AODV, and OLSR. The simulation results demonstrate that SDC achieves much higher delivery ratio, shorter delay, as well as high scalability in various scenarios.|Yoshito Tobe,Niwat Thepvilojanapong,Kaoru Sezaki","80469|VLDB|2005|REED Robust Efficient Filtering and Event Detection in Sensor Networks|This paper presents a set of algorithms for efficiently evaluating join queries over static data tables in sensor networks. We describe and evaluate three algorithms that take advantage of distributed join techniques. Our algorithms are capable of running in limited amounts of RAM, can distribute the storage burden over groups of nodes, and are tolerant to dropped packets and node failures. REED is thus suitable for a wide range of event-detection applications that traditional sensor network database and data collection systems cannot be used to implement.|Daniel J. Abadi,Samuel Madden,Wolfgang Lindner","80497|VLDB|2005|An Efficient SQL-based RDF Querying Scheme|Devising a scheme for efficient and scalable querying of Resource Description Framework (RDF) data has been an active area of current research. However, most approaches define new languages for querying RDF data, which has the following shortcomings ) They are difficult to integrate with SQL queries used in database applications, and ) They incur inefficiency as data has to be transformed from SQL to the corresponding language data format. This paper proposes a SQL based scheme that avoids these problems. Specifically, it introduces a SQL table function RDFMATCH to query RDF data. The results of RDFMATCH table function can be further processed by SQL's rich querying capabilities and seamlessly combined with queries on traditional relational data. Furthermore, the RDFMATCH table function invocation is rewritten as a SQL query, thereby avoiding run-time table function procedural overheads. It also enables optimization of rewritten query in conjunction with the rest of the query. The resulting query is executed efficiently by making use of B-tree indexes as well as specialized subject-property materialized views. This paper describes the functionality of the RDFMATCH table function for querying RDF data, which can optionally include user-defined rulebases, and discusses its implementation in Oracle RDBMS. It also presents an experimental study characterizing the overhead eliminated by avoiding procedural code at runtime, characterizing performance under various input conditions, and demonstrating scalability using  million RDF triples from UniProt protein and annotation data.|Eugene Inseok Chong,Souripriya Das,George Eadon,Jagannathan Srinivasan","16220|IJCAI|2005|Training without data Knowledge Insertion into RBF Neural Networks|A major problem when developing neural networks or machine diagnostics situations is that no data or very little data is available for training on fault conditions. However, the domain expert often has a good idea of what to expect in terms of input and output parameter values. If the expert can express these relationships in the form of rules, this would provide a resource too valuable to ignore. Fuzzy logic is used to handle the imprecision and vagueness of natural language and provides this additional advantage to a system. This paper investigates the development of a novel knowledge insertion algorithm that explores the benefits of prestructuring RBF neural networks by using prior fuzzy domain knowledge and previous training experiences. Pre-structuring is accomplished by using fuzzy rules gained from a domain expert and using them to modify existing Radial Basis Function (RBF) networks. The benefits and novel achievements of this work enable RBF neural networks to be trained without actual data but to rely on input to output mappings defined through expert knowledge.|Kenneth McGarry,Stefan Wermter","80559|VLDB|2005|Using Association Rules for Fraud Detection in Web Advertising Networks|Discovering associations between elements occurring in a stream is applicable in numerous applications, including predictive caching and fraud detection. These applications require a new model of association between pairs of elements in streams. We develop an algorithm, Streaming-Rules, to report association rules with tight guarantees on errors, using limited processing per element, and minimal space. The modular design of Streaming-Rules allows for integration with current stream management systems, since it employs existing techniques for finding frequent elements. The presentation emphasizes the applicability of the algorithm to fraud detection in advertising networks. Such fraud instances have not been successfully detected by current techniques. Our experiments on synthetic data demonstrate scalability and efficiency. On real data, potential fraud was discovered.|Ahmed Metwally,Divyakant Agrawal,Amr El Abbadi","80504|VLDB|2005|Summarizing and Mining Inverse Distributions on Data Streams via Dynamic Inverse Sampling|Emerging data stream management systems approach the challenge of massive data distributions which arrive at high speeds while there is only small storage by summarizing and mining the distributions using samples or sketches. However, data distributions can be \"viewed\" in different ways. A data stream of integer values can be viewed either as the forward distribution f (x), ie., the number of occurrences of x in the stream, or as its inverse, f- (i), which is the number of items that appear i times. While both such \"views\" are equivalent in stored data systems, over data streams that entail approximations, they may be significantly different. In other words, samples and sketches developed for the forward distribution may be ineffective for summarizing or mining the inverse distribution. Yet, many applications such as IP traffic monitoring naturally rely on mining inverse distributions.We formalize the problems of managing and mining inverse distributions and show provable differences between summarizing the forward distribution vs the inverse distribution. We present methods for summarizing and mining inverse distributions of data streams they rely on a novel technique to maintain a dynamic sample over the stream with provable guarantees which can be used for variety of summarization tasks (building quantiles or equidepth histograms) and mining (anomaly detection finding heavy hitters, and measuring the number of rare items), all with provable guarantees on quality of approximations and timespace used by our streaming methods.We also complement our analytical and algorithmic results by presenting an experimental study of the methods over network data streams.|Graham Cormode,S. Muthukrishnan,Irina Rozenbaum","80524|VLDB|2005|Caching with Good Enough Currency Consistency and Completeness|SQL extensions that allow queries to explicitly specify data quality requirements in terms of currency and consistency were proposed in an earlier paper. This paper develops a data quality-aware, finer grained cache model and studies cache design in terms of four fundamental properties presence, consistency, completeness and currency. The model provides an abstract view of the cache to the query processing layer, and opens the door for adaptive cache management. We describe an implementation approach that builds on the MTCache framework for partially materialized views. The optimizer checks most consistency constraints and generates a dynamic plan that includes currency checks and inexpensive checks for dynamic consistency constraints that cannot be validated during optimization. Our solution not only supports transparent caching but also provides fine grained data currency and consistency guarantees.|Hongfei Guo,Per-√\u2026ke Larson,Raghu Ramakrishnan","80523|VLDB|2005|Offline and Data Stream Algorithms for Efficient Computation of Synopsis Structures|Synopsis and small space representations are important data analysis tools and have long been used OLAPDSS systems, approximate query answering, query optimization and data mining. These techniques represent the input in terms broader characteristics and improve efficiency of various applications, e.g., learning, classification, event detection, among many others. In a recent past, the synopsis techniques have gained more currency due to the emerging areas like data stream management.In this tutorial, we propose to revisit algorithms for Wavelet and Histogram synopsis construction. In the recent years, a significant number of papers have appeared which has advanced the state-of-the-art in synopsis construction considerably. In particular, we have seen the development of a large number of efficient algorithms which are also guaranteed to be near optimal. Furthermore, these synopsis construction problems have found deep roots in theory and database systems, and have influenced a wide range of problems. In a different level, a large number of the synopsis construction algorithms use a similar set of techniques. It is extremely valuable to discuss and analyze these techniques, and we expect broader pictures and paradigms to emerge. This would allow us to develop algorithms for newer problems with greater ease. Understanding these recurrent themes and intuition behind the development of these algorithms is one of the main thrusts of the tutorial.Our goal will be to cover a wide spectrum of these topics and make the researchers in VLDB community aware of the new algorithms, optimum or approximate, offline or streaming. The tutorial will be self contained and develop most of the mathematical and database backgrounds needed.|Sudipto Guha,Kyuseok Shim"],["42444|IEICE Transations|2005|Explicitly-Adaptive Time Delay Estimation for Wide-Band Signals|A new method of explicitly adaptive time delay estimation (EATDE) algorithm is proposed for estimating a varying time delay parameter. The proposed method is based on the Haar wavelet transform of cross-correlations. The proposed algorithm can be viewed as a gradient-based optimization of lowpass filtered cross-correlations, but requires less computational power. The algorithm shows a global convergence property for wide-band signals with uncorrelated noises. A convergence analysis including mean behavior, mean-square-error behavior, and steady-state error of delay estimate is given. Simulation results are also provided to demonstrate the performance of the proposed algorithm.|Doh-Hyoung Kim,Youngjin Park","42403|IEICE Transations|2005|Noise-Robust Speech Analysis Using Running Spectrum Filtering|This paper proposes a new robust adaptive processing algorithm that is based on the extended least squares (ELS) method with running spectrum filtering (RSF). By utilizing the different characteristics of running spectra between speech signals and noise signals, RSF can retain speech characteristics while noise is effectively reduced. Then, by using ELS, autoregressive moving average (ARMA) parameters can be estimated accurately. In experiments on real speech contaminated by white Gaussian noise and factory noise, we found that the method we propose offered spectrum estimates that were robust against additive noise.|Qi Zhu,Noriyuki Ohtsuki,Yoshikazu Miyanaga,Norinobu Yoshida","42565|IEICE Transations|2005|An Adaptive Noise Canceller with Low Signal-Distortion Based on Variable Stepsize Subfilters for Human-Robot Communication|This paper proposes an adaptive noise canceller (ANC) with low signal-distortion for human-robot communication. The proposed ANC has two sets of adaptive filters for noise and crosstalk namely, main filters (MFs) and subfilters (SFs) connected in parallel thereto. To reduce signal-distortion in the output, the stepsizes for coefficient adaptation in the MFs are controlled according to estimated signal-to-noise ratios (SNRs) of the input signals. This SNR estimation is carried out using SF output signals. The stepsizes in the SFs are determined based on the ratio of the primary and the reference input signals to cope with a wider range of SNRs. This ratio is used as a rough estimate of the input signal SNR at the primary input. Computer simulation results using TV sound and human voice recorded in a carpeted room show that the proposed ANC reduces both residual noise and signal-distortion by as much as  dB compared to the conventional ANC. Evaluation in speech recognition with this ANC reveals that with a realistic TV sound level, as good recognition rate as in the noise-free condition is achieved.|Miki Sato,Akihiko Sugiyama,Shinichi Ohnaka","42873|IEICE Transations|2005|Tree-Structured Clustering Methods for Piecewise Linear-Transformation-Based Noise Adaptation|This paper proposes the application of tree-structured clustering to the processing of noisy speech collected under various SNR conditions in the framework of piecewise-linear transformation (PLT)-based HMM adaptation for noisy speech. Three kinds of clustering methods are described a one-step clustering method that integrates noise and SNR conditions and two two-step clustering methods that construct trees for each SNR condition. According to the clustering results, a noisy speech HMM is made for each node of the tree structure. Based on the likelihood maximization criterion, the HMM that best matches the input speech is selected by tracing the tree from top to bottom, and the selected HMM is further adapted by linear transformation. The proposed methods are evaluated by applying them to a Japanese dialogue recognition system. The results confirm that the proposed methods are effective in recognizing digitally noise-added speech and actual noisy speech issued by a wide range of speakers under various noise conditions. The results also indicate that the one-step clustering method gives better performance than the two-step clustering methods.|Zhipeng Zhang,Toshiaki Sugimura,Sadaoki Furui","42347|IEICE Transations|2005|Multiple Regression of Log Spectra for In-Car Speech Recognition Using Multiple Distributed Microphones|This paper describes a new multi-channel method of noisy speech recognition, which estimates the log spectrum of speech at a closetalking microphone based on the multiple regression of the log spectra (MRLS) of noisy signals captured by distributed microphones. The advantages of the proposed method are as follows ) The method does not require a sensitive geometric layout, calibration of the sensors nor additional pre-processing for tracking the speech source ) System works in very small computation amounts and ) Regression weights can be statistically optimized over the given training data. Once the optimal regression weights are obtained by regression learning, they can be utilized to generate the estimated log spectrum in the recognition phase, where the speech of close-talking is no longer required. The performance of the proposed method is illustrated by speech recognition of real in-car dialogue data. In comparison to the nearest distant microphone and multi-microphone adaptive beamformer, the proposed approach obtains relative word error rate (WER) reductions of .% and .%, respectively.|Weifeng Li,Tetsuya Shinde,Hiroshi Fujimura,Chiyomi Miyajima,Takanori Nishino,Katunobu Itou,Kazuya Takeda,Fumitada Itakura","42328|IEICE Transations|2005|Speech Recognition Using Finger Tapping Timings|Behavioral synchronization between speech and finger tapping provides a novel approach to improving speech recognition accuracy. We combine a sequence of finger tapping timings recorded alongside an utterance using two distinct methods in the first method, HMM state transition probabilities at the word boundaries are controlled by the timing of the finger tapping in the second, the probability (relative frequency) of the finger tapping is used as a 'feature' and combined with MFCC in a HMM recognition system. We evaluate these methods through connected digit recognition under different noise conditions (AURORA-J). Leveraging the synchrony between speech and finger tapping provides a % relative improvement in connected digit recognition experiments.|Hiromitsu Ban,Chiyomi Miyajima,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","42946|IEICE Transations|2005|Speech Quality Enhancement Using Wavelet Reconstruction Filters|The present paper describes a quality enhancement of band-limited speech signals. In regular telephone communication, the quality of the received speech signal is degraded by band limitation. We propose an effective but simple scheme for obtaining narrowband speech signals in which the frequency components are estimated from band limited signals. The proposed method utilizes aliasing components generated by wavelet reconstruction filters in the inverse discrete wavelet transform. The results of enhancement have been verified by applying this method to speech samples via telephone lines to obtain a noticeable improvement in speech quality.|Seiji Hayashi,Masahiro Suguimoto","42329|IEICE Transations|2005|Developments in Corpus-Based Speech Synthesis Approaching Natural Conversational Speech|This paper describes the special demands of conversational speech in the context of corpus-based speech synthesis. The author proposed the CHATR system of prosody-based unit-selection for concatenative waveform synthesis seven years ago, and now extends this work to incorporate the results of an analysis of five-years of recordings of spontaneous conversational speeech in a wide range of actual daily-life situations. The paper proposes that the expresion of affect (often translated as 'kansei' in Japanese) is the main factor differentiating laboratory speech from realworld conversational speech, and presents a framework for the specification of affect through differences in speaking style and voice quality. Having an enormous corpus of speech samples available for concatenation allows the selection of complete phrase-sized utterance segments, and changes the focus of unit selection from segmental or phonetic continuity to one of prosodic and discoursal appropriateness instead. Samples of the resulting large-corpus-based synthesis can be heard at httpfeast.his.atr.jpAESOP.|Nick Campbell","42785|IEICE Transations|2005|A Lower-Power Register File Based on Complementary Pass-Transistor Adiabatic Logic|This paper presents a novel low-power register file based on adiabatic logic. The register file consists of a storage-cell array, address decoders, readwrite control circuits, sense amplifiers, and readwrite drivers. The storage-cell array is based on the conventional memory cell. All the circuits except the storage-cell array employ CPAL (complementary pass-transistor adiabatic logic) to recover the charge of large node capacitance on address decoders, bit-lines and word-lines in fully adiabatic manner. The minimization of energy consumption was investigated by choosing the optimal size of CPAL circuits for large load capacitance. The power consumption of the proposed adiabatic register file is significantly reduced because the energy transferred to the large capacitance buses is mostly recovered. The energy and functional simulations are performed using the net-list extracted from the layout. HSPICE simulation results indicate that the proposed register file attains energy savings of % to % as compared to the conventional CMOS implementation for clock rates ranging from  to  MHz.|Jianping Hu,Tiefeng Xu,Hong Li","42997|IEICE Transations|2005|Multiband Vector Quantization Based on Inner Product for Wideband Speech Coding|This paper describes a multiband vector quantization (VQ) technique based on inner product for wideband speech coding at  kbs. Our approach consists of splitting the input speech into two separate bands and then applying an independent coding scheme for each band. A code excited linear prediction (CELP) coder is used in the lower band while a transform based coding strategy is applied in the higher band. The spectral components in the higher frequency band are represented by a set of modulated lapped transform (MLT) coefficients. The higher frequency band is divided into three subbands, and the MLT coefficients construct a vector for each subband. Specifically, for the VQ of these vectors, an inner product-based distance measure is proposed as a new strategy. The proposed  kbs coder with the inner-product based distortion measure achieves better performance than the  kbs ITU-T G. in subjective quality tests.|Joon-Hyuk Chang,Sanjit K. Mitra"],["57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57305|GECCO|2005|Extracted global structure makes local building block processing effective in XCS|Michigan-style learning classifier systems (LCSs), such as the accuracy-based XCS system, evolve distributed problem solutions represented by a population of rules. Recently, it was shown that decomposable problems may require effective processing of subsets of problem attributes, which cannot be generally assured with standard crossover operators. A number of competent crossover operators capable of effective identification and processing of arbitrary subsets of variables or string positions were proposed for genetic and evolutionary algorithms. This paper effectively introduces two competent crossover operators to XCS by incorporating techniques from competent genetic algorithms (GAs) the extended compact GA (ECGA) and the Bayesian optimization algorithm (BOA). Instead of applying standard crossover operators, here a probabilistic model of the global population is built and sampled to generate offspring classifiers locally. Various offspring generation methods are introduced and evaluated. Results indicate that the performance of the proposed learning classifier systems XCSECGA and XCSBOA is similar to that of XCS with informed crossover operators that is given all information about problem structure on input and exploits this knowledge using problem-specific crossover operators.|Martin V. Butz,Martin Pelikan,Xavier Llor√†,David E. Goldberg","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","42386|IEICE Transations|2005|An Effective Search Method for Neural Network Based Face Detection Using Particle Swarm Optimization|This paper presents a novel method to speed up neural network (NN) based face detection systems. NN-based face detection can be viewed as a classification and search problem. The proposed method formulates the face search problem as an integer nonlinear optimization problem (INLP) and expands the basic particle swarm optimization (PSO) to handle it. PSO works with a population of particles, each representing a subwindow in an input image. The subwindows are evaluated by how well they match a NN based face filter. A face is indicated when the filter response of the best particle is above a given threshold. Experiments on a set of  test images show the e.ectiveness of the proposed approach. Moreover, the effect of PSO parameter settings on the search performance was investigated.|Masanori Sugisaka,Xinjian Fan","57353|GECCO|2005|Preventing overfitting in GP with canary functions|Overfitting is a fundamental problem of most machine learning techniques, including genetic programming (GP). Canary functions have been introduced in the literature as a concept for preventing overfitting by automatically recognizing when it starts to occur. This paper presents a simple scheme for implementing canary functions using cross-validation. The effectiveness of this technique is demonstrated by applying it to the numeric regression problem. A list of conditions and criteria for applying this technique to other problem domains is also identified. Other strategies for dealing with overfitting in GP are discussed.|Nate Foreman,Matthew P. Evett","57553|GECCO|2005|Hyper-heuristics and classifier systems for solving D-regular cutting stock problems|This paper presents a method for combining concepts of Hyper-heuristics and Learning Classifier Systems for solving D Cutting Stock Problems. The idea behind Hyper-heuristics is to discover some combination of straightforward heuristics to solve a wide range of problems. To be worthwhile, such combination should outperform the single heuristics. In this paper, the Hyper-heuristic is formed using a XCS-type Learning Classifier System which learns a solution procedure when solving individual problems. The XCS evolves a behavior model which determines the possible actions (selection and placement heuristics) for given states of the problem. When tested with a collection of different problems, the method finds very competitive results for most of the cases. The testebed is composed of problems used in other similar studies in the literature. Some additional instances of the testbed were randomly generated.|Hugo Terashima-Mar√≠n,E. J. Flores-√?lvarez,Peter Ross","57333|GECCO|2005|Transition models as an incremental approach for problem solving in evolutionary algorithms|This paper proposes an incremental approach for building solutions using evolutionary computation. It presents a simple evolutionary model called a Transition model in which partial solutions are constructed that interact to provide larger solutions. An evolutionary process is used to merge these partial solutions into a full solution for the problem at hand. The paper provides a preliminary study on the evolutionary dynamics of this model as well as an empirical comparison with other evolutionary techniques on binary constraint satisfaction.|Anne Defaweux,Tom Lenaerts,Jano I. van Hemert,Johan Parent","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57435|GECCO|2005|The compact classifier system motivation analysis and first results|This paper presents an initial analysis of how maximally general and accurate rules can be evolved in a Pittsburgh-style classifier system. In order to be able to perform such analysis we introduce a simple bare-bones Pittsburgh classifier systems---the compact classifier system (CCS)---based on estimation of distribution algorithms. Using a common rule encoding scheme of Pittsburgh classifier systems, CCS maintains a dynamic set of probability vectors that compactly describe a rule set. The compact genetic algorithm is used to evolve each of the initially perturbed probability vectors which represents the rules. Results show how CCS is able to evolve in a compact, simple, and elegant manner rule sets composed by maximally general and accurate rules.|Xavier Llor√†,Kumara Sastry,David E. Goldberg"],["65511|AAAI|2005|Error Bounds for Approximate Value Iteration|Approximate Value Iteration (AVI) is an method for solving a Markov Decision Problem by making successive calls to a supervised learning (SL) algorithm. Sequence of value representations Vn are processed iteratively by Vn+  ATVn where T is the Bellman operator and A an approximation operator. Bounds on the error between the performance of the policies induced by the algorithm and the optimal policy are given as a function of weighted Lp-norms (p  ) of the approximation errors. The results extend usual analysis in L-norm, and allow to relate the performance of AVI to the approximation power (usually expressed in Lp-norm, for p   or ) of the SL algorithm. We illustrate the tightness of these bounds on an optimal replacement problem.|R√©mi Munos","16147|IJCAI|2005|Solving POMDPs with Continuous or Large Discrete Observation Spaces|We describe methods to solve partially observable Markov decision processes (POMDPs) with continuous or large discrete observation spaces. Realistic problems often have rich observation spaces, posing significant problems for standard POMDP algorithms that require explicit enumeration of the observations. This problem is usually approached by imposing an a priori discretisation on the observation space, which can be sub-optimal for the decision making task. However, since only those observations that would change the policy need to be distinguished, the decision problem itself induces a lossless partitioning of the observation space. This paper demonstrates how to find this partition while computing a policy, and how the resulting discretisation of the observation space reveals the relevant features of the application domain. The algorithms are demonstrated on a toy example and on a realistic assisted living task.|Jesse Hoey,Pascal Poupart","65485|AAAI|2005|Risk-Sensitive Planning with One-Switch Utility Functions Value Iteration|Decision-theoretic planning with nonlinear utility functions is important since decision makers are often risk-sensitive in high-stake planning situations. One-switch utility functions are an important class of nonlinear utility functions that can model decision makers whose decisions change with their wealth level. We study how to maximize the expected utility of a Markov decision problem for a given one-switch utility function, which is difficult since the resulting planning problem is not decomposable. We first study an approach that augments the states of the Markov decision problem with the wealth level. The properties of the resulting infinite Markov decision problem then allow us to generalize the standard risk-neutral version of value iteration from manipulating values to manipulating functions that map wealth levels to values. We use a probabilistic blocks-world example to demonstrate that the resulting risk-sensitive version of value iteration is practical.|Yaxin Liu,Sven Koenig","16190|IJCAI|2005|An MCMC Approach to Solving Hybrid Factored MDPs|Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.|Branislav Kveton,Milos Hauskrecht","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","42983|IEICE Transations|2005|A Possibilistic and Stochastic Programming Approach to Fuzzy Random MST Problems|This paper deals with minimum spanning tree problems where each edge weight is a fuzzy random variable. In order to consider the imprecise nature of the decision maker's judgment, a fuzzy goal for the objective function is introduced. A novel decision making model is constructed based on possibility theory and on a stochastic programming model. It is shown that the problem including both randomness and fuzziness is reduced to a deterministic equivalent problem. Finally, a polynomial-time algorithm is provided to solve the problem.|Hideki Katagiri,El Bekkaye Mermri,Masatoshi Sakawa,Kosuke Kato,Ichiro Nishizaki","16056|IJCAI|2005|A Decision-Theoretic Approach to Task Assistance for Persons with Dementia|Cognitive assistive technologies that aid people with dementia (such as Alzheimer's disease) hold the promise to provide such people with an increased level of independence. However, to realize this promise, such systems must account for the specific needs and preferences of individuals. We argue that this form of customization requires a sequential, decision-theoretic model of interaction. We describe both fully and partially observable Markov decision process (POMDP) models of a handwashing task, and show that, despite the potential computational complexity, these can be effectively solved and produce policies that are evaluated as useful by professional caregivers.|Jennifer Boger,Pascal Poupart,Jesse Hoey,Craig Boutilier,Geoff Fernie,Alex Mihailidis","65371|AAAI|2005|Lazy Approximation for Solving Continuous Finite-Horizon MDPs|Solving Markov decision processes (MDPs) with continuous state spaces is a challenge due to, among other problems. the well-known curse of dimensionality. Nevertheless, numerous real-world applications such as transportation planning and telescope observation scheduling exhibit a critical dependence on continuous states. Current approaches to continuous-state MDPs include discretizing their transition models. In this paper, we propose and study an alternative, discretization-free approach we call lazy approximation. Empirical study shows that lazy approximation performs much better than discretization, and we successfully applied this new technique to a more realistic planetary rover planning problem.|Lihong Li,Michael L. Littman","16066|IJCAI|2005|Robust Planning with LRTDP|Stochastic Shortest Path problems (SSPs), a subclass of Markov Decision Problems (MDPs), can be efficiently dealt with using Real-Time Dynamic Programming (RTDP). Yet, MDP models are often uncertain (obtained through statistics or guessing). The usual approach is robust planning searching for the best policy under the worst model. This paper shows how RTDP can be made robust in the common case where transition probabilities are known to lie in a given interval.|Olivier Buffet,Douglas Aberdeen","65617|AAAI|2005|Planning and Execution with Phase Transitions|We consider a special type of continuous-time Markov decision processes (MDPs) that arise when phase-type distributions are used to model the timing of non-Markovian events and actions. We focus, primarily, on the execution of phase-dependent policies. Phases are introduced into a model to represent relevant execution history, but there is no physical manifestation of phases in the real world. We treat phases as partially observable state features and show how a belief distribution over phase configurations can be derived from observable state features through the use of transient analysis for Markov chains. This results in an efficient method for phase tracking during execution that can be combined with the QMDP value method for POMDPs to make action choices. We also discuss, briefly, how the structure of MDPs with phase transitions can be exploited in structured value iteration with symbolic representation of vectors and matrices.|H√•kan L. S. Younes"],["42572|IEICE Transations|2005|A New Method for Solving the Permutation Problem of Frequency-Domain Blind Source Separation|Frequency domain blind source separation has the great advantage that the complicated convolution in time domain becomes multiple efficient multiplications in frequency domain. However, the inherent ambiguity of permutation of ICA becomes an important problem that the separated signals at different frequencies may be permuted in order. Mapping the separated signal at each frequency to a target source remains to be a difficult problem. In this paper, we first discuss the inter-frequency correlation based method , and propose a new method using the continuity in power between adjacent frequency components of same source. The proposed method also implicitly utilizes the information of inter-frequency correlation, as such has better performance than the previous method.|Xuebin Hu,Hidefumi Kobatake","42554|IEICE Transations|2005|Underdetermined Blind Separation of Convolutive Mixtures of Speech Using Time-Frequency Mask and Mixing Matrix Estimation|This paper focuses on the underdetermined blind source separation (BSS) of three speech signals mixed in a real environment from measurements provided by two sensors. To date, solutions to the underdetermined BSS problem have mainly been based on the assumption that the speech signals are sufficiently sparse. They involve designing binary masks that extract signals at time-frequency points where only one signal was assumed to exist. The major issue encountered in previous work relates to the occurrence of distortion, which affects a separated signal with loud musical noise. To overcome this problem, we propose combining sparseness with the use of an estimated mixing matrix. First, we use a geometrical approach to detect when only one source is active and to perform a preliminary separation with a time-frequency mask. This information is then used to estimate the mixing matrix, which allows us to improve our separation. Experimental results show that this combination of time-frequency mask and mixing matrix estimation provides separated signals of better quality (less distortion, less musical noise) than those extracted without using the estimated mixing matrix in reverberant conditions where the reverberant time (TR) was  ms and  ms. Furthermore, informal listening tests clearly show that musical noise is deeply lowered by the proposed method comparatively to the classical approaches.|Audrey Blin,Shoko Araki,Shoji Makino","42642|IEICE Transations|2005|Multistage SIMO-Model-Based Blind Source Separation Combining Frequency-Domain ICA and Time-Domain ICA|In this paper, single-input multiple-output (SIMO)-model-based blind source separation (BSS) is addressed, where unknown mixed source signals are detected at microphones, and can be separated, not into monaural source signals but into SIMO-model-based signals from independent sources as they are at the microphones. This technique is highly applicable to high-fidelity signal processing such as binaural signal processing. First, we provide an experimental comparison between two kinds of SIMO-model-based BSS methods, namely, conventional frequency-domain ICA with projection-back processing (FDICA-PB), and SIMO-ICA which was recently proposed by the authors. Secondly, we propose a new combination technique of the FDICA-PB and SIMO-ICA, which can achieve a higher separation performance than the two methods. The experimental results reveal that the accuracy of the separated SIMO signals in the simple SIMO-ICA is inferior to that of the signals obtained by FDICA-PB under low-quality initial value conditions, but the proposed combination technique can outperform both simple FDICA-PB and SIMO-ICA.|Satoshi Ukai,Tomoya Takatani,Hiroshi Saruwatari,Kiyohiro Shikano,Ryo Mukai,Hiroshi Sawada","42556|IEICE Transations|2005|Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain|This paper overviews a total solution for frequency-domain blind source separation (BSS) of convolutive mixtures of audio signals, especially speech. Frequency-domain BSS performs independent component analysis (ICA) in each frequency bin, and this is more efficient than time-domain BSS. We describe a sophisticated total solution for frequency-domain BSS, including permutation, scaling, circularity, and complex activation function solutions. Experimental results of   ,   ,   ,   , and    (moving sources), (sources  microphones) in a room are promising.|Shoji Makino,Hiroshi Sawada,Ryo Mukai,Shoko Araki","42452|IEICE Transations|2005|A Self-Generator Method for Initial Filters of SIMO-ICA Applied to Blind Separation of Binaural Sound Mixtures|In this paper, we address the blind separation problem of binaural mixed signals, and we propose a novel blind separation method, in which a self-generator for initial filters of Single-Input-Multiple-Output-model-based independent component analysis (SIMO-ICA) is implemented. The original SIMO-ICA which has been proposed by the authors can separate mixed signals, not into monaural source signals but into SIMO-model-based signals from independent sources as they are at the microphones. Although this attractive feature of SIMO-ICA is beneficial to the binaural sound separation, the current SIMO-ICA has a serious drawback in its high sensitivity to the initial settings of the separation filter. In the proposed method, the self-generator for the initial filter functions as the preprocessor of SIMO-ICA, and thus it can provide a valid initial filter for SIMO-ICA. The self-generator is still a blind process because it mainly consists of a frequency-domain ICA (FDICA) part and the direction of arrival estimation part which is driven by the separated outputs of the FDICA. To evaluate its effectiveness, binaural sound separation experiments are carried out under a reverberant condition. The experimental results reveal that the separation performance of the proposed method is superior to those of conventional methods.|Tomoya Takatani,Satoshi Ukai,Tsuyoki Nishikawa,Hiroshi Saruwatari,Kiyohiro Shikano","42438|IEICE Transations|2005|Separation of Sound Sources Propagated in the Same Direction|This paper describes a method for separating a target sound from other noise arriving in a single direction when the target cannot, therefore, be separated by directivity control. Microphones are arranged in a line toward the sources to form null sensitivity points at given distances from the microphones. The null points exclude non-target sound sources on the basis of weighting coefficients for microphone outputs determined by blind source separation. The separation problem is thereby simplified to instantaneous separation by adjustment of the time-delays for microphone outputs. The system uses a direct (i.e. non-iterative) algorithm for blind separation based on second-order statistics, assuming that all sources are non-stationary signals. Simulations show that the -microphone system can separate a target sound with separability of more than  dB for the -source problem, and  dB for the -source problem when the other sources are adjacent.|Akio Ando,Masakazu Iwaki,Kazuho Ono,Koichi Kurozumi","42618|IEICE Transations|2005|Subband-Based Blind Separation for Convolutive Mixtures of Speech|We propose utilizing subband-based blind source separation (BSS) for convolutive mixtures of speech. This is motivated by the drawback of frequency-domain BSS, i.e., when a long frame with a fixed long frame-shift is used to cover reverberation, the number of samples in each frequency decreases and the separation performance is degraded. In subband BSS, () by using a moderate number of subbands, a sufficient number of samples can be held in each subband, and () by using FIR filters in each subband, we can manage long reverberation. We confirm that subband BSS achieves better performance than frequency-domain BSS. Moreover, subband BSS allows us to select a separation method suited to each subband. Using this advantage, we propose efficient separation procedures that consider the frequency characteristics of room reverberation and speech signals () by using longer unmixing filters in low frequency bands and () by adopting an overlap-blockshift in BSS's batch adaptation in low frequency bands. Consequently, frequency-dependent subband processing is successfully realized with the proposed subband BSS.|Shoko Araki,Shoji Makino,Robert Aichner,Tsuyoki Nishikawa,Hiroshi Saruwatari","42498|IEICE Transations|2005|Blind Separation of Speech by Fixed-Point ICA with Source Adaptive Negentropy Approximation|This paper presents a study on the blind separation of a convoluted mixture of speech signals using Frequency Domain Independent Component Analysis (FDICA) algorithm based on the negentropy maximization of Time Frequency Series of Speech (TFSS). The comparative studies on the negentropy approximation of TFSS using generalized Higher Order Statistics (HOS) of different nonquadratic, nonlinear functions are presented. A new nonlinear function based on the statistical modeling of TFSS by exponential power functions has also been proposed. The estimation of standard error and bias, obtained using the sequential delete-one jackknifing method, in the approximation of negentropy of TFSS by different nonlinear functions along with their signal separation performance indicate the superlative power of the exponential-power-based nonlinear function. The proposed nonlinear function has been found to speed-up convergence with slight improvement in the separation quality under reverberant conditions.|Rajkishore Prasad,Hiroshi Saruwatari,Kiyohiro Shikano","42716|IEICE Transations|2005|Blind Separation and Deconvolution for Convolutive Mixture of Speech Combining SIMO-Model-Based ICA and Multichannel Inverse Filtering|We propose a new two-stage blind separation and deconvolution strategy for multiple-input multiple-output (MIMO)-FIR systems driven by colored sound sources, in which single-input multiple-output (SIMO)-model-based ICA (SIMO-ICA) and blind multichannel inverse filtering are combined. SIMO-ICA can separate the mixed signals, not into monaural source signals but into SIMO-model-based signals from independent sources as they are at the microphones. After the separation by the SIMO-ICA, a blind deconvolution technique for the SIMO model can be applied even when each source signal is temporally correlated and the mixing system has a nonminimum phase property. The simulation results reveal that the proposed algorithm can successfully achieve separation and deconvolution of a convolutive mixture of speech, and outperforms a number of conventional ICA-based BSD methods.|Hiroshi Saruwatari,Hiroaki Yamajo,Tomoya Takatani,Tsuyoki Nishikawa,Kiyohiro Shikano","57523|GECCO|2005|Using a Markov network model in a univariate EDA an empirical cost-benefit analysis|This paper presents an empirical cost-benefit analysis of an algorithm called Distribution Estimation Using MRF with direct sampling (DEUMd). DEUMd belongs to the family of Estimation of Distribution Algorithm (EDA). Particularly it is a univariate EDA. DEUMd uses a computationally more expensive model to estimate the probability distribution than other univariate EDAs. We investigate the performance of DEUMd in a range of optimization problem. Our experiments shows a better performance (in terms of the number of fitness evaluation needed by the algorithm to find a solution and the quality of the solution) of DEUMd on most of the problems analysed in this paper in comparison to that of other univariate EDAs. We conclude that use of a Markov Network in a univariate EDA can be of net benefit in defined set of circumstances.|Siddhartha Shakya,John A. W. McCall,Deryck F. Brown"],["65409|AAAI|2005|An Extended Protocol for Multiple-Issue Concurrent Negotiation|Negotiation is the technique for reaching mutually beneficial agreement among agent via communication. A concurrent negotiation problem occurs when an agent needs to negotiate with multiple agents to reach agreement. In this paper, we present a protocol to support many-to-many bilateral multiple-issue negotiation in a competitive environment. The protocol is presented in the context of service-oriented negotiation, where one or more self-interested parties can provide services to one or more other parties. By extending existing negotiation protocols, our described protocol enables both service requestors and service providers to manage several negotiation processes in parallel. Moreover, this protocol mitigates the situation where most one-to-many negotiations are biased in favor of one participating agent, and allow the negotiation participants to make durable commitments to reduce the decommitment situation. We conclude by discussing additional issues related to concurrent multiple-issue negotiation.|Jiangbo Dang,Michael N. Huhns","16069|IJCAI|2005|Fast convergence to satisfying distributions|We investigate an environment where self-interested agents have to find high-quality service resources. Agents have common knowledge about resources which are able to provide these services. The performance of resources is measured by the satisfaction obtained by agents using them. The performance of a resource depends on its intrinsic capability and its current load. We use a satisfying rather than an optimizing framework, where agents are content to receive service quality above a threshold. We introduce a formal framework to characterize the convergence of agents to a state where each agent is satisfied with the performance of the service it is currently using. We analyzed the convergence behavior of such a system and identified a mechanism to speed up convergence.|Teddy Candale,Sandip Sen","42777|IEICE Transations|2005|Corporate Knowledge in Cyberworlds|The aim of this paper is to propose a modeling of corporate knowledge in cyberworlds. An enterprise is considered in the framework of multiagent methodology as a distributed computational system. The Agent-Oriented Abstraction paradigm was proposed earlier to describe in a fully generic way agents and societies of agents. In this paper, we are investigating the application of this paradigm to the abstract modeling of corporate knowledge, extending the scope of traditional knowledge management approaches. We show that such an abstraction mechanism leads to very practical applications for cyberworlds whether on the web or on any other medium. Our approach covers the broader possible scope of corporate knowledge, emphasizing the distributivity and autonomy of agents within cyber systems. This approach can be further used to better simulate and support knowledge management processes.|Pierre Maret,Jacques Calmet","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16061|IJCAI|2005|Efficiency and envy-freeness in fair division of indivisible goods logical representation and complexity|We consider the problem of allocating fairly a set of indivisible goods among agents from the point of view of compact representation and computational complexity. We start by assuming that agents have dichotomous preferences expressed by propositional formulae. We express efficiency and envy-freeness in a logical setting, which reveals unexpected connections to nonmonotonic reasoning. Then we identify the complexity of determining whether there exists an efficient and envy-free allocation, for several notions of efficiency, when preferences are represented in a succinct way (as well as restrictions of this problem). We first study the problem under the assumption that preferences are dichotomous, and then in the general case.|Sylvain Bouveret,J√©r√¥me Lang","16076|IJCAI|2005|On Maximal Classes of Utility Functions for Efficient one-to-one Negotiation|We investigate the properties of an abstract negotiation framework where agents autonomously negotiate over allocations of discrete resources. In this framework, reaching an optimal allocation potentially requires very complex multilateral deals. Therefore, we are interested in identifying classes of utility functions such that any negotiation conducted by means of deals involving only a single resource at at time is bound to converge to an optimal allocation whenever all agents model their preferences using these functions. We show that the class of modular utility functions is not only sufficient but also maximal in this sense.|Yann Chevaleyre,Ulle Endriss,Nicolas Maudet","16039|IJCAI|2005|Achieving Allocatively-Efficient and Strongly Budget-Balanced Mechanisms in the Network Flow Domain for Bounded-Rational Agents|Vickrey-Clarke-Groves (VCG) mechanisms are a framework for finding a solution to a distributed optimization problem in systems of self-interested agents. VCG mechanisms have received wide attention in the AI community because they are efficient and strategy-proof a special case of the Groves family of mechanisms, VCG mechanisms are the only direct-revelation mechanisms that are allocatively efficient and strategy-proof. Unfortunately, they are only weakly budget-balanced. We consider self-interested agents in a network flow domain, and show that in this domain, it is possible to design a mechanism that is both allocatively-efficient and almost completely budget-balanced. This is done by choosing a mechanism that is not strategy-proof but rather strategy-resistant. Instead of using the VCG mechanism, we propose a mechanism in which finding a beneficial manipulation is an NP-complete problem, and the payments from the agents to the mechanism may be minimized as much as desired.|Yoram Bachrach,Jeffrey S. Rosenschein","57342|GECCO|2005|The emulation of social institutions as a method of coevolution|This paper offers a novel approach to coevolution based on the sociological theory of symbolic interactionism. It provides a multi-agent computational model along with experimental results that suggest improved fitness, robustness, and knowledge due to emergent symbol systems. The main contribution of the symbolic-interactionist approach to coevolution is the concept of the emergence of a system in the abstract, where an interface between agents evolves. The interface is an emergent symbol system that focuses selective pressure among agents in ways that have been beneficial to agents as a whole in the past, creating a coevolving system that takes advantage of epistasis rather than having to prevent it. Global fitness thereby emerges from local, selfish interaction. The assignment of roles in this system is endogenous.|Deborah Vakas Duong,John J. Grefenstette","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White"],["16334|IJCAI|2005|Automatic Semantic Role Labeling for Chinese Verbs|Recent years have seen a revived interest in semantic parsing by applying statistical and machine-learning methods to semantically annotated corpora such as the FrameNet and the Proposition Bank. So far much of the research has been focused on English due to the lack of semantically annotated resources in other languages. In this paper, we report first results on semantic role labeling using a pre-release version of the Chinese Proposition Bank. Since the Chinese Proposition Bank is superimposed on top of the Chinese Tree-bank, i.e., the semantic role labels are assigned to constituents in a treebank parse tree, we start by reporting results on experiments using the handcrafted parses in the treebank. This will give us a measure of the extent to which the semantic role labels can be bootstrapped from the syntactic annotation in the treebank. We will then report experiments using a fully automatic Chinese parser that integrates word segmentation, POS-tagging and parsing. This will gauge how successful semantic role labeling can be done for Chinese in realistic situations. We show that our results using hand-crafted parses are slightly higher than the results reported for the state-of-the-art semantic role labeling systems for English using the Penn English Proposition Bank data, even though the Chinese Proposition Bank is smaller in size. When an automatic parser is used, however, the accuracy of our system is much lower than the English state-of-the-art. This reveals an interesting cross-linguistic difference between the two languages, which we attempt to explain. We also describe a method to induce verb classes from the Proposition Bank \"frame files\" that can be used to improve semantic role labeling.|Nianwen Xue,Martha Stone Palmer","42943|IEICE Transations|2005|Extraction of Transformation Rules from UML Diagrams to SpecC|Embedded systems are used in broad fields. They are one of the indispensable and fundamental technologies in a highly informative society in recent years. As embedded systems are large-scale and complicated, it is prosperous to design and develop a system LSI (Large Scale Integration). The structure of the system LSI has been increasing complexity every year. The degree of improvement of its design productivity has not caught up with the degree of its complexity by conventional methods or techniques. Hence, an idea for the design of a system LSI which has the flow of describing specifications of a system in UML (Unified Modeling Language) and then designing the system in a system level language has already proposed. It is important to establish how to convert from UML to a system level language in specification description or design with the idea. This paper proposes, extracts and verifies transformation rules from UML to SpecC which is one of system level languages. SpecC code has been generated actually from elements in diagrams in UML based on the rules. As an example to verify the rules, \"headlights control system of a car\" is adopted. SpecC code has been generated actually from elements in diagrams in UML based on the rules. It has been confirmed that the example is executed correctly in simulations. By using the transformation rules proposed in this paper, specification and implementation of a system can be connected seamlessly. Hence, it can improve the design productivity of a system LSI and the productivity of embedded systems.|Tetsuro Katayama","42826|IEICE Transations|2005|InCom Support System for Informal Communication in D Virtual Worlds Generated from HTML Documents|The importance of informal communication on the Internet has been increasing in recent years. Several systems for informal communication have been developed. These systems, however, require a particular server andor specialized D contents. In this paper, we propose a system, named InCom, for informal communication in a D virtual environment. Browsers which are component of InCom generate D virtual worlds from existing common D HTML documents. Browsers communicate in a peer-to-peer manner. Using avatars makes gaze awareness smooth. Our results show that users shared interests by gaze awareness.|Yuusuke Nakano,Koji Tsukada,Saeko Takagi,Kei Iwasaki,Fujiichi Yoshimoto","42345|IEICE Transations|2005|Recent Progress in Corpus-Based Spontaneous Speech Recognition|This paper overviews recent progress in the development of corpus-based spontaneous speech recognition technology. Although speech is in almost any situation spontaneous, recognition of spontaneous speech is an area which has only recently emerged in the field of automatic speech recognition. Broadening the application of speech recognition depends crucially on raising recognition performance for spontaneous speech. For this purpose, it is necessary to build large spontaneous speech corpora for constructing acoustic and language models. This paper focuses on various achievements of a Japanese -year national project \"Spontaneous Speech Corpus and Processing Technology\" that has recently been completed. Because of various spontaneous-speech specific phenomena, such as filled pauses, repairs, hesitations, repetitions and disfluencies, recognition of spontaneous speech requires various new techniques. These new techniques include flexible acoustic modeling, sentence boundary detection, pronunciation modeling, acoustic as well as language model adaptation, and automatic summarization. Particularly automatic summarization including indexing, a process which extracts important and reliable parts of the automatic transcription, is expected to play an important role in building various speech archives, speech-based information retrieval systems, and human-computer dialogue systems.|Sadaoki Furui","80545|VLDB|2005|FiST Scalable XML Document Filtering by Sequencing Twig Patterns|In recent years, publish-subscribe (pub-sub) systems based on XML document filtering have received much attention. In a typical pub-sub system, subscribed users specify their interest in profiles expressed in the XPath language, and each new content is matched against the user profiles so that the content is delivered to only the interested subscribers. As the number of subscribed users and their profiles can grow very large, the scalability of the system is critical to the success of pub-sub services. In this paper, we propose a novel scalable filtering system called FiST (Filtering by Sequencing Twigs) that transforms twig patterns expressed in XPath and XML documents into sequences using Pr&uumlfer's method. As a consequence, instead of matching linear paths of twig patterns individually and merging the matches during post-processing, FiST performs holistic matching of twig patterns with incoming documents. FiST organizes the sequences into a dynamic hash based index for efficient filtering. We demonstrate that our holistic matching approach yields lower filtering cost and good scalability under various situations.|Joonho Kwon,Praveen Rao,Bongki Moon,Sukho Lee","80571|VLDB|2005|CMS-ToPSS Efficient Dissemination of RSS Documents|Recent years have seen a rise in the number of unconventional publishing tools on the Internet. Tools such as wikis, blogs, discussion forums, and web-based content management systems have experienced tremendous rise in popularity and use primarily because they provide something traditional tools do not easy of use for non computer-oriented users and they are based on the idea of \"collaboration.\" It is estimated, by pewinternet.org, that  million people in the US read blogs (which represents % of the estimated  million US Internet users) while  million people have said that they have created blogs.|Milenko Petrovic,Haifeng Liu,Hans-Arno Jacobsen","42831|IEICE Transations|2005|A Coalition Formation Framework Based on Transitive Dependence|Coalition formation in multi-agent systems (MAS) is becoming increasingly important as it increases the ability of agents to execute tasks and maximize their payoffs. Dependence relations are regarded as the foundation of coalition formation. This paper proposes a novel dependence theory namely transitive dependence theory for dynamic coalition formation in multi-agent systems. Transitive dependence is an extension of direct dependence that supports an agent's reasoning about other social members during coalition formation. Based on the proposed transitive dependence theory, a dynamic coalition formation framework has been worked out which includes information gathering, transitive dependence based reasoning for coalition partners search and coalition resolution. The nested coalitions and how to deal with incomplete knowledge while forming coalitions are also discussed in the paper.|Bo An,Chunyan Miao,Daijie Cheng","80481|VLDB|2005|Database Publication Practices|There has been a growing interest in improving the publication processes for database research papers. This panel reports on recent changes in those processes and presents an initial cut at historical data for the VLDB Journal and ACM Transactions on Database Systems.|Philip A. Bernstein,David J. DeWitt,Andreas Heuer,Zachary G. Ives,Christian S. Jensen,Holger Meyer,M. Tamer √\u2013zsu,Richard T. Snodgrass,Kyu-Young Whang,Jennifer Widom","80467|VLDB|2005|XML Full-Text Search Challenges and Opportunities|An ever growing number of XML repositories are being made available for search. A lot of activity has been deployed in the past few years to query such repositories. In particular, full-text querying of text-rich XML documents has generated a wealth of issues that are being addressed by both the database (DB) and information retrieval (IR) communities. The DB community has traditionally focused on developing query languages and efficient evaluation algorithms for highly structured data. In contrast, the IR community has focused on searching unstructured data, and has developed various techniques for ranking query results and evaluating their effectiveness. Fortunately, recent trends in DB and IR research demonstrate a growing interest in adopting IR techniques in DBs and vice versa , , , , , , , .|Sihem Amer-Yahia,Jayavel Shanmugasundaram","80523|VLDB|2005|Offline and Data Stream Algorithms for Efficient Computation of Synopsis Structures|Synopsis and small space representations are important data analysis tools and have long been used OLAPDSS systems, approximate query answering, query optimization and data mining. These techniques represent the input in terms broader characteristics and improve efficiency of various applications, e.g., learning, classification, event detection, among many others. In a recent past, the synopsis techniques have gained more currency due to the emerging areas like data stream management.In this tutorial, we propose to revisit algorithms for Wavelet and Histogram synopsis construction. In the recent years, a significant number of papers have appeared which has advanced the state-of-the-art in synopsis construction considerably. In particular, we have seen the development of a large number of efficient algorithms which are also guaranteed to be near optimal. Furthermore, these synopsis construction problems have found deep roots in theory and database systems, and have influenced a wide range of problems. In a different level, a large number of the synopsis construction algorithms use a similar set of techniques. It is extremely valuable to discuss and analyze these techniques, and we expect broader pictures and paradigms to emerge. This would allow us to develop algorithms for newer problems with greater ease. Understanding these recurrent themes and intuition behind the development of these algorithms is one of the main thrusts of the tutorial.Our goal will be to cover a wide spectrum of these topics and make the researchers in VLDB community aware of the new algorithms, optimum or approximate, offline or streaming. The tutorial will be self contained and develop most of the mathematical and database backgrounds needed.|Sudipto Guha,Kyuseok Shim"],["42420|IEICE Transations|2005|Globally Guaranteed Robustness Adaptive Fuzzy Control with Application on Highly Uncertain Robot Manipulators|This study proposes a novel adaptive fuzzy control methodology to remove disadvantages of traditional fuzzy approximation based control. Meanwhile, the highly uncertain robot manipulator is taken as an application with either guaranteed robust tracking performances or asymptotic stability in a global sense. First, the design concept, namely, feedforward fuzzy approximation based control, is introduced for a simple uncertain system. Here the desired commands are utilized as the inputs of the Takagi-Sugeno (T-S) fuzzy system to closely compensate the unknown feedforward term required during steady state. Different to traditional works, the assumption on bounded fuzzy approximation error is not needed, while this scheme allows easier implementation architecture. Next, the concept is extended to controlling manipulators and achieves global robust tracking performances. Note that a linear matrix inequality (LMI) technique is applied and provides an easier gain design. Finally, numerical simulations are carried out on a two-link robot to illustrate the expected performances.|Chian-Song Chiu","42739|IEICE Transations|2005|Convergence Properties of a CORDIC-Based Adaptive ARMA Lattice Filter|This paper presents a theoretical convergence analysis of a CORDIC-based adaptive ARMA lattice filter. In previous literatures, several investigation methods for adaptive lattice filters have been proposed however, they are available only for AR-type filters. Therefore, we have developed a distinct technique that can reveal the convergence properties of the CORDIC ARMA lattice filter. The derived technique provides a quantitative convergence analysis, which facilitates an efficient hardware design for the filter. Moreover, our analysis technique can be applied to popular multiplier-based filters by slight modifications. Hence, the presented convergence analysis is significant as a leading attempt to investigate ARMA lattice filters.|Shin'ichi Shiraishi,Miki Haseyama,Hideo Kitajima","42403|IEICE Transations|2005|Noise-Robust Speech Analysis Using Running Spectrum Filtering|This paper proposes a new robust adaptive processing algorithm that is based on the extended least squares (ELS) method with running spectrum filtering (RSF). By utilizing the different characteristics of running spectra between speech signals and noise signals, RSF can retain speech characteristics while noise is effectively reduced. Then, by using ELS, autoregressive moving average (ARMA) parameters can be estimated accurately. In experiments on real speech contaminated by white Gaussian noise and factory noise, we found that the method we propose offered spectrum estimates that were robust against additive noise.|Qi Zhu,Noriyuki Ohtsuki,Yoshikazu Miyanaga,Norinobu Yoshida","42459|IEICE Transations|2005|Near-Field Sound-Source Localization Based on a Signed Binary Code|This paper proposes near-field sound-source localization based on crosscorrelation of a signed binary code. The signed binary code eliminates multibit signal processing for simpler implementation. Explicit formulae with near-field assumption are derived for a two microphone scenario and extended to a three microphone case with front-rear discrimination. Adaptive threshold for enabling and disabling source localization is developed for robustness in noisy environment. The proposed sound-source localization algorithm is implemented on a fixed-point DSP. Evaluation results in a robot scenario demonstrate that near-field assumption and front-rear discrimination provides almost % improvement in DOA estimation. A correct detection rate of % is obtained by a robot in a home environment.|Miki Sato,Akihiko Sugiyama,Osamu Hoshuyama,Nobuyuki Yamashita,Yoshihiro Fujita","42992|IEICE Transations|2005|Test Data Compression Using a Hybrid Run-Length Code Method|This letter proposes a run-length code based test data compression technique capable of efficient compression. The proposed test compression method is based on a hybrid run-length encoding, which greatly reduces test data storage on the tester. The code words are carefully selected so as to increase the compression ratio for the test data. Also, a heuristic mapping algorithm and a scan latch reordering method for don't care values in the test cubes increase the compression ratio. Results indicate that the proposed code and heuristic mapping schemes are very efficient in reducing test data. Reduced test data results in less test storage and test time.|Yongmin Hur","42507|IEICE Transations|2005|Adaptive Mode Control for Low-Power Caches Based on Way-Prediction Accuracy|This paper proposes a novel cache architecture for low power consumption, called \"Adaptive Way-Predicting Cache (AWP cache).\" The AWP cache has multi-operation modes and dynamically adapts the operation mode based on the accuracy of way-prediction results. A confidence counter for way prediction is implemented to each cache set. In order to analyze the effectiveness of the AWP cache, we perform a SRAM design using . m CMOS technology and cycle-accurate processor simulations. As the results, for a benchmark program (.art), it is observed that a performance-aware AWP cache reduces the % of performance overhead caused by an original way-predicting cache to %. Furthermore, a energy-aware AWP cache achieves % of energy reduction, whereas that obtained from the original way-predicting scheme is only %, compared to an non-optimized conventional cache. For the consideration of energy-performance efficiency, we see that the energy-aware AWP cache produces better results the energy-delay product of conventional organization is reduced to only % in average which is % better than the original way-predicting scheme.|Hidekazu Tanaka,Koji Inoue","42522|IEICE Transations|2005|A Simple Bit Allocation Scheme Based on Adaptive Coding for MIMO-OFDM Systems with V-BLAST Detector|We present a simple bit allocation scheme based on adaptive coding for MIMO-OFDM (Multiple Input Multiple Output - Orthogonal Frequency Division Multiplexing) systems with V-BLAST (Vertical-Bell laboratories LAyered Space-Time) detector. The proposed scheme controls the code rate of the channel coding and assigns the same modulation and coding to the set of selected sub-channels, which greatly reduces the feedback burden while achieving good performance. Simulation results show that the proposed scheme with minimal feedback provides significant performance improvement over other systems.|Jongwon Kim,Sanhae Kim,Min-Cheol Hong,Yoan Shin","42428|IEICE Transations|2005|Asymmetric Radio Resource Assignment Scheme for Connection-less Services in CDMAShared-TDD Cellular Packet Communications|The shared time division multiplexing (shared-TDD) scheme has been proposed to accommodate asymmetric communications between uplink and downlink. The accommodation of connection-less services in Shared-TDD systems causes a difficulty of TDD boundary control. This paper proposes a TDD boundary control (resource assignment) scheme, which can optimize a position of the TDD boundary based on the ratio of uplink to downlink traffic in code division multiple access (CDMA)shared-TDD systems with connection-less services. The proposed scheme controls the TDD boundary based on the estimated uplink and downlink traffic. Computer simulations show that the proposed scheme effectively controls the radio resource, and thus improves total system throughput performance.|Yukinari Kobayashi,Kazuo Mori,Hideo Kobayashi","42963|IEICE Transations|2005|Reconfigurable Adaptive FEC System Based on Reed-Solomon Code with Interleaving|This paper proposes a reconfigurable adaptive FEC system based on Reed-Solomon (RS) code with interleaving. In adaptive FEC schemes, error correction capability t is changed dynamically according to the communication channel condition. For given error correction capability t, we can implement an optimal RS decoder composed of minimum hardware units for each t. If the hardware units of the RS decoder can be reduced for any given error correction capability t, we can embed as large deinterleaver as possible into the RS decoder for each t. Reconfiguring the RS decoder embedded with the expanded deinterleaver dynamically for each error correction capability t allows us to decode larger interleaved codes which are more robust error correction codes to burst errors. In a reliable transport protocol, experimental results show that our system achieves up to % lower packet error rate and .% higher data transmission throughput compared to the adaptive FEC scheme on a conventional fixed hardware system. In an unreliable transport protocol, our system achieves up to % better bit error performance with higher code rate compared to the adaptive FEC scheme on a conventional fixed hardware system.|Kazunori Shimizu,Nozomu Togawa,Takeshi Ikenaga,Satoshi Goto","42795|IEICE Transations|2005|On Design for I-Based Diagnosability of CMOS Circuits Using Multiple Power Supplies|This paper presents a novel approach to improving the IDDQ-based diagnosability of a CMOS circuit by dividing the circuit into independent partitions and using a separate power supply for each partition. This technique makes it possible to implement multiple IDDQ measurement points, resulting in improved IDDQ-based diagnosability. The paper formalizes the problem of partitioning a circuit for this purpose and proposes optimal and heuristic based solutions. The effectiveness of the proposed approach is demonstrated through experimental results.|Xiaoqing Wen,Seiji Kajihara,Hideo Tamamoto,Kewal K. Saluja,Kozo Kinoshita"],["43002|IEICE Transations|2005|Content-Based Motion Estimation with Extended Temporal-Spatial Analysis|In adaptive motion estimation, spatial-temporal correlation based motion type inference has been recognized as an effective way to guide the motion estimation strategy adjustment according to video contents. However, the complexity and the reliability of those methods remain two crucial problems. In this paper, a motion vector field model is introduced as the basis for a new spatial-temporal correlation based motion type inference method. For each block, Full Search with Adaptive Search Window (ASW) and Three Step Search (TSS), as two search strategy candidates, can be employed alternatively. Simulation results show that the proposed method can constantly reduce the dynamic computational cost to as low as % to % of that of Full Search (FS), while remaining a closer approximation to FS in terms of visual quality than other fast algorithms for various video sequences. Due to its efficiency and reliability, this method is expected to be a favorable contribution to the mobile video communication where low power real-time video coding is necessary.|Shen Li,Yong Jiang,Takeshi Ikenaga,Satoshi Goto","42935|IEICE Transations|2005|Postprocessing in Block-Based Video Coding Based on a Quantization Noise Model|We present a model of quantization noise in block-coded videos with some assumptions in wavelet domain and propose a postprocessing method to reduce the quantization noise based on the model. A frame of video sequences is considered as a set of one-dimensional (-D) horizontal and vertical signals. The quantization noise is considered as the sum of the blocking noise and the remainder noise. We model the blocking noise as an impulse or that along with a dispersed impulse at each block boundary in the wavelet domain. The validity of the blocking noise model is investigated. We also model the remainder noise as white Gaussian noise at non-edge pixels in the wavelet domain. Whether the model accommodates well to the remainder noise or not is also examined. The blocking noise is reduced by subtracting a profile, whose strength is adaptively estimated, at each block boundary from the coded signal. The remainder noise then is reduced by a soft-thresholding. We also propose a fast algorithm for the proposed method by approximating coefficients of shape profiles used in blocking noise reduction and inverse wavelet transform (WT) filters used in remainder noise reduction. The performance is evaluated for QCIF video sequences coded by H. TMN with quantization parameter (QP) in the range of -- and is compared to that of the MPEG- verification model (VM) post-filter. Experimental results show that the proposed method yields not only PSNR improvement of maximum .--dB over the VM post-filter but also subjective quality nearly free of the blocking artifact and edge blur.|Ick Hoon Jang,Ki Woong Moon,Nam Chul Kim,Tae Sik Kim","42765|IEICE Transations|2005|Logic Synthesis Technique for High Speed Differential Dynamic Logic with Asymmetric Slope Transition|This paper proposes a logic synthesis technique for asymmetric slope differential dynamic logic (ASDDL) circuits. The technique utilizes a commercially available logic synthesis tool that has been well established for static CMOS logic design, where an intermediate library is devised for logic synthesis likely as static CMOS, and then a resulting synthesized circuit is translated automatically into ASDDL implementation at the gate-level logic schematic level as well as at the physical-layout level. A design example of an ASDDL -bit multiplier synthesized in a .-m CMOS technology shows an operation delay time of . nsec, which is a % improvement over a static CMOS design with a static logic standard-cell library that is finely tuned for energy-delay products. Design with the -bit multiplier led to a design time for an ASDDL based dynamic digital circuit  times shorter than that using a fully handcrafted design, and comparable with a static CMOS design.|Masao Morimoto,Yoshinori Tanaka,Makoto Nagata,Kazuo Taki","42989|IEICE Transations|2005|Noise Metrics in Flip-Flop Designs|About --% of the total power in any VLSI circuit is consumed by the clocking system and % of this power consumption is spent by flip-flops. Wider datapaths, deeper pipelines, and increasing number of registers in modern processors have underscored the importance of the flip-flops. As a result, the flip-flops' performance metrics such as, power, delay, and power delay product will become a crucial factor in overall performance of processors. As technology is moving into deep submicron level, noise immunity and noise generated by any component in a digital device is also becoming a vital factor in circuit design. This paper studies various flip-flop designs for their noise immunity and noise generation metrics. It categorizes the flip-flops and reports extensive simulation results for best representative examples including the newly proposed one from the group (a patent is filed for this flip-flop). It compares power, delay, power delay product, number of transistors, number of clocked transistors, noise immunity, and noise generation for flip-flops that are reported as ones with the best performances in the literature.|Mohamed A. Elgamel,Md. Ibrahim Faisal,Magdy A. Bayoumi","42810|IEICE Transations|2005|Self-Adaptive AlgorithmicArchitectural Design for Real-Time Low-Power Video Systems|With reference to video motion estimation in the framework of the new H.AVC video coding standard, this paper presents algorithmic and architectural solutions for the implementation of context-aware coprocessors in real-time, low-power embedded systems. A low-complexity context-aware controller is added to a conventional Full Search (FS) motion estimation engine. While the FS coprocessor is working, the context-aware controller extracts from the intermediate processing results information related to the input signal statistics in order to automatically configure the coprocessor itself in terms of search area size and number of reference frames thus unnecessary computations and memory accesses can be avoided. The achieved complexity saving factor ranges from . to  depending on the input signal while keeping unaltered performance in terms of motion estimation accuracy. The increased efficiency is exploited both for (i) processing time reduction in case of software implementation on a programmable platform (ii) power consumption reduction in case of dedicated hardware implementation in CMOS technology.|Luca Fanucci,Sergio Saponara,Massimiliano Melani,Pierangelo Terreni","42489|IEICE Transations|2005|Filtering of Block Motion Vectors for Use in Motion-Based Video Indexing and Retrieval|Though block-based motion estimation techniques are primarily designed for video coding applications, they are increasingly being used in other video analysis applications due to their simplicity and ease of implementation. The major drawback associated with these techniques is that noises, in the form of false motion vectors, cannot be avoided while capturing block motion vectors. Similar noises may further be introduced when the technique of global motion compensation is applied to obtain true object motion from video sequences where both the camera and object motions are present. This paper presents a new technique for capturing large number of true object motion vectors by eliminating the false motion vector fields, for use in the application of object motion based video indexing and retrieval applications. Experimental results prove that our proposed technique significantly increases the percentage of retained true object motion vectors while eliminating all false motion vectors for variety of standard and non-standard video sequences.|Golam Sorwar,M. Manzur Murshed","42775|IEICE Transations|2005|Low-Hardware-Cost Motion Estimation with Large Search Range for VLSI Multimedia Processors|In this paper, we propose new low-hardware-cost motion estimation with a large search range for VLSI multimedia processors. It reduces the hardware amount required for pixel comparison by reducing both the spatial-resolution and bit-resolution of pixel values. Low-hardware-cost block-matching criterion is also employed. To avoid performance degradation from low resolution, we introduce an \"outlier\" pixel with large overload quantization error in the search window, and a search position is excluded from the motion estimation if its corresponding search window block contains one or more outliers. The proposed motion estimation is easy to implement in VLSI multimedia processors, and it significantly reduces the hardware amount when the search range is larger than   . In MPEG MPML video compression with    search range, it reduces the hardware cost to  that of the full search algorithm, while its degradation of peak signal-to-noise ratio is . dB.|Seongsoo Lee,Min-Cheol Hong,Jae-Kyung Wee","42516|IEICE Transations|2005|Equalizer-Aided Time Delay Tracking Based on -Normed Finite Differences|This paper addresses the estimation of time delay between two spatially separated noisy signals by system identification modeling with the input and output corrupted by additive white Gaussian noise. The proposed method is based on a modified adaptive Butler-Cantoni equalizer that decouples noise variance estimation from channel estimation. The bias in time delay estimates that is induced by input noise is reduced by an IIR whitening filter whose coefficients are found by the Burg algorithm. For step time-variant delays, a dual mode operation scheme is adopted in which we define a normal operating (tracking) mode and an interrupt operating (optimization) mode. In the tracking mode, only a few coefficients of the impulse response vector are monitored through L-normed finite forward differences tracking, while in the optimization mode, the time delay optimized. Simulation results confirm the superiority of the proposed approach at low signal-to-noise ratios.|Jonah Gamba,Tetsuya Shimamura","42375|IEICE Transations|2005|Improving the Performance of the Minimum Statistics Noise Estimator for Single Channel Speech Enhancement|This paper proposes an algorithm to improve the performance of the noise power spectrum estimation using the minimum statistics (MS). The minimum statistics noise estimator (MSNE) that is most efficient for speech enhancement often underestimates noise power when the signal characteristics changes abruptly. The proposed algorithm improves the accuracy of noise estimation by removing harmonic components of the speech signal. Simulation results verify that the performance of the proposed algorithm is better than that of the conventional algorithm in terms of the segmental SNR (SegSNR) and the spectral distance (SD).|Seung-Kyun Ryu,Hong-Goo Kang,Sung-Kyo Jung,Dae Hee Youn","42852|IEICE Transations|2005|Efficient Motion Estimation Using a Modified Early Termination Algorithm in H|In the H. video coding standard,  modes   ,   ,   ,   ,   ,   ,    are used to enhance the coding efficiency. The motion vector estimation with  modes may require huge computing time. Thus, several efficient ME schemes have been proposed to reduce the complexity of ME module in H.. In this paper, we propose a ME scheme using a modified early termination technique to speed up the motion vector estimation procedure while maintaining high image quality. We demonstrate the effectiveness of the proposed method by computer simulation. In the simulation results, the CPU time consumed by the proposed scheme is much less than that of the conventional scheme while the encoded video quality remains unchanged. This is due to the fact that the proposed scheme searches MVs from the smallest block mode to the largest block mode, and utilizes the correlation between neighbor MVs. Furthermore, the process of the proposed ME scheme can bypass to the next mode when the MVs of a mode are highly correlated with each other, while the conventional schemes can not skip to other modes.|Sung-Eun Kim,Jong-Ki Han"],["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","42386|IEICE Transations|2005|An Effective Search Method for Neural Network Based Face Detection Using Particle Swarm Optimization|This paper presents a novel method to speed up neural network (NN) based face detection systems. NN-based face detection can be viewed as a classification and search problem. The proposed method formulates the face search problem as an integer nonlinear optimization problem (INLP) and expands the basic particle swarm optimization (PSO) to handle it. PSO works with a population of particles, each representing a subwindow in an input image. The subwindows are evaluated by how well they match a NN based face filter. A face is indicated when the filter response of the best particle is above a given threshold. Experiments on a set of  test images show the e.ectiveness of the proposed approach. Moreover, the effect of PSO parameter settings on the search performance was investigated.|Masanori Sugisaka,Xinjian Fan","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule"],["57362|GECCO|2005|Feature influence for evolutionary learning|This paper presents an approach that deals with the feature selection problem, and includes two main aspects first, the selection is done during the evolutionary learning process, i.e., it is a dynamic approach and second, the selection is local, i.e., the algorithm selects the best features from the best space region to learn at a given time of the exploration process. While the traditional feature selection is based on the attribute relevance, our approach is based on a new concept, called feature influence, which is aware of the dynamics and locality of the concept. The feature influence provides a measure of the attribute relevance at a certain instant of the evolutionary learning process, since it depends on each generation. Experimental results have been obtained by comparing an EA--based supervised learning algorithm to its modified version to include the concept approached. The results show an excellent performance, as the new adapted algorithm achieves the same classification results while using less rules, less conditions in rules and much less generations. The experiments include the statistical significance of the improvement over a set of sixteen datasets from the UCI repository.|Ra√∫l Gir√°ldez,Jes√∫s S. Aguilar-Ruiz","57341|GECCO|2005|A low-level hybridization between memetic algorithm and VNS for the max-cut problem|The Max-Cut problem consists of finding a partition of the graph nodes into two subsets, such that the sum of the edge weights having endpoints in different subsets is maximized. This NP-hard problem for non planar graphs has different applications in areas such as VLSI and ASIC design. This paper proposes an evolutionary hybrid algorithm based on low-level hybridization between Memetic Algorithms and Variable Neighborhood Search. This algorithm is tested and compared with the results, found in the bibliography, obtained by other hybrid metaheuristics for the same problem. Achieved experimental results show the suitability of the approach, and that the proposed hybrid evolutionary algorithm finds near-optimal solutions. Moreover, on a set of standard test problems, new best known solutions were produced for several instances.|Abraham Duarte,√?ngel S√°nchez,Felipe Fern√°ndez,Ra√∫l Cabido","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","57547|GECCO|2005|Hybridizing evolutionary algorithms and clustering algorithms to find source-code clones|This paper presents a hybrid approach to detect source-code clones that combines evolutionary algorithms and clustering. A case-study is conducted on a small C++ code base. The preliminary investigation indicates that such an approach is effective in detecting groups of source-code clones.|Andrew Sutton,Huzefa H. Kagdi,Jonathan I. Maletic,L. Gwenn Volkert","42386|IEICE Transations|2005|An Effective Search Method for Neural Network Based Face Detection Using Particle Swarm Optimization|This paper presents a novel method to speed up neural network (NN) based face detection systems. NN-based face detection can be viewed as a classification and search problem. The proposed method formulates the face search problem as an integer nonlinear optimization problem (INLP) and expands the basic particle swarm optimization (PSO) to handle it. PSO works with a population of particles, each representing a subwindow in an input image. The subwindows are evaluated by how well they match a NN based face filter. A face is indicated when the filter response of the best particle is above a given threshold. Experiments on a set of  test images show the e.ectiveness of the proposed approach. Moreover, the effect of PSO parameter settings on the search performance was investigated.|Masanori Sugisaka,Xinjian Fan","57374|GECCO|2005|Hierarchical multi-sensor image registration using evolutionary computation|Image registration between multi-sensor imagery is a challenging problem due to the difficulties associated with finding a correspondence between pixels from images taken by the two sensors. However, the moving people in a static scene provide cues to address this problem. In this paper, we propose a hierarchical approach to automatically find the correspondence between the preliminary human silhouettes extracted from synchronous color and infrared (IR) image sequences for image registration using evolutionary computation. The proposed approach reduces the overall computational load without decreasing the final estimation accuracy. Experimental results show that the proposed approach achieves good results for image registration between color and IR imagery.|Ju Han,Bir Bhanu","57297|GECCO|2005|Solving geometric TSP with ants|This paper presents an ant-based approach for solving the Traveling Salesman Problem (TSP). Novel concepts of this algorithm that distinguish it from the other heuristics are the inclusion of a preprocessing stage and the use of a modified version of an ant-based approach with local optimization in multi stages. Experimental results show that this algorithm outperforms ACS  and is comparable to MMAS  for Euclidean TSP instances. Of the  instances of Euclidean TSP from TSPLIB  that were tested, this algorithm found the optimal solution for  instances. For the remaining instances, this algorithm returned solutions that were within .% of the optimum.|Thang Nguyen Bui,Mufit Colpan","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons","57431|GECCO|2005|Combining competent crossover and mutation operators a probabilistic model building approach|This paper presents an approach to combine competent crossover and mutation operators via probabilistic model building. Both operators are based on the probabilistic model building procedure of the extended compact genetic algorithm (eCGA). The model sampling procedure of eCGA, which mimics the behavior of an idealized recombination---where the building blocks (BBs) are exchanged without disruption---is used as the competent crossover operator. On the other hand, a recently proposed BB-wise mutation operator---which uses the BB partition information to perform local search in the BB space---is used as the competent mutation operator. The resulting algorithm, called hybrid extended compact genetic algorithm (heCGA), makes use of the problem decomposition information for () effective recombination of BBs and () effective local search in the BB neighborhood. The proposed approach is tested on different problems that combine the core of three well known problem difficulty dimensions deception, scaling, and noise. The results show that, in the absence of domain knowledge, the hybrid approach is more robust than either single-operator-based approach.|Cl√°udio F. Lima,Kumara Sastry,David E. Goldberg,Fernando G. Lobo","57333|GECCO|2005|Transition models as an incremental approach for problem solving in evolutionary algorithms|This paper proposes an incremental approach for building solutions using evolutionary computation. It presents a simple evolutionary model called a Transition model in which partial solutions are constructed that interact to provide larger solutions. An evolutionary process is used to merge these partial solutions into a full solution for the problem at hand. The paper provides a preliminary study on the evolutionary dynamics of this model as well as an empirical comparison with other evolutionary techniques on binary constraint satisfaction.|Anne Defaweux,Tom Lenaerts,Jano I. van Hemert,Johan Parent"]]},"title":{"entropy":6.344667217638372,"topics":["speech recognition, for speech, for recognition, and speech, blind separation, and for, distributed pomdps, and recognition, recognition using, for multiple, combining and, speech, speech using, motion estimation, based and, using multiple, blind mixtures, natural language, separation mixtures, speech based","genetic algorithm, algorithm for, for the, the and, the, algorithm the, genetic programming, the problem, for problem, evolutionary for, genetic for, and for, evolutionary algorithm, and algorithm, using algorithm, problem, using genetic, for optimization, and genetic, with genetic","for systems, method for, for with, with, design for, adaptive for, ultra wideband, for control, for noise, design and, and for, maximum likelihood, control systems, adaptive with, and systems, for, over channel, systems with, space-time block, performance for","learning for, neural networks, particle optimization, particle swarms, swarms optimization, and its, learning, its application, for using, framework for, vector machine, support machine, support vector, word disambiguation, bayesian networks, artificial immune, for networks, reinforcement learning, sense disambiguation, using genetic","for multiple, based and, distributed pomdps, speech based, based for, and for, multiple recognition, using multiple, speech corpus, motion estimation, in-car speech, for distributed, recognition using, based, robust and, using and, and speech, for motion, microphone for, microphone speech","for data, for image, analysis and, and data, image and, image based, analysis for, data stream, and extraction, and inverse, for stream, for pattern, discriminant analysis, pattern using, from image, efficient for, for document, efficient and, image using, data","and for, and programming, differential evolution, strategies for, the and, evolution for, for logic, logic programs, programs with, using gene, the evolution, and evolution, evolution strategies, and strategies, the programming, with logic, and, using evolution, programming for, using programming","genetic programming, genetic algorithm, for optimization, genetic for, solving problem, for scheduling, search for, algorithm for, with genetic, and genetic, local search, heuristic for, the genetic, optimization algorithm, for dynamic, for solving, approach for, structure and, for problem, efficient the","algorithm for, efficient for, phase transition, scheme for, estimation distribution, for networks, and for, fast for, for cmos, for real-time, real-time with, high-speed and, for the, hoc networks, for embedded, for hoc, for real, for tracking, for core, and cmos","for with, adaptive for, with, for coding, adaptive with, for power, with and, block for, space-time block, and fading, adaptive based, for filter, adaptive filter, fading channel, low power, algorithm with, and code, finite for, for low, for code","learning for, and its, its application, and application, learning, learning and, model for, for robot, artificial immune, for database, for detection, database systems, query for, for xml, for application, and for, markov model, learning with, using model, using detection","framework for, for networks, neural networks, approach for, for mobile, networks, networks using, generation for, hybrid for, feature selection, probabilistic model, for agents, for communication, for object, for control, agents and, mobile and, probabilistic for, and networks, using control"],"ranking":[["42355|IEICE Transations|2005|Improving Keyword Recognition of Spoken Queries by Combining Multiple Speech Recognizers Outputs for Speech-driven WEB Retrieval Task|This paper presents speech-driven Web retrieval models which accept spoken search topics (queries) in the NTCIR- Web retrieval task. The major focus of this paper is on improving speech recognition accuracy of spoken queries and then improving retrieval accuracy in speechdriven Web retrieval. We experimentally evaluated the techniques of combining outputs of multiple LVCSR models in recognition of spoken queries. As model combination techniques, we compared the SVM learning technique with conventional voting schemes such as ROVER. In addition, for investigating the effects on the retrieval performance in vocabulary size of the language model, we prepared two kinds of language models the one's vocabulary size was ,, the other's one was ,. Then, we evaluated the differences in the recognition rates of the spoken queries and the retrieval performance. We showed that the techniques of multiple LVCSR model combination could achieve improvement both in speech recognition and retrieval accuracies in speech-driven text retrieval. Comparing with the retrieval accuracies when an LM with a ,, vocabulary size is used in an LVCSR system, we found that the larger the vocabulary size is, the better the retrieval accuracy is.|Masahiko Matsushita,Hiromitsu Nishizaki,Takehito Utsuro,Seiichi Nakagawa","42830|IEICE Transations|2005|Robust Speech Recognition Using Discrete-Mixture HMMs|This paper introduces new methods of robust speech recognition using discrete-mixture HMMs (DMHMMs). The aim of this work is to develop robust speech recognition for adverse conditions that contain both stationary and non-stationary noise. In particular, we focus on the issue of impulsive noise, which is a major problem in practical speech recognition system. In this paper, two strategies were utilized to solve the problem. In the first strategy, adverse conditions are represented by an acoustic model. In this case, a large amount of training data and accurate acoustic models are required to present a variety of acoustic environments. This strategy is suitable for recognition in stationary or slow-varying noise conditions. The second is based on the idea that the corrupted frames are treated to reduce the adverse effect by compensation method. Since impulsive noise has a wide variety of features and its modeling is difficult, the second strategy is employed. In order to achieve those strategies, we propose two methods. Those methods are based on DMHMM framework which is one type of discrete HMM (DHMM). First, an estimation method of DMHMM parameters based on MAP is proposed aiming to improve trainability. The second is a method of compensating the observation probabilities of DMHMMs by threshold to reduce adverse effect of outlier values. Observation probabilities of impulsive noise tend to be much smaller than those of normal speech. The motivation in this approach is that flooring the observation probability reduces the adverse effect caused by impulsive noise. Experimental evaluations on Japanese LVCSR for read newspaper speech showed that the proposed method achieved the average error rate reduction of .% in impulsive noise conditions. Also the experimental results in adverse conditions that contain both stationary and impulsive noises showed that the proposed method achieved the average error rate reduction of .%.|Tetsuo Kosaka,Masaharu Katoh,Masaki Kohda","42554|IEICE Transations|2005|Underdetermined Blind Separation of Convolutive Mixtures of Speech Using Time-Frequency Mask and Mixing Matrix Estimation|This paper focuses on the underdetermined blind source separation (BSS) of three speech signals mixed in a real environment from measurements provided by two sensors. To date, solutions to the underdetermined BSS problem have mainly been based on the assumption that the speech signals are sufficiently sparse. They involve designing binary masks that extract signals at time-frequency points where only one signal was assumed to exist. The major issue encountered in previous work relates to the occurrence of distortion, which affects a separated signal with loud musical noise. To overcome this problem, we propose combining sparseness with the use of an estimated mixing matrix. First, we use a geometrical approach to detect when only one source is active and to perform a preliminary separation with a time-frequency mask. This information is then used to estimate the mixing matrix, which allows us to improve our separation. Experimental results show that this combination of time-frequency mask and mixing matrix estimation provides separated signals of better quality (less distortion, less musical noise) than those extracted without using the estimated mixing matrix in reverberant conditions where the reverberant time (TR) was  ms and  ms. Furthermore, informal listening tests clearly show that musical noise is deeply lowered by the proposed method comparatively to the classical approaches.|Audrey Blin,Shoko Araki,Shoji Makino","42556|IEICE Transations|2005|Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain|This paper overviews a total solution for frequency-domain blind source separation (BSS) of convolutive mixtures of audio signals, especially speech. Frequency-domain BSS performs independent component analysis (ICA) in each frequency bin, and this is more efficient than time-domain BSS. We describe a sophisticated total solution for frequency-domain BSS, including permutation, scaling, circularity, and complex activation function solutions. Experimental results of   ,   ,   ,   , and    (moving sources), (sources  microphones) in a room are promising.|Shoji Makino,Hiroshi Sawada,Ryo Mukai,Shoko Araki","42618|IEICE Transations|2005|Subband-Based Blind Separation for Convolutive Mixtures of Speech|We propose utilizing subband-based blind source separation (BSS) for convolutive mixtures of speech. This is motivated by the drawback of frequency-domain BSS, i.e., when a long frame with a fixed long frame-shift is used to cover reverberation, the number of samples in each frequency decreases and the separation performance is degraded. In subband BSS, () by using a moderate number of subbands, a sufficient number of samples can be held in each subband, and () by using FIR filters in each subband, we can manage long reverberation. We confirm that subband BSS achieves better performance than frequency-domain BSS. Moreover, subband BSS allows us to select a separation method suited to each subband. Using this advantage, we propose efficient separation procedures that consider the frequency characteristics of room reverberation and speech signals () by using longer unmixing filters in low frequency bands and () by adopting an overlap-blockshift in BSS's batch adaptation in low frequency bands. Consequently, frequency-dependent subband processing is successfully realized with the proposed subband BSS.|Shoko Araki,Shoji Makino,Robert Aichner,Tsuyoki Nishikawa,Hiroshi Saruwatari","42347|IEICE Transations|2005|Multiple Regression of Log Spectra for In-Car Speech Recognition Using Multiple Distributed Microphones|This paper describes a new multi-channel method of noisy speech recognition, which estimates the log spectrum of speech at a closetalking microphone based on the multiple regression of the log spectra (MRLS) of noisy signals captured by distributed microphones. The advantages of the proposed method are as follows ) The method does not require a sensitive geometric layout, calibration of the sensors nor additional pre-processing for tracking the speech source ) System works in very small computation amounts and ) Regression weights can be statistically optimized over the given training data. Once the optimal regression weights are obtained by regression learning, they can be utilized to generate the estimated log spectrum in the recognition phase, where the speech of close-talking is no longer required. The performance of the proposed method is illustrated by speech recognition of real in-car dialogue data. In comparison to the nearest distant microphone and multi-microphone adaptive beamformer, the proposed approach obtains relative word error rate (WER) reductions of .% and .%, respectively.|Weifeng Li,Tetsuya Shinde,Hiroshi Fujimura,Chiyomi Miyajima,Takanori Nishino,Katunobu Itou,Kazuya Takeda,Fumitada Itakura","42822|IEICE Transations|2005|Alaryngeal Speech Enhancement Using Pattern Recognition Techniques|An alaryngeal speech enhancement system is proposed to improve the intelligibility and quality of speech signals generated by an artificial larynx transducer (ALT). Proposed system identifies the voiced segments of alaryngeal speech signal, by using pattern recognition methods, and replaces these by their equivalent voiced segments of normal speech. Evaluation results show that proposed system provides a fairly good improvement of the quality and intelligibility of ALT generated speech.|Gualberto Aguilar-Torres,Mariko Nakano-Miyatake,H√©ctor M. P√©rez Meana","42328|IEICE Transations|2005|Speech Recognition Using Finger Tapping Timings|Behavioral synchronization between speech and finger tapping provides a novel approach to improving speech recognition accuracy. We combine a sequence of finger tapping timings recorded alongside an utterance using two distinct methods in the first method, HMM state transition probabilities at the word boundaries are controlled by the timing of the finger tapping in the second, the probability (relative frequency) of the finger tapping is used as a 'feature' and combined with MFCC in a HMM recognition system. We evaluate these methods through connected digit recognition under different noise conditions (AURORA-J). Leveraging the synchrony between speech and finger tapping provides a % relative improvement in connected digit recognition experiments.|Hiromitsu Ban,Chiyomi Miyajima,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","42715|IEICE Transations|2005|Adaptive Nonlinear Regression Using Multiple Distributed Microphones for In-Car Speech Recognition|In this paper, we address issues in improving hands-free speech recognition performance in different car environments using multiple spatially distributed microphones. In the previous work, we proposed the multiple linear regression of the log spectra (MRLS) for estimating the log spectra of speech at a close-talking microphone. In this paper, the concept is extended to nonlinear regressions. Regressions in the cepstrum domain are also investigated. An effective algorithm is developed to adapt the regression weights automatically to different noise environments. Compared to the nearest distant microphone and adaptive beamformer (Generalized Sidelobe Canceller), the proposed adaptive nonlinear regression approach shows an advantage in the average relative word error rate (WER) reductions of .% and .%, respectively, for isolated word recognition under  real car environments.|Weifeng Li,Chiyomi Miyajima,Takanori Nishino,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","42363|IEICE Transations|2005|An Unsupervised Speaker Adaptation Method for Lecture-Style Spontaneous Speech Recognition Using Multiple Recognition Systems|This paper describes an accurate unsupervised speaker adaptation method for lecture style spontaneous speech recognition using multiple LVCSR systems. In an unsupervised speaker adaptation framework, the improvement of recognition performance by adapting acoustic models remarkably depends on the accuracy of labels such as phonemes and syllables. Therefore, extraction of the adaptation data guided by confidence measure is effective for unsupervised adaptation. In this paper, we looked for the high confidence portions based on the agreement between two LVCSR systems, adapted acoustic models using the portions attached with high accurate labels, and then improved the recognition accuracy. We applied our method to the Corpus of Spontaneous Japanese (CSJ) and the method improved the recognition rate by about .% in comparison with a traditional method.|Seiichi Nakagawa,Tomohiro Watanabe,Hiromitsu Nishizaki,Takehito Utsuro"],["57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","42394|IEICE Transations|2005|Solving Facility Layout Problem Using an Improved Genetic Algorithm|The facility layout problem is one of the most fundamental quadratic assignment problems in operations research. In this paper, we present an improved genetic algorithm for solving the facility layout problem. In our computational model, we propose several improvements to the basic genetic procedures including conditional crossover and mutation. The performance of the proposed method is evaluated on some benchmark problems. Computational results showed that the improved genetic algorithm is capable of producing high-quality solutions.|Rong Long Wang,Kozo Okazaki","57269|GECCO|2005|Inexact pattern matching using genetic algorithm|A Genetic Algorithm for graphical pattern matching based on angle matching had been proposed. It has proven quite effective in matching simple patterns. However, the algorithm needs some modifications to enhance its accuracy on pattern matching when there are some differences between two patterns in terms of numbers of nodes, shapes and rotations. This paper presents the modifications, such as the introduction of node exemption, inexact matching between straight lines and curves in the patterns, and consideration of rotational degrees of the patterns. Each angle is also given with a weight to indicate the significant degree of the angle. A multi-objective function is used to reflect the similarity between two patterns. The experiments designed to evaluate the algorithm have shown very promising results. It is highly accurate on patterns matching with dissimilarities in shapes, numbers of nodes and rotational degrees.|Surapong Auwatanamongkol","57322|GECCO|2005|Directional self-learning of genetic algorithm|In order to overcome the low convergence speed and prematurity of classical genetic algorithm, an improved method named directional self-learning of genetic algorithm (DSLGA) is proposed in this paper. Through the self-learning operator directional information was introduced in local search process. The search direction was guided by the false derivative of the function fitness. Using the four operators among the individuals, the best solution was updated continuously. In experiments, DSLGA was tested on  unconstrained benchmark problems, and the results were compared with the algorithms presented recently. It showed that DSLGA performs much better than the other algorithms both in the quality of the solutions and in the computational complexity.|Lin Cong,Yuheng Sha,Licheng Jiao,Fang Liu","57314|GECCO|2005|MDGA motif discovery using a genetic algorithm|Computationally identifying transcription factor binding sites in the promoter regions of genes is an important problem in computational biology and has been under intensive research for a decade. To predict the binding site locations efficiently, many algorithms that incorporate either approximate or heuristic techniques have been developed. However, the prediction accuracy is not satisfactory and binding site prediction thus remains a challenging problem. In this paper, we develop an approach that can be used to predict binding site motifs using a genetic algorithm. Based on the generic framework of a genetic algorithm, the approach explores the search space of all possible starting locations of the binding site motifs in different target sequences with a population that undergoes evolution. Individuals in the population compete to participate in the crossovers and mutations occur with a certain probability. Initial experiments demonstrated that our approach could achieve high prediction accuracy in a small amount of computation time. A promising advantage of our approach is the fact that the computation time does not explicitly depend on the length of target sequences and hence may not increase significantly when the target sequences become very long.|Dongsheng Che,Yinglei Song,Khaled Rasheed","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57274|GECCO|2005|Heuristic rules embedded genetic algorithm to solve in-core fuel management optimization problem|Because of the large number of possible combinations for the fuel assembly loading in the core, the design of the loading pattern (LP) is a complex optimization problem. It requires finding an optimal fuel arrangement in order to achieve maximum cycle length while satisfying the safety constraints. The objective of this study is to develop a loading pattern optimization code. Generally in-core fuel management codes are written for specific cores and limited fuel inventory. One of the goals of this study is to develop a loading pattern optimization code, which is applicable for all types of Pressurized Water Reactor (PWR) core structures with unlimited number of fuel assembly types in the inventory. To reach this goal an innovative genetic algorithm is developed with modifying the classical representation of the genotype. To obtain the best result in a shorter time not only the representation is changed but also the algorithm is changed to use in-core fuel management heuristics rules. The improved GA code was tested demonstrating the advantages of the introduced enhancements. The core physics code used in this research is Moby-Dick, which was developed to analyze the VVER reactors by SKODA Inc.|Fatih Alim,Kostadin Ivanov","57432|GECCO|2005|Primer design for multiplex PCR using a genetic algorithm|Multiplex Polymerase Chain Reaction (PCR) experiments are used for amplifying several segments of the target DNA simultaneously and thereby to conserve template DNA, reduce the experimental time, and minimize the experimental expense. The success of the experiment is dependent on primer design. However, this can be a dreary task as there are many constrains such as melting temperatures, primer length, GC content and complementarity that need to be optimized to obtain a good PCR product. Motivated by the lack of primer design tools for multiplex PCR genotypic assay, we propose a multiplex PCR primer design tool using a genetic algorithm, which is a stochastic approach based on the concept of biological evolution, biological genetics and genetic operations on chromosomes, to find an optimal selection of primer pairs for multiplex PCR experiments. The presented experimental results indicate that the proposed algorithm is capable of finding a series of primer pairs that obeies the design properties in the same tube.|Feng-Mao Lin,Hsien-Da Huang,Hsi-Yuan Huang,Jorng-Tzong Horng","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["42511|IEICE Transations|2005|On the Use of Wavelet Packets in Ultra Wideband Pulse Shape Modulation Systems|This paper proposes wavelet packets for use in ultra wideband communications. The pulse shapes that are generated are quasi orthogonal and have almost identical time duration. After normalization, an M-ary signaling set can be constructed allowing higher data rate. Finally, the performance of such a system when multipath propagation occurs is investigated by computer simulations. In order to combat multipath fading, a Rake receiver using coherent channel estimation is designed. This channel estimation is carried out using adaptive algorithms such as least-mean square (LMS), normalized least-mean square (NLMS), or recursive least square (RLS) algorithms which adapt the received signal given a reference signal.|St√©phane Ciolino,Mohammad Ghavami,Hamid Aghvami","42748|IEICE Transations|2005|Performance Improvement for Distributed Active Noise Control Systems Based on Simultaneous Equations Method|For multiple-channel active noise control (ANC) systems, distributed systems consisting of more than one controller are useful. In this paper, we propose a performance improvement algorithm for the distributed multiple-channel ANC system based on the simultaneous equations method. In the proposed algorithm, no estimation of error paths is required. This algorithm can provide good performance in canceling primary noises with auto-cross-correlations and achieve stable noise reduction under a change of the error paths.|Mitsuji Muneyasu,Ken'ichi Kagawa,Kensaku Fujii,Takao Hinamoto","16070|IJCAI|2005|A Multidimensional Semantic Framework for Adaptive Hypermedia Systems|This paper introduces a multidimensional semantic framework for adaptive systems. Different planes allow us to represent ontologies of user, her actions, context, device, domain, while the intersection between planes allow us to represent the semantic rules for inferring new user features or adaptation strategies. The adoption of ontology-based framework aims at creating a server for user modeling and adaptation strategy.|Francesca Carmagnola,Federica Cena,Cristina Gena,Ilaria Torre","42855|IEICE Transations|2005|Optimal Tracking Design for Hybrid Uncertain Input-Delay Systems under State and Control Constraints via Evolutionary Programming Approach|A novel digital redesign methodology based on evolutionary programming (EP) is introduced to find the 'best' digital controller for optimal tracking design of hybrid uncertain multi-input multi-output (MIMO) input-delay systems with constraints on states and controls. To deal with these multivariable concurrent specifications and system restrictions, instead of conventional interval methods, the proposed global optimization scheme is able to practically implement optimal digital controller for constrained uncertain hybrid systems with input time delay. Further, an illustrative example is included to demonstrate the efficiency of the proposed method.|Yu-Pin Chang","42598|IEICE Transations|2005|Peak Power Reduction Method Using Adaptive Peak Reduction Signal Level Control for OFDM Transmission Systems|Future broadband mobile communication systems are necessary to achieve the bit rates of  Mbits. Orthogonal Frequency Division Multiplexing (OFDM) transmission is an attractive technology because it can remove the influence of frequency selective fading in broadband transmission by adding a suitable guard interval to each OFDM symbol. However, peak-to-average power ratio (PAPR) is very large in OFDM transmission. In this paper, we propose a new PAPR reduction method which can be applied even when unusable bands are inside the system band. In the proposed method, peak reduction signals are generated by iterative signal processing only in the usable frequency band, and filtering to remove out-of-band components of the peak reduction signals is incorporated into the iterative signal processing. The results of computer simulation show that the proposed method can effectively reduce peak power without expanding the spectrum both outside the system band and into unusable bands inside the system band. By using the proposed method, the broadband mobile communication system with low peak power and high flexibility of frequency band use can be realized.|Shigeru Tomisato,Masaharu Hata","42810|IEICE Transations|2005|Self-Adaptive AlgorithmicArchitectural Design for Real-Time Low-Power Video Systems|With reference to video motion estimation in the framework of the new H.AVC video coding standard, this paper presents algorithmic and architectural solutions for the implementation of context-aware coprocessors in real-time, low-power embedded systems. A low-complexity context-aware controller is added to a conventional Full Search (FS) motion estimation engine. While the FS coprocessor is working, the context-aware controller extracts from the intermediate processing results information related to the input signal statistics in order to automatically configure the coprocessor itself in terms of search area size and number of reference frames thus unnecessary computations and memory accesses can be avoided. The achieved complexity saving factor ranges from . to  depending on the input signal while keeping unaltered performance in terms of motion estimation accuracy. The increased efficiency is exploited both for (i) processing time reduction in case of software implementation on a programmable platform (ii) power consumption reduction in case of dedicated hardware implementation in CMOS technology.|Luca Fanucci,Sergio Saponara,Massimiliano Melani,Pierangelo Terreni","42714|IEICE Transations|2005|Suboptimal Adaptive Filter for Discrete-Time Linear Stochastic Systems|This paper considers the problem of recursive filtering for linear discrete-time systems with uncertain observation. A new approximate adaptive filter with a parallel structure is herein proposed. It is based on the optimal mean square combination of arbitrary number of correlated estimates which is also derived. The equation for error covariance characterizing the mean-square accuracy of the new filter is derived. In consequence of parallel structure of the filtering equations the parallel computers can be used for their design. It is shown that this filter is very effective for multisensor systems containing different types of sensors. A practical implementation issue to consider this filter is also addressed. Example demonstrates the accuracy and efficiency of the proposed filter.|Daebum Choi,Vladimir Shin,Jun Il Ahn,Byung-Ha Ahn","42424|IEICE Transations|2005|Decentralized Supervisory Control of Discrete Event Systems Using Dynamic Default Control|The conventional decentralized supervisory control architectures for discrete event systems assume that default control of controllable events is static. In this paper, we propose a new decentralized supervisory control architecture using dynamic default control of controllable events. We present necessary and sufficient conditions for the existence of a decentralized supervisor in the proposed architecture. Then, we give an example of a language that is achieved in the proposed architecture, but not in the conventional architectures using static default control.|Shigemasa Takai,Toshimitsu Ushio","42671|IEICE Transations|2005|Robust Analysis and Design for Discrete-Time Nonlinear Systems Subject to Actuator Saturation via Fuzzy Control|This paper proposes an analysis and design methodology for the robust control of affine-in-control nonlinear systems subject to actuator saturation in discrete-time formulation. The robust stability condition is derived for the closed-loop system by the introduction of the fuzzy Kronecker delta. Based on the newly acquired stability condition, a design method is proposed to guarantee the robust H performance. In the design, LMI-based pole placement is employed to use the freedom allowed in the selection of the controller. The validity of the proposed method is asserted by the computer simulation.|Sanghyung Lee,Euntai Kim,Hagbae Kim,Mignon Park","42783|IEICE Transations|2005|A Coordinator for Workflow Management Systems with Information Access Control|This paper proposes a coordinator for workflow management systems (WFMSs). It is a basic module for developing WFMSs. It is also a coordinator to coordinate multiple WFMSs. The coordinator provides functions to facilitate executing workflows and to ensure secure access of workflow information. Facilitating workflow execution is well-known, but ensuring secure access of workflow information is identified as important only recently. Although many models ensure secure workflow information access, they fail to offer the features we need. We thus developed a new model for the control. This paper presents the coordinator its access control model.|Shih-Chien Chou,Chien-Jung Wu"],["65537|AAAI|2005|Word Sense Disambiguation with Semi-Supervised Learning|Current word sense disambiguation (WSD) systems based on supervised learning are still limited in that they do not work well for all words in a language. One of the main reasons is the lack of sufficient training data. In this paper, we investigate the use of unlabeled training data for WSD, in the framework of semi-supervised learning. Four semisupervised leaming algorithms are evaluated on  nouns of Senseval- (SE) English lexical sample task and SE English all-words task. Empirical results show that unlabeled data can bring significant improvement in WSD accuracy.|Thanh Phong Pham,Hwee Tou Ng,Wee Sun Lee","65528|AAAI|2005|SenseRelate  TargetWord-A Generalized Framework for Word Sense Disambiguation|Many words in natural language have different meanings when used in different contexts. Sense Relate Target Word is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet Similarity measure of relatedness.|Siddharth Patwardhan,Satanjeev Banerjee,Ted Pedersen","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","42794|IEICE Transations|2005|Machine Learning Based English-to-Korean Transliteration Using Grapheme and Phoneme Information|Machine transliteration is an automatic method to generate characters or words in one alphabetical system for the corresponding characters in another alphabetical system. Machine transliteration can play an important role in natural language application such as information retrieval and machine translation, especially for handling proper nouns and technical terms. The previous works focus on either a grapheme-based or phoneme-based method. However, transliteration is an orthographical and phonetic converting process. Therefore, both grapheme and phoneme information should be considered in machine transliteration. In this paper, we propose a grapheme and phoneme-based transliteration model and compare it with previous grapheme-based and phoneme-based models using several machine learning techniques. Our method shows about % performance improvement.|Jong-Hoon Oh,Key-Sun Choi","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","57403|GECCO|2005|Dynamic-probabilistic particle swarms|The particle swarm algorithm is usually a dynamic process, where a point in the search space to be tested depends on the previous point and the direction of movement. The process can be decomposed, and probability distributions around a center can be used instead of the usual trajectory approach. A version that is both dynamic and Gaussian looks very promising.|James Kennedy","42386|IEICE Transations|2005|An Effective Search Method for Neural Network Based Face Detection Using Particle Swarm Optimization|This paper presents a novel method to speed up neural network (NN) based face detection systems. NN-based face detection can be viewed as a classification and search problem. The proposed method formulates the face search problem as an integer nonlinear optimization problem (INLP) and expands the basic particle swarm optimization (PSO) to handle it. PSO works with a population of particles, each representing a subwindow in an input image. The subwindows are evaluated by how well they match a NN based face filter. A face is indicated when the filter response of the best particle is above a given threshold. Experiments on a set of  test images show the e.ectiveness of the proposed approach. Moreover, the effect of PSO parameter settings on the search performance was investigated.|Masanori Sugisaka,Xinjian Fan","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","42327|IEICE Transations|2005|Unsupervised Word-Sense Disambiguation Using Bilingual Comparable Corpora|An unsupervised method for word-sense disambiguation using bilingual comparable corpora was developed. First, it extracts word associations, i.e., statistically significant pairs of associated words, from the corpus of each language. Then, it aligns word associations by consulting a bilingual dictionary and calculates correlation between senses of a target polysemous word and its associated words, which can be regarded as clues for identifying the sense of the target word. To overcome the problem of disparity of topical coverage between corpora of the two languages as well as the problem of ambiguity in word-association alignment, an algorithm for iteratively calculating a sense-vs.-clue correlation matrix for each target word was devised. Word-sense disambiguation for each instance of the target word is done by selecting the sense that maximizes the score, i.e., a weighted sum of the correlations between each sense and clues appearing in the context of the instance. An experiment using Wall Street Journal and Nihon Keizai Shimbun corpora together with the EDR bilingual dictionary showed that the new method has promising performance namely, the Fmeasure of its sense selection was .% compared to a baseline of .%. The developed method will possibly be extended into a fully unsupervised method that features automatic division and definition of word senses.|Hiroyuki Kaji,Yasutsugu Morimoto","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["42613|IEICE Transations|2005|Frequency Domain Microphone Array Calibration and Beamforming for Automatic Speech Recognition|This investigation proposed two array beamformers SPFDBB (Soft Penalty Frequency Domain Block Beamformer) and FDABB (Frequency Domain Adjustable Block Beamformer). Compared with the conventional beamformers, these frequency-domain methods can significantly reduce the computation power requirement in ASR (Automatic Speech Recognition) based applications. Like other reference signal based techniques, SPFDBB and FDABB minimize microphone's mismatch, desired signal cancellation caused by reflection effects and resolution due to the array's position. Additionally, these proposed methods are suitable for both near-field and far-field environments. Generally, the convolution relation between channel and speech source in time domain cannot be modeled accurately as a multiplication in the frequency domain with a finite window size, especially in ASR applications. SPFDBB and FDABB can approximate this multiplication by treating several frames as a block to achieve a better beamforming result. Moreover, FDABB adjusts the number of frames on-line to cope with the variation of characteristics in both speech and interference signals. A better performance was found to be achievable by combining these methods with an ASR mechanism.|Jwu-Sheng Hu,Chieh-Cheng Cheng","42830|IEICE Transations|2005|Robust Speech Recognition Using Discrete-Mixture HMMs|This paper introduces new methods of robust speech recognition using discrete-mixture HMMs (DMHMMs). The aim of this work is to develop robust speech recognition for adverse conditions that contain both stationary and non-stationary noise. In particular, we focus on the issue of impulsive noise, which is a major problem in practical speech recognition system. In this paper, two strategies were utilized to solve the problem. In the first strategy, adverse conditions are represented by an acoustic model. In this case, a large amount of training data and accurate acoustic models are required to present a variety of acoustic environments. This strategy is suitable for recognition in stationary or slow-varying noise conditions. The second is based on the idea that the corrupted frames are treated to reduce the adverse effect by compensation method. Since impulsive noise has a wide variety of features and its modeling is difficult, the second strategy is employed. In order to achieve those strategies, we propose two methods. Those methods are based on DMHMM framework which is one type of discrete HMM (DHMM). First, an estimation method of DMHMM parameters based on MAP is proposed aiming to improve trainability. The second is a method of compensating the observation probabilities of DMHMMs by threshold to reduce adverse effect of outlier values. Observation probabilities of impulsive noise tend to be much smaller than those of normal speech. The motivation in this approach is that flooring the observation probability reduces the adverse effect caused by impulsive noise. Experimental evaluations on Japanese LVCSR for read newspaper speech showed that the proposed method achieved the average error rate reduction of .% in impulsive noise conditions. Also the experimental results in adverse conditions that contain both stationary and impulsive noises showed that the proposed method achieved the average error rate reduction of .%.|Tetsuo Kosaka,Masaharu Katoh,Masaki Kohda","42887|IEICE Transations|2005|Construction of Audio-Visual Speech Corpus Using Motion-Capture System and Corpus Based Facial Animation|An accurate audio-visual speech corpus is inevitable for talking-heads research. This paper presents our audio-visual speech corpus collection and proposes a head-movement normalization method and a facial motion generation method. The audio-visual corpus contains speech data, movie data on faces, and positions and movements of facial organs. The corpus consists of Japanese phoneme-balanced sentences uttered by a female native speaker. An accurate facial capture is realized by using an optical motion-capture system. We captured high-resolution D data by arranging many markers on the speaker's face. In addition, we propose a method of acquiring the facial movements and removing head movements by using affine transformation for computing displacements of pure facial organs. Finally, in order to easily create facial animation from this motion data, we propose a technique assigning the captured data to the facial polygon model. Evaluation results demonstrate the effectiveness of the proposed facial motion generation method and show the relationship between the number of markers and errors.|Tatsuo Yotsukura,Shigeo Morishima,Satoshi Nakamura","42345|IEICE Transations|2005|Recent Progress in Corpus-Based Spontaneous Speech Recognition|This paper overviews recent progress in the development of corpus-based spontaneous speech recognition technology. Although speech is in almost any situation spontaneous, recognition of spontaneous speech is an area which has only recently emerged in the field of automatic speech recognition. Broadening the application of speech recognition depends crucially on raising recognition performance for spontaneous speech. For this purpose, it is necessary to build large spontaneous speech corpora for constructing acoustic and language models. This paper focuses on various achievements of a Japanese -year national project \"Spontaneous Speech Corpus and Processing Technology\" that has recently been completed. Because of various spontaneous-speech specific phenomena, such as filled pauses, repairs, hesitations, repetitions and disfluencies, recognition of spontaneous speech requires various new techniques. These new techniques include flexible acoustic modeling, sentence boundary detection, pronunciation modeling, acoustic as well as language model adaptation, and automatic summarization. Particularly automatic summarization including indexing, a process which extracts important and reliable parts of the automatic transcription, is expected to play an important role in building various speech archives, speech-based information retrieval systems, and human-computer dialogue systems.|Sadaoki Furui","42347|IEICE Transations|2005|Multiple Regression of Log Spectra for In-Car Speech Recognition Using Multiple Distributed Microphones|This paper describes a new multi-channel method of noisy speech recognition, which estimates the log spectrum of speech at a closetalking microphone based on the multiple regression of the log spectra (MRLS) of noisy signals captured by distributed microphones. The advantages of the proposed method are as follows ) The method does not require a sensitive geometric layout, calibration of the sensors nor additional pre-processing for tracking the speech source ) System works in very small computation amounts and ) Regression weights can be statistically optimized over the given training data. Once the optimal regression weights are obtained by regression learning, they can be utilized to generate the estimated log spectrum in the recognition phase, where the speech of close-talking is no longer required. The performance of the proposed method is illustrated by speech recognition of real in-car dialogue data. In comparison to the nearest distant microphone and multi-microphone adaptive beamformer, the proposed approach obtains relative word error rate (WER) reductions of .% and .%, respectively.|Weifeng Li,Tetsuya Shinde,Hiroshi Fujimura,Chiyomi Miyajima,Takanori Nishino,Katunobu Itou,Kazuya Takeda,Fumitada Itakura","42328|IEICE Transations|2005|Speech Recognition Using Finger Tapping Timings|Behavioral synchronization between speech and finger tapping provides a novel approach to improving speech recognition accuracy. We combine a sequence of finger tapping timings recorded alongside an utterance using two distinct methods in the first method, HMM state transition probabilities at the word boundaries are controlled by the timing of the finger tapping in the second, the probability (relative frequency) of the finger tapping is used as a 'feature' and combined with MFCC in a HMM recognition system. We evaluate these methods through connected digit recognition under different noise conditions (AURORA-J). Leveraging the synchrony between speech and finger tapping provides a % relative improvement in connected digit recognition experiments.|Hiromitsu Ban,Chiyomi Miyajima,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","42451|IEICE Transations|2005|Harmonicity Based Dereverberation for Improving Automatic Speech Recognition Performance and Speech Intelligibility|A speech signal captured by a distant microphone is generally smeared by reverberation, which severely degrades both the speech intelligibility and Automatic Speech Recognition (ASR) performance. Previously, we proposed a single-microphone dereverberation method, named \"Harmonicity based dEReverBeration (HERB).\" HERB estimates the inverse filter for an unknown room transfer function by utilizing an essential feature of speech, namely harmonic structure. In previous studies, improvements in speech intelligibility was shown solely with spectrograms, and improvements in ASR performance were simply confirmed by matched condition acoustic model. In this paper, we undertook a further investigation of HERB's potential as regards to the above two factors. First, we examined speech intelligibility by means of objective indices. As a result, we found that HERB is capable of improving the speech intelligibility to approximately that of clean speech. Second, since HERB alone could not improve the ASR performance sufficiently, we further analyzed the HERB mechanism with a view to achieving further improvements. Taking the analysis results into account, we proposed an appropriate ASR configuration and conducted experiments. Experimental results confirmed that, if HERB is used with an ASR adaptation scheme such as MLLR and a multicondition acoustic model, it is very effective for improving ASR performance even in unknown severely reverberant environments.|Keisuke Kinoshita,Tomohiro Nakatani,Masato Miyoshi","42715|IEICE Transations|2005|Adaptive Nonlinear Regression Using Multiple Distributed Microphones for In-Car Speech Recognition|In this paper, we address issues in improving hands-free speech recognition performance in different car environments using multiple spatially distributed microphones. In the previous work, we proposed the multiple linear regression of the log spectra (MRLS) for estimating the log spectra of speech at a close-talking microphone. In this paper, the concept is extended to nonlinear regressions. Regressions in the cepstrum domain are also investigated. An effective algorithm is developed to adapt the regression weights automatically to different noise environments. Compared to the nearest distant microphone and adaptive beamformer (Generalized Sidelobe Canceller), the proposed adaptive nonlinear regression approach shows an advantage in the average relative word error rate (WER) reductions of .% and .%, respectively, for isolated word recognition under  real car environments.|Weifeng Li,Chiyomi Miyajima,Takanori Nishino,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","42363|IEICE Transations|2005|An Unsupervised Speaker Adaptation Method for Lecture-Style Spontaneous Speech Recognition Using Multiple Recognition Systems|This paper describes an accurate unsupervised speaker adaptation method for lecture style spontaneous speech recognition using multiple LVCSR systems. In an unsupervised speaker adaptation framework, the improvement of recognition performance by adapting acoustic models remarkably depends on the accuracy of labels such as phonemes and syllables. Therefore, extraction of the adaptation data guided by confidence measure is effective for unsupervised adaptation. In this paper, we looked for the high confidence portions based on the agreement between two LVCSR systems, adapted acoustic models using the portions attached with high accurate labels, and then improved the recognition accuracy. We applied our method to the Corpus of Spontaneous Japanese (CSJ) and the method improved the recognition rate by about .% in comparison with a traditional method.|Seiichi Nakagawa,Tomohiro Watanabe,Hiromitsu Nishizaki,Takehito Utsuro","42329|IEICE Transations|2005|Developments in Corpus-Based Speech Synthesis Approaching Natural Conversational Speech|This paper describes the special demands of conversational speech in the context of corpus-based speech synthesis. The author proposed the CHATR system of prosody-based unit-selection for concatenative waveform synthesis seven years ago, and now extends this work to incorporate the results of an analysis of five-years of recordings of spontaneous conversational speeech in a wide range of actual daily-life situations. The paper proposes that the expresion of affect (often translated as 'kansei' in Japanese) is the main factor differentiating laboratory speech from realworld conversational speech, and presents a framework for the specification of affect through differences in speaking style and voice quality. Having an enormous corpus of speech samples available for concatenation allows the selection of complete phrase-sized utterance segments, and changes the focus of unit selection from segmental or phonetic continuity to one of prosodic and discoursal appropriateness instead. Samples of the resulting large-corpus-based synthesis can be heard at httpfeast.his.atr.jpAESOP.|Nick Campbell"],["16159|IJCAI|2005|Combining Structural Descriptions and Image-based Representations for Image Object and Scene Recognition|Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.|Nicolas Do Huu,Williams Paquier,Raja Chatila","42789|IEICE Transations|2005|A Discriminant Analysis Based Recursive Automatic Thresholding Approach for Image Segmentation|In this study, we have proposed an efficient automatic multilevel thresholding method for image segmentation. An effective criterion for measuring the separability of the homogenous objects in the image, based on discriminant analysis, has been introduced to automatically determine the number of thresholding levels to be performed. Then, by applying this discriminant criterion, the object regions with homogeneous illuminations in the image can be recursively and automatically thresholded into separate segmented images. The proposed method is fast and effective in analyzing and thresholding the histogram of the image. In order to conduct an equitable comparative performance evaluation of the proposed method with other thresholding methods, a combinatorial scheme is also introduced to properly reduce the computational complexity of performing multilevel thresholding. The experimental results demonstrated that the proposed method is feasible and computationally efficient in automatic multilevel thresholding for image segmentation.|Bing-Fei Wu,Yen-Lin Chen,Chung-Cheng Chiu","42467|IEICE Transations|2005|A Method of Guaranteeing Image-Quality for Quantization-Based Watermarking Using a Nonorthogonal Transformation|This paper proposes a quantization-based image-quality guaranteed watermarking (IQGW) method using a nonorthogonal discrete wavelet transformation. An IQGW method generates watermarked images of a desired image quality for any image, neither with trial and error nor with image-dependent parameters. To guarantee the image-quality, the proposed method adjusts the energy of the watermark sequence to be embedded based on the relationship between a nonorthogonally transformed domain and the spatial domain for the signal energy. This proposed method extracts the embedded watermark by quantization of watermarked coefficients, no reference image, thus, is required. In addition, it is capable of controlling the objective and subjective image-quality of a watermarked image independently. With features mentioned above, the proposed method is suitable for real-time embedding of Motion JPEG  videos. Moreover, it is able to fuse quantization- and correlation-based watermarking.|Masaaki Fujiyoshi,Osamu Watanabe,Hitoshi Kiya","65543|AAAI|2005|Enhanced Direct Linear Discriminant Analysis for Feature Extraction on High Dimensional Data|We present an enhanced direct linear discriminant analysis (EDLDA) solution to effectively and efficiently extract discriminatory features from high dimensional data. The EDLDA integrates two types of class-wise weighting terms in estimating the average within-class and between-class scatter matrices in order to relate the resulting Fisher criterion more closely to the minimization of classification error. Furthermore, the extracted discriminant features are weighted by mutual information between features and class labels. Experimental results on four biometric datasets demonstrate the promising performance of the proposed method.|A. Kai Qin,S. Y. M. Shi,Ponnuthurai N. Suganthan,Marco Loog","42661|IEICE Transations|2005|The Efficient and Robust Error Resilient Entropy Coding of Compressed Image for Wireless Communications|Many image and video compression algorithms work by splitting the image into blocks and producing variable-length code bits for each block data. If variable-length code data are transmitted consecutively over error-prone channel without any error protection technique, the receiving decoder cannot decode the stream properly. So the standard image and video compression algorithms insert some redundant information into the stream to provide some protection against channel errors. One of such redundancy is resynchronization marker, which enables the decoder to restart the decoding process from a known state in the event of transmission errors, but its frequent use should be restricted not to consume bandwidth too much. The Error Resilient Entropy Code (EREC) is well known method which can regain synchronization without any redundant information. It can work with the overall prefix codes, which many image compression methods use. This paper proposes an improvement to FEREC (Fast Error-Resilient Entropy Coding). It first calculates initial searching position according to bit lengths of consecutive blocks. Second, initial offset is decided using statistical distribution of long and short blocks, and initial offset is adjusted to insure all possible offset value can be examined. The proposed algorithm can speed up the construction of EREC slots, and can preserve compressed image quality in the event of transmission errors. The simulation result shows that the quality of transmitted image is enhanced about .--. dB compared with the existing FEREC when random channel error happens.|Jeong-Sig Kim,Ju-Do Kim,Keun-Young Lee","42941|IEICE Transations|2005|A Nonlinear Principal Component Analysis of Image Data|Principal Component Analysis (PCA) has been applied in various areas such as pattern recognition and data compression. In some cases, however, PCA does not extract the characteristics of the data-distribution efficiently. In order to overcome this problem, we have proposed a novel method of Nonlinear PCA which preserves the order of the principal components. In this paper, we reduce the dimensionality of image data using the proposed method, and examine its effectiveness in the compression and recognition of images.|Ryo Saegusa,Hitoshi Sakano,Shuji Hashimoto","42948|IEICE Transations|2005|Document Image Retrieval for QA Systems Based on the Density Distributions of Successive Terms|Question answering (QA) is the task of retrieving an answer in response to a question by analyzing documents. Although most of the efforts in developing QA systems are devoted to dealing with electronic text, we consider it is also necessary to develop systems for document images. In this paper, we propose a method of document image retrieval for such QA systems. Since the task is not to retrieve all relevant documents but to find the answer somewhere in documents, retrieval should be precision oriented. The main contribution of this paper is to propose a method of improving precision of document image retrieval by taking into account the co-occurrence of successive terms in a question. The indexing scheme is based on two-dimensional distributions of terms and the weight of co-occurrence is measured by calculating the density distributions of terms. The proposed method was tested by using  pages of documents about the major league baseball with  questions and found that it is superior to the baseline method proposed by the authors.|Koichi Kise,Shota Fukushima,Keinosuke Matsumoto","57370|GECCO|2005|Effective image compression using evolved wavelets|Wavelet-based image coders like the JPEG standard are the state of the art in image compression. Unlike traditional image coders, however, their performance depends to a large degree on the choice of a good wavelet. Most wavelet-based image coders use standard wavelets that are known to perform well on photographic images. However, these wavelets do not perform as well on other common image classes, like scanned documents or fingerprints. In this paper, a method based on the coevolutionary genetic algorithm introduced in  is used to evolve specialized wavelets for fingerprint images. These wavelets are compared to the hand-designed wavelet currently used by the FBI to compress fingerprints. The results show that the evolved wavelets consistently outperform the hand-designed wavelet. Using evolution to adapt wavelets to classes of images can therefore significantly increase the quality of compressed images.|Uli Grasemann,Risto Miikkulainen","42885|IEICE Transations|2005|Efficient Wavelet-Based Image Retrieval Using Coarse Segmentation and Fine Region Feature Extraction|Semantic image segmentation and appropriate region content description are crucial issues for region-based image retrieval (RBIR). In this paper, a novel region-based image retrieval method is proposed, which performs fast coarse image segmentation and fine region feature extraction using the decomposition property of image wavelet transform. First, coarse image segmentation is conducted efficiently in the Low-Low(LL) frequency subband of image wavelet transform. Second, the feature vector of each segmented region is hierarchically extracted from all different wavelet frequency subbands, which captures the distinctive feature (e.g., semantic texture) inside one region finely. Experiment results show the efficiency and the effectiveness of the proposed method for region-based image retrieval.|Yongqing Sun,Shinji Ozawa","80523|VLDB|2005|Offline and Data Stream Algorithms for Efficient Computation of Synopsis Structures|Synopsis and small space representations are important data analysis tools and have long been used OLAPDSS systems, approximate query answering, query optimization and data mining. These techniques represent the input in terms broader characteristics and improve efficiency of various applications, e.g., learning, classification, event detection, among many others. In a recent past, the synopsis techniques have gained more currency due to the emerging areas like data stream management.In this tutorial, we propose to revisit algorithms for Wavelet and Histogram synopsis construction. In the recent years, a significant number of papers have appeared which has advanced the state-of-the-art in synopsis construction considerably. In particular, we have seen the development of a large number of efficient algorithms which are also guaranteed to be near optimal. Furthermore, these synopsis construction problems have found deep roots in theory and database systems, and have influenced a wide range of problems. In a different level, a large number of the synopsis construction algorithms use a similar set of techniques. It is extremely valuable to discuss and analyze these techniques, and we expect broader pictures and paradigms to emerge. This would allow us to develop algorithms for newer problems with greater ease. Understanding these recurrent themes and intuition behind the development of these algorithms is one of the main thrusts of the tutorial.Our goal will be to cover a wide spectrum of these topics and make the researchers in VLDB community aware of the new algorithms, optimum or approximate, offline or streaming. The tutorial will be self contained and develop most of the mathematical and database backgrounds needed.|Sudipto Guha,Kyuseok Shim"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","65598|AAAI|2005|A Theory of Forgetting in Logic Programming|The study of forgetting for reasoning has attracted considerable attention in AI. However, much of the work on forgetting, and other related approaches such as independence, irrelevance and novelty, has been restricted to the classical logics. This paper describes a detailed theoretical investigation of the notion of forgetting in the context of logic programming. We first provide a semantic definition of forgetting under the answer sets for extended logic programs. We then discuss the desirable properties and some motivating examples. An important result of this study is an algorithm for computing the result of forgetting in a logic program. Furthermore, we present a modified version of the algorithm and show that the time complexity of the new algorithm is polynomial with respect to the size of the given logic program if the size of certain rules is fixed. We show how the proposed theory of forgetting can be used to characterize the logic program updates.|Kewen Wang,Abdul Sattar,Kaile Su","57512|GECCO|2005|Using gene deletion and gene duplication in evolution strategies|Self-adaptation of the mutation strengths is a powerful mechanism in evolution strategies (ES), but it can fail. As a consequence premature convergence or ending up in a local optimum in multi-modal fitness landscapes can occur. In this article a new approach controlling the process of self-adaptation is proposed. This approach combines the old ideas of gene deletion and gene duplication with the self-adaptation mechanism of the ES. Gene deletion and gene duplication is used to vary the number of independent mutation strengths. In order to demonstrate the practicability of the new approach several multi-modal test functions are used. Methods from statistical design of experiments and regression tree methods are applied to improve the performance of a specific heuristic-problem combination.|Karlheinz Schmitt","57555|GECCO|2005|Using evolutionary computation methods to support analytical models for the evolution and maintenance of conditional strategies in |Biologists have developed models to explain why different environmentally induced morphs of the same organism exist over time. Such conditional strategies are a common form of adaptation to variable environments, whereby an environmental cue allows some individuals to respond to the cue and develop into a morph that is different from the morph of individuals that do not receive the cue. Recently, these efforts have resulted in two different analytical models that give somewhat different predictions. Here we apply evolutionary computation methods to test the two analytical models. The results bear a remarkable similarity to the results of one of the two analytical models. The paper that follows presents the details of a biological application involving snails and barnacles (that occur naturally in two different morphs), moving then to an explanation of two competing mathematical models of the application. Finally, the interdisciplinary paper, which coordinates three separate research projects of a biologist, a mathematician and a computer scientist, describes the evolutionary computation methods used to support one of the two competing analytical models.|Gloria Childress Townsend,Wade N. Hazel,Rick Smock","57513|GECCO|2005|Using predators and preys in evolution strategies|This poster presents an evolution strategy for single- and multi-objective optimization. The model uses the predator-prey approach from ecology to scale between both cases. Furthermore the main issue of adaptation working for single- and multi-objective problem-instances equally is discussed. Particular, the well proved self-adaptation mechanism for the mutation strengths in the single-objective case is adopted for the multi-objective one. This self-adaptation process is supported by a new strategy of competition between predators and preys. Six test functions are used to demonstrate the practicability of the model.|Karlheinz Schmitt,J√∂rn Mehnen,Thomas Michelitsch","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57550|GECCO|2005|Learned mutation strategies in genetic programming for evolution and adaptation of simulated snakebot|In this work we propose an approach of incorporating learned mutation strategies (LMS) in genetic programming (GP) employed for evolution and adaptation of locomotion gaits of simulated snake-like robot (Snakebot). In our approach the LMS are implemented via learned probabilistic context-sensitive grammar (LPCSG). The LPCSG is derived from the originally defined context-free grammar, which usually expresses the syntax of genetic programs in canonical GP. Applying LMS implies that the probabilities of applying each of particular production rules in LPCGS during the mutation depend on the context. These probabilities are learned from the aggregated reward values obtained from the parsed syntax of the evolved best-of-generation Snakebots. Empirically obtained results verify that LMS contributes to the improvement of computational effort of both (i) the evolution of the fastest possible locomotion gaits for various fitness conditions and (ii) the adaptation of these locomotion gaits to challenging environment and degraded mechanical abilities of Snakebot. In all of the cases considered in this study, the locomotion gaits, evolved and adapted employing GP with LMS feature higher velocity and are obtained faster than with canonical GP.|Ivan Tanev","57525|GECCO|2005|Niching in evolution strategies|EAs have the tendency to converge quickly into a single solution. Niching methods, the extension of EAs to address this issue, have been investigated up to date mainly within the field of Genetic Algorithms (GAs). In our study we investigate the basis for niching methods within Evolution Strategies (ES), and propose the first ES niching method. Results show that this method can reliably find and maintain multiple niches even for high-dimensional problems.|Ofer M. Shir,Thomas B√§ck","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","42710|IEICE Transations|2005|Efficient Large Scale Integration PowerGround Network Optimization Based on Grid Genetic Algorithm|In this paper we propose a novel and efficient method for the optimization of the powerground (PG) network in VLSI circuit layouts with reliability constraints. Previous algorithms in the PG network sizing used the sequence-of-linear-programming (SLP) algorithm to solve the nonlinear optimization problems. However the transformation from nonlinear network to linear subnetwork is not optimal enough. Our new method is inspired by the biological evolution and use the grid-genetic-algorithm (GGA) to solve the optimization problem. Experimental results show that new PG network sizes are smaller than previous algorithms, as the fittest survival in the nature. Another significant advance is that GGA method can be applied for all PG network problems because it can get the results directly no matter whether these problems are linear or not. Thus GGA can be adopted in the transient behavior of the PG network sizing in the future, which recently faces on the obstacles in the solution of the complex nonlinear problems.|Yun Yang,Atsushi Kurokawa,Yasuaki Inoue,Wenqing Zhao","42394|IEICE Transations|2005|Solving Facility Layout Problem Using an Improved Genetic Algorithm|The facility layout problem is one of the most fundamental quadratic assignment problems in operations research. In this paper, we present an improved genetic algorithm for solving the facility layout problem. In our computational model, we propose several improvements to the basic genetic procedures including conditional crossover and mutation. The performance of the proposed method is evaluated on some benchmark problems. Computational results showed that the improved genetic algorithm is capable of producing high-quality solutions.|Rong Long Wang,Kozo Okazaki","57322|GECCO|2005|Directional self-learning of genetic algorithm|In order to overcome the low convergence speed and prematurity of classical genetic algorithm, an improved method named directional self-learning of genetic algorithm (DSLGA) is proposed in this paper. Through the self-learning operator directional information was introduced in local search process. The search direction was guided by the false derivative of the function fitness. Using the four operators among the individuals, the best solution was updated continuously. In experiments, DSLGA was tested on  unconstrained benchmark problems, and the results were compared with the algorithms presented recently. It showed that DSLGA performs much better than the other algorithms both in the quality of the solutions and in the computational complexity.|Lin Cong,Yuheng Sha,Licheng Jiao,Fang Liu","57526|GECCO|2005|Resource-limited genetic programming the dynamic approach|Resource-Limited Genetic Programming is a bloat control technique that imposes a single limit on the total amount of resources available to the entire population, where resources are tree nodes or code lines. We elaborate on this recent concept, introducing a dynamic approach to managing the amount of resources available for each generation. Initially low, this amount is increased only if it results in better population fitness. We compare the dynamic approach to the static method where a constant amount of resources is available throughout the run, and with the most traditional usage of a depth limit at the individual level. The dynamic approach does not impair performance on the Symbolic Regression of the quartic polynomial, and achieves excellent results on the Santa Fe Artificial Ant problem, obtaining the same fitness with only a small percentage of the computational effort demanded by the other techniques.|Sara Silva,Ernesto Costa","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57474|GECCO|2005|A hybrid genetic algorithm with pattern search for finding heavy atoms in protein crystals|One approach for determining the molecular structure of proteins is a technique called iso-morphous replacement, in which crystallographers dope protein crystals with heavy atoms, such as mercury or platinum. By comparing measured amplitudes of diffracted x-rays through protein crystals with and without the heavy atoms, the locations of the heavy atoms can be estimated. Once the locations of the heavy atoms are known, the phases of the diffracted x-rays through the protein crystal can be estimated, which in turn enables the structure of the protein to be estimated. Unfortunately, the key step in this process is the estimation of the locations of the heavy atoms, and this is a multi-modal, non-linear inverse problem. We report results of a pilot study that show that a -stage hybrid algorithm, using a stochastic genetic algorithm for stage  followed by a deterministic pattern search algorithm for stage , can successfully locate up to  heavy atoms in computer simulated crystals using noise free data. We conclude that the method may be a viable approach for finding heavy atoms in protein crystals, and suggest ways in which the approach can be scaled up to larger problems.|Joshua L. Payne,Margaret J. Eppstein","57274|GECCO|2005|Heuristic rules embedded genetic algorithm to solve in-core fuel management optimization problem|Because of the large number of possible combinations for the fuel assembly loading in the core, the design of the loading pattern (LP) is a complex optimization problem. It requires finding an optimal fuel arrangement in order to achieve maximum cycle length while satisfying the safety constraints. The objective of this study is to develop a loading pattern optimization code. Generally in-core fuel management codes are written for specific cores and limited fuel inventory. One of the goals of this study is to develop a loading pattern optimization code, which is applicable for all types of Pressurized Water Reactor (PWR) core structures with unlimited number of fuel assembly types in the inventory. To reach this goal an innovative genetic algorithm is developed with modifying the classical representation of the genotype. To obtain the best result in a shorter time not only the representation is changed but also the algorithm is changed to use in-core fuel management heuristics rules. The improved GA code was tested demonstrating the advantages of the introduced enhancements. The core physics code used in this research is Moby-Dick, which was developed to analyze the VVER reactors by SKODA Inc.|Fatih Alim,Kostadin Ivanov","57406|GECCO|2005|Compact genetic algorithm for active interval scheduling in hierarchical sensor networks|This paper introduces a novel scheduling problem called the active interval scheduling problem in hierarchical wireless sensor networks for long-term periodical monitoring applications. To improve the report sensitivity of the hierarchical wireless sensor networks, an efficient scheduling algorithm is desired. In this paper, we propose a compact genetic algorithm (CGA) to optimize the solution quality for sensor network maintenance. The experimental result shows that the proposed CGA brings better solutions in acceptable calculation time.|Ming-Hui Jin,Cheng-Yan Kao,Yu-Cheng Huang,D. Frank Hsu,Ren-Guey Lee,Chih-Kung Lee","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["42663|IEICE Transations|2005|On Linear Least Squares Approach for Phase Estimation of Real Sinusoidal Signals|In this Letter, linear least squares (LLS) techniques for phase estimation of real sinusoidal signals with known or unknown amplitudes are studied. It is proved that the asymptotic performance of the LLS approach attains Cramr-Rao lower bound. For the case of a single tone, a novel LLS algorithm with unit-norm constraint is derived. Simulation results are also included for algorithm evaluation.|Hing-Cheung So","42551|IEICE Transations|2005|Route Selection Metrics in Wireless Mobile Ad Hoc Networks|In this study, we present a way to choose route selection metric while discovering a new route in ad hoc mobile networks. We have used link expiration time and busy rate to calculate the route cost. The route cost is compared to a threshold value to decide whether the traffic of the route is high or low. If it is high then the system chooses busy rate as a route selection metric to avoid traffic congestion and if it is low the link expiration time is used to select the longlasting route. We have examined the characteristics of the routing protocol by computer simulation and found that it over performs the conventional protocols.|Md. Ifte Khairul Hasan,Saburo Takahashi,Jun-ichi Hakoda,Hideyuki Uehara,Mitsuo Yokoyama","42758|IEICE Transations|2005|A Design of Real-Time JPEG Encoder for  Mega Pixel CMOS Image Sensor SoC|In this paper, we propose a hardware architecture of real-time JPEG encoder for . mega pixels CMOS image sensor SoC which can be applied to mobile communication devices. The proposed architecture has an efficient interface scheme with CMOS image sensor and other peripherals for real-time encoding. The JPEG encoder supports the base-line JPEG mode, and processes motion images of which resolution is up to    (CCIR YCrCb , fps) by real-time processing. The JPEG encoder supports  types of resolution, and can serve the  levels of image quality through quantization matrix. The proposed JPEG encoder can transfer encoded motion pictures and raw image data from CMOS image sensor to external device through USB . and a compressed still image is stored at external pseudo SRAM through SRAM interface. And proposed core can communicate parameters of encoding type with other host by IC. The proposed architecture was implemented with VHDL and verified for the functions with Synopsys and Modelsim. The encoder proposed in this paper was fabricated in process of .  of Hynix semiconductor Inc.|Kyeong-Yuk Min,Jong-Wha Chong","42668|IEICE Transations|2005|An Efficient MAC Protocol for Improving the Network Throughput and Energy Efficiency for Ad Hoc Networks|Ad hoc networks are becoming an interesting research area, as they inherently support unique network applications for the wireless communications in a rugged environment, which requires rapid deployment and is difficult to be provided by an infrastructure network. Many issues need to be addressed for the ad hoc networks. In this paper, we propose an efficient distributed coordination function on the media access control protocol to enhance the power conservation of mobile hosts by using a power control algorithm and the network throughput of an ad hoc network by using an algorithm for simultaneous frame transmissions. Extensive simulation is studied to evaluate the improvement of the proposed method. The results of the simulation exhibit significant improvement to the standard access control protocol. With slight improvement of network throughput, up to % of the consumed energy was able to be saved in compared to the standard protocol and up to  times of the energy efficiency was enhanced with the proposed method.|Chien-Yuan Liu,Chun-Hung Lin","43010|IEICE Transations|2005|Variable Frame Skipping Scheme Based on Estimated Quality of Non-coded Frames at Decoder for Real-Time Video Coding|This paper proposes a block-based video encoder employing variable frame skipping (VFS) to improve the video quality in low bit rate channel. The basic idea of VFS mechanism is to decide and skip a suitable, non-fixed number of frames in temporal domain to reduce bit usage. The saved bits can be allocated to enhance the spatial quality of video. In literature, several methods of frame skipping decision have been proposed, but most of them only consider the similarities between neighboring coded frames as the decision criteria. Our proposed method takes into account the reconstruction of the skipped frames using motion-compensated frame interpolation at decoder. The proposed VFS models the reconstructed objective quality of the skipped frame and, therefore, can provide a fast estimate to the frame skipping at encoder. The proposed VFS can determine the suitable frame skipping in real time and provide the encoded video with better spatial-temporal bit allocation.|Tien-Ying Kuo","57565|GECCO|2005|BeeAdHoc an energy efficient routing algorithm for mobile ad hoc networks inspired by bee behavior|In this paper we present BeeAdHoc, a new routing algorithm for energy efficient routing in mobile ad hoc networks. The algorithm is inspired by the foraging principles of honey bees. The algorithm mainly utilizes two types of agents, scouts and foragers, for doing routing in mobile ad hoc networks. BeeAdHoc is a reactive source routing algorithm and it consumes less energy as compared to existing state-of-the-art routing algorithms because it utilizes less control packets to do routing. The results of our extensive simulation experiments show that BeeAdHoc consumes significantly less energy as compared to DSR, AODV, and DSDV, which are state-of-the-art routing algorithms, without making any compromise on traditional performance metrics (packet delivery ratio, delay and throughput).|Horst Wedde,Muddassar Farooq,Thorsten Pannenbaecker,Bjoern Vogel,Christian Mueller,Johannes Meth,Rene Jeruschkat","42529|IEICE Transations|2005|An Optimal Certificate Dispersal Algorithm for Mobile Ad Hoc Networks|In this paper, we focus on the problem that in an ad hoc network, how to send a message securely between two users using the certificate dispersal system. In this system, special data called certificate is issued between two users and these issued certificates are stored among the network. Our final purpose on this certificate dispersal problem is to construct certificate graphs with lower dispersability cost which indicates the average number of certificates stored in each node in an ad hoc network. As our first step, when a certificate graph is given, we construct two efficient certificate dispersal algorithms for strongly connected graphs and directed graphs in this paper. We can show that for a strongly connected graph G  (V, E) and a directed graph H  (V' E'), new upper bounds on dispersability cost on the average number of certificates stored in one node are O(DG + E'V) and O(pGdmax + E'V') respectively, where DG is the diameter of G, dmax is the maximum diameter of strongly connected components of H and pG is the number of strongly connected components of H. Furthermore, we give some new lower bounds for the problem and we also show that our algorithms are optimal for several graph classes.|Hua Zheng,Shingo Omura,Jiro Uchida,Koichi Wada","42534|IEICE Transations|2005|A Power Adapted MAC PAMAC Scheme for Energy Saving in Wireless Ad Hoc Networks|Nowadays, numerous Medium Access Control (MAC) contention protocols for ad hoc networks typically use a fixed transmit power level without using any transmit power control. In this paper, we present an enhancement scheme, called Power Adapted Medium Access Control (PAMAC) scheme for achieving energy conservation, which allows a node to vary its own transmit power on a packet basis. The primary objective of this scheme is to use suitable transmit power level for Clear-To-Send (CTS), DATA, and Acknowledgement (ACK) that still allows to achieve a correct reception of a packet despite intervening path loss, noise and interference. The evaluation of the throughput efficiency per node, energy consumption per node and energy per successfully transmitted bit is performed by a computer simulation. Simulation results indicate that the proposed PAMAC scheme can achieve a high reduction of the energy consumption and energy per successfully transmitted bit and also an improvement in the throughput efficiency per node compared to the conventional Carrier Sense Multiple Access with Collision Avoidance (CSMACA) protocol.|Azman Osman Lim,Susumu Yoshida","42851|IEICE Transations|2005|Real-Time Facial and Eye Gaze Tracking System|The goal of gaze detection is to locate the position (on a monitor) where a user is looking. Previous researches use one wide view camera, which can capture the user's entire face. However, the image resolution is too low with such a camera and the fine movements of user's eye cannot be exactly detected. So, we propose the new gaze detection system with dual cameras (a wide and a narrow view camera). In order to locate the user's eye position accurately, the narrow-view camera has the functionalities of auto focusingpanningtilting based on the detected D eye positions from the wide view camera. In addition, we use the IR-LED illuminators for wide and narrow view camera, which can ease the detecting of facial features, pupil and iris position. To overcome the problem of specular reflection on glasses by illuminator, we use dual IR-LED illuminators for wide and narrow view camera and detect the accurate eye position, which is not hidden by the specular reflection. Experimental results show that the gaze detection error between the computed positions and the real ones is about . cm of RMS error.|Kang Ryoung Park,Jaihie Kim","42673|IEICE Transations|2005|Short-Time Frequency Estimation of a Real Sinusoid|The frequency estimate for a real sinusoid provided by the periodogram has a bias which is particularly severe for a short observation interval. In this paper, two improvements to the periodogram are proposed to reduce this bias. The first method transforms the real tone to a complex sinusoid while the second algorithm subtracts the negative spectral line from the received signal, prior to applying the periodogram. The performance of the two methods is illustrated by comparing with the periodogram and Quinn's interpolation as well as Cramr-Rao lower bound.|Hing-Cheung So,Yiu-Tong Chan"],["42739|IEICE Transations|2005|Convergence Properties of a CORDIC-Based Adaptive ARMA Lattice Filter|This paper presents a theoretical convergence analysis of a CORDIC-based adaptive ARMA lattice filter. In previous literatures, several investigation methods for adaptive lattice filters have been proposed however, they are available only for AR-type filters. Therefore, we have developed a distinct technique that can reveal the convergence properties of the CORDIC ARMA lattice filter. The derived technique provides a quantitative convergence analysis, which facilitates an efficient hardware design for the filter. Moreover, our analysis technique can be applied to popular multiplier-based filters by slight modifications. Hence, the presented convergence analysis is significant as a leading attempt to investigate ARMA lattice filters.|Shin'ichi Shiraishi,Miki Haseyama,Hideo Kitajima","42507|IEICE Transations|2005|Adaptive Mode Control for Low-Power Caches Based on Way-Prediction Accuracy|This paper proposes a novel cache architecture for low power consumption, called \"Adaptive Way-Predicting Cache (AWP cache).\" The AWP cache has multi-operation modes and dynamically adapts the operation mode based on the accuracy of way-prediction results. A confidence counter for way prediction is implemented to each cache set. In order to analyze the effectiveness of the AWP cache, we perform a SRAM design using . m CMOS technology and cycle-accurate processor simulations. As the results, for a benchmark program (.art), it is observed that a performance-aware AWP cache reduces the % of performance overhead caused by an original way-predicting cache to %. Furthermore, a energy-aware AWP cache achieves % of energy reduction, whereas that obtained from the original way-predicting scheme is only %, compared to an non-optimized conventional cache. For the consideration of energy-performance efficiency, we see that the energy-aware AWP cache produces better results the energy-delay product of conventional organization is reduced to only % in average which is % better than the original way-predicting scheme.|Hidekazu Tanaka,Koji Inoue","42437|IEICE Transations|2005|Minimum-Maximum Exclusive Weighted-Mean Filter with Adaptive Window|In this paper, we present a minimum-maximum exclusive weighted-mean filtering algorithm with adaptive window. Image pixels within the varying size of the window are ranked and classified as minimum-maximum and median levels, and then passed through the weighted-mean of median level and identity filters, respectively. The filtering window size is adaptively increasing according to noise ratio without noise measurement. Extensive simulations show that the proposed filter performs better than other medianrank-type filters in removing impulse noise of highly corrupted images.|Jinsung Oh,Changhoon Lee,Younam Kim","42810|IEICE Transations|2005|Self-Adaptive AlgorithmicArchitectural Design for Real-Time Low-Power Video Systems|With reference to video motion estimation in the framework of the new H.AVC video coding standard, this paper presents algorithmic and architectural solutions for the implementation of context-aware coprocessors in real-time, low-power embedded systems. A low-complexity context-aware controller is added to a conventional Full Search (FS) motion estimation engine. While the FS coprocessor is working, the context-aware controller extracts from the intermediate processing results information related to the input signal statistics in order to automatically configure the coprocessor itself in terms of search area size and number of reference frames thus unnecessary computations and memory accesses can be avoided. The achieved complexity saving factor ranges from . to  depending on the input signal while keeping unaltered performance in terms of motion estimation accuracy. The increased efficiency is exploited both for (i) processing time reduction in case of software implementation on a programmable platform (ii) power consumption reduction in case of dedicated hardware implementation in CMOS technology.|Luca Fanucci,Sergio Saponara,Massimiliano Melani,Pierangelo Terreni","42654|IEICE Transations|2005|Bitwidth Optimization for Low Power Digital FIR Filter Design|We propose a novel approach for designing a low power datapath in wireless communication systems. Especially, we focus on the digital FIR filter. Our proposed approach can reduce the power consumption and the circuit area of the digital FIR filter by optimizing the bitwidth of the each filter coefficient with keeping the filter calculation accuracy. At first, we formulate the constraints about keeping accuracy of the filter calculations. We define the problem to find the optimized bitwidth of each filter coefficient. Our defined problem can be solved by using the commercial optimization tool. We evaluate the effects of consuming power reduction by comparing the digital FIR filters designed in the same bitwidth of all coefficients. We confirm that our approach is effective for a low power digital FIR filter.|Kosuke Tarumi,Akihiko Hyodo,Masanori Muroyama,Hiroto Yasuura","42714|IEICE Transations|2005|Suboptimal Adaptive Filter for Discrete-Time Linear Stochastic Systems|This paper considers the problem of recursive filtering for linear discrete-time systems with uncertain observation. A new approximate adaptive filter with a parallel structure is herein proposed. It is based on the optimal mean square combination of arbitrary number of correlated estimates which is also derived. The equation for error covariance characterizing the mean-square accuracy of the new filter is derived. In consequence of parallel structure of the filtering equations the parallel computers can be used for their design. It is shown that this filter is very effective for multisensor systems containing different types of sensors. A practical implementation issue to consider this filter is also addressed. Example demonstrates the accuracy and efficiency of the proposed filter.|Daebum Choi,Vladimir Shin,Jun Il Ahn,Byung-Ha Ahn","16302|IJCAI|2005|Self Adaptive Particle Filter|The particle filter has emerged as a useful tool for problems requiring dynamic state estimation. The efficiency and accuracy of the filter depend mostly on the number of particles used in the estimation and on the propagation function used to reallocate these particles at each iteration. Both features are specified beforehand and are kept fixed in the regular implementation of the filter. In practice this may be highly inappropriate since it ignores errors in the models and the varying dynamics of the processes. This work presents a self adaptive version of the particle filter that uses statistical methods to adapt the number of particles and the propagation function at each iteration. Furthermore, our method presents similar computational load than the standard particle filter. We show the advantages of the self adaptive filter by applying it to a synthetic example and to the visual tracking of targets in a real video sequence.|Alvaro Soto","42725|IEICE Transations|2005|Space-Time-Frequency Turbo Code over Time-Varying and Frequency-Selective Fading Channel|In this paper, we propose and investigate space-time-frequency turbo coded OFDM transmissions through time-varying and frequency-selective fading channel. The proposed turbo code is a serial concatenated convolutional code which consists of space-frequency and time-frequency domain codes. The aim of the proposed turbo code is to obtain both diversity and coding gains over space-time-frequency domain. Using computer simulations and EXtrinsic Information Transfer (EXIT) charts, we investigate the optimum structure of inner and outer codes. Simulations demonstrate that the proposed system leads to significantly enhanced performance. Moreover, we analyze the computational complexity.|Kouji Ishii,Ryuji Kohno","42578|IEICE Transations|2005|Spatio-Temporal Equalization for Space-Time Block Coded Transmission over Frequency Selective Fading Channel with Co-channel Interference|In this paper, we propose a spatio-temporal equalizer for the space-time block coded transmission over the frequency selective fading channels with the presence of co-channel interference (CCI). The proposed equalizer, based on the tapped delay line adaptive array (TDLAA), performs signal equalization and CCI suppression simultaneously using the minimum mean square error (MMSE) method. It is to show that our scheme outperforms the previous two-stage combined adaptive antenna and delayed decision feedback sequence estimator (DDFSE) approach. We also show that performance can be further improved if the synchronization between the preceding and delayed paths is achieved.|Xuan Nam Tran,Tetsuki Taniguchi,Yoshio Karasawa","42963|IEICE Transations|2005|Reconfigurable Adaptive FEC System Based on Reed-Solomon Code with Interleaving|This paper proposes a reconfigurable adaptive FEC system based on Reed-Solomon (RS) code with interleaving. In adaptive FEC schemes, error correction capability t is changed dynamically according to the communication channel condition. For given error correction capability t, we can implement an optimal RS decoder composed of minimum hardware units for each t. If the hardware units of the RS decoder can be reduced for any given error correction capability t, we can embed as large deinterleaver as possible into the RS decoder for each t. Reconfiguring the RS decoder embedded with the expanded deinterleaver dynamically for each error correction capability t allows us to decode larger interleaved codes which are more robust error correction codes to burst errors. In a reliable transport protocol, experimental results show that our system achieves up to % lower packet error rate and .% higher data transmission throughput compared to the adaptive FEC scheme on a conventional fixed hardware system. In an unreliable transport protocol, our system achieves up to % better bit error performance with higher code rate compared to the adaptive FEC scheme on a conventional fixed hardware system.|Kazunori Shimizu,Nozomu Togawa,Takeshi Ikenaga,Satoshi Goto"],["16092|IJCAI|2005|View Learning for Statistical Relational Learning With an Application to Mammography|Statistical relational learning (SRL) constructs probabilistic models from relational databases. A key capability of SRL is the learning of arcs (in the Bayes net sense) connecting entries in different rows of a relational table, or in different tables. Nevertheless, SRL approaches currently are constrained to use the existing database schema. For many database applications, users find it profitable to define alternative \"views\" of the database, in effect defining new fields or tables. Such new fields or tables can also be highly useful in learning. We provide SRL with the capability of learning new views.|Jesse Davis,Elizabeth S. Burnside,In√™s de Castro Dutra,David Page,Raghu Ramakrishnan,V√≠tor Santos Costa,Jude W. Shavlik","16117|IJCAI|2005|Automatic learning of domain model for personalized hypermedia applications|This paper deals with the automatic building of personalized hypermedia. We build upon ideas developed for educational hypermedia the definition of a domain model and the use of overlay user models. Since much work has been done on learning user models and adapting hypermedia based on such models, we tackle the core problem the automatic definition of a domain model for a static hypermedia.|Hermine Njike Fotzo,Thierry Arti√®res,Patrick Gallinari,Julien Blanchard,Guillaume Letellier","42867|IEICE Transations|2005|Extension of Hidden Markov Models for Multiple Candidates and Its Application to Gesture Recognition|We propose a modified Hidden Markov Model (HMM) with a view to improve gesture recognition using a moving camera. The conventional HMM is formulated so as to deal with only one feature candidate per frame. However, for a mobile robot, the background and the lighting conditions are always changing, and the feature extraction problem becomes difficult. It is almost impossible to extract a reliable feature vector under such conditions. In this paper, we define a new gesture recognition framework in which multiple candidates of feature vectors are generated with confidence measures and the HMM is extended to deal with these multiple feature vectors. Experimental results comparing the proposed system with feature vectors based on DCT and the method of selecting only one candidate feature point verifies the effectiveness of the proposed technique.|Yosuke Sato,Tetsuji Ogawa,Tetsunori Kobayashi","42527|IEICE Transations|2005|On the Property of a Discrete Impulse Response Gramian with Application to Model Reduction|It has been observed in the literature that the characteristic polynomial of a discrete system can be computed from the characteristic impulse response Gramian. In this letter it is shown that a given characteristic impulse response Gramian, in fact, contains information on two characteristic polynomials. The importance of this result is illustrated through an application to model reduction of discrete systems.|Younseok Choo","16183|IJCAI|2005|Using Neutral Examples for Learning Polarity|Sentiment analysis is an example of polarity learning. Most research on learning to identify sentiment ignores \"neutral\" examples and instead performs training and testing using only examples of significant polarity. We show that it is crucial to use neutral examples in learning polarity for a variety of reasons and show how neutral examples help us obtain superior classification results in two sentiment analysis test-beds.|Moshe Koppel,Jonathan Schler","80537|VLDB|2005|A Heartbeat Mechanism and Its Application in Gigascope|Data stream management systems often rely on ordering properties of tuple attributes in order to implement non-blocking operators. However, query operators that work with multiple streams, such as stream merge or join, can often still block if one of the input stream is very slow or bursty. In principle, punctuation and heartbeat mechanisms have been proposed to unblock streaming operators. In practice, it is a challenge to incorporate such mechanisms into a high-performance stream management system that is operational in an industrial application.In this paper, we introduce a system for punctuation-carrying heartbeat generation that we developed for Gigascope, a high-performance streaming database for network monitoring, that is operationally used within AT&T's IP backbone. We show how heartbeats can be regularly generated by low-level nodes in query execution plans and propagated upward unblocking all streaming operators on its way. Additionally, our heartbeat mechanism can be used for other applications in distributed settings such as detecting node failures, performance monitoring, and query optimization. A performance evaluation using live data feeds shows that our system is capable of working at multiple Gigabit line speeds in a live, industrial deployment and can significantly decrease the query memory utilization.|Theodore Johnson,S. Muthukrishnan,Vladislav Shkapenyuk,Oliver Spatscheck","42804|IEICE Transations|2005|Query Learning Method for Character Recognition Methods Using Genetic Algorithm|We propose a learning method combining query learning and a \"genetic translator\" we previously developed. Query learning is a useful technique for high-accuracy, high-speed learning and reduction of training sample size. However, it has not been applied to practical optical character readers (OCRs) because human beings cannot recognize queries as character images in the feature space used in practical OCR devices. We previously proposed a character image reconstruction method using a genetic algorithm. This method is applied as a \"translator\" from feature space for query learning of character recognition. The results of an experiment with hand-written numeral recognition show the possibility of training sample size reduction.|Hitoshi Sakano","80528|VLDB|2005|Parallel Execution of Test Runs for Database Application Systems|In a recent paper , it was shown how tests for database application systems can be executed efficiently. The challenge was to control the state of the database during testing and to order the test runs in such a way that expensive reset operations that bring the database into the right state need to be executed as seldom as possible. This work extends that work so that test runs can be executed in parallel. The goal is to achieve linear speed-up andor exploit the available resources as well as possible. This problem is challenging because parallel testing can involve interference between the execution of concurrent test runs.|Florian Haftmann,Donald Kossmann,Eric Lo","42993|IEICE Transations|2005|A Digital Filter for Stochastic Systems with Unknown Structure and Its Application to Psychological Evaluation of Sound Environment|The actual sound environment system exhibits various types of linear and non-linear characteristics, and it often contains an unknown structure. Furthermore, the observations in the sound environment are often in the level-quantized form. In this paper, a method for estimating the specific signal for stochastic systems with unknown structure and the quantized observation is proposed by introducing a system model of the conditional probability type. The effectiveness of the proposed theoretical method is confirmed by applying it to the actual problem of psychological evaluation for the sound environment.|Akira Ikuta,Hisako Masuike,Mitsuo Ohta","65455|AAAI|2005|A Variational Learning Algorithm for the Abstract Hidden Markov Model|We present a fast algorithm for learning the parameters of the abstract hidden Markov model, a type of hierarchical activity recognition model. Learning using exact inference scales poorly as the number of levels in the hierarchy increases therefore, an approximation is required for large models. We demonstrate that variational inference is well suited to solve this problem. Not only does this technique scale. but it also offers a natural way to leverage the context specific independence properties inherent in the model via the fixed point equations. Experiments confirm that the variational approximation significantly reduces the time necessary for learning while estimating parameter values that can be used to make reliable predictions.|Jeffrey Johns,Sridhar Mahadevan"],["57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","42773|IEICE Transations|2005|Dynamic RWA Based on the Combination of Mobile Agents Technique and Genetic Algorithms in WDM Networks with Sparse Wavelength Conversion|Genetic Algorithms (GA) provide an attractive approach to solving the challenging problem of dynamic routing and wavelength assignment (RWA) in optical Wavelength Division Multiplexing (WDM) networks, because they usually achieve a significantly low blocking probability. Available GA-based dynamic RWA algorithms were designed mainly for WDM networks with a wavelength continuity constraint, and they cannot be applied directly to WDM networks with wavelength conversion capability. Furthermore, the available GA-based dynamic RWA algorithms suffer from the problem of requiring a very time consuming process to generate the first population of routes for a request, which may results in a significantly large delay in path setup. In this paper, we study the dynamic RWA problem in WDM networks with sparse wavelength conversion and propose a novel hybrid algorithm for it based on the combination of mobile agents technique and GA. By keeping a suitable number of mobile agents in the network to cooperatively explore the network states and continuously update the routing tables, the new hybrid algorithm can promptly determine the first population of routes for a new request based on the routing table of its source node, without requiring the time consuming process associated with current GA-based dynamic RWA algorithms. To achieve a good load balance in WDM networks with sparse wavelength conversion, we adopt in our hybrid algorithm a new reproduction scheme and a new fitness function that simultaneously takes into account the path length, number of free wavelengths, and wavelength conversion capability in route selection. Our new hybrid algorithm achieves a better load balance and results in a significantly lower blocking probability than does the Fixed-Alternate routing algorithm, both for optical networks with sparse and full-range wavelength converters and for optical networks with sparse and limited-range wavelength converters. This was verified by an extensive simulation study on the ns- network simulator and two typical network topologies. The ability to guarantee both a low blocking probability and a small setup delay makes the new hybrid dynamic RWA algorithm very attractive for current optical circuit switching networks and also for the next generation optical burst switching networks.|Vinh Trong Le,Xiaohong Jiang,Son-Hong Ngo,Susumu Horiguchi","42551|IEICE Transations|2005|Route Selection Metrics in Wireless Mobile Ad Hoc Networks|In this study, we present a way to choose route selection metric while discovering a new route in ad hoc mobile networks. We have used link expiration time and busy rate to calculate the route cost. The route cost is compared to a threshold value to decide whether the traffic of the route is high or low. If it is high then the system chooses busy rate as a route selection metric to avoid traffic congestion and if it is low the link expiration time is used to select the longlasting route. We have examined the characteristics of the routing protocol by computer simulation and found that it over performs the conventional protocols.|Md. Ifte Khairul Hasan,Saburo Takahashi,Jun-ichi Hakoda,Hideyuki Uehara,Mitsuo Yokoyama","16231|IJCAI|2005|Generalization Error of Linear Neural Networks in an Empirical Bayes Approach|It is well known that in unidentifiable models, the Bayes estimation has the advantage of generalization performance to the maximum likelihood estimation. However, accurate approximation of the posterior distribution requires huge computational costs. In this paper, we consider an empirical Bayes approach where a part of the parameters are regarded as hyperparameters, which we call a subspace Bayes approach, and theoretically analyze the generalization error of three-layer linear neural networks. We show that a subspace Bayes approach is asymptotically equivalent to a positivepart James-Stein type shrinkage estimation, and behaves similarly to the Bayes estimation in typical cases.|Shinichi Nakajima,Sumio Watanabe","42566|IEICE Transations|2005|Fair-Efficient Guard Bandwidth Coefficients Selection in Call Admission Control for Mobile Multimedia Communications Using Framework of Game Theory|Call admission control (CAC) plays a significant role in providing the efficient use of the limited bandwidth and the desired quality-of-service (QoS) in mobile multimedia communications. As efficiency is an important performance issue for CAC in the mobile networks with multimedia services, the concept of fairness among services should also be considered. Game theory provides an appropriate framework for formulating such fair and efficient CAC problem. Thus, in this paper, a framework based on game theory (both of noncooperative and cooperative games) is proposed to select fair-efficient guard bandwidth coefficients of the CAC scheme for the asymmetrical traffic case in mobile multimedia communications. The proposed game theoretic framework provides fairness and efficiency in the aspects of bandwidth utilization and QoS for multiple classes of traffic, and also guarantees the proper priority mechanism. Call classes are viewed as the players of a game. Utility function of the player is defined to be of two types, the bandwidth utilization and the weighted sum of new call accepting probability and handoff succeeding probability. The numerical results show that, for both types of the utility function, there is a unique equilibrium point of the noncooperative game for any given offered load. For the cooperative game, the arbitration schemes for the interpersonal comparisons of utility and the bargaining problem are investigated. The results also indicate that, for both types of the utility function, the Nash solution with the origin (,) as the starting point of the bargaining problem can achieve higher total utility than the previous CAC scheme while at the same time providing fairness by satisfying a set of fairness axioms. Since the Nash solution is determined from the domain of the Pareto boundary, the way to generate the Pareto boundary is also provided. Therefore, the Nash solution can be obtained easily.|Jenjoab Virapanicharoen,Watit Benjapolakul","42529|IEICE Transations|2005|An Optimal Certificate Dispersal Algorithm for Mobile Ad Hoc Networks|In this paper, we focus on the problem that in an ad hoc network, how to send a message securely between two users using the certificate dispersal system. In this system, special data called certificate is issued between two users and these issued certificates are stored among the network. Our final purpose on this certificate dispersal problem is to construct certificate graphs with lower dispersability cost which indicates the average number of certificates stored in each node in an ad hoc network. As our first step, when a certificate graph is given, we construct two efficient certificate dispersal algorithms for strongly connected graphs and directed graphs in this paper. We can show that for a strongly connected graph G  (V, E) and a directed graph H  (V' E'), new upper bounds on dispersability cost on the average number of certificates stored in one node are O(DG + E'V) and O(pGdmax + E'V') respectively, where DG is the diameter of G, dmax is the maximum diameter of strongly connected components of H and pG is the number of strongly connected components of H. Furthermore, we give some new lower bounds for the problem and we also show that our algorithms are optimal for several graph classes.|Hua Zheng,Shingo Omura,Jiro Uchida,Koichi Wada","65363|AAAI|2005|Hybrid Possibilistic Networks|Possibilistic networks are important tools for dealing with uncertain pieces of information. For multiply-connected networks, it is well known that the inference process is a hard problem. This paper studies a new representation of possibilistic networks, called hybrid possibilistic networks. The uncertainty is no longer represented by local conditional possibility distributions, but by their compact representations which are possibilistic knowledge bases. We show that the inference algorithm in hybrid networks is strictly more efficient than the ones of standard propagation algorithm.|Salem Benferhat,Salma Smaoui","42720|IEICE Transations|2005|Optimal Call Admission Control for Voice Traffic in Cellular Mobile Communication Networks|We propose a new call admission control (CAC) scheme for voice calls in cellular mobile communication networks. It is assumed that the rejection of a hand-off call is less desirable than that of a new call, for a hand-off call loss would cause a severe mental pain to a user. We consider the pains of rejecting new and hand-off calls as different costs. The key idea of our CAC is to restrict the admission of new calls in order to minimize the total expected costs per unit time over the long term. An optimal policy is derived from a semi-Markov decision process in which the intervals between successive decision epochs are exponentially distributed. Based on this optimal policy, we calculate the steady state probability for the number of established voice connections in a cell. We then evaluate the probability of blocking new calls and the probability of forced termination of hand-off calls. In the numerical experiments, it is found that the forced termination probability of hand-off calls is reduced significantly by our CAC scheme at the slight expense of the blocking probability of new calls and the channel utilization. Comparison with the static guard channel scheme is made.|Minoru Ohmikawa,Hideaki Takagi,Sang-Yong Kim","16296|IJCAI|2005|Decentralized Search in Networks Using Homophily and Degree Disparity|We propose a new algorithm for finding a target node in a network whose topology is known only locally. We formulate this task as a problem of decision making under uncertainty and use the statistical properties of the graph to guide this decision. This formulation uses the homophily and degree structure of the network simultaneously, differentiating our algorithm from those previously proposed in the literature. Because homophily and degree disparity are characteristics frequently observed in real-world networks, the algorithm we propose is applicable to a wide variety of networks, including two families that have received much recent attention small-world and scale-free networks.|√\u2013zg√ºr Simsek,David Jensen","42662|IEICE Transations|2005|History-Based Auxiliary Mobility Management Strategy for Hierarchical Mobile IPv Networks|The reduction of the signaling load associated with IP mobility management is one of the significant challenges to IP mobility support protocols. Hierarchical Mobile IPv (HMIPv) aims to reduce the number of the signaling messages in the backbone networks, and improve handoff performance by reducing handoff latency. However, this does not imply any change to the periodic binding update (BU) to the home agent (HA) and the correspondent node (CN), and now a mobile node (MN) additionally should send it to the mobility anchor point (MAP). Moreover, the MAP should tunnel the received packets to be routed to the MN. These facts mean that the reduction of the BU messages in the backbone networks can be achieved at the expense of the increase in the signaling bandwidth consumption within a MAP domain. On the other hand, it is observed that an MN may habitually stay for a relatively long time or spend on using much Internet in a specific cell (hereafter, home cell) covering its home, office or laboratory, etc. Thus, considering the preceding facts and observation, HMIPv may not be favorable especially during a home cell residence time in terms of signaling bandwidth consumption. To overcome these drawbacks of HMIPv, we propose a history-based auxiliary mobility management strategy (H-HMIPv) to enable an MN to selectively switch its mobility management protocols according to whether it is currently in its home cell or not in HMIPv networks. The operation of H-HMIPv is almost the same as that of HMIPv except either when an MN entersleaves its home cell or while it stays in its home cell. Once an MN knows using its history that it enters its home cell, it behaves as if it operates in Mobile IPv (MIPv), not in HMIPv, until it leaves its home cell No periodic BU messages to the MAP and no packet tunneling occur during the MN's home cell residence time. The numerical results indicate that compared with HMIPv, H-HMIPv has apparent potential to reduce the signaling bandwidth consumption and the MAP blocking probability.|Ki-Sik Kong,Sung-Ju Roh,Chong-Sun Hwang"]]}}