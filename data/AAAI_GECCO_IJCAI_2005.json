{"abstract":{"entropy":6.806471456181441,"topics":["natural language, machine learning, learning, learning classifier, planning domains, support vector, data mining, vector machine, machine data, present learning, approach learning, reinforcement learning, model-based diagnosis, systems based, based reasoning, vector svm, learning systems, support machine, learning example, learning sequential","constraint satisfaction, arc consistency, constraint problem, problem, markov decision, solving problem, satisfaction problem, consider problem, quantified boolean, constraint, optimization problem, disjunctive temporal, logic programs, partially observable, value variables, constraint planning, algorithms constraint, markov mdps, search constraint, boolean satisfiability","genetic algorithms, evolutionary algorithms, genetic programming, algorithms, present algorithms, particle swarm, evolutionary optimization, present approach, algorithms optimization, present, search algorithms, present novel, particle pso, present model, web search, bayesian networks, fitness function, belief change, present based, swarm pso","agents, combinatorial auctions, issue scene, consider agents, self-interested agents, sensor networks, classifier xcs, multi-agent systems, computational model, agents conditions, agents coalitions, increasingly important, autonomous robot, real-world application, control robot, negotiation agents, mobile robot, agents environments, systems increasingly, robot","natural language, description logic, language generation, context natural, actions effects, natural generation, natural systems, language systems, space, actions, rules, processing, developed, word, reason, find, sense, idea, situations, extension","machine learning, support vector, vector machine, data mining, learning data, machine data, vector svm, support machine, machine svm, neural networks, data, learning model, vector data, model dynamical, support data, machine, model, task, text, game","disjunctive temporal, disjunctive problem, introduce problem, recent years, framework problem, introduce semantic, present framework, framework, introduce framework, introduce, general, recent, complex, allows, software, paper, propositional, semantic, define, like","solving problem, markov decision, partially observable, algorithms solving, decision problem, markov mdps, decision mdps, markov processes, problem backbone, decision processes, evolutionary computation, markov model, decision, solving, model, evolutionary, decomposition, provide, state, approximate","evolutionary algorithms, algorithms optimization, particle swarm, evolutionary optimization, optimization problem, particle pso, novel algorithms, swarm pso, estimation algorithms, algorithms eas, hybrid algorithms, estimation distribution, evolutionary eas, swarm algorithms, distribution algorithms, swarm optimization, particle optimization, estimation model, present estimation, evolutionary problem","selection algorithms, bayesian networks, selection genetic, genetic population, performance algorithms, feature selection, negative selection, given problem, scheduling problem, selection problem, efficient algorithms, given, proposes, generic, commonly, analyze, approaches, individuals, optimisation, attention","self-interested agents, agents, agents coalitions, negotiation agents, agents environments, process, systems agents, environments, communication, order, challenges, key, automated, objects, automatically, interaction, computing, cost, computer, open","computational model, time, major, data, issue, computational, complexity, accurate, recognition, concept, prediction, analysis, robotics, structure, general, learn, explores, central, detect, experiments"],"ranking":[["57472|GECCO|2005|Extraction of informative genes from microarray data|Identification of those genes that might anticipate the clinical behavior of different types of cancers is challenging due to availability of a smaller number of patient samples compared to huge number of genes, and the noisy nature of microarray data. After selection of some good genes based on signal-to-noise ratio, unsupervised learning like clustering and supervised learning like k-nearest neighbor (kNN) classifier are widely used in cancer researches to correlate the pathological behavior of cancers with the gene expression levels' differences in cancerous and normal tissues. By applying adaptive searches like Probabilistic Model Building Genetic Algorithm (PMBGA), it may be possible to get a smaller size gene subset that would classify patient samples more accurately than the above methods. In this paper, we propose a new PMBGA based method to extract informative genes from microarray data using Support Vector Machine (SVM) as a classifier. We apply our method to three microarray data sets and present the experimental results. Our method with SVM obtains encouraging results on those data sets as compared with the rank based method using kNN as a classifier.|Topon Kumar Paul,Hitoshi Iba","65477|AAAI|2005|Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts|Automatic document summarization is a problem of creating a document surrogate that adequately represents the full document content. We aim at a summarization system that can replicate the quality of summaries created by humans. In this paper we investigate the machine learning method for extracting full sentences from documents based on the document semantic graph structure. In particular, we explore how the Support Vector Machines (SVM) learning method is affected by the quality of linguistic analyses and the corresponding semantic graph representations. We apply two types of linguistic analysis () a simple part-of-speech tagging of noun phrases and verbs and () full logical form analysis which identifies Subject-Predicate-Object triples, and then build the semantic graphs. We train the SVM classifier to identify summary nodes and use these nodes to extract sentences. Experiments with the DUC  and CAST datasets show that the SVM based extraction of sentences does not differ significantly for the simple and the sophisticated syntactic analysis. In both cases the graph attributes used in learning are essential for the classifier performance and the quality of extracted summaries.|Jure Leskovec,Natasa Milic-Frayling,Marko Grobelnik","65605|AAAI|2005|Unsupervised and Semi-Supervised Multi-Class Support Vector Machines|We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.|Linli Xu,Dale Schuurmans","16233|IJCAI|2005|A Machine Learning Approach to Identification and Resolution of One-Anaphora|We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.|Hwee Tou Ng,Yu Zhou,Robert Dale,Mary Gardiner","16303|IJCAI|2005|Beyond TFIDF Weighting for Text Categorization in the Vector Space Model|KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.|Pascal Soucy,Guy W. Mineau","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","65497|AAAI|2005|Giving Advice about Preferred Actions to Reinforcement Learners Via Knowledge-Based Kernel Regression|We present a novel formulation for providing advice to a reinforcement learner that employs support-vector regression as its function approximator. Our new method extends a recent advice-giving technique, called Knowledge-Based Kernel Regression (KBKR), that accepts advice concerning a single action of a reinforcement learner. In KBKR, users can say that in some set of states, an action's value should be greater than some linear expression of the current state. In our new technique, which we call Preference KBKR (Pref-KBKR), the user can provide advice in a more natural manner by recommending that some action is preferred over another in the specified set of states. Specifying preferences essentially means that users are giving advice about policies rather than Q values, which is a more natural way for humans to present advice. We present the motivation for preference advice and a proof of the correctness of our extension to KBKR. In addition, we show empirical results that our method can make effective use of advice on a novel reinforcement-learning task, based on the RoboCup simulator, which we call Breakaway. Our work demonstrates the significant potential of advice-giving techniques for addressing complex reinforcement learning problems, while further demonstrating the use of support-vector regression for reinforcement learning.|Richard Maclin,Jude W. Shavlik,Lisa Torrey,Trevor Walker,Edward W. Wild","65604|AAAI|2005|Software Testing by Active Learning for Commercial Games|As software systems have become larger, exhaustive testing has become increasingly onerous. This has rendered statistical software testing and machine learning techniques increasingly attractive. Drawing from both of these, we present an active learning framework for blackbox software testing. The active learning approach samples inputoutput pairs from a blackbox and learns a model of the system's behaviour. This model is then used to select new inputs for sampling. This framework has been developed in the context of commercial video games, complex virtual worlds with high-dimensional state spaces, too large for exhaustive testing. Beyond its correctness, developers need to evaluate the gameplay of a game, properties such as difficulty. We use the learned model not only to guide sampling but also to summarize the game's behaviour for the developer to evaluate. We present results from our semi-automated gameplay analysis by machine learning (SAGA-ML) tool applied to Electronics Arts' FIFA Soccer game.|Gang Xiao,Finnegan Southey,Robert C. Holte,Dana F. Wilkinson"],["16119|IJCAI|2005|The Rules of Constraint Modelling|Many and diverse combinatorial problems have been solved successfully using finite-domain constraint programming. However, to apply constraint programming to a particular domain, the problem must first be modelled as a constraint satisfaction or optimisation problem. Since constraints provide a rich language, typically many alternative models exist. Formulating a good model therefore requires a great deal of expertise. This paper describes CONJURE, a system that refines a specification of a problem in the abstract constraint specification language ESSENCE into a set of alternative constraint models. Refinement is compositional alternative constraint models are generated by composing refinements of the components of the specification. Experimental results demonstrate that CONJURE is able to generate a variety of models for practical problems from their ESSENCE specifications.|Alan M. Frisch,Christopher Jefferson,Bernadette Martínez Hernández,Ian Miguel","16190|IJCAI|2005|An MCMC Approach to Solving Hybrid Factored MDPs|Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.|Branislav Kveton,Milos Hauskrecht","16133|IJCAI|2005|The Complexity of Quantified Constraint Satisfaction Problems under Structural Restrictions|We give a clear picture of the tractabilityintractability frontier for quantified constraint satisfaction problems (QCSPs) under structural restrictions. On the negative side, we prove that checking QCSP satisfiability remains PSPACE-hard for all known structural properties more general than bounded treewidth and for the incomparable hypergraph acyclicity. Moreover, if the domain is not fixed, the problem is PSPACE-hard even for tree-shaped constraint scopes. On the positive side, we identify relevant tractable classes, including QCSPs with prefix  having bounded hypertree width, and QCSPs with a bounded number of guards. The latter are solvable in polynomial time without any bound on domains or quantifier alternations.|Georg Gottlob,Gianluigi Greco,Francesco Scarcello","16209|IJCAI|2005|Identifying Conflicts in Overconstrained Temporal Problems|We describe a strong connection between maximally satisfiable and minimally unsatisfiable subsets of constraint systems. Using this relationship, we develop a two-phase algorithm, employing powerful constraint satisfaction techniques, for the identification of conflicting sets of constraints in infeasible constraint systems. We apply this technique to overconstrained instances of the Disjunctive Temporal Problem (DTP), an expressive form of temporal constraint satisfaction problems. Using randomly-generated benchmarks, we provide experimental results that demonstrate how the algorithm scales with problem size and constraint density.|Mark H. Liffiton,Michael D. Moffitt,Martha E. Pollack,Karem A. Sakallah","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","65502|AAAI|2005|A Framework for Representing and Solving NP Search Problems|NP search and decision problems occur widely in AI, and a number of general-purpose methods for solving them have been developed. The dominant approaches include propositional satisfiability (SAT), constraint satisfaction problems (CSP), and answer set programming (ASP). Here, we propose a declarative constraint programming framework which we believe combines many strengths of these approaches, while addressing weaknesses in each of them. We formalize our approach as a model extension problem, which is based on the classical notion of extension of a structure by new relations. A parameterized version of this problem captures NP. We discuss properties of the formal framework intended to support effective modelling, and prospects for effective solver design.|David G. Mitchell,Eugenia Ternovska","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder","16286|IJCAI|2005|Structural Symmetry Breaking|Symmetry breaking has been shown to be an important method to speed up the search in constraint satisfaction problems that contain symmetry. When breaking symmetry by dominance detection, a computationally efficient symmetry breaking scheme can be achieved if we can solve the dominance detection problem in polynomial time. We study the complexity of dominance detection when value and variable symmetry appear simultaneously in constraint satisfaction problems (CSPs) with single-valued variables and set-CSPs. We devise an efficient dominance detection algorithm for CSPs with single-valued variables that yields symmetry-free search trees and that is based on the abstraction to the actual, intuitive structure of a symmetric CSP.|Meinolf Sellmann,Pascal Van Hentenryck","16299|IJCAI|2005|Value Ordering for Finding All Solutions|In finding all solutions to a constraint satisfaction problem, or proving that there are none, with a search algorithm that backtracks chronologically and forms k-way branches, the order in which the values are assigned is immaterial. However, we show that if the values of a variable are assigned instead via a sequence of binary choice points, and the removal of the value just tried from the domain of the variable is propagated before another value is selected, the value ordering can affect the search effort. We show that this depends on the problem constraints for some types of constraints, we show that the savings in search effort can be significant, given a good value ordering.|Barbara M. Smith,Paula Sturdy"],["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["65394|AAAI|2005|Robust and Self-Repairing Formation Control for Swarms of Mobile Agents|We describe a decentralized algorithm for coordinating a swarm of identically-programmed mobile agents to spatially self-aggregate into arbitrary shapes using only local interactions. Our approach, called SHAPEBUGS, generates a consensus coordinate system by agents continually performing local trilaterations, and achieves shape formation by simultaneously allowing agents to disperse within the defined D shape using a Contained Gas Model. This approach has several novel features () agents can easily aggregate into arbitrary user-specified shapes, using a formation process that is independent of the number of agents () the system automatically adapts to influx and death of agents, as well as accidental displacement. We show that the consensus coordinate system is robust and provides reasonable accuracy in the face of significant sensor and movement error.|Jimming Cheng,Winston Cheng,Radhika Nagpal","65428|AAAI|2005|Agent-Organized Networks for Multi-Agent Production and Exchange|As multi-agent systems grow in size and complexity, social networks that govern the interactions among the agents will directly impact system behavior at the individual and collective levels. Examples of such large-scale, networked multi-agent systems include peer-to-peer networks, distributed information retrieval, and agent-based supply chains. One way of dealing with the uncertain and dynamic nature of such environments is to endow agents with the ability to modify the agent social network by autonomously adapting their local connectivity structure. In this paper, we present a framework for agent-organized networks (AONs) in the context of multi-agent production and exchange, and experimentally evaluate the feasibility and efficiency of specific AON strategies. We find that decentralized network adaptation can significantly improve organizational performance. Additionally, we analyze several properties of the resulting network structures and consider their relationship to the observed increase in organizational performance.|Matthew E. Gaston,Marie desJardins","65566|AAAI|2005|OAR A Formal Framework for Multi-Agent Negotiation|In Multi-Agent systems, agents often need to make decisions about how to interact with each other when negotiating over task allocation. In this paper, we present OAR, a formal framework to address the question of how the agents should interact in an evolving environment in order to achieve their different goals. The traditional categorization of self-interested and cooperative agents is unified by adopting a utility view. We illustrate mathematically that the degree of cooperativeness of an agent and the degree of its selfdirectness are not directly related. We also show how OAR can be used to evaluate different negotiation strategies and to develop distributed mechanisms that optimize the performance dynamically. This research demonstrates that sophisticated probabilistic modeling can be used to understand the behaviors of a system with complex agent interactions.|Jiaying Shen,Ingo Weber,Victor R. Lesser","16335|IJCAI|2005|Coalitional Games in Open Anonymous Environments|Coalition formation is a key aspect of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts (such as the Shapley value, core, least core, and nucleolus) have been proposed. In this paper, we demonstrate how these concepts are vulnerable to various kinds of manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names (one acting as many), collusion (many acting as one), and the hiding of skills. To address these threats, we introduce a new solution concept called the anonymity-proof core, which is robust to these manipulations. We show that the anonymity-proof core is characterized by certain simple axiomatic conditions. Furthermore, we show that by relaxing these conditions, we obtain a concept called the least anonymity-proof core, which is guaranteed to be non-empty. We also show that computational hardness of manipulation may provide an alternative barrier to manipulation.|Makoto Yokoo,Vincent Conitzer,Tuomas Sandholm,Naoki Ohta,Atsushi Iwasaki","16041|IJCAI|2005|Sequential-Simultaneous Information Elicitation in Multi-Agent Systems|We introduce a general setting for information elicitation in multi-agent systems, where agents may be approached both sequentially and simultaneously in order to compute a function that depends on their private secrets. We consider oblivious mechanisms for sequential-simultaneous information elicitation. In such mechanisms the ordering of agents to be approached is fixed in advance. Surprisingly, we show that these mechanisms, which are easy to represent and implement are sufficient for very general settings, such as for the classical uniform model, where agents' secret bits are uniformly distributed, and for the computation of the majority function and other classical threshold functions. Moreover, we provide efficient algorithms for the verification of the existence of the desired elicitation mechanisms, and for synthesizing such mechanisms.|Gal Bahar,Moshe Tennenholtz","65374|AAAI|2005|Coordination and Adaptation in Impromptu Teams|Coordinating a team of autonomous agents is one of the major challenges in building effective multiagcnt systems. Many techniques have been devised for this problem. and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques. though. is that the team members are developed together as a whole. In many multi agent scenarios. this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills. models. strategies. and coordination mechanisms. and no external organization is imposed upon them. In particular. we propose two techniques. one adaptive and one predictive. for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.|Michael H. Bowling,Peter McCracken","65560|AAAI|2005|Cooperative Exploration in the Electronic Marketplace|In this paper we study search strategies of agents that represent buyer agents' coalitions in electronic marketplaces. The representative agents operate in environments where numerous potential complex opportunities can be found. Each opportunity is associated with several different terms and conditions thus differing from other opportunities by its value for the coalition. Given a search cost, the goal of the representative agent is to find the best set of opportunities which fulfills the coalition's demands with the maximum overall utility, to be divided among the coalition members. Given the option of side-payments, this strategy will always be preferred by all coalition members (thus no conflict of interests), regardless of the coalition's payoff division protocol. We analyze the incentive to form such coalitions and extract the optimal search strategy for their representative agents, with a distinction between operating in BC and CC markets. Based on our findings we suggest efficient algorithms to be used by the representative agents for calculating a strategy that maximizes their expected utilities. A computational-based example is given, illustrating the achieved performance as a function of the coalition's members' heterogeneity level.|David Sarne,Sarit Kraus","57342|GECCO|2005|The emulation of social institutions as a method of coevolution|This paper offers a novel approach to coevolution based on the sociological theory of symbolic interactionism. It provides a multi-agent computational model along with experimental results that suggest improved fitness, robustness, and knowledge due to emergent symbol systems. The main contribution of the symbolic-interactionist approach to coevolution is the concept of the emergence of a system in the abstract, where an interface between agents evolves. The interface is an emergent symbol system that focuses selective pressure among agents in ways that have been beneficial to agents as a whole in the past, creating a coevolving system that takes advantage of epistasis rather than having to prevent it. Global fitness thereby emerges from local, selfish interaction. The assignment of roles in this system is endogenous.|Deborah Vakas Duong,John J. Grefenstette","16258|IJCAI|2005|PsychSim Modeling Theory of Mind with Decision-Theoretic Agents|Agent-based modeling of human social behavior is an increasingly important research area. A key factor in human social interaction is our beliefs about others, a theory of mind. Whether we believe a message depends not only on its content but also on our model of the communicator. How we act depends not only on the immediate effect but also on how we believe others will react. In this paper, we discuss PsychSim, an implemented multiagent-based simulation tool for modeling interactions and influence. While typical approaches to such modeling have used first-order logic, Psych-Sim agents have their own decision-theoretic model of the world, including beliefs about its environment and recursive models of other agents. Using these quantitative models of uncertainty and preferences, we have translated existing psychological theories into a decision-theoretic semantics that allow the agents to reason about degrees of believability in a novel way. We discuss PsychSim's underlying architecture and describe its application to a school violence scenario for illustration.|David V. Pynadath,Stacy Marsella","65611|AAAI|2005|Coalitional Games in Open Anonymous Environments|Coalition formation is a key aspect of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts (such as the Shapley value, core, least core, and nucleolus) have been proposed. In this paper, we demonstrate how these concepts are vulnerable to various kinds of manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names (one acting as many), collusion (many acting as one), and the hiding of skills. To address these threats, we introduce a new solution concept called the anonymity-proof core, which is robust to these manipulations. We show that the anonymity-proof core is characterized by certain simple axiomatic conditions. Furthermore, we show that by relaxing these conditions, we obtain a concept called the least anonymity-proof core, which is guaranteed to be non-empty. We also show that computational hardness of manipulation may provide an alternative barrier to manipulation.|Makoto Yokoo,Vincent Conitzer,Tuomas Sandholm,Naoki Ohta,Atsushi Iwasaki"],["16122|IJCAI|2005|Feature Generation for Text Categorization Using World Knowledge|We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.|Evgeniy Gabrilovich,Shaul Markovitch","65528|AAAI|2005|SenseRelate  TargetWord-A Generalized Framework for Word Sense Disambiguation|Many words in natural language have different meanings when used in different contexts. Sense Relate Target Word is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet Similarity measure of relatedness.|Siddharth Patwardhan,Satanjeev Banerjee,Ted Pedersen","16157|IJCAI|2005|MDL-based Acquisition of Substitutability Relationships between Discourse Connectives|Knowledge of which lexical items convey the same meaning in a given context is important for many Natural Language Processing tasks. This paper concerns the substitutability of discourse connectives in particular. This paper proposes a datadriven method based on a Minimum Description Length (MDL) criterion for automatically learning substitutability of connectives. The method is shown to outperform two baseline classifiers.|Ben Hutchinson","57572|GECCO|2005|Use of a genetic algorithm in brills transformation-based part-of-speech tagger|The tagging problem in natural language processing is to find a way to label every word in a text as a particular part of speech, e.g., proper noun. An effective way of solving this problem with high accuracy is the transformation-based or \"Brill\" tagger. In Brill's system, a number of transformation templates are specified a priori that are instantiated and ranked during a greedy search-based algorithm. This paper describes a variant of Brill's implementation that instead uses a genetic algorithm to generate the instantiated rules and provide an adaptive ranking. Based on tagging accuracy, the new system provides a better hybrid evolutionary computation solution to the part-of-speech (POS) problem than the previous attempt. Although not able to make up for the use of a priori knowledge utilized by Brill, the method appears to point the way for an improved solution to the tagging problem.|Garnett Carl Wilson,Malcolm I. Heywood","16329|IJCAI|2005|Appropriate Microplanning Choices for Low-Skilled Readers|We have developed a set of microplanning choice rules which are intended to enable Natural Language Generation (NLG) systems to generate appropriate texts for readers with below-average literacy, focusing in particular on choices related to how discourse structure is expressed (cue phrases, ordering, sentence structure). Evaluation experiments suggest that our rules do enhance the readability of texts for low-skilled readers, although there is still room for improvement.|Sandra Williams,Ehud Reiter","16336|IJCAI|2005|Extraction of Hierarchies Based on Inclusion of Co-occurring Words with Frequency Information|In this paper, we propose a method of automatically extracting word hierarchies based on the inclusion relations of word appearance patterns in corpora. We applied the complementary similarity measure (CSM) to determine a hierarchical structure of word meanings. The CSM is a similarity measure developed for recognizing degraded machine-printed text. There are CSMs for both binary and gray-scale images. The CSM for binary images has been applied to estimate one-to-many relations, such as superordinate-subordinate relations, and to extract word hierarchies. However, the CSM for gray-scale images has not been applied to natural language processing. Here, we apply the latter to extract word hierarchies from corpora. To do this, we used frequency information for co-occurring words, which is not considered when using the CSM for binary images. We compared our hierarchies with those obtained using the CSM for binary images, and evaluated them by measuring their degree of agreement with the EDR electronic dictionary.|Eiko Yamamoto,Kyoko Kanzaki,Hitoshi Isahara","16304|IJCAI|2005|Evaluating an NLG System using Post-Editing|Computer-generated texts, whether from Natural Language Generation (NLG) or Machine Translation (MT) systems, are often post-edited by humans before being released to users. The frequency and type of post-edits is a measure of how well the system works, and can be used for evaluation. We describe how we have used post-edit data to evaluate SUMTIME-MOUSAM, an NLG system that produces weather forecasts.|Somayajulu Sripada,Ehud Reiter,Lezan Hawizy","65460|AAAI|2005|Learning to Transform Natural to Formal Languages|This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains.|Rohit J. Kate,Yuk Wah Wong,Raymond J. Mooney","65530|AAAI|2005|Identifying Similar Words and Contexts in Natural Language with SenseClusters|SenseClusters is a freely available intelligent system that clusters together similar contexts in natural language text. Thereafter it assigns identifying labels to these clusters based on their content. It is a purely unsupervised approach that is language independent, and uses no knowledge other than what is available in raw un-annotated corpora. In addition to clustering similar contexts, it can be used to identify synonyms and sets of related words. It has been applied to a diverse range of problems, including proper name disambiguation, word sense discrimination, email organization, and document clustering. SenseClusters is a complete system that supports feature selection from large corpora, several different context representation schemes, various clustering algorithms, the creation of descriptive and discriminating labels for the discovered clusters, and evaluation relative to gold standard data.|Ted Pedersen,Anagha Kulkarni","16058|IJCAI|2005|Viewing Referring Expression Generation as Search|Almost all natural language generation (NLG) systems are faced with the problem of the generation of referring expressions (GRE) given a symbol corresponding to an intended referent, how do we work out the semantic content of a referring expression that uniquely identifies the entity in question This is now one of the most widely explored problems in NLG over the last  years, a number of algorithms have been proposed for addressing different aspects of this problem, but the different approaches taken make it very difficult to compare and contrast the algorithms provided in any meaningful way. In this paper, we show how viewing the problem of referring expression generation as a search problem allows us to recast existing algorithms in a way that makes their similarities and differences clear.|Bernd Bohnet,Robert Dale"],["57472|GECCO|2005|Extraction of informative genes from microarray data|Identification of those genes that might anticipate the clinical behavior of different types of cancers is challenging due to availability of a smaller number of patient samples compared to huge number of genes, and the noisy nature of microarray data. After selection of some good genes based on signal-to-noise ratio, unsupervised learning like clustering and supervised learning like k-nearest neighbor (kNN) classifier are widely used in cancer researches to correlate the pathological behavior of cancers with the gene expression levels' differences in cancerous and normal tissues. By applying adaptive searches like Probabilistic Model Building Genetic Algorithm (PMBGA), it may be possible to get a smaller size gene subset that would classify patient samples more accurately than the above methods. In this paper, we propose a new PMBGA based method to extract informative genes from microarray data using Support Vector Machine (SVM) as a classifier. We apply our method to three microarray data sets and present the experimental results. Our method with SVM obtains encouraging results on those data sets as compared with the rank based method using kNN as a classifier.|Topon Kumar Paul,Hitoshi Iba","65477|AAAI|2005|Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts|Automatic document summarization is a problem of creating a document surrogate that adequately represents the full document content. We aim at a summarization system that can replicate the quality of summaries created by humans. In this paper we investigate the machine learning method for extracting full sentences from documents based on the document semantic graph structure. In particular, we explore how the Support Vector Machines (SVM) learning method is affected by the quality of linguistic analyses and the corresponding semantic graph representations. We apply two types of linguistic analysis () a simple part-of-speech tagging of noun phrases and verbs and () full logical form analysis which identifies Subject-Predicate-Object triples, and then build the semantic graphs. We train the SVM classifier to identify summary nodes and use these nodes to extract sentences. Experiments with the DUC  and CAST datasets show that the SVM based extraction of sentences does not differ significantly for the simple and the sophisticated syntactic analysis. In both cases the graph attributes used in learning are essential for the classifier performance and the quality of extracted summaries.|Jure Leskovec,Natasa Milic-Frayling,Marko Grobelnik","65605|AAAI|2005|Unsupervised and Semi-Supervised Multi-Class Support Vector Machines|We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.|Linli Xu,Dale Schuurmans","16303|IJCAI|2005|Beyond TFIDF Weighting for Text Categorization in the Vector Space Model|KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.|Pascal Soucy,Guy W. Mineau","65427|AAAI|2005|A Hybrid GenerativeDiscriminative Approach to Semi-Supervised Classifier Design|Semi-supervised classifier design that simultaneously utilizes both labeled and unlabeled samples is a major research issue in machine learning. Existing semisupervised learning methods belong to either generative or discriminative approaches. This paper focuses on probabilistic semi-supervised classifier design and presents a hybrid approach to take advantage of the generative and discriminative approaches. Our formulation considers a generative model trained on labeled samples and a newly introduced bias correction model. Both models belong to the same model family. The proposed hybrid model is constructed by combining both generative and bias correction models based on the maximum entropy principle. The parameters of the bias correction model are estimated by using training data, and combination weights are estimated so that labeled samples are correctly classified. We use naive Bayes models as the generative models to apply the hybrid approach to text classification problems. In our experimental results on three text data sets, we confirmed that the proposed method significantly outperformed pure generative and discriminative methods when the classification performances of the both methods were comparable.|Akinori Fujino,Naonori Ueda,Kazumi Saito","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","57566|GECCO|2005|Automatic feature selection in neuroevolution|Feature selection is the process of finding the set of inputs to a machine learning algorithm that will yield the best performance. Developing a way to solve this problem automatically would make current machine learning methods much more useful. Previous efforts to automate feature selection rely on expensive meta-learning or are applicable only when labeled training data is available. This paper presents a novel method called FS-NEAT which extends the NEAT neuroevolution method to automatically determine an appropriate set of inputs for the networks it evolves. By learning the network's inputs, topology, and weights simultaneously, FS-NEAT addresses the feature selection problem without relying on meta-learning or labeled data. Initial experiments in an autonomous car racing simulation demonstrate that FS-NEAT can learn better and faster than regular NEAT. In addition, the networks it evolves are smaller and require fewer inputs. Furthermore, FS-NEAT's performance remains robust even as the feature selection task it faces is made increasingly difficult.|Shimon Whiteson,Peter Stone,Kenneth O. Stanley,Risto Miikkulainen,Nate Kohl","65525|AAAI|2005|Redescription Mining Structure Theory and Algorithms|We introduce a new data mining problem--redescription mining--that unifies considerations of conceptual clustering, constructive induction, and logical formula discovery. Redescription mining begins with a collection of sets, views it as a propositional vocabulary, and identifies clusters of data that can be defined in at least two ways using this vocabulary. The primary contributions of this paper are conceptual and theoretical (i) we formally study the space of redescriptions underlying a dataset and characterize their intrinsic structure, (ii) we identify impossibility as well as strong possibility results about when mining redescriptions is feasible, (iii) we present several scenarios of how we can custom-build redescription mining solutions for various biases, and (iv) we outline how many problems studied in the larger machine learning community are really special cases of redescription mining. By highlighting its broad scope and relevance. we aim to establish the importance of redescription mining and make the case for a thrust in this new line of research.|Laxmi Parida,Naren Ramakrishnan","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","65555|AAAI|2005|Learning Static Object Segmentation from Motion Segmentation|Dividing an image into its constituent objects can be a useful first step in many visual processing tasks, such as object classification or determining the arrangement of obstacles in an environment. Motion segmentation is a rich source of training data for learning to segment objects by their static image properties. Background subtraction can distinguish between moving objects and their surroundings, and the techniques of statistical machine learning can capture information about objects' shape, size. color, brightness, and texture properties. Presented with a new, static image, the trained model can infer the proper segmentation of the objects present in a scene. The algorithm presented in this work uses the techniques of Markov random field modeling and belief propagation inference, outperforms a standard segmentation algorithm on an object segmentation task, and outperforms a learned boundary detector at determining object boundaries on the test data.|Michael G. Ross,Leslie Pack Kaelbling"],["65503|AAAI|2005|Augmenting Disjunctive Temporal Problems with Finite-Domain Constraints|We present a general framework for augmenting instances of the Disjunctive Temporal Problem (DTP) with finite-domain constraints. In this new formalism, the bounds of the temporal constraints become conditional on the finite-domain assignment. This hybridization makes it possible to reason simultaneously about temporal relationships between events as well as their nontemporal properties. We provide a special case of this hybridization that allows reasoning about a limited form of spatial constraints namely, the travel time induced by the locations of a set of activities. We develop a least-commitment algorithm for efficiently finding solutions to this combined constraint system and provide empirical results demonstrating the effectiveness of our approach.|Michael D. Moffitt,Bart Peintner,Martha E. Pollack","16322|IJCAI|2005|Disjunctive Temporal Planning with Uncertainty|Driven by planning problems with both disjunctive constraints and contingency, we define the Disjunctive Temporal Problem with Uncertainty (DTPU), an extension of the DTP that includes contingent events. Generalizing existing work on Simple Temporal Problems with Uncertainty, we divide the time-points into controllable and uncontrollable classes, and propose varying notions of controllability to replace the notion of consistency.|Kristen Brent Venable,Neil Yorke-Smith","16235|IJCAI|2005|Possibilistic Stable Models|In this work, we define a new framework in order to improve the knowledge representation power of Answer Set Programming paradigm. Our proposal is to use notions from possibility theory to extend the stable model semantics by taking into account a certainty level, expressed in terms of necessity measure, on each rule of a normal logic program. First of all, we introduce possibilistic definite logic programs and show how to compute the conclusions of such programs both in syntactic and semantic ways. The syntactic handling is done by help of a fix-point operator, the semantic part relies on a possibility distribution on all sets of atoms and we show that the two approaches are equivalent. In a second part, we define what is a possibilistic stable model for a normal logic program, with default negation. Again, we define a possibility distribution allowing to determine the stable models.|Pascal Nicolas,Laurent Garcia,Igor Stéphan","16196|IJCAI|2005|Resolution in Max-SAT and its relation to local consistency in weighted CSPs|Max-SAT is an optimization version of the well-known SAT problem. It is of great importance from both a theoretical and a practical point of view. In recent years, there has been considerable interest in finding efficient solving techniques Alsinet et al.,  Xing and Zhang,  Shen and Zhang,  de Givry et al., . Most of this work focus on the computation of good quality lower bounds to be used within a branch and bound algorithm. Unfortunately, lower bounds are described in a procedural way. Because of that, it is difficult to realize the logic that is behind. In this paper we introduce a logical framework for Max-SAT solving. Using this framework, we introduce an extension of the Davis-Putnam algorithm (that we call Max-DPLL) and the resolution rule. Our framework has the advantage of nicely integrating branch and bound concepts such as the lower and upper bound, as well as hiding away implementation details. We show that Max-DPLL augmented with a restricted form of resolution at each branching point is an effective solving strategy. We also show that the resulting algorithm is closely related with some local consistency properties developed for weighted constraint satisfaction problems.|Javier Larrosa,Federico Heras","16083|IJCAI|2005|A Unified Theory of Structural Tractability for Constraint Satisfaction and Spread Cut Decomposition|In this paper we introduce a generic form of structural decomposition for the constraint satisfaction problem, which we call a guarded decomposition. We show that many existing decomposition methods can be characterized in terms of finding guarded decompositions satisfying certain specified additional conditions. Using the guarded decomposition framework we are also able to define a new form of decomposition, which we call a spread cut. We show that discovery of width k spread-cut decompositions is tractable for each k, and that the spread cut decomposition strongly generalize all existing decompositions except hypertrees. Finally we exhibit a family of hypergraphs Hn, for n  , ,  ..., where the width of the best hypertree decomposition of each Hn is at least n, but the width of the best spreadcut decomposition is at most n.|David A. Cohen,Peter Jeavons,Marc Gyssens","65382|AAAI|2005|Prioritized Component Systems|We introduce a flexible framework to specify problem solutions (outcomes) and preferences among them. The proposal combines ideas from answer-set programming (ASP), answer-set optimization (ASO) and CP-nets. The problem domain is structured into components. ASP techniques are used to specify values of components, as well as global (intercomponent) constraints among these values. ASO methods are used to describe preferences among the values of a component and CP-net techniques to represent intercomponent dependencies and corresponding preferences.|Gerhard Brewka,Ilkka Niemelä,Miroslaw Truszczynski","65467|AAAI|2005|Heterogeneous Multirobot Coordination with Spatial and Temporal Constraints|Existing approaches to multirobot coordination separate scheduling and task allocation, but finding the optimal schedule with joint tasks and spatial constraints requires robots to simultaneously solve the scheduling, task allocation, and path planning problems. We present a formal description of the multirobot joint task allocation problem with heterogeneous capabilities and spatial constraints and an instantiation of the problem for the search and rescue domain. We introduce a novel declarative framework for modeling the problem as a mixed integer linear programming (MILP) problem and present a centralized anytime algorithm with error bounds. We demonstrate that our algorithm can outperform standard MILP solving techniques, greedy heuristics, and a market based approach which separates scheduling and task allocation.|Mary Koes,Illah R. Nourbakhsh,Katia P. Sycara","16104|IJCAI|2005|On Solution Correspondences in Answer-Set Programming|We introduce a general framework for specifying program correspondence under the answer-set semantics. The framework allows to define different kinds of equivalence notions, including previously defined notions like strong and uniform equivalence, in which programs are extended with rules from a given context, and correspondence is determined by means of a binary relation. In particular, refined equivalence notions based on projected answer sets can be defined within this framework, where not all parts of an answer set are of relevance. We study general characterizations of inclusion and equivalence problems, introducing novel semantical structures. Furthermore, we deal with the issue of determining counterexamples for a given correspondence problem, and we analyze the computational complexity of correspondence checking.|Thomas Eiter,Hans Tompits,Stefan Woltran","16102|IJCAI|2005|Updating Action Domain Descriptions|How can an intelligent agent update her knowledge base about an action domain, relative to some conditions (possibly obtained from earlier observations) We study this question in a formal framework for reasoning about actions and change, in which the meaning of an action domain description can be represented by a directed graph whose nodes correspond to states and whose edges correspond to action occurrences. We define the update of an action domain description in this framework, and show among other results that a solution to this problem can be obtained by a divide-and-conquer approach in some cases. We also introduce methods to compute a solution and an approximate solution to this problem, and analyze the computational complexity of these problems. Finally, we discuss techniques to improve the quality of solutions.|Thomas Eiter,Esra Erdem,Michael Fink,Ján Senko","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons"],["65511|AAAI|2005|Error Bounds for Approximate Value Iteration|Approximate Value Iteration (AVI) is an method for solving a Markov Decision Problem by making successive calls to a supervised learning (SL) algorithm. Sequence of value representations Vn are processed iteratively by Vn+  ATVn where T is the Bellman operator and A an approximation operator. Bounds on the error between the performance of the policies induced by the algorithm and the optimal policy are given as a function of weighted Lp-norms (p  ) of the approximation errors. The results extend usual analysis in L-norm, and allow to relate the performance of AVI to the approximation power (usually expressed in Lp-norm, for p   or ) of the SL algorithm. We illustrate the tightness of these bounds on an optimal replacement problem.|Rémi Munos","16147|IJCAI|2005|Solving POMDPs with Continuous or Large Discrete Observation Spaces|We describe methods to solve partially observable Markov decision processes (POMDPs) with continuous or large discrete observation spaces. Realistic problems often have rich observation spaces, posing significant problems for standard POMDP algorithms that require explicit enumeration of the observations. This problem is usually approached by imposing an a priori discretisation on the observation space, which can be sub-optimal for the decision making task. However, since only those observations that would change the policy need to be distinguished, the decision problem itself induces a lossless partitioning of the observation space. This paper demonstrates how to find this partition while computing a policy, and how the resulting discretisation of the observation space reveals the relevant features of the application domain. The algorithms are demonstrated on a toy example and on a realistic assisted living task.|Jesse Hoey,Pascal Poupart","65485|AAAI|2005|Risk-Sensitive Planning with One-Switch Utility Functions Value Iteration|Decision-theoretic planning with nonlinear utility functions is important since decision makers are often risk-sensitive in high-stake planning situations. One-switch utility functions are an important class of nonlinear utility functions that can model decision makers whose decisions change with their wealth level. We study how to maximize the expected utility of a Markov decision problem for a given one-switch utility function, which is difficult since the resulting planning problem is not decomposable. We first study an approach that augments the states of the Markov decision problem with the wealth level. The properties of the resulting infinite Markov decision problem then allow us to generalize the standard risk-neutral version of value iteration from manipulating values to manipulating functions that map wealth levels to values. We use a probabilistic blocks-world example to demonstrate that the resulting risk-sensitive version of value iteration is practical.|Yaxin Liu,Sven Koenig","16190|IJCAI|2005|An MCMC Approach to Solving Hybrid Factored MDPs|Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.|Branislav Kveton,Milos Hauskrecht","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","65451|AAAI|2005|Planning in Models that Combine Memory with Predictive Representations of State|Models of dynamical systems based on predictive state representations (PSRs) use predictions of future observations as their representation of state. A main departure from traditional models such as partially observable Markov decision processes (POMDPs) is that the PSR-model state is composed entirely of observable quantities. PSRs have recently been extended to a class of models called memory-PSRs (mPSRs) that use both memory of past observations and predictions of future observations in their state representation. Thus, mPSRs preserve the PSR-property of the state being composed of observable quantities while potentially revealing structure in the dynamical system that is not exploited in PSRs. In this paper, we demonstrate that the structure captured by mPSRs can be exploited quite naturally for stochastic planning based on value-iteration algorithms. In particular, we adapt the incremental-pruning (IP) algorithm defined for planning in POMDPs to mPSRs. Our empirical results show that our modified IP on mPSRs outperforms, in most cases, IP on both PSRs and POMDPs.|Michael R. James,Satinder P. Singh","65422|AAAI|2005|Efficient Maximization in Solving POMDPs|We present a simple, yet effective improvement to the dynamic programming algorithm for solving partially observable Markov decision processes. The technique targets the vector pruning operation during the maximization step, a key source of complexity in POMDP algorithms. We identify two types of structures in the belief space and exploit them to reduce significantly the number of constraints in the linear programs used for pruning. The benefits of the new technique are evaluated both analytically and experimentally, showing that it can lead to significant performance improvement. The results open up new research opportunities to enhance the performance and scalability of several POMDP algorithms.|Zhengzhu Feng,Shlomo Zilberstein","16056|IJCAI|2005|A Decision-Theoretic Approach to Task Assistance for Persons with Dementia|Cognitive assistive technologies that aid people with dementia (such as Alzheimer's disease) hold the promise to provide such people with an increased level of independence. However, to realize this promise, such systems must account for the specific needs and preferences of individuals. We argue that this form of customization requires a sequential, decision-theoretic model of interaction. We describe both fully and partially observable Markov decision process (POMDP) models of a handwashing task, and show that, despite the potential computational complexity, these can be effectively solved and produce policies that are evaluated as useful by professional caregivers.|Jennifer Boger,Pascal Poupart,Jesse Hoey,Craig Boutilier,Geoff Fernie,Alex Mihailidis","65371|AAAI|2005|Lazy Approximation for Solving Continuous Finite-Horizon MDPs|Solving Markov decision processes (MDPs) with continuous state spaces is a challenge due to, among other problems. the well-known curse of dimensionality. Nevertheless, numerous real-world applications such as transportation planning and telescope observation scheduling exhibit a critical dependence on continuous states. Current approaches to continuous-state MDPs include discretizing their transition models. In this paper, we propose and study an alternative, discretization-free approach we call lazy approximation. Empirical study shows that lazy approximation performs much better than discretization, and we successfully applied this new technique to a more realistic planetary rover planning problem.|Lihong Li,Michael L. Littman","65617|AAAI|2005|Planning and Execution with Phase Transitions|We consider a special type of continuous-time Markov decision processes (MDPs) that arise when phase-type distributions are used to model the timing of non-Markovian events and actions. We focus, primarily, on the execution of phase-dependent policies. Phases are introduced into a model to represent relevant execution history, but there is no physical manifestation of phases in the real world. We treat phases as partially observable state features and show how a belief distribution over phase configurations can be derived from observable state features through the use of transient analysis for Markov chains. This results in an efficient method for phase tracking during execution that can be combined with the QMDP value method for POMDPs to make action choices. We also discuss, briefly, how the structure of MDPs with phase transitions can be exploited in structured value iteration with symbolic representation of vectors and matrices.|Håkan L. S. Younes"],["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57501|GECCO|2005|Real-coded crossover as a role of kernel density estimation|This paper presents a kernel density estimation method by means of real-coded crossovers. Estimation of density algorithms (EDAs) are evolutionary optimization techniques, which determine the sampling strategy by means of a parametric probabilistic density function estimated from the population. Real-coded Genetic Algorithm (RCGA) does not explicitly estimate any probabilistic distribution, however, the probabilistic model of the population is implicitly estimated by crossovers and the sampling strategy is determined by this implicit probabilistic model. Based on this understanding, we propose a novel density estimation algorithm by using crossovers as nonparametric kernels and apply this kernel density estimation to the Gaussian Mixture modeling. We show that the proposed method is superior in the robustness of the computation and in the accuracy of the estimation by the comparison of conventional EM estimation.|Jun Sakuma,Shigenobu Kobayashi","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57584|GECCO|2005|MRI magnet design search space analysis EDAs and a real-world problem with significant dependencies|This paper introduces the design of superconductive magnet configurations in Magnetic Resonance Imaging (MRI) systems as a challenging real-world problem for Evolutionary Algorithms (EAs). Analysis of the problem structure is conducted using a general statistical method, which could be easily applied to other problems. The results suggest that the problem is highly multimodal and likely to present a significant challenge for many algorithms. Through a series of preliminary experiments, a continuous Estimation of Distribution Algorithm (EDA) is shown to be able to generate promising designs with a small computational effort. The importance of utilizing problem-specific knowledge and the ability of an algorithm to capture dependencies in solving complex real-world problems is also highlighted.|Bo Yuan,Marcus Gallagher,Stuart Crozier","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57421|GECCO|2005|Fitness uniform deletion a simple way to preserve diversity|A commonly experienced problem with population based optimisation methods is the gradual decline in population diversity that tends to occur over time. This can slow a system's progress or even halt it completely if the population converges on a local optimum from which it cannot escape. In this paper we present the Fitness Uniform Deletion Scheme (FUDS), a simple but somewhat unconventional approach to this problem. Under FUDS the deletion operation is modified to only delete those individuals which are \"common\" in the sense that there exist many other individuals of similar fitness in the population. This makes it impossible for the population to collapse to a collection of highly related individuals with similar fitness. Our experimental results on a range of optimisation problems confirm this, in particular for deceptive optimisation problems the performance is significantly more robust to variation in the selection intensity.|Shane Legg,Marcus Hutter","57266|GECCO|2005|Goal-oriented preservation of essential genetic information by offspring selection|This contribution proposes an enhanced and generic selection model for Genetic Algorithms (GAs) and Genetic Programming (GP) which is able to preserve the alleles which are part of a high quality solution. Some selected aspects of these enhanced techniques are discussed exemplarily on the basis of standardized benchmark problems.|Michael Affenzeller,Stefan Wagner 0002,Stephan M. Winkler","57362|GECCO|2005|Feature influence for evolutionary learning|This paper presents an approach that deals with the feature selection problem, and includes two main aspects first, the selection is done during the evolutionary learning process, i.e., it is a dynamic approach and second, the selection is local, i.e., the algorithm selects the best features from the best space region to learn at a given time of the exploration process. While the traditional feature selection is based on the attribute relevance, our approach is based on a new concept, called feature influence, which is aware of the dynamics and locality of the concept. The feature influence provides a measure of the attribute relevance at a certain instant of the evolutionary learning process, since it depends on each generation. Experimental results have been obtained by comparing an EA--based supervised learning algorithm to its modified version to include the concept approached. The results show an excellent performance, as the new adapted algorithm achieves the same classification results while using less rules, less conditions in rules and much less generations. The experiments include the statistical significance of the improvement over a set of sixteen datasets from the UCI repository.|Raúl Giráldez,Jesús S. Aguilar-Ruiz","57375|GECCO|2005|Applying both positive and negative selection to supervised learning for anomaly detection|This paper presents a novel approach of applying both positive selection and negative selection to supervised learning for anomaly detection. It first learns the patterns of the normal class via co-evolutionary genetic algorithm, which is inspired from the positive selection, and then generates synthetic samples of the anomaly class, which is based on the negative selection in the immune system. Two algorithms about synthetic generation of the anomaly class are proposed. One deals with data sets containing a few anomalous samples while the other deals with data sets containing no anomalous samples at all. The experimental results on some benchmark data sets from UCI data set repertory show that the detection rate is improved evidently, accompanied by a slight increase in false alarm rate via introducing novel synthetic samples of the anomaly class. The advantages of our method are the increased ability of classifiers in identifying both previously known and innovative anomalies, and the maximal degradation of overfitting phenomenon.|Xiaoshu Hang,Honghua Dai","57454|GECCO|2005|Optimizing parameters of a mobile ad hoc network protocol with a genetic algorithm|Mobile ad hoc networks are typically designed and evaluated in generic simulation environments. However the real conditions in which these networks are deployed can be quite different in terms of RF attentution, topology, and traffic load. Furthermore, specific situations often have a need for a network that is optimized along certain characteristics such as delay, energy or overhead. In response to the variety of conditions and requirements, ad hoc networking protocols are often designed with many modifiable parameters. However, there is currently no methodical way for choosing values for the parameters other than intuition and broad experience. In this paper we investigate the use of genetic algorithms for automated selection of parameters in an ad hoc networking system. We provide experimental results demonstrating that the genetic algorithm can optimize for different classes of operating conditions. We also compare our genetic algorithm optimization against hand-tuning in a complex, realistic scenario and show how the genetic algorithm provides better performance.|David J. Montana,Jason Redi","57468|GECCO|2005|A hardware pipeline for function optimization using genetic algorithms|Genetic Algorithms (GAs) are very commonly used as function optimizers, basically due to their search capability. A number of different serial and parallel versions of GA exist. In this paper, a pipelined version of the commonly used Genetic Algorithms and a corresponding hardware platform is described. The main idea of achieving pipelined execution of different operations of GA is to use a stochastic selection function which works with the fitness value of the candidate chromosome only. The modified algorithm is termed PLGA (Pipelined Genetic Algorithm). When executed in a CGA (Classical Genetic Algorithm) framework, the stochastic selection gives comparable performances with the roulette-wheel selection. In the pipelined hardware environment, PLGA will be much faster than the CGA. When executed on similar hardware platforms, PLGA may attain a maximum speedup of four over CGA. However, if CGA is executed in a uniprocessor system the speedup is much more. A comparison of PLGA against PGA (Parallel Genetic Algorithms) shows that PLGA may be even more effective than PGAs. A scheme for realizing the hardware pipeline is also presented. Since a general function evaluation unit is essential, a detailed description of one such unit is presented.|Malay Kumar Pakhira,Rajat K. De","57541|GECCO|2005|Is negative selection appropriate for anomaly detection|Negative selection algorithms for hamming and real-valued shape-spaces are reviewed. Problems are identified with the use of these shape-spaces, and the negative selection algorithm in general, when applied to anomaly detection. A straightforward self detector classification principle is proposed and its classification performance is compared to a real-valued negative selection algorithm and to a one-class support vector machine. Earlier work suggests that real-value negative selection requires a single class to learn from. The investigations presented in this paper reveal, however, that when applied to anomaly detection, the real-valued negative selection and self detector classification techniques require positive and negative examples to achieve a high classification accuracy. Whereas, one-class SVMs only require examples from a single class.|Thomas Stibor,Philipp H. Mohr,Jonathan Timmis,Claudia Eckert","57567|GECCO|2005|A genetic algorithm approach to the selection of near-optimal subsets from large sets|The problem attempted in this paper is to select a sample from a large set where the sample is required to have a particular average property. The problem can be expressed as an optimisation problem where one selects a subset of r objects from a group of n objects and the objective function is the mismatch between the required average property and that of a proposed sample. We test our method on a real-life problem which arises when we model the assets of a life insurance company in order to understand its risk, solvency andor capital requirements.In this paper we describe a genetic algorithm developed to solve the generic selection task. We demonstrate the algorithm successfully solving our test problem.|P. Whiting,P. W. Poon,J. N. Carter","57423|GECCO|2005|ARGEN  AREPO mixing the artificial genetic engineering and artificial evolution of populations to improve the search process|In this paper we analyze the performance of several evolutionary algorithms in the feature and instance selection problem. It is also introduced the ARGEN + AREPO search algorithm which has been tested in the same problem. There is no need to adapt parameters in this genetic algorithm, except the population size. The reported preliminary results show that using this technique in a wrapper model to search data subsets, we can obtain accuracy similar to the obtained with some of the genetic algorithms models here presented, but with less data.|Agustín León-Barranco,Sandra E. Barajas,Carlos A. Reyes García"],["65409|AAAI|2005|An Extended Protocol for Multiple-Issue Concurrent Negotiation|Negotiation is the technique for reaching mutually beneficial agreement among agent via communication. A concurrent negotiation problem occurs when an agent needs to negotiate with multiple agents to reach agreement. In this paper, we present a protocol to support many-to-many bilateral multiple-issue negotiation in a competitive environment. The protocol is presented in the context of service-oriented negotiation, where one or more self-interested parties can provide services to one or more other parties. By extending existing negotiation protocols, our described protocol enables both service requestors and service providers to manage several negotiation processes in parallel. Moreover, this protocol mitigates the situation where most one-to-many negotiations are biased in favor of one participating agent, and allow the negotiation participants to make durable commitments to reduce the decommitment situation. We conclude by discussing additional issues related to concurrent multiple-issue negotiation.|Jiangbo Dang,Michael N. Huhns","16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","65561|AAAI|2005|Solving the Auction-Based Task Allocation Problem in an Open Environment|In this paper we analyze the process of allocating tasks to self-interested agents in uncertain changing open environments. The allocator in our model is responsible for the performance of dynamically arriving tasks using a second price reverse auction as the allocation protocol. Since the agents are self-interested (i.e. each agent attempts to maximize its own revenue), previous models concerning cooperative agents aiming for a joint goal are not applicable. Thus the main challenge is to identify a set of equilibrium strategies - a stable solution where no agent can benefit from changing its strategy given the other agents' strategies - for any specific environmental settings. We formulate the model and discuss the difficulty in extracting the agents' equilibrium strategies directly from the model's equations. Consequently we propose an efficient algorithm to accurately approximate the agents' equilibrium strategies. A comparative illustration through simulation of the system performance in a closed and open environments is given, emphasizing the advantage of the allocator operating in the latter environment, reaching results close to those obtained by a central enforceable allocation.|David Sarne,Sarit Kraus","65587|AAAI|2005|Observation-based Model for BDI-Agents|We present a new computational model of BDI-agents, called the observation-based BDI-model. The key point of this BDI-model is to express agents' beliefs, desires and intentions as a set of runs (computing paths), which is exactly a system in the interpreted system model, a well-known agent model due to Halpern and his colleagues. Our BDI-model is computationally grounded in that we are able to associate the BDI-agent model with a computer program, and formulas, involving agents' beliefs, desires (goals) and intentions, can be understood as properties of program computations. We present a sound and complete proof system with respect to our BDI-model and explore how symbolic model checking techniques can be applied to model checking BDI-agents. In order to make our BDI-model more flexible and practically realistic, we generalize it so that agents can have multiple sources of beliefs, goals and intentions.|Kaile Su,Abdul Sattar,Kewen Wang,Xiangyu Luo,Guido Governatori,Vineet Padmanabhan","65566|AAAI|2005|OAR A Formal Framework for Multi-Agent Negotiation|In Multi-Agent systems, agents often need to make decisions about how to interact with each other when negotiating over task allocation. In this paper, we present OAR, a formal framework to address the question of how the agents should interact in an evolving environment in order to achieve their different goals. The traditional categorization of self-interested and cooperative agents is unified by adopting a utility view. We illustrate mathematically that the degree of cooperativeness of an agent and the degree of its selfdirectness are not directly related. We also show how OAR can be used to evaluate different negotiation strategies and to develop distributed mechanisms that optimize the performance dynamically. This research demonstrates that sophisticated probabilistic modeling can be used to understand the behaviors of a system with complex agent interactions.|Jiaying Shen,Ingo Weber,Victor R. Lesser","16335|IJCAI|2005|Coalitional Games in Open Anonymous Environments|Coalition formation is a key aspect of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts (such as the Shapley value, core, least core, and nucleolus) have been proposed. In this paper, we demonstrate how these concepts are vulnerable to various kinds of manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names (one acting as many), collusion (many acting as one), and the hiding of skills. To address these threats, we introduce a new solution concept called the anonymity-proof core, which is robust to these manipulations. We show that the anonymity-proof core is characterized by certain simple axiomatic conditions. Furthermore, we show that by relaxing these conditions, we obtain a concept called the least anonymity-proof core, which is guaranteed to be non-empty. We also show that computational hardness of manipulation may provide an alternative barrier to manipulation.|Makoto Yokoo,Vincent Conitzer,Tuomas Sandholm,Naoki Ohta,Atsushi Iwasaki","65374|AAAI|2005|Coordination and Adaptation in Impromptu Teams|Coordinating a team of autonomous agents is one of the major challenges in building effective multiagcnt systems. Many techniques have been devised for this problem. and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques. though. is that the team members are developed together as a whole. In many multi agent scenarios. this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills. models. strategies. and coordination mechanisms. and no external organization is imposed upon them. In particular. we propose two techniques. one adaptive and one predictive. for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.|Michael H. Bowling,Peter McCracken","65560|AAAI|2005|Cooperative Exploration in the Electronic Marketplace|In this paper we study search strategies of agents that represent buyer agents' coalitions in electronic marketplaces. The representative agents operate in environments where numerous potential complex opportunities can be found. Each opportunity is associated with several different terms and conditions thus differing from other opportunities by its value for the coalition. Given a search cost, the goal of the representative agent is to find the best set of opportunities which fulfills the coalition's demands with the maximum overall utility, to be divided among the coalition members. Given the option of side-payments, this strategy will always be preferred by all coalition members (thus no conflict of interests), regardless of the coalition's payoff division protocol. We analyze the incentive to form such coalitions and extract the optimal search strategy for their representative agents, with a distinction between operating in BC and CC markets. Based on our findings we suggest efficient algorithms to be used by the representative agents for calculating a strategy that maximizes their expected utilities. A computational-based example is given, illustrating the achieved performance as a function of the coalition's members' heterogeneity level.|David Sarne,Sarit Kraus","65611|AAAI|2005|Coalitional Games in Open Anonymous Environments|Coalition formation is a key aspect of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts (such as the Shapley value, core, least core, and nucleolus) have been proposed. In this paper, we demonstrate how these concepts are vulnerable to various kinds of manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names (one acting as many), collusion (many acting as one), and the hiding of skills. To address these threats, we introduce a new solution concept called the anonymity-proof core, which is robust to these manipulations. We show that the anonymity-proof core is characterized by certain simple axiomatic conditions. Furthermore, we show that by relaxing these conditions, we obtain a concept called the least anonymity-proof core, which is guaranteed to be non-empty. We also show that computational hardness of manipulation may provide an alternative barrier to manipulation.|Makoto Yokoo,Vincent Conitzer,Tuomas Sandholm,Naoki Ohta,Atsushi Iwasaki","65545|AAAI|2005|Distributing Coalitional Value Calculations among Cooperative Agents|The process of forming coalitions of software agents generally requires calculating a value for every possible coalition which indicates how beneficial that coalition would be if it was formed. Now, since the number of possible coalitions increases exponentially with the number of agents involved, having one agent calculate all the values is inefficient. Given this, we present a novel algorithm for distributing this calculation among agents in cooperative environments. Specifically, by using our algorithm, each agent is assigned some part of the calculation such that the agents' shares are exhaustive and disjoint. Moreover, the algorithm is decentralized, requires no communication between the agents, and has minimal memory requirements. To evaluate the effectiveness of our algorithm we compare it with the only other algorithm available in the literature (due to Shehory and Kraus). This shows that for the case of  agents, the distribution process of our algorithm took .% of the time, the values were calculated using .% of the memory, the calculation redundancy was reduced from  to , and the total number of bytes sent between the agents dropped from  to  (note that for larger numbers of agents, these improvements become exponentially better).|Talal Rahwan,Nicholas R. Jennings"],["16159|IJCAI|2005|Combining Structural Descriptions and Image-based Representations for Image Object and Scene Recognition|Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.|Nicolas Do Huu,Williams Paquier,Raja Chatila","65606|AAAI|2005|Using Modified Lasso Regression to Learn Large Undirected Graphs in a Probabilistic Framework|Learning the structures of large undirected graphs with thousands of nodes from data has been an open challenge. In this paper, we use graphical Gaussian model (GGM) as the underlying model and propose a novel ARD style Wishart prior for the precision matrix of the GGM. which encodes the graph structure we want to learn. With this prior, we can get the MAP estimation of the precision matrix by solving (a modified version of) Lasso regressions and achieve a sparse solution. We use our approach to learn genetic regulatory networks from genome-wide expression microarray data and protein-binding location analysis data. Evaluated on the basis of consistency with the GO annotations, the experiments show that our approach has a much better performance than the clustering-based approaches and BN learning approaches in discovering gene regulatory modules.|Fan Li,Yiming Yang","57584|GECCO|2005|MRI magnet design search space analysis EDAs and a real-world problem with significant dependencies|This paper introduces the design of superconductive magnet configurations in Magnetic Resonance Imaging (MRI) systems as a challenging real-world problem for Evolutionary Algorithms (EAs). Analysis of the problem structure is conducted using a general statistical method, which could be easily applied to other problems. The results suggest that the problem is highly multimodal and likely to present a significant challenge for many algorithms. Through a series of preliminary experiments, a continuous Estimation of Distribution Algorithm (EDA) is shown to be able to generate promising designs with a small computational effort. The importance of utilizing problem-specific knowledge and the ability of an algorithm to capture dependencies in solving complex real-world problems is also highlighted.|Bo Yuan,Marcus Gallagher,Stuart Crozier","57314|GECCO|2005|MDGA motif discovery using a genetic algorithm|Computationally identifying transcription factor binding sites in the promoter regions of genes is an important problem in computational biology and has been under intensive research for a decade. To predict the binding site locations efficiently, many algorithms that incorporate either approximate or heuristic techniques have been developed. However, the prediction accuracy is not satisfactory and binding site prediction thus remains a challenging problem. In this paper, we develop an approach that can be used to predict binding site motifs using a genetic algorithm. Based on the generic framework of a genetic algorithm, the approach explores the search space of all possible starting locations of the binding site motifs in different target sequences with a population that undergoes evolution. Individuals in the population compete to participate in the crossovers and mutations occur with a certain probability. Initial experiments demonstrated that our approach could achieve high prediction accuracy in a small amount of computation time. A promising advantage of our approach is the fact that the computation time does not explicitly depend on the length of target sequences and hence may not increase significantly when the target sequences become very long.|Dongsheng Che,Yinglei Song,Khaled Rasheed","16206|IJCAI|2005|Location-Based Activity Recognition using Relational Markov Networks|In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.|Lin Liao,Dieter Fox,Henry A. Kautz","16131|IJCAI|2005|The computational complexity of dominance and consistency in CP-nets|We investigate the computational complexity of testing dominance and consistency in CP-nets. Previously, the complexity of dominance has been determined for restricted classes in which the dependency graph of the CP-net is acyclic. However, there are preferences of interest that define cyclic dependency graphs these are modeled with general CP-nets. In our main results, we show here that both dominance and consistency for general CP-nets are PSPACE-complete. We then consider the concept of strong dominance, dominance equivalence and dominance incomparability, and several notions of optimality, and identify the complexity of the corresponding decision problems. The reductions used in the proofs are from STRIPS planning, and thus reinforce the earlier established connections between both areas.|Judy Goldsmith,Jérôme Lang,Miroslaw Truszczynski,Nic Wilson","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","65609|AAAI|2005|Bitbots Simple Robots Solving Complex Tasks|Sensing uncertainty is a central issue in robotics. Sensor limitations often prevent accurate state estimation, and robots find themselves confronted with a complicated infonnation (belief) space. In this paper we define and characterize the information spaces of very simple robots, called Bitbots, which have severe sensor limitations. While complete estimation of the robot's state is impossible, careful consideration and management of the uncertainty is presented as a search in the information space. We show that these simple robots can solve several challenging online problems, even though they can neither obtain a complete map of their environment nor exactly localize themselves. However, when placed in an unknown environment, Bitbots can build a topological representation of it and then perform pursuit-evasion (i.e., locate all moving targets inside this environment). This paper introduces Bitbots, and provides both theoretical analysis of their information spaces and simulation results.|Anna Yershova,Benjamín Tovar,Robert Ghrist,Steven M. LaValle","65610|AAAI|2005|Activity Recognition through Goal-Based Segmentation|A major issue in activity recognition in a sensor network is how to automatically segment the low-level signal sequences in order to optimize the probabilistic recognition models for goals and activities. Past efforts have relied on segmenting the signal sequences by hand, which is both time-consuming and error-prone. In our view, segments should correspond to atomic human activities that enable a goal-recognizer to operate optimally the two are intimately related. In this paper, we present a novel method for building probabilistic activity models at the same time as we segment signal sequences into motion patterns. We model each motion pattern as a linear dynamic model and the transitions between motion patterns as a Markov process conditioned on goals. Our EM learning algorithm simultaneously learns the motion-pattern boundaries and probabilistic models for goals and activities, which in turn can be used to accurately recognize activities in an online phase. A major advantage of our algorithm is that it can reduce the human effort in segmenting and labeling signal sequences. We demonstrate the effectiveness of our algorithm using the data collected in a real wireless environment.|Jie Yin,Dou Shen,Qiang Yang,Ze-Nian Li","57444|GECCO|2005|Using evolutionary optimization to improve Markov-based classification with limited training data|Bayesian classification using Markov model analysis of token strings is used in many areas such as computational linguistics, speech recognition, and bioinformatics. Unfortunately, for many problems, the available data sets are too small to accurately estimate the large number of parameters in a Markov model. In our work, we explore the possibility of using string space transformations to reduce the perplexity of the modeling problem and thereby improve model performance. The set of all possible string-to-string transformation functions is very large. By using a genetic algorithm to search for transformation functions that improve the performance of a Markov-based classifier, we are able to construct a classifier system that performs better than the Markov classifier alone. We go on to demonstrate the improved performance on the problem of classifying English and Spanish character strings, where training set size is arbitrarily limited.|Timothy Meekhof,Robert B. Heckendorn"]]},"title":{"entropy":6.21720706383947,"topics":["models for, differential evolution, for function, artificial immune, local search, combinatorial auctions, vector machine, support vector, neural networks, support machine, system for, dynamic environments, phase transition, search and, models, multimodal optimization, function optimization, and evolution, evolution strategies, with search","genetic algorithm, algorithm for, algorithm the, genetic programming, the problems, genetic for, evolutionary algorithm, using genetic, for the, for problems, evolutionary for, the, the and, and genetic, evolutionary the, using algorithm, and algorithm, for, genetic the, for scheduling","with algorithm, with genetic, particle swarms, for optimization, particle optimization, sense disambiguation, word sense, method for, word disambiguation, swarms optimization, with, constraint optimization, estimation distribution, estimation and, optimization algorithm, for with, multiobjective optimization, distribution algorithm, optimization with, for robot","learning for, distributed pomdps, solving problems, natural language, and, bayesian networks, for and, and constraint, constraint satisfaction, framework for, description logic, classifier system, learning, planning for, logic programs, representation and, for constraint, reasoning, planning domains, reinforcement learning","system for, artificial immune, for networks, neural networks, markov models, the artificial, training networks, the system, and system, training for, and artificial, immune system, networks, strategy for, system, networks models, system using, markov networks, artificial system, and networks","for function, differential evolution, and evolution, evolution for, multimodal optimization, strategies for, function optimization, using evolution, and strategies, evolution strategies, differential for, the function, for multimodal, with evolution, multimodal function, analysis for, analysis the, the evolution, with function, function and","from the, for data, from data, from, evolving for, for text, web, evolving, automatic, extraction, supervised, towards, relation, theory, statistical, finite, mining, between, ranking, collaborative","algorithm the, for the, the problems, evolutionary algorithm, the and, genetic the, the, evolutionary the, evolutionary for, evolutionary and, evolutionary computation, algorithm problems, and population, evolutionary problems, analysis the, computation the, the impact, algorithm for, and algorithm, large-scale","particle swarms, for optimization, particle optimization, method for, swarms optimization, optimization, for classification, approach for, for swarms, approach, classification, exploiting, communication, interactive, virtual, xcs, autonomous, filtering","optimization algorithm, multiobjective optimization, for control, constrained optimization, optimization with, multi-objective optimization, hybrid approach, for multiple, optimization and, hybrid for, for mobile, algorithm for, for optimization, with algorithm, control, hybrid, mobile, networks, fitness, sequence","learning for, learning and, learning, natural language, language for, reinforcement learning, learning games, for inference, learning language, inference, formulas, coordination, concepts, formal, online, robot, complex, propositional","and constraint, distributed pomdps, for constraint, constraint satisfaction, distributed and, for case-based, for satisfaction, structural and, combining and, constraint pomdps, temporal and, with constraint, constraint problems, distributed constraint, semantic for, for and, temporal, semantic, hierarchical, localization"],"ranking":[["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57463|GECCO|2005|Enhancing differential evolution performance with local search for high dimensional function optimization|In this paper, we proposed Fittest Individual Refinement (FIR), a crossover based local search method for Differential Evolution (DE). The FIR scheme accelerates DE by enhancing its search capability through exploration of the neighborhood of the best solution in successive generations. The proposed memetic version of DE (augmented by FIR) is expected to obtain an acceptable solution with a lower number of evaluations particularly for higher dimensional functions. Using two different implementations DEfirDE and DEfirSPX we showed that proposed FIR increases the convergence velocity of DE for well known benchmark functions as well as improves the robustness of DE against variation of population. Experiments using multimodal landscape generator showed our proposed algorithms consistently outperformed their parent algorithms. A performance comparison with reported results of well known real coded memetic algorithms is also presented.|Nasimul Noman,Hitoshi Iba","57555|GECCO|2005|Using evolutionary computation methods to support analytical models for the evolution and maintenance of conditional strategies in |Biologists have developed models to explain why different environmentally induced morphs of the same organism exist over time. Such conditional strategies are a common form of adaptation to variable environments, whereby an environmental cue allows some individuals to respond to the cue and develop into a morph that is different from the morph of individuals that do not receive the cue. Recently, these efforts have resulted in two different analytical models that give somewhat different predictions. Here we apply evolutionary computation methods to test the two analytical models. The results bear a remarkable similarity to the results of one of the two analytical models. The paper that follows presents the details of a biological application involving snails and barnacles (that occur naturally in two different morphs), moving then to an explanation of two competing mathematical models of the application. Finally, the interdisciplinary paper, which coordinates three separate research projects of a biologist, a mathematician and a computer scientist, describes the evolutionary computation methods used to support one of the two competing analytical models.|Gloria Childress Townsend,Wade N. Hazel,Rick Smock","57480|GECCO|2005|Evolutionary strategies for multi-scale radial basis function kernels in support vector machines|In support vector machines (SVM), the kernel functions which compute dot product in feature space significantly affect the performance of classifiers. Each kernel function is suitable for some tasks. A universal kernel is not possible, and the kernel must be chosen for the tasks under consideration by hand. In order to obtain a flexible kernel function, a family of radial basis function (RBF) kernels is proposed. Multi-scale RBF kernels are combined by including weights. Then, the evolutionary strategies are used to adjust these weights and the widths of the RBF kernels. The proposed kernel is proved to be a Mercer's kernel. The experimental results show that the use of multi-scale RBF kernels result in better performance than that of a single Gaussian RBF on benchmarks.|Tanasanee Phienthrakul,Boonserm Kijsirikul","57354|GECCO|2005|An artificial immune network for multimodal function optimization on dynamic environments|Multimodal optimization algorithms inspired by the immune system are generally characterized by a dynamic control of the population size and by diversity maintenance along the search. One of the most popular proposals is denoted opt-aiNet (artificial immune network for optimization) and is extended here to deal with time-varying fitness functions. Additional procedures are designed to improve the overall performance and the robustness of the immune-inspired approach, giving rise to a version for dynamic optimization, denoted dopt-aiNet. Firstly, challenging benchmark problems in static multimodal optimization are considered to validate the new proposal. No parameter adjustment is necessary to adapt the algorithm according to the peculiarities of each problem. In the sequence, dynamic environments are considered, and usual evaluation indices are adopted to assess the performance of dopt-aiNet and compare with alternative solution procedures available in the literature.|Fabrício Olivetti de França,Fernando J. Von Zuben,Leandro Nunes de Castro","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","57546|GECCO|2005|Applying metaheuristic techniques to search the space of bidding strategies in combinatorial auctions|Many non-cooperative settings that could potentially be studied using game theory are characterized by having very large strategy spaces and payoffs that are costly to compute. Best response dynamics is a method of searching for pure-strategy equilibria in games that is attractive for its simplicity and scalability (relative to more analytical approaches). However, when the cost of determining the outcome of a particular set of joint strategies is high, it is impractical to compute the payoffs of all possible responses to the other players actions. Thus, we study metaheuristic approaches--genetic algorithms and tabu search in particular--to explore the strategy space. We configure the parameters of metaheuristics to adapt to the problem of finding the best response strategy and present how it can be helpful in finding Nash equilibria of combinatorial auctions which is an important solution concept in game theory.|Ashish Sureka,Peter R. Wurman","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57423|GECCO|2005|ARGEN  AREPO mixing the artificial genetic engineering and artificial evolution of populations to improve the search process|In this paper we analyze the performance of several evolutionary algorithms in the feature and instance selection problem. It is also introduced the ARGEN + AREPO search algorithm which has been tested in the same problem. There is no need to adapt parameters in this genetic algorithm, except the population size. The reported preliminary results show that using this technique in a wrapper model to search data subsets, we can obtain accuracy similar to the obtained with some of the genetic algorithms models here presented, but with less data.|Agustín León-Barranco,Sandra E. Barajas,Carlos A. Reyes García"],["57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","57269|GECCO|2005|Inexact pattern matching using genetic algorithm|A Genetic Algorithm for graphical pattern matching based on angle matching had been proposed. It has proven quite effective in matching simple patterns. However, the algorithm needs some modifications to enhance its accuracy on pattern matching when there are some differences between two patterns in terms of numbers of nodes, shapes and rotations. This paper presents the modifications, such as the introduction of node exemption, inexact matching between straight lines and curves in the patterns, and consideration of rotational degrees of the patterns. Each angle is also given with a weight to indicate the significant degree of the angle. A multi-objective function is used to reflect the similarity between two patterns. The experiments designed to evaluate the algorithm have shown very promising results. It is highly accurate on patterns matching with dissimilarities in shapes, numbers of nodes and rotational degrees.|Surapong Auwatanamongkol","57322|GECCO|2005|Directional self-learning of genetic algorithm|In order to overcome the low convergence speed and prematurity of classical genetic algorithm, an improved method named directional self-learning of genetic algorithm (DSLGA) is proposed in this paper. Through the self-learning operator directional information was introduced in local search process. The search direction was guided by the false derivative of the function fitness. Using the four operators among the individuals, the best solution was updated continuously. In experiments, DSLGA was tested on  unconstrained benchmark problems, and the results were compared with the algorithms presented recently. It showed that DSLGA performs much better than the other algorithms both in the quality of the solutions and in the computational complexity.|Lin Cong,Yuheng Sha,Licheng Jiao,Fang Liu","57314|GECCO|2005|MDGA motif discovery using a genetic algorithm|Computationally identifying transcription factor binding sites in the promoter regions of genes is an important problem in computational biology and has been under intensive research for a decade. To predict the binding site locations efficiently, many algorithms that incorporate either approximate or heuristic techniques have been developed. However, the prediction accuracy is not satisfactory and binding site prediction thus remains a challenging problem. In this paper, we develop an approach that can be used to predict binding site motifs using a genetic algorithm. Based on the generic framework of a genetic algorithm, the approach explores the search space of all possible starting locations of the binding site motifs in different target sequences with a population that undergoes evolution. Individuals in the population compete to participate in the crossovers and mutations occur with a certain probability. Initial experiments demonstrated that our approach could achieve high prediction accuracy in a small amount of computation time. A promising advantage of our approach is the fact that the computation time does not explicitly depend on the length of target sequences and hence may not increase significantly when the target sequences become very long.|Dongsheng Che,Yinglei Song,Khaled Rasheed","57499|GECCO|2005|Multiobjective VLSI cell placement using distributed genetic algorithm|Genetic Algorithms have worked fairly well for the VLSI cell placement problem, albeit with significant run times. Two parallel models for GA are presented for VLSI cell placement where the objectives are optimizing power dissipation, timing performance and interconnect wirelength, while layout width is a constraint. A Master-Slave approach is mentioned wherein both fitness calculation and crossover mechanism are distributed among slaves. A Multi-Deme parallel GA is also presented in which each processor works independently on an allocated subpopulation followed by information exchange through migration of chromosomes. A pseudo-diversity approach is taken, wherein similar solutions with the same overall cost values are not permitted in the population at any given time. A series of experiments are performed on ISCAS- benchmarks to show the performance of the Multi-Deme approach.|Sadiq M. Sait,Mohammed Faheemuddin,Mahmood R. Minhas,Syed Sanaullah","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57428|GECCO|2005|Multiplex PCR primer design for gene family using genetic algorithm|The multiplex PCR experiment is to amplify multiple regions of a DNA sequence at the same time by using different primer pairs. Designing feasible primer pairs for multiplex PCR is a tedious task since there are too many constraints to be satisfied. In this paper, a new method for multiplex PCR primer design strategy using genetic algorithm is proposed. The proposed algorithm is able to find a set of suitable primer pairs more efficient and uses a MAP model to speed up the examination of the specificity constraint that is important for gene family sequences. The dry-dock experiment shows that the proposed algorithm finds several sets of primer pairs of gene family sequences for multiplex PCR that not only obey the design properties, but also have specificity.|Hong-Long Liang,Chungnan Lee,Jain-Shing Wu","57495|GECCO|2005|Mission planning for joint suppression of enemy air defenses using a genetic algorithm|In this paper we present a genetic algorithm applied to the problem of mission planning for Joint Suppression of Enemy Air Defenses (JSEAD) in support of air strike operations. The stochastic nature of JSEAD scenarios and the complexity of JSEAD operations and interactions make this an especially challenging problem within the military domain. JSEAD planners and analysts stand to benefit from any advances in tools that address this problem. While our interest in this subject is broad, in this paper we are specifically investigating methods for developing robust plans that include routes for JSEAD assets, target types, firing ranges, and take off time, subject to multiple objective functions that capture different aspects of mission performance. The multi-objective optimization is performed by the Dynamic Non-Dominated Sorting GA (DNSGA), a non-elitist variant of NSGA-II. The objective functions are evaluated using a stochastic agent-based JSEAD simulation, and we assess the quality of mission plans produced by the GA in a set of test scenarios. The results from these tests indicate that our approach has significant promise as a component of a JSEAD mission planning tool.|Jeffrey P. Ridder,Jason C. HandUber","57432|GECCO|2005|Primer design for multiplex PCR using a genetic algorithm|Multiplex Polymerase Chain Reaction (PCR) experiments are used for amplifying several segments of the target DNA simultaneously and thereby to conserve template DNA, reduce the experimental time, and minimize the experimental expense. The success of the experiment is dependent on primer design. However, this can be a dreary task as there are many constrains such as melting temperatures, primer length, GC content and complementarity that need to be optimized to obtain a good PCR product. Motivated by the lack of primer design tools for multiplex PCR genotypic assay, we propose a multiplex PCR primer design tool using a genetic algorithm, which is a stochastic approach based on the concept of biological evolution, biological genetics and genetic operations on chromosomes, to find an optimal selection of primer pairs for multiplex PCR experiments. The presented experimental results indicate that the proposed algorithm is capable of finding a series of primer pairs that obeies the design properties in the same tube.|Feng-Mao Lin,Hsien-Da Huang,Hsi-Yuan Huang,Jorng-Tzong Horng","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["16250|IJCAI|2005|A Scalable Method for Multiagent Constraint Optimization|We present in this paper a new, complete method for distributed constraint optimization, based on dynamic programming. It is a utility propagation method, inspired by the sum-product algorithm, which is correct only for tree-shaped constraint networks. In this paper, we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. Our algorithm requires a linear number of messages, whose maximal size depends on the induced width along the particular pseudotree chosen. We compare our algorithm with backtracking algorithms, and present experimental results. For some problem types we report orders of magnitude fewer messages, and the ability to deal with arbitrarily large problems. Our algorithm is formulated for optimization problems, but can be easily applied to satisfaction problems as well.|Adrian Petcu,Boi Faltings","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57476|GECCO|2005|Multiobjective shape optimization with constraints based on estimation distribution algorithms and correlated information|A new approach based on Estimation Distribution Algorithms for constrained multiobjective shape optimization is proposed in this article. Pareto dominance and feasibility rules are used to handle constraints. The algorithm uses feasible and infeasible individuals to estimate the probability distribution of evolving designs. Additionally, correlation among problem design variables is used to improve exploration. The design objectives are minimum weight and minimum nodal displacement. Also, the resulting structures must fulfill three design constraints a) maximum permissible Von Misses stress, b)connectedness of the structure elements, and c) small holes are not allowed in the structure. The finite element method is used to evaluate the objective functions and stress constraint.|Sergio Ivvan Valdez Peña,Salvador Botello Rionda,Arturo Hernández Aguirre","16072|IJCAI|2005|Word Sense Disambiguation with Distribution Estimation|A word sense disambiguation (WSD) system trained on one domain and applied to a different domain will show a decrease in performance. One major reason is the different sense distributions between different domains. This paper presents novel application of two distribution estimation algorithms to provide estimates of the sense distribution of the new domain data set. Even though our training examples are automatically gathered from parallel corpora, the sense distributions estimated are good enough to achieve a relative improvement of % when incorporated into our WSD system.|Yee Seng Chan,Hwee Tou Ng","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens","57437|GECCO|2005|Learning computer programs with the bayesian optimization algorithm|We describe an extension of the Bayesian Optimization Algorithm (BOA), a probabilistic model building genetic algorithm, to the domain of program tree evolution. The new system, BOA programming (BOAP), improves significantly on previous probabilistic model building genetic programming (PMBGP) systems in terms of the articulacy and open-ended flexibility of the models learned, and hence control over the distribution of instances generated. Innovations include a novel tree representation and a generalized program evaluation scheme.|Moshe Looks,Ben Goertzel,Cassio Pennachin"],["16230|IJCAI|2005|Networked Distributed POMDPs A Synergy of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","65516|AAAI|2005|Networked Distributed POMDPs A Synthesis of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present two novel algorithms for ND-POMDPs a distributed policy generation algorithm that performs local search and a systematic policy search that is guaranteed to reach the global optimal.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","16133|IJCAI|2005|The Complexity of Quantified Constraint Satisfaction Problems under Structural Restrictions|We give a clear picture of the tractabilityintractability frontier for quantified constraint satisfaction problems (QCSPs) under structural restrictions. On the negative side, we prove that checking QCSP satisfiability remains PSPACE-hard for all known structural properties more general than bounded treewidth and for the incomparable hypergraph acyclicity. Moreover, if the domain is not fixed, the problem is PSPACE-hard even for tree-shaped constraint scopes. On the positive side, we identify relevant tractable classes, including QCSPs with prefix  having bounded hypertree width, and QCSPs with a bounded number of guards. The latter are solvable in polynomial time without any bound on domains or quantifier alternations.|Georg Gottlob,Gianluigi Greco,Francesco Scarcello","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","65613|AAAI|2005|Learning Measures of Progress for Planning Domains|We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress (parmar ), which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results.|Sung Wook Yoon,Alan Fern,Robert Givan","65506|AAAI|2005|A Constraint Satisfaction Approach to Geospatial Reasoning|The large number of data sources on the Internet can be used to augment and verify the accuracy of geospatial sources, such as gazetteers and annotated satellite imagery. Data sources such as satellite imagery, maps, gazetteers and vector data have been traditionally used in geographic infonnation systems (GIS), but nontraditional geospatial data, such as online phone books and property records are more difficult to relate to imagery. In this paper, we present a novel approach to combining extracted information from imagery, road vector data, and online data sources. We represent the problem of identifying buildings in satellite images as a constraint satisfing problem (CSP) and use constraint programming to solve it. We apply this technique to real-world data sources in EI Segundo, CA and our experimental evaluation shows how this approach can accurately identify buildings when provided with both traditional and nontraditional data sources.|Martin Michalowski,Craig A. Knoblock","16106|IJCAI|2005|Reinforcement Learning in POMDPs Without Resets|We consider the most realistic reinforcement learning setting in which an agent starts in an unknown environment (the POMDP) and must follow one continuous and uninterrupted chain of experience with no access to \"resets\" or \"offline\" simulation. We provide algorithms for general connected POMDPs that obtain near optimal average reward. One algorithm we present has a convergence rate which depends exponentially on a certain horizon time of an optimal policy, but has no dependence on the number of (unobservable) states. The main building block of our algorithms is an implementation of an approximate reset strategy, which we show always exists in every POMDP. An interesting aspect of our algorithms is how they use this strategy when balancing exploration and exploitation.|Eyal Even-Dar,Sham M. Kakade,Yishay Mansour","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder","65544|AAAI|2005|Towards Learning Stochastic Logic Programs from Proof-Banks|Stochastic logic programs combine ideas from probabilistic grammars with the expressive power of definite clause logic as such they can be considered as an extension of probabilistic context-free grammars. Motivated by an analogy with learning tree-bank grammars, we study how to learn stochastic logic programs from proof-trees. Using proof-trees as examples imposes strong logical constraints on the structure of the target stochastic logic program. These constraints can be integrated in the least general generalization (lgg) operator, which is employed to traverse the search space. Our implementation employs a greedy search guided by the maximum likelihood principle and failure-adjusted maximization. We also report on a number of simple experiments that show the promise of the approach.|Luc De Raedt,Kristian Kersting,Sunna Torge"],["65569|AAAI|2005|The DEFACTO System Training Tool for Incident Commanders|Techniques for augmenting the automation of routine coordination are rapidly reaching a level of effectiveness where they can simulate realistic coordination on the ground for large numbers of emergency response entities (e.g. fire engines. police cars) for the sake of training. Furthermore, it seems inevitable that future disaster response systems will utilize such technology. We have constructed a new system, DE-FACTO (Demonstrating Effective Flexible Agent Coordination of Teams through Omnipresence), that integrates state-of-the-art agent reasoning capabilities and D visualization into a unique high fidelity system for training incident commanders. The DEFACTO system achieves this goal via three main components (i) Omnipresent Viewer - intuitive interface, (ii) Proxy Framework - for team coordination, and (iii) Flexible Interaction - between the incident commander and the team. We have performed detailed preliminary experiments with DEFACTO in the fire-fighting domain. In addition, DEFACTO has been repeatedly demonstrated to key police and fire department personnel in Los Angeles area, with very positive feedback.|Nathan Schurr,Janusz Marecki,John P. Lewis,Milind Tambe,Paul Scerri","16071|IJCAI|2005|Sensitivity Analysis in Markov Networks|This paper explores the topic of sensitivity analysis in Markov networks, by tackling questions similar to those arising in the context of Bayesian networks the tuning of parameters to satisfy query constraints, and the bounding of query changes when perturbing network parameters. Even though the distribution induced by a Markov network corresponds to ratios of multi-linear functions, whereas the distribution induced by a Bayesian network corresponds to multi-linear functions, the results we obtain for Markov networks are as effective computationally as those obtained for Bayesian networks. This similarity is due to the fact that conditional probabilities have the same functional form in both Bayesian and Markov networks, which turns out to be the more influential factor. The major difference we found, however, is in how changes in parameter values should be quantified, as such parameters are interpreted differently in Bayesian networks and Markov networks.|Hei Chan,Adnan Darwiche","57356|GECCO|2005|A comparative analysis of artificial immune network models|This paper presents a review of different artificial immune network models, which have been published during the last years. A general model of artificial immune network is presented, which provides a common notation that allows the comparison of different models. A descriptive and comparative analysis is presented emphasizing similarities, differences and relationships between models. Finally, some conclusions and suggestions for improving existent models are presented.|Juan Carlos Galeano,Angélica Veloza-Suan,Fabio A. González","57418|GECCO|2005|Artificial immune system for solving generalized geometric problems a preliminary results|Generalized geometric programming (GGP) is an optimization method in which the objective function and constraints are nonconvex functions. Thus, a GGP problem includes multiple local optima in its solution space. When using conventional nonlinear programming methods to solve a GGP problem, local optimum may be found, or the procedure may be mathematically tedious. To find the global optimum of a GGP problem, a bio-immune-based approach is considered. This study presents an artificial immune system (AIS) including an operator to control the number of antigen-specific antibodies based on an idiotypic network hypothesis an editing operator of receptor with a Cauchy distributed random number, and a bone marrow operator used to generate diverse antibodies. The AIS method was tested with a set of published GGP problems, and their solutions were compared with the known global GGP solutions. The testing results show that the proposed approach potentially converges to the global solutions.|Jui-Yu Wu,Yun-Kung Chung","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","16206|IJCAI|2005|Location-Based Activity Recognition using Relational Markov Networks|In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.|Lin Liao,Dieter Fox,Henry A. Kautz","65576|AAAI|2005|Discriminative Training of Markov Logic Networks|Many machine learning applications require a combination of probability and first-order logic. Markov logic networks (MLNs) accomplish this by attaching weights to first-order clauses, and viewing these as templates for features of Markov networks. Model parameters (i.e., clause weights) can be learned by maximizing the likelihood of a relational database, but this can be quite costly and lead to suboptimal results for any given prediction task. In this paper we propose a discriminative approach to training MLNs, one which optimizes the conditional likelihood of the query predicates given the evidence ones, rather than the joint likelihood of all predicates. We extend Collins's () voted perceptron algorithm for HMMs to MLNs by replacing the Viterbi algorithm with a weighted satisfiability solver. Experiments on entity resolution and link prediction tasks show the advantages of this approach compared to generative MLN training, as well as compared to purely probabilistic and purely logical approaches.|Parag Singla,Pedro Domingos","16220|IJCAI|2005|Training without data Knowledge Insertion into RBF Neural Networks|A major problem when developing neural networks or machine diagnostics situations is that no data or very little data is available for training on fault conditions. However, the domain expert often has a good idea of what to expect in terms of input and output parameter values. If the expert can express these relationships in the form of rules, this would provide a resource too valuable to ignore. Fuzzy logic is used to handle the imprecision and vagueness of natural language and provides this additional advantage to a system. This paper investigates the development of a novel knowledge insertion algorithm that explores the benefits of prestructuring RBF neural networks by using prior fuzzy domain knowledge and previous training experiences. Pre-structuring is accomplished by using fuzzy rules gained from a domain expert and using them to modify existing Radial Basis Function (RBF) networks. The benefits and novel achievements of this work enable RBF neural networks to be trained without actual data but to rely on input to output mappings defined through expert knowledge.|Kenneth McGarry,Stefan Wermter","57364|GECCO|2005|Performance assessment of an artificial immune system multiobjective optimizer by two improved metrics|In this study, we introduce two improved assessment metrics of multiobjective optimizers, Nondominated Ratio and Spacing Distribution, and analyze their rationality and validity. Based on the concept of Immunodominance and Antibody Clonal Selection Theory, a novel multiobjective optimization algorithm, Immune Dominance Clonal Multiobjective Algorithm (IDCMA), is put forward. The simulation comparisons between IDCMA and the Strength Pareto Evolutionary Algorithm show that IDCMA has the best performance in popular metrics such as Spacing, Coverage of Two Sets and the two new metrics presented in this paper when low-dimensional multiobjective problems are concerned. The statistical results of the four metrics also show that Spacing Distribution conquers some limitations of Spacing triumphantly, and Nondominated Ratio conquers the limitation of Coverage of Two Sets that only compared between two sets.|Maoguo Gong,Licheng Jiao,Haifeng Du,Ronghua Shang,Bin Lu","57366|GECCO|2005|An artificial immune system algorithm for CDMA multiuser detection over multi-path channels|Based on the Antibody Clonal Selection Theory of immunology, we put forward a novel clonal selection algorithm for multiuser detection in Code-division Multiple-access Systems. By using the clonal selection operator, the new algorithm can carry out the global search and the local search in many directions rather than one direction around the same individual simultaneously. After discussing the main characters of the new algorithm, especially the convergence and complexity, the performance of the proposed receiver, named by CAMUD, is evaluated via computer simulations and compared to that of other suboptimal schemes as well as to that of Optimal Multiuser detector (OMD) and conventional detector in CDMA systems over Multi-Path Channels. When compared with the OMD scheme, the CAMUD is capable of reducing the computational complexity significantly. On the other hand, when compared with standard genetic algorithm and improved genetic algorithm, theoretical analysis and Monte Carlo simulations show that the CAMUD with same complexity has optimal performance in eliminating MAI and \"near-far\" resistance. The simulations also show that the CAMUD performs quite well even when the number of active users and the length of the transmitted packet are considerably large.|Maoguo Gong,Ling Wang,Licheng Jiao,Haifeng Du"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57463|GECCO|2005|Enhancing differential evolution performance with local search for high dimensional function optimization|In this paper, we proposed Fittest Individual Refinement (FIR), a crossover based local search method for Differential Evolution (DE). The FIR scheme accelerates DE by enhancing its search capability through exploration of the neighborhood of the best solution in successive generations. The proposed memetic version of DE (augmented by FIR) is expected to obtain an acceptable solution with a lower number of evaluations particularly for higher dimensional functions. Using two different implementations DEfirDE and DEfirSPX we showed that proposed FIR increases the convergence velocity of DE for well known benchmark functions as well as improves the robustness of DE against variation of population. Experiments using multimodal landscape generator showed our proposed algorithms consistently outperformed their parent algorithms. A performance comparison with reported results of well known real coded memetic algorithms is also presented.|Nasimul Noman,Hitoshi Iba","57512|GECCO|2005|Using gene deletion and gene duplication in evolution strategies|Self-adaptation of the mutation strengths is a powerful mechanism in evolution strategies (ES), but it can fail. As a consequence premature convergence or ending up in a local optimum in multi-modal fitness landscapes can occur. In this article a new approach controlling the process of self-adaptation is proposed. This approach combines the old ideas of gene deletion and gene duplication with the self-adaptation mechanism of the ES. Gene deletion and gene duplication is used to vary the number of independent mutation strengths. In order to demonstrate the practicability of the new approach several multi-modal test functions are used. Methods from statistical design of experiments and regression tree methods are applied to improve the performance of a specific heuristic-problem combination.|Karlheinz Schmitt","57513|GECCO|2005|Using predators and preys in evolution strategies|This poster presents an evolution strategy for single- and multi-objective optimization. The model uses the predator-prey approach from ecology to scale between both cases. Furthermore the main issue of adaptation working for single- and multi-objective problem-instances equally is discussed. Particular, the well proved self-adaptation mechanism for the mutation strengths in the single-objective case is adopted for the multi-objective one. This self-adaptation process is supported by a new strategy of competition between predators and preys. Six test functions are used to demonstrate the practicability of the model.|Karlheinz Schmitt,Jörn Mehnen,Thomas Michelitsch","57447|GECCO|2005|Promising infeasibility and multiple offspring incorporated to differential evolution for constrained optimization|In this paper, we incorporate a diversity mechanism to the differential evolution algorithm to solve constrained optimization problems without using a penalty function. The aim is twofold () to allow infeasible solutions with a promising value of the objective function to remain in the population and also () to increase the probabilities of an individual to generate a better offspring while promoting collaboration of all the population to generate better solutions. These goals are achieved by allowing each parent to generate more than one offspring. The best offspring is selected using a comparison mechanism based on feasibility and this child is compared against its parent. To maintain diversity, the proposed approach uses a mechanism successfully adopted with other evolutionary algorithms where, based on a parameter Sr a solution (between the best offspring and the current parent) with a better value of the objective function can remain in the population, regardless of its feasibility. The proposed approach is validated using test functions from a well-known benchmark commonly adopted to validate constraint-handling techniques used with evolutionary algorithms. The statistical results obtained by the proposed approach are highly competitive (based on quality, robustness and number of evaluations of the objective function) with respect to other constraint-handling techniques, either based on differential evolution or on other evolutionary algorithms, that are representative of the state-of-the-art in the area. Finally, a small set of experiments were made to detect sensitivity of the approach to its parameters.|Efrén Mezura-Montes,Jesús Velázquez-Reyes,Carlos A. Coello Coello","57354|GECCO|2005|An artificial immune network for multimodal function optimization on dynamic environments|Multimodal optimization algorithms inspired by the immune system are generally characterized by a dynamic control of the population size and by diversity maintenance along the search. One of the most popular proposals is denoted opt-aiNet (artificial immune network for optimization) and is extended here to deal with time-varying fitness functions. Additional procedures are designed to improve the overall performance and the robustness of the immune-inspired approach, giving rise to a version for dynamic optimization, denoted dopt-aiNet. Firstly, challenging benchmark problems in static multimodal optimization are considered to validate the new proposal. No parameter adjustment is necessary to adapt the algorithm according to the peculiarities of each problem. In the sequence, dynamic environments are considered, and usual evaluation indices are adopted to assess the performance of dopt-aiNet and compare with alternative solution procedures available in the literature.|Fabrício Olivetti de França,Fernando J. Von Zuben,Leandro Nunes de Castro","57276|GECCO|2005|Fitness-based neighbor selection for multimodal function optimization|We propose a selection scheme called Fitness-based Neighbor Selection (FNS) for multimodal optimization. The FNS is aimed for ill-scaled and locally multimodal domain, both found in real-world numerical optimization problem.In FNS, selection is applied to parent-child pair that most likely belong to the same attractor. We determine such pair with statistical comparison of the fitness values sampled from region between the pairs, instead of conventional Euclidean distance. In addition, the ranks of a parent among sampled values are used to determine if the parent is replaceable. These measurements makes the algorithm scale-invariant thus robust in ill-scaled domain.|Shin Ando,Shigenobu Kobayashi","57525|GECCO|2005|Niching in evolution strategies|EAs have the tendency to converge quickly into a single solution. Niching methods, the extension of EAs to address this issue, have been investigated up to date mainly within the field of Genetic Algorithms (GAs). In our study we investigate the basis for niching methods within Evolution Strategies (ES), and propose the first ES niching method. Results show that this method can reliably find and maintain multiple niches even for high-dimensional problems.|Ofer M. Shir,Thomas Bäck","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li","57277|GECCO|2005|Adaptive isolation model using data clustering for multimodal function optimization|In this paper, we propose a GA model called Adaptive Isolation Model(AIM), for multimodal optimization. It uses a data clustering algorithm to detect clusters in GA population, which identifies the attractors in the fitness landscape. Then, subpopulations which makes-up the clusters are isolated and optimized independently. Meanwhile, the region of the isolated subpopulations in the original landscape are suppressed. The isolation increases comprehensiveness, i.e., the probability of finding weaker attractors, and the overall efficiency of multimodal search. The advantage of the AIM is that it does not require distance between the optima as a presumed parameter, as it is estimated from the variancecovariance matrix of the subpopulation.Further, AIM's behavior and efficiency is equivalent to basic GA in unimodal landscape, in terms of number of evaluation. Therefore, it is applied recursively to all subpopulations until they converge to a suboptima. This makes AIM suitable for locally-multimodal landscapes, which have closely located attractors that are difficult to distinguish in the initial run.The performance of AIM is evaluated in several benchmark problems and compared to iterated hill-climbing methods.|Shin Ando,Jun Sakuma,Shigenobu Kobayashi"],["57472|GECCO|2005|Extraction of informative genes from microarray data|Identification of those genes that might anticipate the clinical behavior of different types of cancers is challenging due to availability of a smaller number of patient samples compared to huge number of genes, and the noisy nature of microarray data. After selection of some good genes based on signal-to-noise ratio, unsupervised learning like clustering and supervised learning like k-nearest neighbor (kNN) classifier are widely used in cancer researches to correlate the pathological behavior of cancers with the gene expression levels' differences in cancerous and normal tissues. By applying adaptive searches like Probabilistic Model Building Genetic Algorithm (PMBGA), it may be possible to get a smaller size gene subset that would classify patient samples more accurately than the above methods. In this paper, we propose a new PMBGA based method to extract informative genes from microarray data using Support Vector Machine (SVM) as a classifier. We apply our method to three microarray data sets and present the experimental results. Our method with SVM obtains encouraging results on those data sets as compared with the rank based method using kNN as a classifier.|Topon Kumar Paul,Hitoshi Iba","65550|AAAI|2005|Activity Recognition from Accelerometer Data|Activity recognition fits within the bigger framework of context awareness. In this paper, we report on our efforts to recognize user activity from accelerometer data. Activity recognition is formulated as a classification problem. Performance of base-level classifiers and meta-level classifiers is compared. Plurality Voting is found to perform consistently well across different settings.|Nishkam Ravi,Nikhil Dandekar,Preetham Mysore,Michael L. Littman","65498|AAAI|2005|Searching for Common Sense Populating Cyc from the Web|The Cyc project is predicated on the idea that effective machine learning depends on having a core of knowledge that provides a context for novel learned information - what is known informally as \"common sense.\" Over the last twenty years, a sufficient core of common sense knowledge has been entered into Cyc to allow it to begin effectively and flexibly supporting its most important task increasing its own store of world knowledge. In this paper, we present initial work on a method of using a combination of Cyc and the World Wide Web, accessed via Google, to assist in entering knowledge into Cyc. The long-term goal is automating the process of building a consistent, formalized representation of the world in the Cyc knowledge base via machine learning. We present preliminary results of this work and describe how we expect the knowledge acquisition process to become more accurate, faster, and more automated in the future.|Cynthia Matuszek,Michael J. Witbrock,Robert C. Kahlert,John Cabral,David Schneider,Purvesh Shah,Douglas B. Lenat","65514|AAAI|2005|Automatic Text Summarization of Newswire Lessons Learned from the Document Understanding Conference|Since , the Document Understanding Conferences have been the forum for researchers in automatic text summarization to compare methods and results on common test sets. Over the years, several types of summarization tasks have been addressed--single document summarization, multi-document summarization, summarization focused by question, and headline generation. This paper is an overview of the achieved results in the different types of summarization tasks. We compare both the broader classes of baselines, systems and humans, as well as individual pairs of summarizers (both human and automatic). An analysis of variance model is fitted, with summarizer and input set as independent variables, and the coverage score as the dependent variable, and simulation-based multiple comparisons were performed. The results document the progress in the field as a whole, rather then focusing on a single system, and thus can serve as a future reference on the work done up to date, as well as a starting point in the formulation of future tasks. Results also indicate that most progress in the field has been achieved in generic multi-document summarization and that the most challenging task is that of producing a focused summary in answer to a questiontopic.|Ani Nenkova","65529|AAAI|2005|Function-Based Classification from D Data via Generic and Symbolic Models|We propose a novel scheme for function-based classification of objects in D images. The classification process calls for constructing a generic multi-level hierarchical description of object classes in terms of functional components. Functionality is derived from a large set of geometric attributes and relationships between object parts. Initially, the input range data describing each object instance is segmented, each object part is labeled as one of a few possible primitives, and each group of primitive parts is tagged by a functional symbol. Connections between primitive parts and functional parts at the same level in the hierarchy are labeled as well. Then, the generic multi-level hierarchical description of object classes is built using the functionalities of a number of object instances. During classification, a search through a finite graph using a probabilistic fitness measure is performed to find the best assignment of object parts to the functional structures of each class. An object is assigned to a class providing the highest fitness value. The scheme does not require a-priori knowledge about any class. We tested the proposed scheme on a database of about one thousand different D objects. The results show high accuracy in classification.|Michael Pechuk,Octavian Soldea,Ehud Rivlin","65584|AAAI|2005|Using the GEMS System for Cancer Diagnosis and Biomarker Discovery from Microarray Gene Expression Data|We will demonstrate the GEMS system for automated development and evaluation of high-quality cancer diagnostic models and biomarker discovery from microarray gene expression data. The development of GEMS was informed by the results of an extensive algorithmic evaluation using  microarray datasets. The system was further evaluated in two cross-dataset applications and using  microarray datasets. The performance of models produced by GEMS is comparable or better than the results obtained by human analysts, and these models generalize well to independent samples in cross-dataset applications. The system is freely available for download from httpwww.gems-system.org for noncommercial use.|Alexander R. Statnikov,Ioannis Tsamardinos,Constantin F. Aliferis","57317|GECCO|2005|Conformation of an ideal bucky ball molecule by genetic algorithm and geometric constraint from pair distance data genetic algorithm|A genetic algorithm is proposed with real value variables, spatially based crossover operator, a small mutation, large scale mutation, vector sum local search and geometric only based objective function to generate candidate molecule conformations from atomic pair distance data. To better simulate experimental data only information from the pair distance data is used as constraints. Ideal Bucky ball with  atoms is used as the test case with both perfect pair distance data and Gaussian noise perturbed pair distance data. The GA generated result shows molecules close to ideal Bucky balls but with some defects. A description of the spatially based crossover operator is provided along with a local search based on vector summed error for each atom.|David M. Cherba,William F. Punch,Phil Duxbury,Simon Billinge,Pavol Juhas","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","16244|IJCAI|2005|Building the Semantic Web Tower from RDF Straw|A same-syntax extension of RDF to first-order logic results in a collapse of the model theory due to logical paradoxes resulting from diagonalization. RDF is thus the wrong material for building the Semantic Web tower.|Peter F. Patel-Schneider","57551|GECCO|2005|From supervised ranking to evolving behaviours of a robotic team|Using artificial evolution successfully to design behaviours of multiple robot systems has been reported in recent years. Most of such reports are focused on the design of low level controllers. Design of high level team coordination strategies is rarely covered perhaps because the design of an appropriate chromosome representation for a complex multi-agent system is not an easy task. In this paper we propose that by treating the action decisions of every team member as a supervised ranking problem, the chromosome design problem can be solved systematically.We have tested this approach by dynamically solving the problems in the Solomon's benchmark of Vehicle Routing Problem with Time Windows . Experiments show that our approach can create some simple behaviours which, whilst not optimal, are robust and above average in quality.|Kai Wing Tang,Ray A. Jarvis"],["57306|GECCO|2005|A hybrid evolutionary algorithm for the p-median problem|A hybrid evolutionary algorithm (EA) for the p-median problem consist of two stages, each of which is a steady-state hybrid EA. These EAs encode selections of medians as subsets of the candidate sites, apply a recombination operator tailored to the problem, and select symbols in chromosomes to mutate based on an explicit collective memory (named virtual loser). They also apply a sequence of two or three local search procedures to each new solution. Tests e.g. on the benchmark problem instances of ORLIB returned results within .% of the best solutions known.|István Borgulya","57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57282|GECCO|2005|Local and global order  convergence of a surrogate evolutionary algorithm|A Quasi-Monte-Carlo method based on the computation of a surrogate model of the fitness function is proposed, and its convergence at super-linear rate  is proved under rather mild assumptions on the fitness function -- but assuming that the starting point lies within a small neighborhood of a global maximum. A memetic algorithm is then constructed, that performs both a random exploration of the search space and the exploitation of the best-so-far points using the previous surrogate local algorithm, coupled through selection. Under the same mild hypotheses, the global convergence of the memetic algorithm, at the same  rate, is proved.|Anne Auger,Marc Schoenauer,Olivier Teytaud","57430|GECCO|2005|Evolutionary computation and the c-value paradox|The C-value Paradox is the name given in biology to the wide variance in and often very large amount of DNA in eukaryotic genomes and the poor correlation between DNA length and perceived organism complexity. Several hypotheses exist which purport to explain the Paradox. Surprisingly there is a related phenomenon in evolutionary computation, known as code bloat, for which a different set of hypotheses has arisen. This paper describes a new hypothesis for the C-value Paradox derived from models of code bloat. The new explanation is that there is a selective bias in preference of genetic events which increase DNA material over those which decrease it. The paper suggests one possible concrete mechanism by which this may occur deleting strands of DNA is more likely to damage genomic material than migrating or copying strands. The paper also discusses other hypotheses in biology and in evolutionary computation, and provides a simulation example as a proof of concept.|Sean Luke","57524|GECCO|2005|An evolutionary algorithm to generate hyper-ellipsoid detectors for negative selection|This paper introduces hyper-ellipsoids as an improvement to hyper-spheres as intrusion detectors in a negative selection problem within an artificial immune system. Since hyper-spheres are a specialization of hyper-ellipsoids, hyper-ellipsoids retain the benefits of hyper-spheres. However, hyper-ellipsoids are much more flexible, mostly in that they can be stretched and reoriented. The viability of using hyper-ellipsoids is established using several pedagogical problems. We conjecture that fewer hyper-ellipsoids than hyper-spheres are needed to achieve similar coverage of nonself space in a negative selection problem. Experimentation validates this conjecture. In pedagogical benchmark problems, the number of hyper-ellipsoids to achieve good results is significantly (%) smaller than the associated number of hyper-spheres.|Joseph M. Shapiro,Gary B. Lamont,Gilbert L. Peterson","57379|GECCO|2005|Towards a self-stopping evolutionary algorithm using coupling from the past|In this paper a stopping criterion for a particular class of evolutionary algorithms is devised. First, a model of a generic evolutionary algorithm using iterated random maps is presented. The model allows the exploration of a connection between coupling from the past, and a stopping criterion for evolutionary algorithms. Accordingly, a method to stop a generic evolutionary algorithm is proposed. Some computational experiments are carried out to test the stopping criterion, using a modified version of coupling from the past. Empirical evidence is shown to support the suitability of the criterion.|German Hernandez,Kenneth Wilder,Fernando Niño,Julian Garcia","57429|GECCO|2005|The molecule evoluator an interactive evolutionary algorithm for designing drug molecules|To help chemists design new drugs, we created a tool that uses interactive evolution to design drug molecules, the \"Molecule Evoluator\". In contrast to most other evolutionary de novo design programs, the molecule representation and the set of mutations enable it to both search the chemical space of all drug like molecules extensively and to fine-tune molecular structures to the problem at hand. Additionally, we use interaction with the user as a fitness function, which is new in evolutionary algorithms in drug design. This interactivity allows the Molecule Evoluator to use the domain knowledge of the chemist to estimate the ease of synthesis and the biological activity of the compound. This knowledge can guide the optimization process and thereby improve its results. Chemists of our department using the Molecule Evoluator were able to find six novel and synthesizable druglike core structures, indicating that the Molecule Evoluator can be used as a tool to enhance the chemist's creativity.|Eric-Wubbo Lameijer,Adriaan P. IJzerman,Joost N. Kok","57516|GECCO|2005|A multiple objective evolutionary algorithm for multiple sequence alignment|The problem of multiple sequence alignment is important for bioinformatics. This problem is widely studied and a popular tool to solve this problem is Clustal X. This work introduces a multiple objective evolutionary algorithm to improve solutions obtained from Clustal X. The proposed method is tested with the dataset from BAliBASE database.|Pasut Seeluangsawat,Prabhas Chongstitvatana","57298|GECCO|2005|Map-labelling with a multi-objective evolutionary algorithm|We present a multi-objective evolutionary algorithm approach to the map-labelling problem. Map-labelling involves placing labels for sites onto a map such that the result is easy to read and usable for navigation. However, map-users vary in their priorities and capabilities for example, sight-impaired users need to maximise font-size, whereas other users may be willing to accept smaller labels in exchange for increased clarity of bindings of labels to sites. With a multi-objective approach, we evolve a range of labellings from which users can select according to their particular circumstances. We present results from labelling two maps, including a difficult, dense map of Newcastle County in Delaware, which clearly illustrate the advantages of the multi-objective approach.|Lucas Bradstreet,Luigi Barone,R. Lyndon While"],["57492|GECCO|2005|Particle swarm optimization for analysis of mass spectral serum profiles|Serum profiling using mass spectrometry is an emerging technology with a great potential to provide biomarkers for complex diseases such as cancer. However, protein profiles obtained from current mass spectrometric technologies are characterized by their high dimensionality and complex spectra with substantial level of noise. These characteristics have generated challenges in discovery of proteins and protein-profiles that distinguish cancer patients from healthy individuals. This paper proposes a novel machine learning method that combines support vector machines with particle swarm optimization for biomarker discovery. Prior to applying the proposed biomarker selection algorithm, low-level analysis methods are used for smoothing, baseline correction, normalization, and peak detection. The proposed method is applied for biomarker discovery from serum mass spectral profiles of liver cancer patients and controls.|Habtom W. Ressom,Rency S. Varghese,Daniel Saha,Eduard Orvisky,Lenka Goldman,Emanuel F. Petricoin,Thomas P. Conrads,Timothy D. Veenstra,Mohamed Abdel-Hamid,Christopher A. Loffredo,Radoslav Goldman","65413|AAAI|2005|A Particle Filtering Based Approach to Approximating Interactive POMDPs|POMDPs provide a principled framework for sequential planning in single agent settings. An extension of POMDPs to multi agent settings, called interactive POMDPs (I-POMDPs), replaces POMDP belief spaces with interactive hierarchical belief systems which represent an agent's belief about the physical world, about beliefs of the other agent(s), about their beliefs about others' beliefs, and so on. This modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute. We describe a method for obtaining approximate solutions to IPOMDPs based on particle filtering (PF). We utilize the interactive PF which descends the levels of interactive belief hierarchies and samples and propagates beliefs at each level. The interactive PF is able to deal with the belief space complexity, but it does not address the policy space complexity. We provide experimental results and chart future work.|Prashant Doshi,Piotr J. Gmytrasiewicz","57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57403|GECCO|2005|Dynamic-probabilistic particle swarms|The particle swarm algorithm is usually a dynamic process, where a point in the search space to be tested depends on the previous point and the direction of movement. The process can be decomposed, and probability distributions around a center can be used instead of the usual trajectory approach. A version that is both dynamic and Gaussian looks very promising.|James Kennedy","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["57394|GECCO|2005|Comparison of evolutionary multiobjective optimization with rference solution-based single-objective approach|In this paper, we demonstrate advantages and disadvantages of an evolutionary multiobjective optimization (EMO) approach in comparison with a reference solution-based single-objective approach through computational experiments on multiobjective  knapsack problems. The main characteristic feature of the EMO approach is that no a priori information about the decision maker's preference is assumed. The EMO approach tries to find well-distributed trade-off solutions with a wide range of objective values as many as possible. A final solution is supposed to be chosen from the obtained trade-off solutions by the decision maker. On the other hand, the reference solution-based approach utilizes the information about the decision maker's preference in the form of a reference solution. We examine whether the EMO approach can find good trade-off solutions close to an arbitrarily given reference solution. Experimental results show that good solutions are not always obtained by the EMO approach. We also examine where the reference solution-based approach can find many trade-off solutions around the given reference solution. Experimental results show that many trade-off solutions can not be obtained even when an archive population of non-dominated solutions is stored in the reference solution-based approach. Based on these observations, we suggest a hybrid approach.|Hisao Ishibuchi,Kaname Narukawa","57447|GECCO|2005|Promising infeasibility and multiple offspring incorporated to differential evolution for constrained optimization|In this paper, we incorporate a diversity mechanism to the differential evolution algorithm to solve constrained optimization problems without using a penalty function. The aim is twofold () to allow infeasible solutions with a promising value of the objective function to remain in the population and also () to increase the probabilities of an individual to generate a better offspring while promoting collaboration of all the population to generate better solutions. These goals are achieved by allowing each parent to generate more than one offspring. The best offspring is selected using a comparison mechanism based on feasibility and this child is compared against its parent. To maintain diversity, the proposed approach uses a mechanism successfully adopted with other evolutionary algorithms where, based on a parameter Sr a solution (between the best offspring and the current parent) with a better value of the objective function can remain in the population, regardless of its feasibility. The proposed approach is validated using test functions from a well-known benchmark commonly adopted to validate constraint-handling techniques used with evolutionary algorithms. The statistical results obtained by the proposed approach are highly competitive (based on quality, robustness and number of evaluations of the objective function) with respect to other constraint-handling techniques, either based on differential evolution or on other evolutionary algorithms, that are representative of the state-of-the-art in the area. Finally, a small set of experiments were made to detect sensitivity of the approach to its parameters.|Efrén Mezura-Montes,Jesús Velázquez-Reyes,Carlos A. Coello Coello","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57294|GECCO|2005|Fitness inheritance for noisy evolutionary multi-objective optimization|This paper compares the performance of anti-noise methods, particularly probabilistic and re-sampling methods, using NSGA. It then proposes a computationally less expensive approach to counteracting noise using re-sampling and fitness inheritance. Six problems with different difficulties are used to test the methods. The results indicate that the probabilistic approach has better convergence to the Pareto optimal front, but it looses diversity quickly. However, methods based on re-sampling are more robust against noise but they are computationally very expensive to use. The proposed fitness inheritance approach is very competitive to re-sampling methods with much lower computational cost.|Lam Thu Bui,Hussein A. Abbass,Daryl Essam","57564|GECCO|2005|The effectiveness of multiobjective optimizer in single-objective optimization enviroment|This paper presents two new approaches for transforming a single-objective problem into a multi-objective problem. The first approach is based on relaxation of the constraints of the problem and the other is based on the addition of noise to the objective value or decision variable. Intuitively, these approaches provide more freedom to explore and a reduced likelihood of becoming trapped in local optima.Through numerical examples, we showed that the multi-objective versions produced by relaxing constraints can provide good results and that using the addition of noise can obtain better solutions when the function is multimodal and separable.|Shinya Watanabe,Kazutoshi Sakakibara","57416|GECCO|2005|A co-evolutionary hybrid algorithm for multi-objective optimization of gene regulatory network models|In this paper, the parameters of a genetic network for rice flowering time control have been estimated using a multi-objective genetic algorithm approach. We have modified the recently introduced concept of fuzzy dominance to hybridize the well-known Nelder Mead Simplex algorithm for better exploitation with a multi-objective genetic algorithm. A co-evolutionary approach is proposed to adapt the fuzzy dominance parameters. Additional changes to the previous approach have also been incorporated here for faster convergence, including elitism. Our results suggest that this hybrid algorithm performs significantly better than NSGA-II, a standard algorithm for multi-objective optimization.|Praveen Koduru,Sanjoy Das,Stephen Welch,Judith L. Roe,Zenaida P. Lopez-Dee","65559|AAAI|2005|Development of a Hybrid Knowledge-Based System for Multiobjective Optimization of Power Distribution System Operations|The development of a hybrid knowledge-based system with a coupling between knowledge-based and numerical methods for multiobjective optimization of power distribution operations is described. The advantages of a hybrid knowledge-based system are described followed by the system objectives, means of control, and constraints. A framework is provided that describes the necessary development stages of a commercial knowledge-based package. An overview of the utility knowledge acquisition procedure is provided to appreciate the complexity of defining the rule base. This is followed by a description of the flow of information in a three-level hierarchical rule base and a summary of network radiality, parameter. and performance rules employed in this rule base. After a heuristic preprocessor identifies a list of switch closures that would seem to reduce total system losses, network radiality rules assess if a particular search path has identified a switch that can be closed and a corresponding switch opened to maintain the radiality of the system or if the path is worth pursuing further. Network parameter rules ensure the system operates within original design parameters. Network performance rules assess the reduction in total system losses of each proposed switching operation. Where there is a coupling between knowledge-based and numerical methods, the integration of numerical methods is described. Finally, the validation and simulations as well as the benefits of this hybrid knowledge-based system are described.|Robert J. Sárfi,A. M. G. Solo","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens","57437|GECCO|2005|Learning computer programs with the bayesian optimization algorithm|We describe an extension of the Bayesian Optimization Algorithm (BOA), a probabilistic model building genetic algorithm, to the domain of program tree evolution. The new system, BOA programming (BOAP), improves significantly on previous probabilistic model building genetic programming (PMBGP) systems in terms of the articulacy and open-ended flexibility of the models learned, and hence control over the distribution of instances generated. Innovations include a novel tree representation and a generalized program evaluation scheme.|Moshe Looks,Ben Goertzel,Cassio Pennachin"],["16200|IJCAI|2005|Growth of Motor Coordination in Early Robot Learning|We present an implementation of a model of very early sensory-motor development, guided by results from developmental psychology. Behavioral acquisition and growth is demonstrated through constraint-lifting mechanisms initiated by global state variables. The results show how staged competence can be shaped by qualitative behavior changes produced by anatomical, computational and maturational constraints.|Mark H. Lee,Qinggang Meng","16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","65590|AAAI|2005|Online Resource Allocation Using Decompositional Reinforcement Learning|This paper considers a novel application domain for reinforcement learning that of \"autonomic computing,\" i.e. selfmanaging computing systems. RL is applied to an online resource allocation task in a distributed multi-application computing environment with independent time-varying load in each application. The task is to allocate servers in real time so as to maximize the sum of performance-based expected utility in each application. This task may be treated as a composite MDP, and to exploit the problem structure, a simple localized RL approach is proposed, with better scalability than previous approaches. The RL approach is tested in a realistic prototype data center comprising real servers, real HTTP requests, and realistic time-varying demand. This domain poses a number of major challenges associated with live training in a real system, including the need for rapid training, exploration that avoids excessive penalties, and handling complex, potentially non-Markovian system effects. The early results are encouraging in overnight training, RL performs as well as or slightly better than heavily researched model-based approaches derived from queuing theory.|Gerald Tesauro","16136|IJCAI|2005|Learning Strategies for Open-Domain Natural Language Question Answering|We present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources, questions, and answers. Our approach formulates QA as a problem of first order inference over a suitably expressive, learned representation. This framework draws on prior work in learning action and problem-solving strategies, as well as relational learning methods. We describe the design of a system implementing this model in the framework of natural language question answering for story comprehension. Finally, we compare our approach to three prior systems, and present experimental results demonstrating the efficacy of our model.|Eugene Grois,David C. Wilkins","16257|IJCAI|2005|Learning and Inference over Constrained Output|We study learning structured output in a discriminative framework where values of the output variables are estimated by local classifiers. In this framework, complex dependencies among the output variables are captured by constraints and dictate which global labels can be inferred. We compare two strategies, learning independent classifiers and inference based training, by observing their behaviors in different conditions. Experiments and theoretical justification lead to the conclusion that using inference based learning is superior when the local classifiers are difficult to learn but may require many examples before any discernible difference can be observed.|Vasin Punyakanok,Dan Roth,Wen-tau Yih,Dav Zimak","57522|GECCO|2005|Constructive induction and genetic algorithms for learning concepts with complex interaction|Constructive Induction is the process of transforming the original representation of hard concepts with complex interaction into a representation that highlights regularities. Most Constructive Induction methods apply a greedy strategy to find interacting attributes and then construct functions over them. This approach fails when complex interaction exists among attributes and the search space has high variation. In this paper, we illustrate the importance of applying Genetic Algorithms as a global search strategy for these methods and present MFEGA, while comparing it with other GA-based Constructive Induction methods. We empirically analyze our Genetic Algorithm's operators and compare MFEGA with greedy-based methods. We also performed experiments to evaluate the presented method when concept has attributes participating in more than one complex interaction. In experiments that are conducted, MFEGA successfully finds interacting attributes and constructs functions to represent interactions. Results show the advantage of using Genetic Algorithms for Constructive Induction when compared with greedy-based methods.|Leila Shila Shafti,Eduardo Pérez","65546|AAAI|2005|Robust Textual Inference Via Learning and Abductive Reasoning|We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., ). An abductive theorem prover then tries to find the minimum \"cost\" set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntacticsemantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE  challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.|Rajat Raina,Andrew Y. Ng,Christopher D. Manning","65460|AAAI|2005|Learning to Transform Natural to Formal Languages|This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains.|Rohit J. Kate,Yuk Wah Wong,Raymond J. Mooney","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons","65356|AAAI|2005|Leveraging Language into Learning|I hypothesize that learning a vocabulary to communicate between components of a system is equivalent to general learning. Moreover, I assert that some problems of general learning, such as eliminating bad hypotheses, deepening shallow representations, and generation of near-misses, will become simpler when refactored into communication learning problems.|Jacob Beal"],["16230|IJCAI|2005|Networked Distributed POMDPs A Synergy of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","65614|AAAI|2005|Exploiting the Structure of Hierarchical Plans in Temporal Constraint Propagation|Quantitative temporal constraints are an essential requirement for many planning domains. The HTN planning paradigm has proven to be better suited than other approaches to many applications. To date, however, efficiently integrating temporal reasoning with HTN planning has been little explored. This paper describes a means to exploit the structure of a HTN plan in performing temporal propagation on an associated Simple Temporal Network. By exploiting the natural restriction on permitted temporal constraints, the time complexity of propagation can be sharply reduced, while completeness of the inference is maintained. Empirical results indicate an order of magnitude improvement on real-world plans.|Neil Yorke-Smith","65542|AAAI|2005|Constraint-Based Preferential Optimization|We first show that the optimal and undominated outcomes of an unconstrained (and possibly cyclic) CP-net are the solutions of a set of hard constraints. We then propose a new algorithm for finding the optimal outcomes of a constrained CP-net which makes use of hard constraint solving. Unlike previous algorithms, this new algorithm works even with cyclic CP-nets. In addition. the algorithm is not tied to CP-nets, but can work with any preference formalism which produces a preorder over the outcomes. We also propose an approximation method which weakens the preference ordering induced by the CP-net, returning a larger set of outcomes, but provides a significant computational advantage. Finally, we describe a weighted constraint approach that allows to find good solutions even when optimals do not exist.|Steven David Prestwich,Francesca Rossi,Kristen Brent Venable,Toby Walsh","65516|AAAI|2005|Networked Distributed POMDPs A Synthesis of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present two novel algorithms for ND-POMDPs a distributed policy generation algorithm that performs local search and a systematic policy search that is guaranteed to reach the global optimal.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","16133|IJCAI|2005|The Complexity of Quantified Constraint Satisfaction Problems under Structural Restrictions|We give a clear picture of the tractabilityintractability frontier for quantified constraint satisfaction problems (QCSPs) under structural restrictions. On the negative side, we prove that checking QCSP satisfiability remains PSPACE-hard for all known structural properties more general than bounded treewidth and for the incomparable hypergraph acyclicity. Moreover, if the domain is not fixed, the problem is PSPACE-hard even for tree-shaped constraint scopes. On the positive side, we identify relevant tractable classes, including QCSPs with prefix  having bounded hypertree width, and QCSPs with a bounded number of guards. The latter are solvable in polynomial time without any bound on domains or quantifier alternations.|Georg Gottlob,Gianluigi Greco,Francesco Scarcello","16083|IJCAI|2005|A Unified Theory of Structural Tractability for Constraint Satisfaction and Spread Cut Decomposition|In this paper we introduce a generic form of structural decomposition for the constraint satisfaction problem, which we call a guarded decomposition. We show that many existing decomposition methods can be characterized in terms of finding guarded decompositions satisfying certain specified additional conditions. Using the guarded decomposition framework we are also able to define a new form of decomposition, which we call a spread cut. We show that discovery of width k spread-cut decompositions is tractable for each k, and that the spread cut decomposition strongly generalize all existing decompositions except hypertrees. Finally we exhibit a family of hypergraphs Hn, for n  , ,  ..., where the width of the best hypertree decomposition of each Hn is at least n, but the width of the best spreadcut decomposition is at most n.|David A. Cohen,Peter Jeavons,Marc Gyssens","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","65506|AAAI|2005|A Constraint Satisfaction Approach to Geospatial Reasoning|The large number of data sources on the Internet can be used to augment and verify the accuracy of geospatial sources, such as gazetteers and annotated satellite imagery. Data sources such as satellite imagery, maps, gazetteers and vector data have been traditionally used in geographic infonnation systems (GIS), but nontraditional geospatial data, such as online phone books and property records are more difficult to relate to imagery. In this paper, we present a novel approach to combining extracted information from imagery, road vector data, and online data sources. We represent the problem of identifying buildings in satellite images as a constraint satisfing problem (CSP) and use constraint programming to solve it. We apply this technique to real-world data sources in EI Segundo, CA and our experimental evaluation shows how this approach can accurately identify buildings when provided with both traditional and nontraditional data sources.|Martin Michalowski,Craig A. Knoblock","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder"]]}}