{"abstract":{"entropy":6.804007696229205,"topics":["machine learning, recent years, markov decision, natural language, reinforcement learning, markov processes, learning, description logic, decision processes, constraint satisfaction, partially observable, support vector, agents, search engine, web pages, learning systems, web, web search, knowledge base, information","speech recognition, present novel, division multiplexing, orthogonal division, frequency division, plays role, orthogonal frequency, orthogonal multiplexing, speech, frequency multiplexing, present systems, novel approach, ultra wideband, speech enhancement, motion estimation, systems based, ultra uwb, describes systems, describes speech, image","genetic algorithm, algorithm, evolutionary algorithm, genetic programming, present algorithm, optimization problem, particle swarm, algorithm problem, search algorithm, problem, algorithm optimization, solving problem, evolutionary computation, optimization, paper algorithm, present approach, search heuristic, solve problem, algorithm based, consider problem","neural network, artificial intelligence, widely used, network, sensor network, time series, wide range, wireless network, data management, petri nets, data stream, blind separation, bayesian network, distributed systems, arc consistency, classifier systems, data, immune systems, address problem, data integration","recent years, description logic, multi-agent systems, recent research, knowledge base, information systems, recent work, case-based reasoning, logic knowledge, resource allocation, multi-agent agents, logic reasoning, growing interest, recommender systems, self-interested agents, recent shown, coalition formation, received attention, allocation agents, recent interest","natural language, search engine, web pages, web search, data mining, queries data, information retrieval, semantic web, web services, xml data, web, web mining, materialized views, data web, query, database systems, database, xml document, query data, query learning","present novel, novel approach, present based, paper based, systems based, proposes novel, based, speech synthesis, paper novel, novel, speaker identification, paper present, novel based, present approach, automatic speech, automatic recognition, novel image, present efficient, present systems, technique","describes systems, design systems, control systems, access control, design, present design, present implementation, multiple access, low power, timing synchronization, digital circuit, systems implementation, proposes design, time delay, control, describes design, emotional speaking, present systems, describes, circuit","evolutionary algorithm, search algorithm, present algorithm, search heuristic, local search, differential evolution, evolutionary search, traveling salesman, evolution strategies, search, search space, present evolutionary, adaptive algorithm, algorithm applied, fitness function, algorithm used, successfully applied, dimensionality reduction, present search, algorithm test","genetic algorithm, genetic programming, genetic problem, problem programming, algorithm based, evolutionary algorithm, paper genetic, describes genetic, hybrid algorithm, feature selection, selection algorithm, genetic gas, genetic used, present genetic, paper algorithm, building block, present algorithm, algorithm gas, cartesian genetic, based genetic","wide range, immune systems, artificial immune, blind separation, sharing secret, software engineering, signature scheme, separation bss, source separation, xcs systems, schema data, schema mapping, blind bss, learning xcs, inspired immune, data source, scheme secure, source bss, classifier xcs, blind source","neural network, sensor network, wireless network, network, classifier systems, bayesian network, petri nets, arc consistency, problem network, paper network, present network, mobile robot, hoc network, wireless communication, cellular automata, computer vision, structure network, network data, control systems, xcsf computed"],"ranking":[["16533|IJCAI|2007|Bayesian Inverse Reinforcement Learning|Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.|Deepak Ramachandran,Eyal Amir","16313|IJCAI|2005|Temporal-Difference Networks with History|Temporal-difference (TD) networks are a formalism for expressing and learning grounded world knowledge in a predictive form Sutton and Tanner, . However, not all partially observable Markov decision processes can be efficiently learned with TD networks. In this paper, we extend TD networks by allowing the network-update process (answer network) to depend on the recent history of previous actions and observations rather than only on the most recent action and observation. We show that this extension enables the solution of a larger class of problems than can be solved by the original TD networks or by history-based methods alone. In addition, we apply TD networks to a problem that, while still simple, is significantly larger than has previously been considered. We show that history-extended TD networks can learn much of the common-sense knowledge of an egocentric gridworld domain with a single bit of perception.|Brian Tanner,Richard S. Sutton","66123|AAAI|2007|Continuous State POMDPs for Object Manipulation Tasks|My research focus is on using continuous state partially observable Markov decision processes (POMDPs) to perform object manipulation tasks using a robotic arm. During object manipulation, object dynamics can be extremely complex, non-linear and challenging to specify. To avoid modeling the full complexity of possible dynamics. I instead use a model which switches between a discrete number of simple dynamics models. By learning these models and extending Porta's continuous state POMDP framework (Porta et at. ) to incorporate this switching dynamics model, we hope to handle tasks that involve absolute and relative dynamics within a single framework. This dynamics model may be applicable not only to object manipulation tasks, but also to a number of other problems, such as robot navigation. By using an explicit model of uncertainty, I hope to create solutions to object manipulation tasks that more robustly handle the noisy sensory information received by physical robots.|Emma Brunskill","42933|IEICE Transations|2005|CHQ A Multi-Agent Reinforcement Learning Scheme for Partially Observable Markov Decision Processes|In this paper, we propose a new reinforcement learning scheme called CHQ that could efficiently acquire appropriate policies under partially observable Markov decision processes (POMDP) involving probabilistic state transitions, that frequently occurs in multi-agent systems in which each agent independently takes a probabilistic action based on a partial observation of the underlying environment. A key idea of CHQ is to extend the HQ-learning proposed by Wiering et al. in such a way that it could learn the activation order of the MDP subtasks as well as an appropriate policy under each MDP subtask. The goodness of the proposed scheme is experimentally evaluated. The result of experiments implies that it can acquire a deterministic policy with a sufficiently high success rate, even if the given task is POMDP with probabilistic state transitions.|Hiroshi Osada,Satoshi Fujita","65498|AAAI|2005|Searching for Common Sense Populating Cyc from the Web|The Cyc project is predicated on the idea that effective machine learning depends on having a core of knowledge that provides a context for novel learned information - what is known informally as \"common sense.\" Over the last twenty years, a sufficient core of common sense knowledge has been entered into Cyc to allow it to begin effectively and flexibly supporting its most important task increasing its own store of world knowledge. In this paper, we present initial work on a method of using a combination of Cyc and the World Wide Web, accessed via Google, to assist in entering knowledge into Cyc. The long-term goal is automating the process of building a consistent, formalized representation of the world in the Cyc knowledge base via machine learning. We present preliminary results of this work and describe how we expect the knowledge acquisition process to become more accurate, faster, and more automated in the future.|Cynthia Matuszek,Michael J. Witbrock,Robert C. Kahlert,John Cabral,David Schneider,Purvesh Shah,Douglas B. Lenat","44230|IEICE Transations|2007|Zero-Anaphora Resolution in Chinese Using Maximum Entropy|In this paper, we propose a learning classifier based on maximum entropy (ME) for resolving zero-anaphora in Chinese text. Besides regular grammatical, lexical, positional and semantic features motivated by previous research on anaphora resolution, we develop two innovative Web-based features for extracting additional semantic information from the Web. The values of the two features can be obtained easily by querying the Web using some patterns. Our study shows that our machine learning approach is able to achieve an accuracy comparable to that of state-of-the-art systems. The Web as a knowledge source can be incorporated effectively into the ME learning framework and significantly improves the performance of our approach.|Jing Peng,Kenji Araki","65913|AAAI|2006|Action Selection in Bayesian Reinforcement Learning|My research attempts to address on-line action selection in reinforcement learning from a Bayesian perspective. The idea is to develop more effective action selection techniques by exploiting information in a Bayesian posterior, while also selecting actions by growing an adaptive, sparse lookahead tree. I further augment the approach by considering a new value function approximation strategy for the belief-state Markov decision processes induced by Bayesian learning.|Tao Wang","16293|IJCAI|2005|Intimate Learning A Novel Approach for Combining Labelled and Unlabelled Data|This paper introduces a new bootstrapping method closely related to co-training and scoped-learning. The method is tested on a Web information extraction task of learning course names from web pages in which we use very few labelled items as seed data ( web pages) and combine with an unlabelled set ( web pages). The overall performance improved the precisionrecall from .%.% for a baseline EM-based method to .%.% for intimate learning.|Zhongmin Shi,Anoop Sarkar","66064|AAAI|2007|Optimizing Anthrax Outbreak Detection Using Reinforcement Learning|The potentially catastrophic impact of a bioterrorist attack makes developing effective detection methods essential for public health. In the case of anthrax attack, a delay of hours in making a right decision can lead to hundreds of lives lost. Current detection methods trade off reliability of alarms for early detection of outbreaks. The performance of these methods can be improved by modem disease-specific modeling techniques which take into account the potential costs and effects of an attack to provide optimal warnings. We study this optimization problem in the reinforcement learning framework. The key contribution of this paper is to apply Partially Observable Markov Decision Processes (POMDPs) on outbreak detection mechanism for improving alarm function in anthrax outbreak detection. Our approach relies on estimating the future benefit of true alarms and the costs of false alarms and using these quantities to identify an optimal decision. We present empirical evidence illustrating that the performance of detection methods with respect to sensitivity and timeliness is improved significantly by utilizing POMDPs.|Masoumeh T. Izadi,David L. Buckeridge","44237|IEICE Transations|2007|Constructing a Multilayered Boundary to Defend against Intrusive Anomalies|We propose a model for constructing a multilayered boundary in an information system to defend against intrusive anomalies by correlating a number of parametric anomaly detectors. The model formulation is based on two observations. First, anomaly detectors differ in their detection coverage or blind spots. Second, operating environments of the anomaly detectors reveal different information about system anomalies. The correlation among observation-specific anomaly detectors is first formulated as a Partially Observable Markov Decision Process, and then a policy-gradient reinforcement learning algorithm is developed for an optimal cooperation search, with the practical objectives being broader overall detection coverage and fewer false alerts. A host-based experimental scenario is developed to illustrate the principle of the model and to demonstrate its performance.|Zonghua Zhang,Hong Shen"],["43816|IEICE Transations|2007|MLSE Detection with Blind Linear Prediction and Subcarriers Interpolation for DSTBC-OFDM Systems|This paper proposes low-complexity blind detection for orthogonal frequency division multiplexing (OFDM) systems with the differential space-time block code (DSTBC) under time-varying frequency-selective Rayleigh fading. The detector employs the maximum likelihood sequence estimation (MLSE) in cooperation with the blind linear prediction (BLP), of which prediction coefficients are determined by the method of Lagrange multipliers. Interpolation of channel frequency responses is also applied to the detector in order to reduce the complexity. A complexity analysis and computer simulations demonstrate that the proposed detector can reduce the complexity to about a half, and that the complexity reduction causes only a loss of  dB in average EbN at BER of - when the prediction order and the degree of polynomial approximation are  and , respectively.|Seree Wanichpakdeedecha,Kazuhiko Fukawa,Hiroshi Suzuki,Satoshi Suyama","43877|IEICE Transations|2007|Finite Parameter Model for Doubly-Selective Channel Estimation in OFDM|To describe joint time-and frequency-selective (doubly-selective) channels in mobile broadband wireless communications, we propose to use the finite parameter model based on the same Bessel functions for each tap (Bessel model). An expression of channel estimation mean squared error (MSE) based on the finite parameter models in Orthogonal Frequency Division Multiplexing (OFDM) systems is derived. Then, our Bessel model is compared with commonly used finite parameter models in terms of the channel estimation MSE. Even if the channel taps have different channel correlations and some of the taps do not coincide with the Bessel function, the channel estimation MSE of the Bessel model is shown to be comparable or outperform existing models as validated by Monte-Carlo simulations over an ensemble of channels in typical urban and suburban environments.|Kok Ann Donny Teo,Shuichi Ohno","42596|IEICE Transations|2005|A Timing Synchronization Method with Low-Volume DSP for OFDM Packet Transmission Systems|This paper proposes a simple timing synchronization method in order to design a timing synchronization circuit with low-complex and low-volume digital signal processing (DSP) for orthogonal frequency division multiplexing (OFDM) packet transmission systems. The proposed method utilizes the subtraction process for acquirement of a timing metric of fast Fourier transform (FFT) window, whereas the conventional methods utilize the multiplication process. This paper adopts the proposed method to a standardized OFDM format, IEEE .a, and elucidates that the proposed one shows good transmission performance as well as the conventional one in fast time-variant multi-path Rayleigh fading channels by computer simulation.|Ryota Kimura,Ryuhei Funada,Hiroshi Harada,Manabu Sawada,Shoji Shinoda","43043|IEICE Transations|2006|Joint Estimation of Frequency Offset and Channel Frequency Response Using EM Algorithm for OFDM Systems|Orthogonal Frequency Division Multiplexing (OFDM) systems are very sensitive to the frequency offset of the local oscillator at the receiver while the symbol timing offset can be absorbed in the guard interval. For the same reason, estimation of the frequency characteristics, needed for OFDM to be adapted to the frequency selective fading, can only be carried out conventionally after the frequency offset has been compensated. And accurate estimation of large frequency offset certainly requires high precision estimate of the frequency characteristics. In this paper, we propose a new joint estimation method of the frequency offset and the channel frequency response using an Expectation-Maximization (EM) algorithm for OFDM systems. The proposed algorithm overcomes the limitation of the thus far proposed algorithm. By computer simulations, we show the proposed algorithm provides estimation accuracy close to its lower bound in a wide range of the frequency offset.|Masahiro Fujii,Makoto Itami,Kohji Itoh","43376|IEICE Transations|2006|IQ Imbalance Compensation Scheme for MB-OFDM Using Transmission Diversity|Currently, multiband orthogonal frequency division multiplexing (MB-OFDM) is considered to be one of the modulation schemes of UWB and is being actively investigated. It is necessary to provide low-cost receivers for consumers to receive wide support for the MB-OFDM system. Such receivers can be achieved by utilizing direct-conversion architecture. Direct-conversion architecture suffers from IQ imbalance. IQ imbalance causes intercarrier interference (ICI) in the demodulated signals. In this paper, a new scheme of IQ imbalance compensation using transmit diversity is proposed. This scheme enables the system to achieve frequency diversity and simultaneously compensates for the influence of IQ imbalance. It is shown that the performance of the proposed scheme is better than that of the conventional IQ imbalance compensation scheme.|Yohei Kato,Tsuyoshi Ikuno,Yukitoshi Sanada","43851|IEICE Transations|2007|Low-Complexity Maximum Likelihood Frequency Offset Estimation for OFDM|This letter proposes a low-complexity estimation method of integer frequency offset in orthogonal frequency division multiplexing (OFDM) systems. The performance and complexity of the proposed method are compared with that of Morelli and Mengali's method based on maximum likelihood (ML) technique. The results show that the performance of the proposed method is comparable to that of M&M method with reduced complexity.|Hyun Yang,Hyoung-Kyu Song,Young-Hwan You","42522|IEICE Transations|2005|A Simple Bit Allocation Scheme Based on Adaptive Coding for MIMO-OFDM Systems with V-BLAST Detector|We present a simple bit allocation scheme based on adaptive coding for MIMO-OFDM (Multiple Input Multiple Output - Orthogonal Frequency Division Multiplexing) systems with V-BLAST (Vertical-Bell laboratories LAyered Space-Time) detector. The proposed scheme controls the code rate of the channel coding and assigns the same modulation and coding to the set of selected sub-channels, which greatly reduces the feedback burden while achieving good performance. Simulation results show that the proposed scheme with minimal feedback provides significant performance improvement over other systems.|Jongwon Kim,Sanhae Kim,Min-Cheol Hong,Yoan Shin","44333|IEICE Transations|2007|Single Channel Speech Enhancement Based on Perceptual Frequency-Weighting|The present paper describes a quality enhancement of speech corrupted by additive background noise in a single channel system. The proposed approach is based on the introduction of perceptual criteria using a frequency-weighting filter in a subtractive-type enhancement process. This newly developed algorithm allows for an automatic adaptation in the time and frequency of the enhancement system and finds a suitable noise estimate according to the frequency of the corrupted speech. Experimental results show that the proposed approach can efficiently remove additive noise related to various types of noise corruption.|Seiji Hayashi,Masahiro Suguimoto","44046|IEICE Transations|2007|Reduced-Complexity Detection for DPC-OFTDMA System Enhanced by Multi-Layer MIMO-OFDM in Wireless Multimedia Communications|During these years, we have been focusing on developing ultra high-data-rate wireless access systems for future wireless multimedia communications. One of such kind of systems is called DPC-OFTDMA (dynamic parameter controlled orthogonal frequency and time division multiple access) which targets at beyond  Mbps data rate. In order to support higher data rates, e.g., several hundreds of Mbps or even Gbps for future wireless multimedia applications (e.g., streaming video and file transfer), it is necessary to enhance DPC-OFTDMA system based on MIMO-OFDM (multiple-input multiple-output orthogonal frequency division multiplexing) platform. In this paper, we propose an enhanced DPC-OFTDMA system based on Multi-Layer MIMO-OFDM scheme which combines both diversity and multiplexing in order to exploit potentials of both techniques. The performance investigation shows the proposed scheme has better performance than its counterpart based on full-multiplexing MIMO-OFDM scheme. In addition to the Exhaustive Detection (EXD) scheme which applies the same detection algorithm on each subcarrier independently, we propose the Reduced-Complexity Detection (RCD) scheme. The complexity reduction is achieved by exploiting the suboptimal Layer Detection Order and subcarrier correlation. The simulation results show that huge complexity can be reduced with very small performance loss, by using the proposed detection scheme. For example, .% complexity can be cut off with only . dB performance loss for the    enhanced DPC-OFTDMA system.|Ming Lei,Hiroshi Harada","44036|IEICE Transations|2007|A Novel Modulation with Parallel Combinatory and High Compaction Multi-Carrier Modulation|In this paper, we propose a new modulation named parallel combinatoryhigh compaction multi-carrier modulation (PCHC-MCM) using the techniques of parallel combinatory orthogonal frequency division multiplexing (PC-OFDM) and high compaction multi-carrier modulation (HC-MCM). Two types of PCHC-MCM systems, which are named as modulated PCHC-MCM system and (unmodulated) PCHC-MCM system, can be designed. The modulated PCHC-MCM system achieves better bit-error rate (BER) performance than that of HC-MCM system with equal bandwidth efficiency (BWE). The PCHC-MCM system can obtain the better peak-to-average power ratio (PAPR) characteristics by selecting appropriate constellation for each subcarrier. On the other hand, since PCHC-MCM can divide the PC-OFDM symbol duration into multiple time-slots, the advantages of frequency hopping (FH) can be applied in the PCHC-MCM system. Therefore, we also combine the PCHC-MCM and frequency hopping multiple access (FHMA) to propose a novel multiple access (MA) system. It can simultaneously transmit multiple users' data within one symbol duration of PC-OFDM.|Yafei Hou,Masanori Hamamura"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","58086|GECCO|2007|A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design|This paper presents a hybrid evolutionary programming algorithm to solve the spread spectrum radar polyphase code design problem. The proposed algorithm uses an Evolutionary Programming (EP) approach as global search heuristic. This EP is hybridized with a gradient-based local search procedure which includes a dynamic step adaptation procedure to perform accurate and efficient local search for better solutions. Numerical examples demonstrate that the algorithm outperforms existing approaches for this problem.|√?ngel M. P√©rez-Bellido,Sancho Salcedo-Sanz,Emilio G. Ort√≠z-Garc√≠a,Antonio Portilla-Figueras","43989|IEICE Transations|2007|A Genetic Algorithm with Conditional Crossover and Mutation Operators and Its Application to Combinatorial Optimization Problems|In this paper, we present a modified genetic algorithm for solving combinatorial optimization problems. The modified genetic algorithm in which crossover and mutation are performed conditionally instead of probabilistically has higher global and local search ability and is more easily applied to a problem than the conventional genetic algorithms. Three optimization problems are used to test the performances of the modified genetic algorithm. Experimental studies show that the modified genetic algorithm produces better results over the conventional one and other methods.|Rong Long Wang,Shinichi Fukuta,Jiahai Wang,Kozo Okazaki","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","58203|GECCO|2007|Hybrid evolutionary algorithms on minimum vertex cover for random graphs|This paper analyzes the hierarchical Bayesian optimization algorithm (hBOA) on minimum vertex cover for standard classes of random graphs and transformed SAT instances. The performance of hBOA is compared with that of the branch-and-bound problem solver (BB), the simple genetic algorithm (GA) and the parallel simulated annealing (PSA). The results indicate that BB is significantly outperformed by all the other tested methods, which is expected as BB is a complete search algorithm and minimum vertex cover is an NP-complete problem. The best performance is achieved with hBOA nonetheless, the performance differences between hBOA and other evolutionary algorithms are relatively small, indicating that mutation-based search and recombination-based search lead to similar performance on the tested problem instances.|Martin Pelikan,Rajiv Kalapala,Alexander K. Hartmann","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","58240|GECCO|2007|Symbiotic tabu search|Recombination in the Genetic Algorithm (GA) is supposed to extract the component characteristics from two parents and reassemble them in different combinations hopefully producing an offspring that has the good characteristics of both parents. Symbiotic Combination is formerly introduced as an alternative for sexual recombination operator to overcome the need of explicit design of recombination operators in GA all. This paper presents an optimization algorithm based on using this operator in Tabu Search. The algorithm is benchmarked on two problem sets and is compared with standard genetic algorithm and symbiotic evolutionary adaptation model, showing success rates higher than both cited algorithms.|Ramin Halavati,Saeed Bagheri Shouraki,Bahareh Jafari Jashmi,Mojdeh Jalali Heravi","57756|GECCO|2006|A fast hybrid genetic algorithm for the quadratic assignment problem|Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the \"fast hybrid genetic algorithm\" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm.|Alfonsas Misevicius","57751|GECCO|2006|Evolutionary learning with kernels a generic solution for large margin problems|In this paper we embed evolutionary computation into statistical learning theory. First, we outline the connection between large margin optimization and statistical learning and see why this paradigm is successful for many pattern recognition problems. We then embed evolutionary computation into the most prominent representative of this class of learning methods, namely into Support Vector Machines (SVM). In contrast to former applications of evolutionary algorithms to SVMs we do not only optimize the method or kernel parameters. We rather use both evolution strategies and particle swarm optimization in order to directly solve the posed constrained optimization problem. Transforming the problem into the Wolfe dual reduces the total runtime and allows the usage of kernel functions. Exploiting the knowledge about this optimization problem leads to a hybrid mutation which further decreases convergence time while classification accuracy is preserved. We will show that evolutionary SVMs are at least as accurate as their quadratic programming counterparts on six real-world benchmark data sets. The evolutionary SVM variants frequently outperform their quadratic programming competitors. Additionally, the proposed algorithm is more generic than existing traditional solutions since it will also work for non-positive semidefinite kernel functions and for several, possibly competing, performance criteria.|Ingo Mierswa","57612|GECCO|2006|A new hybrid evolutionary algorithm for the huge -cardinality tree problem|In recent years it has been shown that an intelligent combination of metaheuristics with other optimization techniques can significantly improve over the application of a pure metaheuristic. In this paper, we combine the evolutionary computation paradigm with dynamic programming for the application to the NP-hard k-cardinality tree problem. Given an undirected graph G with node and edge weights, this problem consists of finding a tree in G with exactly k edges such that the sum of the weights is minimal. The genetic operators of our algorithm are based on an existing dynamic programming algorithm from the literature for finding optimal subtrees in a given tree. The simulation results show that our algorithm is able to improve the best known results for benchmark problems from the literature in  cases.|Christian Blum"],["57958|GECCO|2007|Dendritic cells for SYN scan detection|Artificial immune systems have previously been applied to the problem of intrusion detection. The aim of this research is to develop an intrusion detection system based on the function of Dendritic Cells (DCs). DCs are antigen presenting cells and key to the activation of the human immune system, behaviour which has been abstracted to form the Dendritic Cell Algorithm (DCA). In algorithmic terms, individual DCs perform multi-sensor data fusion, asynchronously correlating the fused data signals with a secondary data stream. Aggregate output of a population of cells is analysed and forms the basis of an anomaly detection system. In this paper the DCA is applied to the detection of outgoing port scans using TCP SYN packets. Results show that detection can be achieved with the DCA, yet some false positives can be encountered when simultaneously scanning and using other network services. Suggestions are made for using adaptive signals to alleviate this uncovered problem.|Julie Greensmith,Uwe Aickelin","43628|IEICE Transations|2006|Application-Coexistent Wire-Rate Network Monitor for  Gigabit-per-Second Network|To apply network monitoring functions to emerging high-quality video streaming services, we proposed an application-coexistent monitor (APCM). In APCM, a streaming server can works as an active monitor and a passive monitor. In addition, IP packets sent from the server carry monitoring information together with application's data such as video signals. To achieve APCM on a -Gbps network, we developed a network interface card for an application-coexistent wire-rate network monitor (AWING NIC). It provides () a function to append GPS-based accurate timestamps to every packet that streaming applications send and receive, which can be used for real-time monitoring of delays and inter-packet gap, and () functions to capture and generate -Gbps wire-rate traffic without depending on packets' size, achieved by our highly-efficient DMA-transfer mechanisms. Such monitoring capability are unprecedented in existing PC-based systems because of the limitation in PC system's architecture. As an evaluation of APCM in an actual network, we conducted an experiment to transmit a -Gbps high-quality video stream over an IP network with the system in which we installed the AWING NIC. The results revealed that the video stream became highly bursty by passing through the network, and the observed smallest inter-packet gap corresponds to the value of -Gbps wire-rate traffic, which supports the effectiveness of our development.|Kenji Shimizu,Tsuyoshi Ogura,Tetsuo Kawano,Hiroyuki Kimiyama,Mitsuru Maruyama,Kei'ichi Koyanagi","57320|GECCO|2005|A pareto archive evolutionary strategy based radial basis function neural network training algorithm for failure rate prediction in overhead feeders|This paper outlines a radial basis function neural network approach to predict the failures in overhead distribution lines of power delivery systems. The RBF networks are trained using historical data. The network sizes and errors are simultaneously minimized using the Pareto Archive Evolutionary Strategy algorithm. Mutation of the network is carried out by invoking an orthogonal least square procedure. The performance of the proposed method was compared to a fuzzy inference approach and with multilayered perceptrons. The results suggest that this approach outperforms the other techniques for the prediction of failure rates.|Grant Cochenour,Jerad Simon,Sanjoy Das,Anil Pahwa,Surasish Nag","65846|AAAI|2006|A Manifold Regularization Approach to Calibration Reduction for Sensor-Network Based Tracking|The ability to accurately detect the location of a mobile node in a sensor network is important for many artificial intelligence (AI) tasks that range from robotics to context-aware computing. Many previous approaches to the location-estimation problem assume the availability of calibrated data. However, to obtain such data requires great effort. In this paper, we present a manifold regularization approach known as LeMan to calibration-effort reduction for tracking a mobile node in a wireless sensor network. We compute a subspace mapping function between the signal space and the physical space by using a small amount of labeled data and a large amount of unlabeled data. This mapping function can be used online to determine the location of mobile nodes in a sensor network based on the signals received. We use Crossbow MICA to setup the network and USB camera array to obtain the ground truth. Experimental results show that we can achieve a higher accuracy with much less calibration effort as compared to several previous systems.|Jeffrey Junfeng Pan,Qiang Yang,Hong Chang,Dit-Yan Yeung","80537|VLDB|2005|A Heartbeat Mechanism and Its Application in Gigascope|Data stream management systems often rely on ordering properties of tuple attributes in order to implement non-blocking operators. However, query operators that work with multiple streams, such as stream merge or join, can often still block if one of the input stream is very slow or bursty. In principle, punctuation and heartbeat mechanisms have been proposed to unblock streaming operators. In practice, it is a challenge to incorporate such mechanisms into a high-performance stream management system that is operational in an industrial application.In this paper, we introduce a system for punctuation-carrying heartbeat generation that we developed for Gigascope, a high-performance streaming database for network monitoring, that is operationally used within AT&T's IP backbone. We show how heartbeats can be regularly generated by low-level nodes in query execution plans and propagated upward unblocking all streaming operators on its way. Additionally, our heartbeat mechanism can be used for other applications in distributed settings such as detecting node failures, performance monitoring, and query optimization. A performance evaluation using live data feeds shows that our system is capable of working at multiple Gigabit line speeds in a live, industrial deployment and can significantly decrease the query memory utilization.|Theodore Johnson,S. Muthukrishnan,Vladislav Shkapenyuk,Oliver Spatscheck","80469|VLDB|2005|REED Robust Efficient Filtering and Event Detection in Sensor Networks|This paper presents a set of algorithms for efficiently evaluating join queries over static data tables in sensor networks. We describe and evaluate three algorithms that take advantage of distributed join techniques. Our algorithms are capable of running in limited amounts of RAM, can distribute the storage burden over groups of nodes, and are tolerant to dropped packets and node failures. REED is thus suitable for a wide range of event-detection applications that traditional sensor network database and data collection systems cannot be used to implement.|Daniel J. Abadi,Samuel Madden,Wolfgang Lindner","43553|IEICE Transations|2006|DCLUE A Distributed Cluster Emulator|Given the availability of high-speed Ethernet and HW based protocol offload, clustered systems using a commodity network fabric (e.g., TCPIP over Ethernet) are expected to become more attractive for a range of e-business and data center applications. In this paper, we describe a comprehensive simulation to study the performance of clustered database systems using such a fabric. The simulation model currently supports both TCP and SCTP as the transport protocol and models an Oracle i like clustered DBMS running a TPC-C like workload. The model can be used to study a wide variety of issues regarding the performance of clustered DBMS systems including the impact of enhancements to network layers (transport, IP, MAC), QoS mechanisms or latency improvements, and cluster-wide power control issues.|Krishna Kant,Amit Sahoo,Nrupal Jani","80603|VLDB|2006|A Middleware for Fast and Flexible Sensor Network Deployment|A key problem in current sensor network technology is the heterogeneity of the available software and hardware platforms which makes deployment and application development a tedious and time consuming task. To minimize the unnecessary and repetitive implementation of identical functionalities for different platforms, we present our Global Sensor Networks (GSN) middleware which supports the flexible integration and discovery of sensor networks and sensor data, enables fast deployment and addition of new platforms, provides distributed querying, filtering, and combination of sensor data, and supports the dynamic adaption of the system configuration during operation. GSN's central concept is the virtual sensor abstraction which enables the user to declaratively specify XML-based deployment descriptors in combination with the possibility to integrate sensor network data through plain SQL queries over local and remote sensor data sources. In this demonstration, we specifically focus on the deployment aspects and allow users to dynamically reconfigure the running system, to add new sensor networks on the fly, and to monitor the effects of the changes via a graphical interface. The GSN implementation is available from httpglobalsn.sourceforge.net.|Karl Aberer,Manfred Hauswirth,Ali Salehi","65597|AAAI|2005|CORMS AI Decision Support System for Monitoring US Maritime Environment|Rule based reasoning and case based reasoning have emerged as two important and complementary reasoning methodologies in artificial intelligence (AI). This paper describes the approach for the development of CORMS AI, a decision support system which employs rule-based and case-based reasoning to assist NOAA's Center for Operational Oceanographic Products and Services watch standing personnel in monitoring the quality of marine environmental data and information. CORMS AI has been in operation since July . The system accurately and reliably identifies suspect data and network disruptions, and has decreased the amount of time it takes to identify and troubleshoot sensor, network, and server failures. CORMS AI has proven to be robust, extendable, and cost effective. It is estimated that CORMS AI will save government over one million dollars per year when its full range of quality control monitoring capabilities is implemented.|Haleh Vafaie,Carl Cecere","65785|AAAI|2006|Performing Incremental Bayesian Inference by Dynamic Model Counting|The ability to update the structure of a Bayesian network when new data becomes available is crucial for building adaptive systems. Recent work by Sang, Beame, and Kautz (AAAI ) demonstrates that the well-known Davis-Putnam procedure combined with a dynamic decomposition and caching technique is an effective method for exact inference in Bayesian networks with high density and width. In this paper, we define dynamic model counting and extend the dynamic decomposition and caching technique to multiple runs on a series of problems with similar structure. This allows us to perform Bayesian inference incrementally as the structure of the network changes. Experimental results show that our approach yields significant improvements over the previous model counting approaches on multiple challenging Bayesian network instances.|Wei Li 0002,Peter van Beek,Pascal Poupart"],["16738|IJCAI|2007|Quantified Coalition Logic|We add a limited but useful form of quantification to Coalition Logic, a popular formalism for reasoning about cooperation in game-like multi-agent systems. The basic constructs of Quantified Coalition Logic (QCL) allow us to express properties as \"there exists a coalition C satisfying property P such that C can achieve . We give an axiomatization of QCL, and show that while it is no more expressive than Coalition Logic, it is exponentially more succinct. The time complexity of QCL model checking for symbolic and explicit state representations is shown to be no worse than that of Coalition Logic. We illustrate the formalism by showing how to succinctly specify such social choice mechanisms as majority voting, which in Coalition Logic require specifications that are exponentially long in the number of agents.|Thomas √\u2026gotnes,Wiebe van der Hoek,Michael Wooldridge","66270|AAAI|2007|Dominance and Equivalence for Sensor-Based Agents|This paper describes recent results from the robotics community that develop a theory, similar in spirit to the theory of computation, for analyzing sensor-based agent systems. The central element to this work is a notion of dominance of one such system over another. This relation is formally based on the agents' progression through a derived information space, but may informally be understood as describing one agent's ability to \"simulate\" another. We present some basic properties of this dominance relation and demonstrate its usefulness by applying it to a basic problem in robotics. We argue that this work is of interest to a broad audience of artificial intelligence researchers for two main reasons. First, it calls attention to the possibility of studying belief spaces in way that generalizes both probabilistic and nondeterministic uncertainty models. Second, it provides a means for evaluating the information that an agent is able to acquire (via its sensors and via conformant actions), independent of any optimality criterion and of the task to be completed.|Jason M. O'Kane,Steven M. LaValle","65469|AAAI|2005|Description Logic-Ground Knowledge Integration and Management|This abstract describes ongoing work in developing large-scale knowledge repositories. The project addresses three primary aspects of such systems integration of knowledge sources access and retrieval of stored knowledge scalable, effective repositories. Previous results have shown the effectiveness of description logic-based representations in integrating knowledge sources and the role of non-standard inferences in supporting repository reasoning tasks. Current efforts include developing general-purpose mechanisms for adapting reasoning algorithms for optimized inference under known domain structure and effective use of database technology as a large-scale knowledge base backend.|Joseph Kopena","66236|AAAI|2007|Optimal Regression for Reasoning about Knowledge and Actions|We show how in the propositional case both Reiter's and Scherl & Levesque's solutions to the frame problem can be modelled in dynamic epistemic logic (DEL), and provide an optimal regression algorithm for the latter. Our method is as follows we extend Reiter's framework by integrating observation actions and modal operators of knowledge, and encode the resulting formalism in DEL with announcement and assignment operators. By extending Lutz' recent satisfiability-preserving reduction to our logic, we establish optimal decision procedures for both Reiter's and Scherl & Levesque's approaches satisfiability is NP-complete for one agent, PSPACE-complete for multiple agents and EXPTIME-complete when common knowledge is involved.|Hans P. van Ditmarsch,Andreas Herzig,Tiago De Lima","16505|IJCAI|2007|Market Based Resource Allocation with Incomplete Information|Although there are some research efforts toward resource allocation in multi-agent systems (MAS), most of these work assume that each agent has complete information about other agents. This research investigates interactions among selfish, rational, and autonomous agents in resource allocation, each with incomplete information about other entities, and each seeking to maximize its expected utility. This paper presents a proportional resource allocation mechanism and gives a game theoretical analysis of the optimal strategies and the analysis shows the existence of equilibrium in the incomplete information setting. By augmenting the resource allocation mechanism with a deal optimization mechanism, trading agents can be programmed to optimize resource allocation results by updating beliefs and resubmitting bids. Experimental results showed that by having a deal optimization stage, the resource allocation mechanism produced generally optimistic outcomes (close to market equilibrium).|Bo An,Chunyan Miao,Zhiqi Shen","80848|VLDB|2007|Reasoning about the Behavior of Semantic Web Services with Concurrent Transaction Logic|The recent upsurge in the interest in Semantic Web services and the high-profile projects such as the WSMO, OWLS, and SWSL, have drawn attention to the importance of logic-based modeling of the behavior of Web services. In the context of Semantic Web services, the logic-based approach has many applications, including service discovery, service choreography, enactment, and contracting for services. In this paper we propose logic-based methods for reasoning about service behavior, including the aforementioned choreography, contracting, and enactment. The formalism underlying our framework is Concurrent Transaction Logic---a logic for declarative specification, analysis, and execution of database transactions. The new results include reasoning about service behavior under more general sets of constraints and extension of the framework towards conditional control and data flow---two crucial aspect that were missing in previous logical formalizations.|Dumitru Roman,Michael Kifer","16512|IJCAI|2007|Collaborative Inductive Logic Programming for Path Planning|In distributed systems, learning does not necessarily involve the participation of agents directly in the inductive process itself. Instead, many systems frequently employ multiple instances of induction separately. In this paper, we develop and evaluate a new approach for learning in distributed systems that tightly integrates processes of induction between agents, based on inductive logic programming techniques. The paper's main contribution is the integration of an epistemic approach to reasoning about knowledge with inverse entailment during induction. The new approach facilitates a systematic approach to the sharing of knowledge and invention of predicates only when required. We illustrate the approach using the well-known path planning problem and compare results empirically to (multiple instances of) single agent-based induction over varying distributions of data. Given a chosen path planning algorithm, our algorithm enables agents to combine their local knowledge in an effective way to avoid central control while significantly reducing communication costs.|Jian Huang,Adrian R. Pearce","42831|IEICE Transations|2005|A Coalition Formation Framework Based on Transitive Dependence|Coalition formation in multi-agent systems (MAS) is becoming increasingly important as it increases the ability of agents to execute tasks and maximize their payoffs. Dependence relations are regarded as the foundation of coalition formation. This paper proposes a novel dependence theory namely transitive dependence theory for dynamic coalition formation in multi-agent systems. Transitive dependence is an extension of direct dependence that supports an agent's reasoning about other social members during coalition formation. Based on the proposed transitive dependence theory, a dynamic coalition formation framework has been worked out which includes information gathering, transitive dependence based reasoning for coalition partners search and coalition resolution. The nested coalitions and how to deal with incomplete knowledge while forming coalitions are also discussed in the paper.|Bo An,Chunyan Miao,Daijie Cheng","16616|IJCAI|2007|Multi-Winner Elections Complexity of Manipulation Control and Winner-Determination|Although recent years have seen a surge of interest in the computational aspects of social choice, no attention has previously been devoted to elections with multiple winners, e.g., elections of an assembly or committee. In this paper, we fully characterize the worst-case complexity of manipulation and control in the context of four prominent multi-winner voting systems. Additionally, we show that several tailor-made multi-winner voting schemes are impractical, as it is NP-hard to select the winners in these schemes.|Ariel D. Procaccia,Jeffrey S. Rosenschein,Aviv Zohar","80481|VLDB|2005|Database Publication Practices|There has been a growing interest in improving the publication processes for database research papers. This panel reports on recent changes in those processes and presents an initial cut at historical data for the VLDB Journal and ACM Transactions on Database Systems.|Philip A. Bernstein,David J. DeWitt,Andreas Heuer,Zachary G. Ives,Christian S. Jensen,Holger Meyer,M. Tamer √\u2013zsu,Richard T. Snodgrass,Kyu-Young Whang,Jennifer Widom"],["58119|GECCO|2007|Multiobjective clustering with automatic k-determination for large-scale data|Web mining - data mining for web data - is a key factor of web technologies. Especially, web behavior mining has attracted a great deal of attention recently. Behavior mining involves analyzing the behavior of users, finding patterns of user behavior, and predicting their subsequent behaviors or interests. Web behavior mining is used in web advertising systems or content recommendation systems. To analyze huge amounts of data, such as web data, data-clustering techniques are usually used. Data clustering is a technique involving the separation of data into groups according to similarity, and is usually used in the first step of data mining. In the present study, we developed a scalable data-clustering algorithm for web mining based on existent evolutionary multiobjective clustering algorithm. To derive clusters, we applied multiobjective clustering with automatic k-determination (MOCK). It has been reported that MOCK shows better performance than k-means, agglutination methods, and other evolutionary clustering algorithms. MOCK can also find the appropriate number of clusters using the information of the trade-off curve. The k-determination scheme of MOCK is powerful and strict. However the computational costs are too high when applied to clustering huge data. In this paper, we propose a scalable automatic k-determination scheme. The proposed scheme reduces Pareto-size and the appropriate number of clusters can usually be determined.|Nobukazu Matake,Tomoyuki Hiroyasu,Mitsunori Miki,Tomoharu Senda","43591|IEICE Transations|2006|An Efficient Schema-Based Technique for Querying XML Data|As data integration over the Web has become an increasing demand, there is a growing desire to use XML as a standard format for data exchange. For sharing their grammars efficiently, most of the XML documents in use are associated with a document structure description, such as DTD or XML schema. However, the document structure information is not utilized efficiently in previously proposed techniques of XML query processing. In this paper, we present a novel technique that reduces the disk IO complexity of XML query processing. We design a schema-based numbering scheme called SPAR that incorporates both structure information and tag names extracted from DTD or XML schema. Based on SPAR, we develop a mechanism called VirtualJoin that significantly reduces disk IO workload for processing XML queries. As shown by experiments, VirtualJoin outperforms many prior techniques.|Dao Dinh Kha,Masatoshi Yoshikawa","80741|VLDB|2007|Efficient Keyword Search over Virtual XML Views|Emerging applications such as personalized portals, enterprise search and web integration systems often require keyword search over semi-structured views. However, traditional information retrieval techniques are likely to be expensive in this context because they rely on the assumption that the set of documents being searched is materialized. In this paper, we present a system architecture and algorithm that can efficiently evaluate keyword search queries over virtual (unmaterialized) XML views. An interesting aspect of our approach is that it exploits indices present on the base data and thereby avoids materializing large parts of the view that are not relevant to the query results. Another feature of the algorithm is that by solely using indices, we can still score the results of queries over the virtual view, and the resulting scores are the same as if the view was materialized. Our performance evaluation using the INEX data set in the Quark  open-source XML database system indicates that the proposed approach is scalable and efficient.|Feng Shao,Lin Guo,Chavdar Botev,Anand Bhaskar,Muthiah Chettiar,Fan Yang 0002,Jayavel Shanmugasundaram","80520|VLDB|2005|The SphereSearch Engine for Unified Ranked Retrieval of Heterogeneous XML and Web Documents|This paper presents the novel SphereSearch Engine that provides unified ranked retrieval on heterogeneous XML and Web data. Its search capabilities include vague structure conditions, text content conditions, and relevance ranking based on IR statistics and statistically quantified ontological relationships. Web pages in HTML or PDF are automatically converted into XML format, with the option of generating semantic tags by means of linguistic annotation tools. For Web data the XML-oriented query engine is leveraged to provide very rich search options that cannot be expressed in traditional Web search engines concept-aware and link-aware querying that takes into account the implicit structure and context of Web pages. The benefits of the SphereSearch engine are demonstrated by experiments with a large and richly tagged but non-schematic open encyclopedia extended with external documents.|Jens Graupmann,Ralf Schenkel,Gerhard Weikum","66062|AAAI|2007|Mining Web Query Hierarchies from Clickthrough Data|In this paper, we propose to mine query hierarchies from clickthrough data, which is within the larger area of automatic acquisition of knowledge from the Web. When a user submits a query to a search engine and clicks on the returned Web pages, the user's understanding of the query as well as its relation to the Web pages is encoded in the clickthrough data. With millions of queries being submitted to search engines every day, it is both important and beneficial to mine the knowledge hidden in the queries and their intended Web pages. We can use this information in various ways, such as providing query suggestions and organizing the queries. In this paper, we plan to exploit the knowledge hidden in clickthrough logs by constructing query hierarchies, which can reflect the relationship among queries. Our proposed method consists of two stages generating candidate queries and determining \"generalizationspecialization\" relatinns between these queries in a hierarchy. We test our method on some labeled data sets and illustrate the effectiveness of our proposed solution empirically.|Dou Shen,Min Qin,Weizhu Chen,Qiang Yang,Zheng Chen","80542|VLDB|2005|Database-Inspired Search|\"WQL A Query Language for the WWW\", published in , presented a language with several distinctive features. Employing existing indexes as access paths, it allowed the selection of documents using conditions on semi-structured documents and maintaining dynamic views of navigational queries. WQL was capable of automatically filling out forms and navigating through them. Finally, in the SQL tradition, it was a declarative query language, that could be the subject of optimization.Ten years later, we examine some current trends in the domain of search, namely the emergence of system-level search services and of the semantic web. In this context, we explore whether WQL's ideas are still relevant to help improve information search and retrieval. We identify two main environments for searching, the enterprise and the web at large. Both environments could benefit from database-inspired integration language, and an execution system that implements it.|David Konopnicki,Oded Shmueli","80829|VLDB|2007|EntityRank Searching Entities Directly and Holistically|As the Web has evolved into a data-rich repository, with the standard \"page view,\" current search engines are becoming increasingly inadequate for a wide range of query tasks. While we often search for various data \"entities\" (e.g., phone number, paper PDF, date), today's engines only take us indirectly to pages. While entities appear in many pages, current engines only find each page individually. Toward searching directly and holistically for finding information of finer granularity, we study the problem of entity search, a significant departure from traditional document retrieval. We focus on the core challenge of ranking entities, by distilling its underlying conceptual model Impression Model and developing a probabilistic ranking framework, EntityRank, that is able to seamlessly integrate both local and global information in ranking. We evaluate our online prototype over a TB Web corpus, and show that EntityRank performs effectively.|Tao Cheng,Xifeng Yan,Kevin Chen-Chuan Chang","65845|AAAI|2006|An Investigation into the Feasibility of the Semantic Web|We investigate the challenges that must be addressed for the Semantic Web to become a feasible enterprise. Specifically we focus on the query answering capability of the Semantic Web. We put forward that two key challenges we face are heterogeneity and scalability. We propose a flexible and decentralized framework for addressing the heterogeneity problem and demonstrate that sufficient reasoning is possible over a large dataset by taking advantage of database technologies and making some tradeoff decisions. As a proof of concept, we collect a significant portion of the available Semantic Web data use our framework to resolve some heterogeneity and reason over the data as one big knowledge base. In addition to demonstrating the feasibility of a \"real\" Semantic Web, our experiments have provided us with some interesting insights into how it is evolving and the type of queries that can be answered.|Zhengxiang Pan,Abir Qasem,Jeff Heflin","80519|VLDB|2005|Database Change Notifications Primitives for Efficient Database Query Result Caching|Many database applications implement caching of data from a back-end database server to avoid repeated round trips to the back-end and to improve response times for end-user requests. For example, consider a web application that caches dynamic web content in the mid-tier , . The content of dynamic web pages is usually assembled from data stored in the underlying database system and subject to modification whenever the data sources are modified. The workload is ideal for caching query results most queries are read-only (browsing sessions) and only a small portion of the queries are actually modifying data. Caching at the mid-tier helps off-load the back-end database servers and can increase scalability of a distributed system drastically.|C√©sar A. Galindo-Legaria,Torsten Grabs,Christian Kleinerman,Florian Waas","80702|VLDB|2006|Query Optimization over Web Services|Web services are becoming a standard method of sharing data and functionality among loosely-coupled systems. We propose a general-purpose Web Service Management System (WSMS) that enables querying multiple web services in a transparent and integrated fashion. This paper tackles a first basic WSMS problem query optimization for Select-Project-Join queries spanning multiple web services. Our main result is an algorithm for arranging a query's web service calls into a pipelined execution plan that optimally exploits parallelism among web services to minimize the query's total running time. Surprisingly, the optimal plan can be found in polynomial time even in the presence of arbitrary precedence constraints among web services, in contrast to traditional query optimization where the analogous problem is NP-hard. We also give an algorithm for determining the optimal granularity of data \"chunks\" to be used for each web service call. Experiments with an initial prototype indicate that our algorithms can lead to significant performance improvement over more straightforward techniques.|Utkarsh Srivastava,Kamesh Munagala,Jennifer Widom,Rajeev Motwani"],["16245|IJCAI|2005|Sophia A novel approach for Textual Case-based Reasoning|In this paper we present a novel methodology for textual case-based reasoning. This technique is unique in that it automatically discovers case and similarity knowledge, is language independent, is scaleable and facilitates semantic similarity between cases to be carried out inherently without the need for domain knowledge. In addition it provides an insight into the thematical content of the case-base as a whole, which enables users to better structure queries. We present an analysis of the competency of the system by assessing the quality of the similarity knowledge discovered and show how it is ideally suited to case-based retrieval (querying by example).|David W. Patterson,Niall Rooney,Vladimir Dobrynin,Mykola Galushka","43705|IEICE Transations|2006|Perceptually Weighted Mel-Cepstrum Analysis of Speech Based on Psychoacoustic Model|This letter proposes a novel approach for mel-cepstral analysis based on the psychoacoustic model of MPEG. A perceptual weighting function is developed by applying cubic spline interpolation on the signal-to-mask ratios (SMRs) which are obtained from the psychoacoustic model. Experiments on speaker identification and speech re-synthesis showed that the proposed method not only improved the speaker recognition performance, but also improved the speech quality of the re-synthesized speech.|Hongwu Yang,Dezhi Huang,Lianhong Cai","65708|AAAI|2006|Towards Modeling Threaded Discussions using Induced Ontology Knowledge|Online discussion boards are a popular form of web-based computer-mediated communication, especially in the areas of distributed education and customer support. Automatic analysis for discussion understanding would enable better information assessment and assistance. This paper describes an extensive study of the relationship between individual messages and full discussion threads. We present a new approach to classifying discussions using a Rocchio-style classifier with little cost for data labeling. In place of a labeled data set, we employ a coarse domain ontology that is automatically induced from a canonical text in a novel way and use it to build discussion topic profiles. We describe a new classify-by-dominance strategy for classifying discussion threads and demonstrate that in the presence of noise it can perform better than the standard classify-as-a-whole approach with an error rate reduction of .%. This analysis of human conversation via online discussions provides a basis for the development of future information extraction and question answering techniques.|Donghui Feng,Jihie Kim,Erin Shaw,Eduard H. Hovy","16046|IJCAI|2005|A language for functional interpretation of model based simulation|Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.|Jonathan Bell,Neal Snooke,Chris Price","43233|IEICE Transations|2006|Entropy Based Associative Memory|In this paper, an entropy based associative memory model will be proposed and applied to memory retrievals with an orthogonal learning model to compare with the conventional model based on the quadratic Lyapunov functional to be minimized. In the present approach, the updating dynamics will be constructed on the basis of the entropy minimization strategy which may be reduced asymptotically to the above-mentioned autocorrelation dynamics as a special case. From numerical results, it will be found that the presently proposed novel approach realizes twice of the memory capacity in comparison with the autocorrelation based dynamics such as associatron.|Masahiro Nakagawa","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","43467|IEICE Transations|2006|Noise Reduction in Time Domain Using Referential Reconstruction|We present a novel approach for single-channel noise reduction of speech signals contaminated by additive noise. In this approach, the system requires speech samples to be uttered in advance by the same speaker as that of the input signal. Speech samples used in this method must have enough phonetic variety to reconstruct the input signal. In the proposed method, which we refer to as referential reconstruction, we have used a small database created from examples of speech, which will be called reference signals. Referential reconstruction uses an example-based approach, in which the objective is to find the candidate speech frame which is the most similar to the clean input frame without noise, although the input frame is contaminated with noise. When candidate frames are found, they become final outputs without any special processing. In order to find the candidate frames, a correlation coefficient is used as a similarity measure. Through automatic speech recognition experiments, the proposed method was shown to be effective, particularly for low-SNR speech signals corrupted with white noise or noise in high-frequency bands. Since the direct implementation of this method requires infeasible computational cost for searching through reference signals, a coarse-to-fine strategy is introduced in this paper.|Takehiro Ihara,Takayuki Nagai,Kazuhiko Ozeki,Akira Kurematsu","44333|IEICE Transations|2007|Single Channel Speech Enhancement Based on Perceptual Frequency-Weighting|The present paper describes a quality enhancement of speech corrupted by additive background noise in a single channel system. The proposed approach is based on the introduction of perceptual criteria using a frequency-weighting filter in a subtractive-type enhancement process. This newly developed algorithm allows for an automatic adaptation in the time and frequency of the enhancement system and finds a suitable noise estimate according to the frequency of the corrupted speech. Experimental results show that the proposed approach can efficiently remove additive noise related to various types of noise corruption.|Seiji Hayashi,Masahiro Suguimoto","65981|AAAI|2007|Incorporating Observer Biases in Keyhole Plan Recognition Efficiently|Plan recognition is the process of inferring other agents' plans and goals based on their observable actions. Essentially all previous work in plan recognition has focused on the recognition process itself, with no regard to the use of the information in the recognizing agent. As a result, low-likelihood recognition hypotheses that may imply significant meaning to the observer, are ignored in existing work. In this paper, we present novel efficient algorithms that allows the observer to incorporate her own biases and preferences--in the form of a utility function--into the plan recognition process. This allows choosing recognition hypotheses based on their expected utility to the observer. We call this Utility-based Plan Recognition (UPR). While reasoning about such expected utilities is intractable in the general case, we present a hybrid symbolicdecision-theoretic plan recognizer, whose complexity is O(N DT), where N is the plan library size, D is the depth of the library and T is the number of observations. We demonstrate the efficacy of this approach with experimental results in several challenging recognition tasks.|Dorit Avrahami-Zilberbrand,Gal A. Kaminka","44167|IEICE Transations|2007|An Interactive Open-Vocabulary Chinese Name Input System Using Syllable Spelling and Character Description Recognition Modules for Error Correction|The open-vocabulary name recognition technique is one of the most challenging tasks in the application of automatic Chinese speech recognition technology. It can be used as the free name input method for telephony speech applications and automatic directory assistance systems. A Chinese name usually has two to three characters, each of which is pronounced as a single tonal syllable. Obviously, it is very confusing to recognize a three-syllable word from millions to billions of possible candidates. A novel interactive automatic-speech-recognition system is proposed to resolve this highly challenging task. This system was built as an open-vocabulary Chinese name recognition system using character-based approaches. Two important character-input speech-recognition modules were designed as backoff approaches in this system to complete the name input or to correct any misrecognized characters. Finite-state networks were compiled from regular grammar of syllable spellings and character descriptions for these two speech recognition modules. The possible candidate names cover more than five billions. This system has been tested publicly and proved a robust way to interact with the speaker. An .% name recognition success rate was achieved by the interactive open-vocabulary Chinese name input system.|Nick Jui Chang Wang"],["42718|IEICE Transations|2005|Stabilizing a Class of Nonlinear Systems Based on Approximate Feedback Linearization|We present a method of stabilizing a class of nonlinear systems which are not necessarily feedback linearizable. First, we show a new way of constructing a diffeomorphism to transform a class of nonlinear systems to the feedback linearized form with perturbation. Then, we propose a semi-globally stabilizing control law for nonlinear systems that are connected by a chain of integrator perturbed by arbitrary nonlinear terms. In our approach, we have flexibility in choosing a diffeomorphism where the system is not restricted to involutivity and this leads to reduction in computational burden and flexibility in controller design.|Ho-Lim Choi,Jong-Tae Lim","42966|IEICE Transations|2005|An RBAC-Based Access Control Model for Object-Oriented Systems Offering Dynamic Aspect Features|This paper proposes a model for access control within object-oriented systems. The model is based on RBAC (role-based access control) and is called DRBAC (dynamic RBAC). Although RBAC is powerful in access control, the original design of RBAC required that user-role assignments and role-permission assignments should be handled statically (i.e., the assignments should be handled by human beings). Nevertheless, the following dynamic features are necessary in access control within a software system (a) managing dynamic role switching, (b) avoiding Trojan horses, (c) managing role associations, and (d) handling dynamic role creation and deletion. DRBAC offers the dynamic features. This paper proposes DRBAC.|Shih-Chien Chou","42596|IEICE Transations|2005|A Timing Synchronization Method with Low-Volume DSP for OFDM Packet Transmission Systems|This paper proposes a simple timing synchronization method in order to design a timing synchronization circuit with low-complex and low-volume digital signal processing (DSP) for orthogonal frequency division multiplexing (OFDM) packet transmission systems. The proposed method utilizes the subtraction process for acquirement of a timing metric of fast Fourier transform (FFT) window, whereas the conventional methods utilize the multiplication process. This paper adopts the proposed method to a standardized OFDM format, IEEE .a, and elucidates that the proposed one shows good transmission performance as well as the conventional one in fast time-variant multi-path Rayleigh fading channels by computer simulation.|Ryota Kimura,Ryuhei Funada,Hiroshi Harada,Manabu Sawada,Shoji Shinoda","44024|IEICE Transations|2007|Behavioral Circuit Macromodeling and Analog LSI Implementation for Automobile Engine Intake System|Accurate estimating or measuring the intake manifold absolute pressure plays an important role in automobile engine control. In order to achieve the real-time estimation of the absolute pressure, the high accuracy and high speed processing ability are required for automobile engine control systems. Therefore, in this paper, an analog method is discussed and a fully integrated analog circuit is proposed to simulate automobile intake systems. Furthermore, a novel behavioral macromodeling is proposed for the analog circuit design. With the analog circuit, the intake manifold absolute pressure, which plays an important role for the effective automobile engine control, can be accurately estimated or measured in real time.|Zhangcai Huang,Yasuaki Inoue,Hong Yu,Jun Pan,Yun Yang,Quan Zhang,Shuai Fang","42765|IEICE Transations|2005|Logic Synthesis Technique for High Speed Differential Dynamic Logic with Asymmetric Slope Transition|This paper proposes a logic synthesis technique for asymmetric slope differential dynamic logic (ASDDL) circuits. The technique utilizes a commercially available logic synthesis tool that has been well established for static CMOS logic design, where an intermediate library is devised for logic synthesis likely as static CMOS, and then a resulting synthesized circuit is translated automatically into ASDDL implementation at the gate-level logic schematic level as well as at the physical-layout level. A design example of an ASDDL -bit multiplier synthesized in a .-m CMOS technology shows an operation delay time of . nsec, which is a % improvement over a static CMOS design with a static logic standard-cell library that is finely tuned for energy-delay products. Design with the -bit multiplier led to a design time for an ASDDL based dynamic digital circuit  times shorter than that using a fully handcrafted design, and comparable with a static CMOS design.|Masao Morimoto,Yoshinori Tanaka,Makoto Nagata,Kazuo Taki","42590|IEICE Transations|2005|An Efficient Software-Defined Radio Architecture for Multi-Mode WCDMA Applications|This letter describes an efficient architecture for a Software Defined Radio (SDR) Wideband Code Division Multiple Access (WCDMA) receiver using for high performance wireless communication systems. The architecture is composed of a Radio Frequency (RF) front-end, an Analog-to-Digital Converter (ADC), and a Quadrature Amplitude Modulation (QAM) demodulator. A coherent demodulator, with a complete digital synchronization scheme, achieves the bit-error rate (BER) of - with the implementation loss of . dB for a raw Quadrature Phase Shift King (QPSK) signal.|Jaesang Lim,Yongchul Song,Jeong Pyo Kim,Beomsup Kim","43337|IEICE Transations|2006|Tunable Wordlength Architecture for a Low Power Wireless OFDM Demodulator|We present a low power architecture that dynamically controls wordlengths in a wireless OFDM demodulator. Finding the optimum wordlength for digital circuit systems is difficult because the trade-off between the hardware cost and system performance is not conclusive. Actual circuit systems have large wordlengths at the circuit design level to avoid calculation errors caused by a lack of dynamic range. This indicates that power dissipation can still be reduced under better conditions. We propose a tunable wordlength architecture that dynamically changes its own wordlength according to the communication environment. The proposed OFDM demodulator measures error vector magnitudes (EVMs) from de-modulated signals and tunes the wordlength to satisfy the required quality of communication by monitoring the EVM performance. The demodulator can reduce dissipated energy by a maximum of  and % in AWGN and multipath fading channels.|Shingo Yoshizawa,Yoshikazu Miyanaga","42671|IEICE Transations|2005|Robust Analysis and Design for Discrete-Time Nonlinear Systems Subject to Actuator Saturation via Fuzzy Control|This paper proposes an analysis and design methodology for the robust control of affine-in-control nonlinear systems subject to actuator saturation in discrete-time formulation. The robust stability condition is derived for the closed-loop system by the introduction of the fuzzy Kronecker delta. Based on the newly acquired stability condition, a design method is proposed to guarantee the robust H performance. In the design, LMI-based pole placement is employed to use the freedom allowed in the selection of the controller. The validity of the proposed method is asserted by the computer simulation.|Sanghyung Lee,Euntai Kim,Hagbae Kim,Mignon Park","43090|IEICE Transations|2006|Synchronization Mechanism for TimedUntimed Mixed-Signal System Level Design Environment|Recently, system level design languages (SLDL), which can describe both hardware and software aspects of the design, are receiving attention. Mixed-signal extensions of SLDL enable current discrete-oriented SLDLs to describe and simulate not only digital systems but also digital-analog mixed-signal systems. The synchronization between discrete and continuous behaviors is widely regarded as a critical part in the extensions. In this paper, we present an event-driven synchronization mechanism for both timed and untimed system level designs through which discrete and continuous behaviors are synchronized via AD events and DA events. We also demonstrate how the synchronization mechanism can be incorporated into the kernel of SLDL, such as SpecC. In the extended kernel, a new simulation cycle, the AMS cycle, is introduced. Three case studies show that the extended SpecC-based system level design environment using our synchronization mechanism works well with timeduntimed mixed-signal system level description.|Yu Liu,Satoshi Komatsu,Masahiro Fujita","80707|VLDB|2006|Load Shedding in Stream Databases A Control-Based Approach|In Data Stream Management Systems (DSMSs), query processing has to meet various Quality-of-Service (QoS) requirements. In many data stream applications, processing delay is the most critical quality requirement since the value of query results decreases dramatically over time. The ability to remain within a desired level of delay is significantly hampered under situations of overloading, which are common in data stream systems. When overloaded, DSMSs employ load shedding in order to meet quality requirements and keep pace with the high rate of data arrivals. Data stream applications are extremely dynamic due to bursty data arrivals and time-varying data processing costs. Current approaches ignore system status information in decision-making and consequently are unable to achieve desired control of quality under dynamic load. In this paper, we present a quality management framework that leverages well studied feedback control techniques. We discuss the design and implementation of such a framework in a real DSMS - the Borealis stream manager. Our data management framework is built on the advantages of system identification and rigorous controller analysis. Experimental results show that our solution achieves significantly fewer QoS (delay) violations with the same or lower level of data loss, as compared to current strategies utilized in DSMSs. It is also robust and bears negligible computational overhead.|Yi-Cheng Tu,Song Liu,Sunil Prabhakar,Bin Yao"],["57439|GECCO|2005|Measuring mobility and the performance of global search algorithms|The global search properties of heuristic search algorithms are not well understood. In this paper, we introduce a new metric, mobility, that quantifies the dispersion of local optima visited during a search. This allows us to explore two questions How disperse are the local optima visited during a search How does mobility relate to algorithm performance We compare local search with two evolutionary algorithms, CHC and CMA-ES, on a set of non-separable, non-symmetric, multi-modal test functions. Given our mobility metric, we show that algorithms visiting more disperse local optima tend to be better optimizers.|Monte Lunacek,L. Darrell Whitley,James N. Knight","58086|GECCO|2007|A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design|This paper presents a hybrid evolutionary programming algorithm to solve the spread spectrum radar polyphase code design problem. The proposed algorithm uses an Evolutionary Programming (EP) approach as global search heuristic. This EP is hybridized with a gradient-based local search procedure which includes a dynamic step adaptation procedure to perform accurate and efficient local search for better solutions. Numerical examples demonstrate that the algorithm outperforms existing approaches for this problem.|√?ngel M. P√©rez-Bellido,Sancho Salcedo-Sanz,Emilio G. Ort√≠z-Garc√≠a,Antonio Portilla-Figueras","43989|IEICE Transations|2007|A Genetic Algorithm with Conditional Crossover and Mutation Operators and Its Application to Combinatorial Optimization Problems|In this paper, we present a modified genetic algorithm for solving combinatorial optimization problems. The modified genetic algorithm in which crossover and mutation are performed conditionally instead of probabilistically has higher global and local search ability and is more easily applied to a problem than the conventional genetic algorithms. Three optimization problems are used to test the performances of the modified genetic algorithm. Experimental studies show that the modified genetic algorithm produces better results over the conventional one and other methods.|Rong Long Wang,Shinichi Fukuta,Jiahai Wang,Kozo Okazaki","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","57641|GECCO|2006|Evolutionary optimization of ZIP a controlled explosion in hyperspace|The \"ZIP\" adaptive trading algorithm has been demonstrated to outperform human traders in experimental studies of continuous double auction (CDA) markets. The original ZIP algorithm requires the values of eight control parameters to be set correctly. A new extension of the ZIP algorithm, called ZIP, requires the values of  parameters to be set correctly. ZIP is shown here to produce significantly better results than the original ZIP (called \"ZIP\" hereafter). A genetic algorithm (GA) is used to search the -dimensional ZIP parameter space, and it finds parameter vectors that yield ZIP traders with mean scores significantly better than those of ZIPs. This paper shows that this optimizing evolutionary search works best when the GA itself controls the dimensionality of the search-space, so that the search commences in an -d space and thereafter the dimensionality of the search-space is gradually increased by the GA until it is exploring a -d space. Furthermore, the results from ZIP cast some doubt on prior ZIP results concerning the evolution of new 'hybrid' auction mechanisms that appeared to be better than the CDA.|Dave Cliff","57921|GECCO|2007|A memetic algorithm for the low autocorrelation binary sequence problem|Finding binary sequences with low auto correlation is a very hard problem with many practical applications. In this paper we analyze several meta heuristic approaches to tackle the construction of this kind of sequences. We focus on two different local search strategies, steepest descent local search (SDLS) and tabu search (TS), and their use both as stand-alone techniques and embedded within a memetic algorithm (MA). Plain evolutionary algorithms are shown to perform worse than stand-alone local search strategies. However, a MA endowed with TS turns out to be a state-of-the-art algorithm it consistently finds optimal sequences in considerably less time than previous approaches reported in the literature.|Jos√© E. Gallardo,Carlos Cotta,Antonio J. Fern√°ndez","58024|GECCO|2007|A discrete differential evolution algorithm for the permutation flowshop scheduling problem|In this paper, a novel discrete differential evolution (DDE) algorithm is presented to solve the permutation flowhop scheduling problem with the makespan criterion. The DDE algorithm is simple in nature such that it first mutates a target population to produce the mutant population. Then the target population is recombined with the mutant population in order to generate a trial population. Finally, a selection operator is applied to both target and trial populations to determine who will survive for the next generation based on fitness evaluations. As a mutation operator in the discrete differential evolution algorithm, a destruction and construction procedure is employed to generate the mutant population. We propose a referenced local search, which is embedded in the discrete differential evolution algorithm to further improve the solution quality. Computational results show that the proposed DDE algorithm with the referenced local search is very competitive to the iterated greedy algorithm which is one of the best performing algorithms for the permutation flowshop scheduling problem in the literature.|Quan-Qe Pan,Mehmet Fatih Tasgetiren,Yun-Chia Liang","57860|GECCO|2006|The LEM implementation of learnable evolution model and its testing on complex function optimization problems|Learnable Evolution Model (LEM) is a form of non-Darwinian evolutionary computation that employs machine learning to guide evolutionary processes. Its main novelty are new type of operators for creating new individuals, specifically, hypothesis generation, which learns rules indicating subareas in the search space that likely contain the optimum, and hypothesis instantiation, which populates these subspaces with new individuals. This paper briefly describes the newest and most advanced implementation of learnable evolution, LEM, its novel features, and results from its comparison with a conventional, Darwinian-type evolutionary computation program (EA), a cultural evolution algorithm (CA), and the estimation of distribution algorithm (EDA) on selected function optimization problems (with the number of variables varying up to ). In every experiment, LEM outperformed the compared programs in terms of the evolution length (the number of fitness evaluations needed to achieved a desired solution), sometimes more than by one order of magnitude.|Janusz Wojtusiak,Ryszard S. Michalski","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","57877|GECCO|2007|An extended mutation concept for the local selection based differential evolution algorithm|A new mutation concept is proposed to generalize local selection based Differential Evolution algorithm to work in general multi-modal problems. Three variations of the proposed method are compared with classic Differential Evolution algorithm using a set of five well known test functions and their variants. The general idea of the new mutation operation is to divide the mutation into two parts the local and global mutation. The global mutation works as a migration operator allowing the algorithm perform global search efficiently, while the local mutation improves the efficiency of local search. The results show that the concept of global mutation is able to generalize the good performance of local selection based Differential Evolution from convex uni-modal functions to general non-convex and multi-modal problems. Among the tested functions, the new method was able to outperform the classic Differential Evolution in all butone. A limited analysis of the effects of control parameters to the performance of the algorithm is also done.|Jani R√∂nkk√∂nen,Jouni Lampinen"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","57868|GECCO|2006|A comparative study of immune system based genetic algorithms in dynamic environments|Diversity and memory are two major mechanisms used in biology to keep the adaptability of organisms in the ever-changing environment in nature. These mechanisms can be integrated into genetic algorithms to enhance their performance for problem optimization in dynamic environments. This paper investigates several GAs inspired by the ideas of biological immune system and transformation schemes for dynamic optimization problems. An aligned transformation operator is proposed and combined to the immune system based genetic algorithm to deal with dynamic environments. Using a series of systematically constructed dynamic test problems, experiments are carried out to compare several immune system based genetic algorithms, including the proposed one, and two standard genetic algorithms enhanced with memory and random immigrants respectively. The experimental results validate the efficiency of the proposed aligned transformation and corresponding immune system based genetic algorithm in dynamic environments.|Shengxiang Yang","43989|IEICE Transations|2007|A Genetic Algorithm with Conditional Crossover and Mutation Operators and Its Application to Combinatorial Optimization Problems|In this paper, we present a modified genetic algorithm for solving combinatorial optimization problems. The modified genetic algorithm in which crossover and mutation are performed conditionally instead of probabilistically has higher global and local search ability and is more easily applied to a problem than the conventional genetic algorithms. Three optimization problems are used to test the performances of the modified genetic algorithm. Experimental studies show that the modified genetic algorithm produces better results over the conventional one and other methods.|Rong Long Wang,Shinichi Fukuta,Jiahai Wang,Kozo Okazaki","58068|GECCO|2007|Solving the artificial ant on the Santa Fe trail problem in   fitness evaluations|In this paper, we provide an algorithm that systematically considers all small trees in the search space of genetic programming. These small trees are used to generate useful subroutines for genetic programming. This algorithm is tested on the Artificial Ant on the Santa Fe Trail problem, a venerable problem for genetic programming systems. When four levels of iteration are used, the algorithm presented here generates better results than any known published result by a factor of .|Steffen Christensen,Franz Oppacher","57955|GECCO|2007|Genetic algorithms for water quality management in an urban watershed|This paper describes the use of genetic algorithms for water quality management in an urban watershed. This is achieved by linking a genetic algorithm-based optimization model in a disaggregated manner with a water quality simulation model.|Mohammad Tufail,Lindell E. Ormsbee","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","57793|GECCO|2006|A survey of mutation techniques in genetic programming|The importance of mutation varies across evolutionary computation domains including genetic programming, evolution strategies, and genetic algorithms. In the genetic programming community, researchers' view of mutation's effectiveness spans the range from an ineffective or marginal operator, to a neutral operator, to a highly effective operator that evolves solutions more effectively than genetic programming with crossover alone. Mutation implementation and associated parameters are often under reported in genetic programming research and typically lack context that justifies the technique and parameter selection. In part, reporting variance stems from the adaptation of mutation developed by the genetic algorithm community, and the creation of new mutation techniques in genetic programming. This survey describes the controversial operator in genetic programming applications, mutation selection operators, mutation techniques and offers an organization of mutation characteristics. We suggest methodologies to improve reporting of mutation parameters and related individual selection methods.|Alan Piszcz,Terence Soule","57589|GECCO|2005|Molecular programming evolving genetic programs in a test tube|We present a molecular computing algorithm for evolving DNA-encoded genetic programs in a test tube. The use of synthetic DNA molecules combined with biochemical techniques for variation and selection allows for various possibilities for building novel evolvable hardware. Also, the possibility of maintaining a huge number of individuals and their massively parallel manipulation allows us to make robust decisions by the \"molecular\" genetic programs evolved within a single population. We evaluate the potentials of this \"molecular programming\" approach by solving a medical diagnosis problem on a simulated DNA computer. Here the individual genetic program represents a decision list of variable length and the whole population takes part in making probabilistic decisions. Tested on a real-life leukemia diagnosis data, the evolved molecular genetic programs showed a comparable performance to decision trees. The molecular evolutionary algorithm can be adapted to solve problems in bio-technology and nano-technology where the physico-chemical evolution of target molecules is of pressing importance.|Byoung-Tak Zhang,Ha-Young Jang","57756|GECCO|2006|A fast hybrid genetic algorithm for the quadratic assignment problem|Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the \"fast hybrid genetic algorithm\" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm.|Alfonsas Misevicius","57934|GECCO|2007|Evolutionary selection of minimum number of features for classification of gene expression data using genetic algorithms|Selecting the most relevant factors from genetic profiles that can optimally characterize cellular states is of crucial importance in identifying complex disease genes and biomarkers for disease diagnosis and assessing drug efficiency. In this paper, we present an approach using a genetic algorithm for a feature subset selection problem that can be used in selecting the near optimum set of genes for classification of cancer data. In substantial improvement over existing methods, we classified cancer data with high accuracy with less features.|Alper K√º√ß√ºkural,Reyyan Yeniterzi,S√ºveyda Yeniterzi,Osman Ugur Sezerman"],["42572|IEICE Transations|2005|A New Method for Solving the Permutation Problem of Frequency-Domain Blind Source Separation|Frequency domain blind source separation has the great advantage that the complicated convolution in time domain becomes multiple efficient multiplications in frequency domain. However, the inherent ambiguity of permutation of ICA becomes an important problem that the separated signals at different frequencies may be permuted in order. Mapping the separated signal at each frequency to a target source remains to be a difficult problem. In this paper, we first discuss the inter-frequency correlation based method , and propose a new method using the continuity in power between adjacent frequency components of same source. The proposed method also implicitly utilizes the information of inter-frequency correlation, as such has better performance than the previous method.|Xuebin Hu,Hidefumi Kobatake","43417|IEICE Transations|2006|Nonlinear Blind Source Separation Method for X-Ray Image Separation|In this study, we propose a robust approach for blind source separation (BSS) by using radial basis function networks (RBFNs) and higher-order statistics (HOS). The RBFN is employed to estimate the inverse of a hypothetical complicated mixing procedure. It transforms the observed signals into high-dimensional space, in which one can simply separate the transformed signals by using a cost function. Recently, Tan et al. proposed a nonlinear BSS method, in which higher-order moments between source signals and observations are matched in the cost function. However, it has a strict restriction that it requires the higher-order statistics of sources to be known. We propose a cost function that consists of higher-order cumulants and the second-order moment of signals to remove the constraint. The proposed approach has the capacity of not only recovering the complicated mixed signals, but also reducing noise from observed signals. Simulation results demonstrate the validity of the proposed approach. Moreover, a result of application to X-ray image separation also shows its practical applicability.|Nuo Zhang,Jianming Lu,Takashi Yahagi","42554|IEICE Transations|2005|Underdetermined Blind Separation of Convolutive Mixtures of Speech Using Time-Frequency Mask and Mixing Matrix Estimation|This paper focuses on the underdetermined blind source separation (BSS) of three speech signals mixed in a real environment from measurements provided by two sensors. To date, solutions to the underdetermined BSS problem have mainly been based on the assumption that the speech signals are sufficiently sparse. They involve designing binary masks that extract signals at time-frequency points where only one signal was assumed to exist. The major issue encountered in previous work relates to the occurrence of distortion, which affects a separated signal with loud musical noise. To overcome this problem, we propose combining sparseness with the use of an estimated mixing matrix. First, we use a geometrical approach to detect when only one source is active and to perform a preliminary separation with a time-frequency mask. This information is then used to estimate the mixing matrix, which allows us to improve our separation. Experimental results show that this combination of time-frequency mask and mixing matrix estimation provides separated signals of better quality (less distortion, less musical noise) than those extracted without using the estimated mixing matrix in reverberant conditions where the reverberant time (TR) was  ms and  ms. Furthermore, informal listening tests clearly show that musical noise is deeply lowered by the proposed method comparatively to the classical approaches.|Audrey Blin,Shoko Araki,Shoji Makino","42642|IEICE Transations|2005|Multistage SIMO-Model-Based Blind Source Separation Combining Frequency-Domain ICA and Time-Domain ICA|In this paper, single-input multiple-output (SIMO)-model-based blind source separation (BSS) is addressed, where unknown mixed source signals are detected at microphones, and can be separated, not into monaural source signals but into SIMO-model-based signals from independent sources as they are at the microphones. This technique is highly applicable to high-fidelity signal processing such as binaural signal processing. First, we provide an experimental comparison between two kinds of SIMO-model-based BSS methods, namely, conventional frequency-domain ICA with projection-back processing (FDICA-PB), and SIMO-ICA which was recently proposed by the authors. Secondly, we propose a new combination technique of the FDICA-PB and SIMO-ICA, which can achieve a higher separation performance than the two methods. The experimental results reveal that the accuracy of the separated SIMO signals in the simple SIMO-ICA is inferior to that of the signals obtained by FDICA-PB under low-quality initial value conditions, but the proposed combination technique can outperform both simple FDICA-PB and SIMO-ICA.|Satoshi Ukai,Tomoya Takatani,Hiroshi Saruwatari,Kiyohiro Shikano,Ryo Mukai,Hiroshi Sawada","42556|IEICE Transations|2005|Blind Source Separation of Convolutive Mixtures of Speech in Frequency Domain|This paper overviews a total solution for frequency-domain blind source separation (BSS) of convolutive mixtures of audio signals, especially speech. Frequency-domain BSS performs independent component analysis (ICA) in each frequency bin, and this is more efficient than time-domain BSS. We describe a sophisticated total solution for frequency-domain BSS, including permutation, scaling, circularity, and complex activation function solutions. Experimental results of   ,   ,   ,   , and    (moving sources), (sources  microphones) in a room are promising.|Shoji Makino,Hiroshi Sawada,Ryo Mukai,Shoko Araki","44043|IEICE Transations|2007|A Distortion-Free Learning Algorithm for Feedforward Multi-Channel Blind Source Separation|FeedForward (FF-) Blind Source Separation (BSS) systems have some degree of freedom in the solution space. Therefore, signal distortion is likely to occur. First, a criterion for the signal distortion is discussed. Properties of conventional methods proposed to suppress the signal distortion are analyzed. Next, a general condition for complete separation and distortion-free is derived for multi-channel FF-BSS systems. This condition is incorporated in learning algorithms as a distortion-free constraint. Computer simulations using speech signals and stationary colored signals are performed for the conventional methods and for the new learning algorithms employing the proposed distortion-free constraint. The proposed method can well suppress signal distortion, while maintaining a high source separation performance.|Akihide Horita,Kenji Nakayama,Akihiro Hirano","42618|IEICE Transations|2005|Subband-Based Blind Separation for Convolutive Mixtures of Speech|We propose utilizing subband-based blind source separation (BSS) for convolutive mixtures of speech. This is motivated by the drawback of frequency-domain BSS, i.e., when a long frame with a fixed long frame-shift is used to cover reverberation, the number of samples in each frequency decreases and the separation performance is degraded. In subband BSS, () by using a moderate number of subbands, a sufficient number of samples can be held in each subband, and () by using FIR filters in each subband, we can manage long reverberation. We confirm that subband BSS achieves better performance than frequency-domain BSS. Moreover, subband BSS allows us to select a separation method suited to each subband. Using this advantage, we propose efficient separation procedures that consider the frequency characteristics of room reverberation and speech signals () by using longer unmixing filters in low frequency bands and () by adopting an overlap-blockshift in BSS's batch adaptation in low frequency bands. Consequently, frequency-dependent subband processing is successfully realized with the proposed subband BSS.|Shoko Araki,Shoji Makino,Robert Aichner,Tsuyoki Nishikawa,Hiroshi Saruwatari","42438|IEICE Transations|2005|Separation of Sound Sources Propagated in the Same Direction|This paper describes a method for separating a target sound from other noise arriving in a single direction when the target cannot, therefore, be separated by directivity control. Microphones are arranged in a line toward the sources to form null sensitivity points at given distances from the microphones. The null points exclude non-target sound sources on the basis of weighting coefficients for microphone outputs determined by blind source separation. The separation problem is thereby simplified to instantaneous separation by adjustment of the time-delays for microphone outputs. The system uses a direct (i.e. non-iterative) algorithm for blind separation based on second-order statistics, assuming that all sources are non-stationary signals. Simulations show that the -microphone system can separate a target sound with separability of more than  dB for the -source problem, and  dB for the -source problem when the other sources are adjacent.|Akio Ando,Masakazu Iwaki,Kazuho Ono,Koichi Kurozumi","43405|IEICE Transations|2006|A Two-Stage Method for Single-Channel Speech Enhancement|A time domain (TD) speech enhancement technique to improve SNR in noise-contaminated speech is proposed. Additional supplementary scheme is applied to estimate the degree of noise of noisy speech. This is estimated from a function, which is previously prepared as the function of the parameter of the degree of noise. The function is obtained by least square (LS) method using the given degree of noise and the estimated parameter of the degree of noise. This parameter is obtained from the autocorrelation function (ACF) on frame-by-frame basis. This estimator almost accurately estimates the degree of noise and it is useful to reduce noise. The proposed method is based on two-stage processing. In the first stage, subtraction in time domain (STD), which is equivalent to ordinary spectral subtraction (SS), is carried out. In the result, the noise is reduced to a certain level. Further reduction of noise and by-product noise residual is carried out in the second stage, where blind source separation (BSS) technique is applied in time domain. Because the method is a single-channel speech enhancement, the other signal is generated by taking the noise characteristics into consideration in order to apply BSS. The generated signal plays a very important role in BSS. This paper presents an adaptive algorithm for separating sources in convolutive mixtures modeled by finite impulse response (FIR) filters. The coefficients of the FIR filter are estimated from the decorrelation of two mixtures. Here we are recovering only one signal of interest, in particular the voice of primary speaker free from interfering noises. In the experiment, the different levels of noise are added to the clean speech signal and the improvement of SNR at each stage is investigated. The noise types considered initially in this study consist of the synthesized white and color noise with SNR set from  to  dB. The proposed method is also tested with other real-world noises. The results show that the satisfactory SNR improvement is attained in the two-stage processing.|Mohammad E. Hamid,Takeshi Fukabayashi","42716|IEICE Transations|2005|Blind Separation and Deconvolution for Convolutive Mixture of Speech Combining SIMO-Model-Based ICA and Multichannel Inverse Filtering|We propose a new two-stage blind separation and deconvolution strategy for multiple-input multiple-output (MIMO)-FIR systems driven by colored sound sources, in which single-input multiple-output (SIMO)-model-based ICA (SIMO-ICA) and blind multichannel inverse filtering are combined. SIMO-ICA can separate the mixed signals, not into monaural source signals but into SIMO-model-based signals from independent sources as they are at the microphones. After the separation by the SIMO-ICA, a blind deconvolution technique for the SIMO model can be applied even when each source signal is temporally correlated and the mixing system has a nonminimum phase property. The simulation results reveal that the proposed algorithm can successfully achieve separation and deconvolution of a convolutive mixture of speech, and outperforms a number of conventional ICA-based BSD methods.|Hiroshi Saruwatari,Hiroaki Yamajo,Tomoya Takatani,Tsuyoki Nishikawa,Kiyohiro Shikano"],["65535|AAAI|2005|An Ecological Approach to Agent Population Management|The problem of maintaining a desired number of mobile agents on a network is not trivial, especially if what is required is a completely decentralized solution. Decentralized control makes a system more robust and less susceptible to partial failures. The problem of agent population management is exacerbated on wireless ad hoc networks where host mobility can result in significant changes in the network size and topology. System stability is also of critical importance. This paper analyzes the stability of a previously proposed ecology-inspired approach to agent population management, and proposes improvements. The stability of the new ecology based strategy is proved theoretically, and the conclusions are verified with a set of experiments.|Maxim Peysakhov,Robert N. Lass,William C. Regli,Moshe Kam","42569|IEICE Transations|2005|Blinking Long-Range Connections Increase the Functionality of Locally Connected Networks|Information processing with only locally connected networks such as cellular neural networks is advantageous for integrated circuit implementations. Adding long range connections can often enhance considerably their performance. It is sufficient to activate these connections randomly from time to time (blinking connections). This can be realized by sending packets on a communication network underlying the information processing network that is needed anyway for bringing information in and out of the locally connected network. We prove for the case of multi-stable networks that if the long-range connections are switched on and off sufficiently fast, the behavior of the blinking network is with high probability the same as the behavior of the time-averaged network. In the averaged network the blinking connections are replaced by fixed connections with low (average) coupling strength.|Martin Hasler,Igor Belykh","42668|IEICE Transations|2005|An Efficient MAC Protocol for Improving the Network Throughput and Energy Efficiency for Ad Hoc Networks|Ad hoc networks are becoming an interesting research area, as they inherently support unique network applications for the wireless communications in a rugged environment, which requires rapid deployment and is difficult to be provided by an infrastructure network. Many issues need to be addressed for the ad hoc networks. In this paper, we propose an efficient distributed coordination function on the media access control protocol to enhance the power conservation of mobile hosts by using a power control algorithm and the network throughput of an ad hoc network by using an algorithm for simultaneous frame transmissions. Extensive simulation is studied to evaluate the improvement of the proposed method. The results of the simulation exhibit significant improvement to the standard access control protocol. With slight improvement of network throughput, up to % of the consumed energy was able to be saved in compared to the standard protocol and up to  times of the energy efficiency was enhanced with the proposed method.|Chien-Yuan Liu,Chun-Hung Lin","65846|AAAI|2006|A Manifold Regularization Approach to Calibration Reduction for Sensor-Network Based Tracking|The ability to accurately detect the location of a mobile node in a sensor network is important for many artificial intelligence (AI) tasks that range from robotics to context-aware computing. Many previous approaches to the location-estimation problem assume the availability of calibrated data. However, to obtain such data requires great effort. In this paper, we present a manifold regularization approach known as LeMan to calibration-effort reduction for tracking a mobile node in a wireless sensor network. We compute a subspace mapping function between the signal space and the physical space by using a small amount of labeled data and a large amount of unlabeled data. This mapping function can be used online to determine the location of mobile nodes in a sensor network based on the signals received. We use Crossbow MICA to setup the network and USB camera array to obtain the ground truth. Experimental results show that we can achieve a higher accuracy with much less calibration effort as compared to several previous systems.|Jeffrey Junfeng Pan,Qiang Yang,Hong Chang,Dit-Yan Yeung","43191|IEICE Transations|2006|Blocking Probability of a DS-CDMA Multi-Hop Virtual Cellular Network|A wireless multi-hop virtual cellular network (VCN) was recently proposed to avoid the large peak transmit power, resulting from the high transmission rates expected for future mobile communication systems. In VCN, calls hop through several links to reach the central port, which is the gateway to the network. With the use of a routing algorithm based on the total uplink transmit power minimization criterion, the total transmit power of all the multi-hop links between the mobile terminal and the central port can be significantly reduced, in comparison with the present (single-hop) cellular network. In this paper, an \"on-demand\" channel assignment strategy, using the channel segregation dynamic channel allocation (CS-DCA) algorithm, is proposed for multi-hop DS-CDMA VCN. Computer simulation is conducted to evaluate the blocking probability performance and make a comparison between the VCN and the present cellular network.|Lalla Soundous El Alami,Eisuke Kudoh,Fumiyuki Adachi","65588|AAAI|2005|Stable Service Placement on Dynamic Peer-to-Peer Networks A Heuristic for the Distributed Center Problem|The proliferation of wireless networks has underscored the need for systems capable of coping with sporadic network connectivity. The restriction of communication to neighboring hosts makes determining the global state especially difficult, if not impractical. This paper addresses the problem of coordinating the positions of an arbitrary number of services, encapsulated by mobile agents, in a dynamic peer-to-peer network. The agents' collective goal is to minimize the distance between hosts and services, even if the topology is changing constantly. We propose a distributed algorithm to efficiently calculate the stationary distribution of the network. This can be used as a hill climbing heuristic for agents to find near-optimal locations at which to provide services. Finally, we show that the agent-based hill climbing approach is temporally-stable relative to the instantaneous optimum.|Evan Sultanik,William C. Regli","43633|IEICE Transations|2006|An Adaptive Medium Access Control Protocol for Reliable Broadcast and Unicast in Ad Hoc Networks|An ad hoc network is formed by a group of mobile hosts communicating over wireless channels. There is no any fixed network interaction and centralized administration. Because a routing protocol needs an efficient medium access control (MAC) protocol to support, to design an efficient MAC protocol is important and fundamental in ad hoc networks. So far, no other MAC protocol has stable broadcast performance in the dense mobile ad hoc network. In this paper, we address the issue of reliable broadcast and stable performance at the MAC layer. We present a reliable and adaptive broadcast MAC protocol RAMAC which is a TDMA-based distributed MAC protocol for the broadcast reservation in mobile ad hoc networks. We divide the area into many grid cells with the support of GPS. We use the properties of grid cells to design an efficient protocol. RAMAC is characterized by five important features (i) A dynamic frame size is generated in every contention. This dynamic frame size can let RAMAC adapt to the network load. (ii) Our well-designed reservation protocol can avoid the deadlock problem. (iii) When the network is dense, RAMAC can still work stably however, no other MAC protocols can work well in the dense network. (iv) We propose a reservation protocol that can efficiently and fast reserve data slots. (v) The well-designed grid architecture makes the senders of unicast in a grid cell transmit concurrently as many as possible, so RAMAC is highly parallel in unicast.|Young-Ching Deng,Ching-Chi Hsu,Ferng-Ching Lin","42521|IEICE Transations|2005|Wireless ATM Backbone Network Design Problem|Personal Communication Network (PCN) is an emerging wireless network that promises many new services for the telecommunication industry. The high speed backbone network (ATM or WDM) is one possible approach to provide broadband wireless transmission with PCN's using the ATM switching networks for interconnection of PCN cells. The wireless ATM backbone network design problem is that of allocating backbone links among ATM switches to reduce the effects of terminal mobility on the performance of ATM-based PCN's. In this paper, the wireless ATM backbone network design (WABND) problem is formulated and studied. The goal of the WABND is to minimize the location update cost under constraints. Since WABND is NP-hard, a heuristic algorithm and a genetic algorithm are proposed to solve it. These algorithms are used to find the close-to-optimal solution. Simulated results show that the proposed algorithms are able to achieve good performance.|Der-Rong Din","43395|IEICE Transations|2006|A Method of Simple Adaptive Control for Nonlinear Systems Using Neural Networks|This paper presents a method of simple adaptive control (SAC) using neural networks for a class of nonlinear systems with bounded-input bounded-output (BIBO) and bounded nonlinearity. The control input is given by the sum of the output of the simple adaptive controller and the output of the neural network. The neural network is used to compensate for the nonlinearity of the plant dynamics that is not taken into consideration in the usual SAC. The role of the neural network is to construct a linearized model by minimizing the output error caused by nonlinearities in the control systems. Furthermore, convergence and stability analysis of the proposed method is performed. Finally, the effectiveness of the proposed method is confirmed through computer simulation.|Muhammad Yasser,Agus Trisanto,Jianming Lu,Takashi Yahagi","43066|IEICE Transations|2006|Performance of Affordable Neural Network for Back Propagation Learning|Cell assembly is one of explanations of information processing in the brain, in which an information is represented by a firing space pattern of a group of plural neurons. On the other hand, effectiveness of neural network has been confirmed in pattern recognition, system control, signal processing, and so on, since the back propagation learning was proposed. In this study, we propose a new network structure with affordable neurons in the hidden layer of the feedforward neural network. Computer simulated results show that the proposed network exhibits a good performance for the back propagation learning. Furthermore, we confirm the proposed network has a good generalization ability.|Yoko Uwate,Yoshifumi Nishio"]]},"title":{"entropy":6.688291968156865,"topics":["learning for, the web, reinforcement learning, efficient for, framework for, and for, learning, description logic, for planning, constraint satisfaction, learning and, planning with, sense disambiguation, for logic, semantic web, multi-agent systems, reasoning about, word disambiguation, data streams, query for","for systems, method for, and for, for with, control for, adaptive for, control systems, design for, design and, estimation for, for channel, motion estimation, and systems, for based, with and, filter for, scheme for, for ofdm, wireless networks, for communication","speech recognition, and for, for recognition, using and, support vector, for image, method for, model for, image using, using model, between and, speech and, based model, feature extraction, and recognition, model and, based and, for speech, natural language, for using","algorithm for, genetic algorithm, genetic programming, for the, genetic for, the, the problem, for problem, particle swarm, the and, algorithm the, neural networks, using genetic, evolutionary algorithm, and its, and algorithm, its application, evolutionary for, for optimization, genetic and","query for, for data, multi-agent systems, for distributed, protocol for, for xml, data streams, for systems, for database, for streams, key agreement, database systems, distributed and, protocol and, query processing, for processing, processing and, privacy and, for pattern, distributed systems","for reasoning, and reasoning, with and, reasoning about, for with, for domain, representation for, probabilistic model, and for, and complexity, the reasoning, probabilistic and, probabilistic for, business processes, the complexity, representation and, the domain, case-based reasoning, complexity for, least squares","for channel, estimation for, analysis for, for ofdm, estimation and, for noise, maximum likelihood, analysis and, estimation with, frequency for, noise based, and channel, reduction for, over channel, error for, and for, for signal, fading channel, noise reduction, estimation distribution","adaptive for, for codes, for sequence, decoding codes, zone sequence, adaptive with, zero-correlation zone, and codes, sequence with, adaptive using, linear for, ldpc codes, zone set, zero-correlation sequence, for set, decoding based, for software, codes with, zero-correlation set, design codes","and for, method for, method and, using and, generation for, between and, and application, natural language, and, the and, for classification, language and, based and, for environments, and its, and systems, language for, for management, and retrieval, tool for","and evaluation, for object, for robot, situation calculus, theory and, object and, extraction and, self-organizing map, feature extraction, and their, matching using, grammatical evolution, for extraction, evaluation for, for text, robot using, mobile robot, for tracking, for matching, object tracking","for the, the problem, the and, algorithm the, the, for problem, search for, analysis the, evolutionary the, the performance, and problem, petri nets, using the, the with, study the, and search, search space, the effects, the evolution, heuristic for","particle swarm, for optimization, particle optimization, solving problem, swarm optimization, model for, the optimization, for solving, swarm for, markov processes, decision tree, and optimization, ant colony, optimization problem, particle for, arc consistency, gene expression, markov decision, decision for, for routing"],"ranking":[["65537|AAAI|2005|Word Sense Disambiguation with Semi-Supervised Learning|Current word sense disambiguation (WSD) systems based on supervised learning are still limited in that they do not work well for all words in a language. One of the main reasons is the lack of sufficient training data. In this paper, we investigate the use of unlabeled training data for WSD, in the framework of semi-supervised learning. Four semisupervised leaming algorithms are evaluated on  nouns of Senseval- (SE) English lexical sample task and SE English all-words task. Empirical results show that unlabeled data can bring significant improvement in WSD accuracy.|Thanh Phong Pham,Hwee Tou Ng,Wee Sun Lee","16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","16726|IJCAI|2007|Combining Learning and Word Sense Disambiguation for Intelligent User Profiling|Understanding user interests from text documents can provide support to personalized information recommendation services. Typically, these services automatically infer the user profile, a structured model of the user interests, from documents that were already deemed relevant by the user. Traditional keyword-based approaches are unable to capture the semantics of the user interests. This work proposes the integration of linguistic knowledge in the process of learning semantic user profiles that capture concepts concerning user interests. The proposed strategy consists of two steps. The first one is based on a word sense disambiguation technique that exploits the lexical database WordNet to select, among all the possible meanings (senses) of a polysemous word, the correct one. In the second step, a nave Bayes approach learns semantic sense-based user profiles as binary text classifiers (user-likes and user-dislikes) from disambiguated documents. Experiments have been conducted to compare the performance obtained by keyword-based profiles to that obtained by sense-based profiles. Both the classification accuracy and the effectiveness of the ranking imposed by the two different kinds of profile on the documents to be recommended have been considered. The main outcome is that the classification accuracy is increased with no improvement on the ranking. The conclusion is that the integration of linguistic knowledge in the learning process improves the classification of those documents whose classification score is close to the likesdislikes threshold (the items for which the classification is highly uncertain).|Giovanni Semeraro,Marco Degemmis,Pasquale Lops,Pierpaolo Basile","16373|IJCAI|2007|Learning User Clicks in Web Search|Machine learning for predicting user clicks in Web-based search offers automated explanation of user activity. We address click prediction in the Web search scenario by introducing a method for click prediction based on observations of past queries and the clicked documents. Due to the sparsity of the problem space, commonly encountered when learning for Web search, new approaches to learn the probabilistic relationship between documents and queries are proposed. Two probabilistic models are developed, which differ in the interpretation of the query-document co-occurrences. A novel technique, namely, conditional probability hierarchy, flexibly adjusts the level of granularity in parsing queries, and, as a result, leverages the advantages of both models.|Ding Zhou,Levent Bolelli,Jia Li,C. Lee Giles,Hongyuan Zha","65528|AAAI|2005|SenseRelate  TargetWord-A Generalized Framework for Word Sense Disambiguation|Many words in natural language have different meanings when used in different contexts. Sense Relate Target Word is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet Similarity measure of relatedness.|Siddharth Patwardhan,Satanjeev Banerjee,Ted Pedersen","16328|IJCAI|2005|Learning Subjective Representations for Planning|Planning involves using a model of an agent's actions to find a sequence of decisions which achieve a desired goal. It is usually assumed that the models are given, and such models often require expert knowledge of the domain. This paper explores subjective representations for planning that are learned directly from agent observations and actions (requiring no initial domain knowledge). A non-linear embedding technique called Action Respecting Embedding is used to construct such a representation. It is then shown how to extract the effects of the agent's actions as operators in this learned representation. Finally, the learned representation and operators are combined with search to find sequences of actions that achieve given goals. The efficacy of this technique is demonstrated in a challenging robot-vision-inspired image domain.|Dana F. Wilkinson,Michael H. Bowling,Ali Ghodsi","80848|VLDB|2007|Reasoning about the Behavior of Semantic Web Services with Concurrent Transaction Logic|The recent upsurge in the interest in Semantic Web services and the high-profile projects such as the WSMO, OWLS, and SWSL, have drawn attention to the importance of logic-based modeling of the behavior of Web services. In the context of Semantic Web services, the logic-based approach has many applications, including service discovery, service choreography, enactment, and contracting for services. In this paper we propose logic-based methods for reasoning about service behavior, including the aforementioned choreography, contracting, and enactment. The formalism underlying our framework is Concurrent Transaction Logic---a logic for declarative specification, analysis, and execution of database transactions. The new results include reasoning about service behavior under more general sets of constraints and extension of the framework towards conditional control and data flow---two crucial aspect that were missing in previous logical formalizations.|Dumitru Roman,Michael Kifer","16483|IJCAI|2007|Learning Semantic Descriptions of Web Information Sources|The Internet is full of information sources providing various types of data from weather forecasts to travel deals. These sources can be accessed via web-forms, Web Services or RSS feeds. In order to make automated use of these sources, one needs to first model them semantically. Writing semantic descriptions for web sources is both tedious and error prone. In this paper we investigate the problem of automatically generating such models. We introduce a framework for learning Datalog definitions for web sources, in which we actively invoke sources and compare the data they produce with that of known sources of information. We perform an inductive search through the space of plausible source definitions in order to learn the best possible semantic model for each new source. The paper includes an empirical evaluation demonstrating the effectiveness of our approach on real-world web sources.|Mark James Carman,Craig A. Knoblock","65613|AAAI|2005|Learning Measures of Progress for Planning Domains|We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress (parmar ), which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results.|Sung Wook Yoon,Alan Fern,Robert Givan","16072|IJCAI|2005|Word Sense Disambiguation with Distribution Estimation|A word sense disambiguation (WSD) system trained on one domain and applied to a different domain will show a decrease in performance. One major reason is the different sense distributions between different domains. This paper presents novel application of two distribution estimation algorithms to provide estimates of the sense distribution of the new domain data set. Even though our training examples are automatically gathered from parallel corpora, the sense distributions estimated are good enough to achieve a relative improvement of % when incorporated into our WSD system.|Yee Seng Chan,Hwee Tou Ng"],["43626|IEICE Transations|2006|Design and Fabrication of the Wireless Systems for Pressure Monitoring Systems in the Gastro-Intestinal Track|Diseases in the gastro-intestinal track are becoming more prevalent. In order to diagnose a patient, the various signals of the digestive organ, such as temperature, pH, and pressure, can offer helpful information. The variation of a pressure signal of the gastro-intestinal track can offer information about digestive troubles or provide clues about diseases. This paper presents a wireless system for the pressure monitoring system, which includes a swallow-type pressure capsule and the external receiving system. A transmitter, a transmitting antenna (Helix), a receiver, and a receiving antenna (Loop) were designed and fabricated in consideration of the MPE, power consumption, system size, signal to noise ratio and modulation method. The wireless system designed and implemented for the pressure monitoring system was verified by in-vivo experiments. As a result, we found each organ has its own characteristic pressure fluctuation.|Yeon Kwan Moon,Jyung Hyun Lee,Hee Joon Park,JuGab Lee,Jae Jong Ryu,Chul-Ho Won,JungHee Lee,Jin-Ho Cho,Hyun Chul Choi","42546|IEICE Transations|2005|Joint Estimation of Doppler Spread and Carrier Frequency Offset for OFDM Systems|In this letter, a joint estimation algorithm of Doppler spread and frequency offset for OFDM systems in Rayleigh fading channels is proposed based on the autocorrelation function between the last part of the received OFDM signal and its copy in guard interval. It is shown by computer simulations that the proposed algorithm performs well for different Doppler spread values and carrier frequency offsets.|Bin Sheng,Xiaohu You","42855|IEICE Transations|2005|Optimal Tracking Design for Hybrid Uncertain Input-Delay Systems under State and Control Constraints via Evolutionary Programming Approach|A novel digital redesign methodology based on evolutionary programming (EP) is introduced to find the 'best' digital controller for optimal tracking design of hybrid uncertain multi-input multi-output (MIMO) input-delay systems with constraints on states and controls. To deal with these multivariable concurrent specifications and system restrictions, instead of conventional interval methods, the proposed global optimization scheme is able to practically implement optimal digital controller for constrained uncertain hybrid systems with input time delay. Further, an illustrative example is included to demonstrate the efficiency of the proposed method.|Yu-Pin Chang","42598|IEICE Transations|2005|Peak Power Reduction Method Using Adaptive Peak Reduction Signal Level Control for OFDM Transmission Systems|Future broadband mobile communication systems are necessary to achieve the bit rates of  Mbits. Orthogonal Frequency Division Multiplexing (OFDM) transmission is an attractive technology because it can remove the influence of frequency selective fading in broadband transmission by adding a suitable guard interval to each OFDM symbol. However, peak-to-average power ratio (PAPR) is very large in OFDM transmission. In this paper, we propose a new PAPR reduction method which can be applied even when unusable bands are inside the system band. In the proposed method, peak reduction signals are generated by iterative signal processing only in the usable frequency band, and filtering to remove out-of-band components of the peak reduction signals is incorporated into the iterative signal processing. The results of computer simulation show that the proposed method can effectively reduce peak power without expanding the spectrum both outside the system band and into unusable bands inside the system band. By using the proposed method, the broadband mobile communication system with low peak power and high flexibility of frequency band use can be realized.|Shigeru Tomisato,Masaharu Hata","43043|IEICE Transations|2006|Joint Estimation of Frequency Offset and Channel Frequency Response Using EM Algorithm for OFDM Systems|Orthogonal Frequency Division Multiplexing (OFDM) systems are very sensitive to the frequency offset of the local oscillator at the receiver while the symbol timing offset can be absorbed in the guard interval. For the same reason, estimation of the frequency characteristics, needed for OFDM to be adapted to the frequency selective fading, can only be carried out conventionally after the frequency offset has been compensated. And accurate estimation of large frequency offset certainly requires high precision estimate of the frequency characteristics. In this paper, we propose a new joint estimation method of the frequency offset and the channel frequency response using an Expectation-Maximization (EM) algorithm for OFDM systems. The proposed algorithm overcomes the limitation of the thus far proposed algorithm. By computer simulations, we show the proposed algorithm provides estimation accuracy close to its lower bound in a wide range of the frequency offset.|Masahiro Fujii,Makoto Itami,Kohji Itoh","43757|IEICE Transations|2007|Decentralized Adaptive Control of Large-Scale Nonaffine Nonlinear Systems Using Radial Basis Function Neural Networks|In this paper, a novel decentralized adaptive neural network controller is proposed for a class of large-scale nonlinear systems with unknown nonlinear, nonaffine subsystems and unknown nonlinear interconnections. The stability of the closed loop system is guaranteed by introducing a robust adaptive bound based on Lyapunov stability analysis. A radial-basis function type neural network is used in the paper. To show the effectiveness of the proposed method, we performed some simulation studies. The results of simulation become very promising.|Bahram Karimi,Mohammad Bagher Menhaj,Iman Saboori","42764|IEICE Transations|2005|A Design and Performance Evaluation of a Class of Channel Reservation Techniques for Medium Access Control Protocols in High Bit-Rate Wireless Communications|This paper introduces  channel reservation techniques for medium access control (MAC) protocols suitable for high bit-rate wireless communication systems. The first  algorithms, namely CFP, CAP, COP, COP+SPL, CFP+SPL, UNI and UNI+LA, are applicable to systems with single-access chance per frame, whereas the other  algorithms, namely MT-CFP, MT-CFP+SPL, MT-UNI, MT-UNI+LUA and MT-UNI+LUT are suitable for systems with multi-access attempts per frame. The performance of these techniques are analytically evaluated and compared with the existing known techniques. The analytical model derived here are also validated through Monte Carlo computer simulations. Numerical results show that all proposed techniques are in general more superior to conventional reservation techniques. Finally when comparing between all proposed schemes in terms of both throughput performance and practical feasibility it is found that the MT-UNI+LA scheme are relatively efficient and suitable for practical applications.|Warakorn Srichavengsup,Nattapon Sivamok,Atipong Suriya,Lunchakorn Wuttisittikulkij","42522|IEICE Transations|2005|A Simple Bit Allocation Scheme Based on Adaptive Coding for MIMO-OFDM Systems with V-BLAST Detector|We present a simple bit allocation scheme based on adaptive coding for MIMO-OFDM (Multiple Input Multiple Output - Orthogonal Frequency Division Multiplexing) systems with V-BLAST (Vertical-Bell laboratories LAyered Space-Time) detector. The proposed scheme controls the code rate of the channel coding and assigns the same modulation and coding to the set of selected sub-channels, which greatly reduces the feedback burden while achieving good performance. Simulation results show that the proposed scheme with minimal feedback provides significant performance improvement over other systems.|Jongwon Kim,Sanhae Kim,Min-Cheol Hong,Yoan Shin","43395|IEICE Transations|2006|A Method of Simple Adaptive Control for Nonlinear Systems Using Neural Networks|This paper presents a method of simple adaptive control (SAC) using neural networks for a class of nonlinear systems with bounded-input bounded-output (BIBO) and bounded nonlinearity. The control input is given by the sum of the output of the simple adaptive controller and the output of the neural network. The neural network is used to compensate for the nonlinearity of the plant dynamics that is not taken into consideration in the usual SAC. The role of the neural network is to construct a linearized model by minimizing the output error caused by nonlinearities in the control systems. Furthermore, convergence and stability analysis of the proposed method is performed. Finally, the effectiveness of the proposed method is confirmed through computer simulation.|Muhammad Yasser,Agus Trisanto,Jianming Lu,Takashi Yahagi","42671|IEICE Transations|2005|Robust Analysis and Design for Discrete-Time Nonlinear Systems Subject to Actuator Saturation via Fuzzy Control|This paper proposes an analysis and design methodology for the robust control of affine-in-control nonlinear systems subject to actuator saturation in discrete-time formulation. The robust stability condition is derived for the closed-loop system by the introduction of the fuzzy Kronecker delta. Based on the newly acquired stability condition, a design method is proposed to guarantee the robust H performance. In the design, LMI-based pole placement is employed to use the freedom allowed in the selection of the controller. The validity of the proposed method is asserted by the computer simulation.|Sanghyung Lee,Euntai Kim,Hagbae Kim,Mignon Park"],["42342|IEICE Transations|2005|A Data-Driven Model Parameter Compensation Method for Noise-Robust Speech Recognition|A data-driven approach that compensates the HMM parameters for the noisy speech recognition is proposed. Instead of assuming some statistical approximations as in the conventional methods such as the PMC, the various statistical information necessary for the HMM parameter adaptation is directly estimated by using the Baum-Welch algorithm. The proposed method has shown improved results compared with the PMC for the noisy speech recognition.|Yongjoo Chung","42830|IEICE Transations|2005|Robust Speech Recognition Using Discrete-Mixture HMMs|This paper introduces new methods of robust speech recognition using discrete-mixture HMMs (DMHMMs). The aim of this work is to develop robust speech recognition for adverse conditions that contain both stationary and non-stationary noise. In particular, we focus on the issue of impulsive noise, which is a major problem in practical speech recognition system. In this paper, two strategies were utilized to solve the problem. In the first strategy, adverse conditions are represented by an acoustic model. In this case, a large amount of training data and accurate acoustic models are required to present a variety of acoustic environments. This strategy is suitable for recognition in stationary or slow-varying noise conditions. The second is based on the idea that the corrupted frames are treated to reduce the adverse effect by compensation method. Since impulsive noise has a wide variety of features and its modeling is difficult, the second strategy is employed. In order to achieve those strategies, we propose two methods. Those methods are based on DMHMM framework which is one type of discrete HMM (DHMM). First, an estimation method of DMHMM parameters based on MAP is proposed aiming to improve trainability. The second is a method of compensating the observation probabilities of DMHMMs by threshold to reduce adverse effect of outlier values. Observation probabilities of impulsive noise tend to be much smaller than those of normal speech. The motivation in this approach is that flooring the observation probability reduces the adverse effect caused by impulsive noise. Experimental evaluations on Japanese LVCSR for read newspaper speech showed that the proposed method achieved the average error rate reduction of .% in impulsive noise conditions. Also the experimental results in adverse conditions that contain both stationary and impulsive noises showed that the proposed method achieved the average error rate reduction of .%.|Tetsuo Kosaka,Masaharu Katoh,Masaki Kohda","43558|IEICE Transations|2006|Acoustic Model Adaptation Using First-Order Linear Prediction for Reverberant Speech|This paper describes a hands-free speech recognition technique based on acoustic model adaptation to reverberant speech. In hands-free speech recognition, the recognition accuracy is degraded by reverberation, since each segment of speech is affected by the reflection energy of the preceding segment. To compensate for the reflection signal we introduce a frame-by-frame adaptation method adding the reflection signal to the means of the acoustic model. The reflection signal is approximated by a first-order linear prediction from the observation signal at the preceding frame, and the linear prediction coefficient is estimated with a maximum likelihood method by using the EM algorithm, which maximizes the likelihood of the adaptation data. Its effectiveness is confirmed by word recognition experiments on reverberant speech.|Tetsuya Takiguchi,Masafumi Nishimura,Yasuo Ariki","42348|IEICE Transations|2005|Applying Sparse KPCA for Feature Extraction in Speech Recognition|This paper presents an analysis of the applicability of Sparse Kernel Principal Component Analysis (SKPCA) for feature extraction in speech recognition, as well as, a proposed approach to make the SKPCA technique realizable for a large amount of training data, which is an usual context in speech recognition systems. Although the KPCA (Kernel Principal Component Analysis) has proved to be an efficient technique for being applied to speech recognition, it has the disadvantage of requiring training data reduction, when its amount is excessively large. This data reduction is important to avoid computational unfeasibility andor an extremely high computational burden related to the feature representation step of the training and the test data evaluations. The standard approach to perform this data reduction is to randomly choose frames from the original data set, which does not necessarily provide a good statistical representation of the original data set. In order to solve this problem a likelihood related re-estimation procedure was applied to the KPCA framework, thus creating the SKPCA, which nevertheless is not realizable for large training databases. The proposed approach consists in clustering the training data and applying to these clusters a SKPCA like data reduction technique generating the reduced data clusters. These reduced data clusters are merged and reduced in a recursive procedure until just one cluster is obtained, making the SKPCA approach realizable for a large amount of training data. The experimental results show the efficiency of SKPCA technique with the proposed approach over the KPCA with the standard sparse solution using randomly chosen frames and the standard feature extraction techniques.|Amaro Lima,Heiga Zen,Yoshihiko Nankaku,Keiichi Tokuda,Tadashi Kitamura,Fernando Gil Resende","42343|IEICE Transations|2005|Dialogue Speech Recognition by Combining Hierarchical Topic Classification and Language Model Switching|An efficient, scalable speech recognition architecture combining topic detection and topic-dependent language modeling is proposed for multi-domain spoken language systems. In the proposed approach, the inferred topic is automatically detected from the user's utterance, and speech recognition is then performed by applying an appropriate topic-dependent language model. This approach enables users to freely switch between domains while maintaining high recognition accuracy. As topic detection is performed on a single utterance, detection errors may occur and propagate through the system. To improve robustness, a hierarchical back-off mechanism is introduced where detailed topic models are applied when topic detection is confident and wider models that cover multiple topics are applied in cases of uncertainty. The performance of the proposed architecture is evaluated when combined with two topic detection methods unigram likelihood and SVMs (Support Vector Machines). On the ATR Basic Travel Expression Corpus, both methods provide a significant reduction in WER (.% and .%, respectively) compared to a single language model system. Furthermore, recognition accuracy is comparable to performing decoding with all topic-dependent models in parallel, while the required computational cost is much reduced.|Ian R. Lane,Tatsuya Kawahara,Tomoko Matsui,Satoshi Nakamura","42822|IEICE Transations|2005|Alaryngeal Speech Enhancement Using Pattern Recognition Techniques|An alaryngeal speech enhancement system is proposed to improve the intelligibility and quality of speech signals generated by an artificial larynx transducer (ALT). Proposed system identifies the voiced segments of alaryngeal speech signal, by using pattern recognition methods, and replaces these by their equivalent voiced segments of normal speech. Evaluation results show that proposed system provides a fairly good improvement of the quality and intelligibility of ALT generated speech.|Gualberto Aguilar-Torres,Mariko Nakano-Miyatake,H√©ctor M. P√©rez Meana","42328|IEICE Transations|2005|Speech Recognition Using Finger Tapping Timings|Behavioral synchronization between speech and finger tapping provides a novel approach to improving speech recognition accuracy. We combine a sequence of finger tapping timings recorded alongside an utterance using two distinct methods in the first method, HMM state transition probabilities at the word boundaries are controlled by the timing of the finger tapping in the second, the probability (relative frequency) of the finger tapping is used as a 'feature' and combined with MFCC in a HMM recognition system. We evaluate these methods through connected digit recognition under different noise conditions (AURORA-J). Leveraging the synchrony between speech and finger tapping provides a % relative improvement in connected digit recognition experiments.|Hiromitsu Ban,Chiyomi Miyajima,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura","43520|IEICE Transations|2006|Robust Speech Recognition by Using Compensated Acoustic Scores|This paper proposes a new compensation method of acoustic scores in the Viterbi search for robust speech recognition. This method introduces noise models to represent a wide variety of noises and realizes robust decoding together with conventional techniques of subtraction and adaptation. This method uses likelihoods of noise models in two ways. One is to calculate a confidence factor for each input frame by comparing likelihoods of speech models and noise models. Then the weight of the acoustic score for a noisy frame is reduced according to the value of the confidence factor for compensation. The other is to use the likelihood of noise model as an alternative that of a silence model when given noisy input. Since a lower confidence factor compresses acoustic scores, the decoder rather relies on language scores and keeps more hypotheses within a fixed search depth for a noisy frame. An experiment using commentary transcriptions of a broadcast sports program (MLB Major League Baseball) showed that the proposed method obtained a .% relative word error reduction. The method also reduced the relative error rate of key words by .%, and this is expected lead to an improvement metadata extraction accuracy.|Shoei Sato,Kazuo Onoe,Akio Kobayashi,Toru Imai","42363|IEICE Transations|2005|An Unsupervised Speaker Adaptation Method for Lecture-Style Spontaneous Speech Recognition Using Multiple Recognition Systems|This paper describes an accurate unsupervised speaker adaptation method for lecture style spontaneous speech recognition using multiple LVCSR systems. In an unsupervised speaker adaptation framework, the improvement of recognition performance by adapting acoustic models remarkably depends on the accuracy of labels such as phonemes and syllables. Therefore, extraction of the adaptation data guided by confidence measure is effective for unsupervised adaptation. In this paper, we looked for the high confidence portions based on the agreement between two LVCSR systems, adapted acoustic models using the portions attached with high accurate labels, and then improved the recognition accuracy. We applied our method to the Corpus of Spontaneous Japanese (CSJ) and the method improved the recognition rate by about .% in comparison with a traditional method.|Seiichi Nakagawa,Tomohiro Watanabe,Hiromitsu Nishizaki,Takehito Utsuro","42715|IEICE Transations|2005|Adaptive Nonlinear Regression Using Multiple Distributed Microphones for In-Car Speech Recognition|In this paper, we address issues in improving hands-free speech recognition performance in different car environments using multiple spatially distributed microphones. In the previous work, we proposed the multiple linear regression of the log spectra (MRLS) for estimating the log spectra of speech at a close-talking microphone. In this paper, the concept is extended to nonlinear regressions. Regressions in the cepstrum domain are also investigated. An effective algorithm is developed to adapt the regression weights automatically to different noise environments. Compared to the nearest distant microphone and adaptive beamformer (Generalized Sidelobe Canceller), the proposed adaptive nonlinear regression approach shows an advantage in the average relative word error rate (WER) reductions of .% and .%, respectively, for isolated word recognition under  real car environments.|Weifeng Li,Chiyomi Miyajima,Takanori Nishino,Katsunobu Itou,Kazuya Takeda,Fumitada Itakura"],["42394|IEICE Transations|2005|Solving Facility Layout Problem Using an Improved Genetic Algorithm|The facility layout problem is one of the most fundamental quadratic assignment problems in operations research. In this paper, we present an improved genetic algorithm for solving the facility layout problem. In our computational model, we propose several improvements to the basic genetic procedures including conditional crossover and mutation. The performance of the proposed method is evaluated on some benchmark problems. Computational results showed that the improved genetic algorithm is capable of producing high-quality solutions.|Rong Long Wang,Kozo Okazaki","43989|IEICE Transations|2007|A Genetic Algorithm with Conditional Crossover and Mutation Operators and Its Application to Combinatorial Optimization Problems|In this paper, we present a modified genetic algorithm for solving combinatorial optimization problems. The modified genetic algorithm in which crossover and mutation are performed conditionally instead of probabilistically has higher global and local search ability and is more easily applied to a problem than the conventional genetic algorithms. Three optimization problems are used to test the performances of the modified genetic algorithm. Experimental studies show that the modified genetic algorithm produces better results over the conventional one and other methods.|Rong Long Wang,Shinichi Fukuta,Jiahai Wang,Kozo Okazaki","58084|GECCO|2007|A genetic algorithm for coverage problems|This paper describes a genetic algorithm approach to coverage problems, that is, problems where the aim is to discover an example for each class in a given classification scheme.|Colin G. Johnson","43356|IEICE Transations|2006|Solving the Graph Planarization Problem Using an Improved Genetic Algorithm|An improved genetic algorithm for solving the graph planarization problem is presented. The improved genetic algorithm which is designed to embed a graph on a plane, performs crossover and mutation conditionally instead of probability. The improved genetic algorithm is verified by a large number of simulation runs and compared with other algorithms. The experimental results show that the improved genetic algorithm performs remarkably well and outperforms its competitors.|Rong Long Wang,Kozo Okazaki","57687|GECCO|2006|A genetic algorithm for the longest common subsequence problem|A genetic algorithm for the longest common subsequence problem encodes candidate sequences as binary strings that indicate subsequences of the shortest or first string. Its fitness function penalizes sequences not found in all the strings. In tests on  sets of three strings, a dynamic programming algorithm returns optimum solutions quickly on smaller instances and increasingly slowly on larger instances. Repeated trials of the GA always identify optimum subsequences, and it runs in reasonable times even on the largest instances.|Brenda Hinkemeyer,Bryant A. Julstrom","57756|GECCO|2006|A fast hybrid genetic algorithm for the quadratic assignment problem|Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the \"fast hybrid genetic algorithm\" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm.|Alfonsas Misevicius","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao","58219|GECCO|2007|A fuzzy genetic algorithm for the dynamic cell formation problem|This paper deals with a fuzzy genetic algorithm applied to a manufacturing cell formation problem. We discuss the importance of taking into account the dynamic aspect of the problem that has been poorly studied in the related literature. Using a multi-periodic planning horizon modeling, two strategies are considered passive and active. The first strategy consists of maintaining the same composition of machines during the overall planning horizon, while the second allows performing a different composition for each period. When the decision maker wants to choose the most adequate strategy for its environment, there is a need to control the proposed evolutionary solving approach, due to the complexity of the model. For that purpose, we propose an off-line fuzzy logic enhancement. The results, using this enhancement, are better than those obtained using the GA alone.|Menouar Boulif,Karim Atif","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens","44105|IEICE Transations|2007|Binary Self-Organizing Map with Modified Updating Rule and Its Application to Reproduction of Genetic Algorithm|In this paper, we propose a modified reproduction strategy of a Genetic Algorithm (GA) utilizing a Self-Organizing Map (SOM) with a novel updating rule of binary weight vectors based on a significance of elements of inputs. In this rule, an updating order of elements is decided by considering fitness values of individuals in a population. The SOM with the proposed updating rule can realize an effective reproduction.|Ryosuke Kubota,Keiichi Horio,Takeshi Yamakawa"],["42904|IEICE Transations|2005|Dynamic Replica Control Based on Fairly Assigned Variation of Data for Loosely Coupled Distributed Database Systems|This paper proposes a decentralized and asynchronous replica control method based on a fair assignment of the variation in numerical data that has weak consistency for loosely coupled database systems managed or used by different organizations of human activity. Our method eliminates the asynchronous abort of already committed transactions even if replicas in all network partitions continue to process transactions when network partitioning occurs. A decentralized and asynchronous approach is needed because it is difficult to keep a number of loosely coupled systems in working order, and replica operations performed in a centralized and synchronous way can degrade the performance of transaction processing. We eliminate the transaction abort by fairly distributing the variation in numerical data to replicas according to their demands and updating the distributed variation using only asynchronously propagated update transactions without calculating the precise global state among reachable replicas. In addition, fairly assigning the variation of data to replicas equalizes the disadvantages of processing update transactions among replicas. Fairness control for assigning the data variation is performed by averaging the variation requested by the replicas. A simulation showed that our system can achieve extremely high performance for processing update transactions and fairness among replicas.|Takao Yamashita","80791|VLDB|2007|Randomized Algorithms for Data Reconciliation in Wide Area Aggregate Query Processing|Many aspects of the data integration problem have been considered in the literature how to match schemas across different data sources, how to decide when different records refer to the same entity, how to efficiently perform the required entity resolution in a batch fashion, and so on. However, what has largely been ignored is a way to efficiently deploy these existing methods in a realistic, distributed enterprise integration environment. The straightforward use of existing methods often requires that all data be shipped to a coordinator for cleaning, which is often unacceptable. We develop a set of randomized algorithms that allow efficient application of existing entity resolution methods to the answering of aggregate queries over data that have been distributed across multiple sites. Using our methods, it is possible to efficiently generate aggregate query results that account for duplicate and inconsistent values scattered across a federated system.|Fei Xu,Chris Jermaine","80503|VLDB|2005|Sketching Streams Through the Net Distributed Approximate Query Tracking|Emerging large-scale monitoring applications require continuous tracking of complex data-analysis queries over collections of physically-distributed streams. Effective solutions have to be simultaneously spacetime efficient (at each remote monitor site), communication efficient (across the underlying communication network), and provide continuous, guaranteed-quality approximate query answers. In this paper, we propose novel algorithmic solutions for the problem of continuously tracking a broad class of complex aggregate queries in such a distributed-streams setting. Our tracking schemes maintain approximate query answers with provable error guarantees, while simultaneously optimizing the storage space and processing time at each remote site, and the communication cost across the network. They rely on tracking general-purpose randomized sketch summaries of local streams at remote sites along with concise prediction models of local site behavior in order to produce highly communication- and spacetime-efficient solutions. The result is a powerful approximate query tracking framework that readily incorporates several complex analysis queries (including distributed join and multi-join aggregates, and approximate wavelet representations), thus giving the first known low-overhead tracking solution for such queries in the distributed-streams model.|Graham Cormode,Minos N. Garofalakis","80544|VLDB|2005|StreamGlobe Processing and Sharing Data Streams in Grid-Based PP Infrastructures|Data stream processing is currently gaining importance due to the developments in novel application areas like e-science, e-health, and e-business (considering RFID, for example). Focusing on e-science, it can be observed that scientific experiments and observations in many fields, e. g., in physics and astronomy, create huge volumes of data which have to be interchanged and processed. With experimental and observational data coming in particular from sensors, online simulations, etc., the data has an inherently streaming nature. Furthermore, continuing advances will result in even higher data volumes, rendering storing all of the delivered data prior to processing increasingly impractical. Hence, in such e-science scenarios, processing and sharing of data streams will play a decisive role. It will enable new possibilities for researchers, since they will be able to subscribe to interesting data streams of other scientists without having to set up their own devices or experiments. This results in much better utilization of expensive equipment such as telescopes, satellites, etc. Further, processing and sharing data streams on-the-fly in the network helps to reduce network traffic and to avoid network congestion. Thus, even huge streams of data can be handled efficiently by removing unnecessary parts early on, e. g., by early filtering and aggregation, and by sharing previously generated data streams and processing results.|Richard Kuntschke,Bernhard Stegmaier,Alfons Kemper,Angelika Reiser","80622|VLDB|2006|Query Processing in the AquaLogic Data Services Platform|BEA recently introduced a new middleware product called the Aqua-Logic Data Services Platform (ALDSP). The purpose of ALDSP is to make it easy to design, develop, deploy, and maintain a data services layer in the world of service-oriented architecture (SOA). ALDSP provides a declarative foundation for building SOA applications and services that need to access and compose information from a range of enterprise data sources this foundation is based on XML, XML Schema, and XQuery. This paper focuses on query processing in ALDSP, describing its overall query processing architecture, its query compiler and runtime system, its distributed query processing techniques, the translation of XQuery plan fragments into SQL when relational data sources are involved, and the production of lineage information to support updates. Several XQuery extensions that were added in support of requirements related to data services are also covered.|Vinayak R. Borkar,Michael J. Carey,Dmitry Lychagin,Till Westmann,Daniel Engovatov,Nicola Onose","66036|AAAI|2007|Centralized Distributed or Something Else Making Timely Decisions in Multi-Agent Systems|In multi-agent systems, agents need to share information in order to make good decisions. Who does what in order to achieve this matters a lot. The assignment of responsibility influences delay and consequently affects agents' abilities to make timely decisions. It is often unclear which approaches are best. We develop a model where one can easily test the impact of different assignments and information sharing protocols by focusing only on the delays caused by computation and communication. Using the model, we obtain interesting results that provide insight about the types of assignments that perform well in various domains and how slight variations in protocols can make great differences in feasibility.|Tim Harbers,Rajiv T. Maheswaran,Pedro A. Szekely","43811|IEICE Transations|2007|Adaptive Processing over Distributed Networks|The article describes recent adaptive estimation algorithms over distributed networks. The algorithms rely on local collaborations and exploit the space-time structure of the data. Each node is allowed to communicate with its neighbors in order to exploit the spatial dimension, while it also evolves locally to account for the time dimension. Algorithms of the least-mean-squares and least-squares types are described. Both incremental and diffusion strategies are considered.|Ali H. Sayed,Cassio G. Lopes","57779|GECCO|2006|Adaption in distributed systems an evolutionary approach|There is a trend towards networked and distributed systems, complicating the design process of self-adaptive software. Logistics networks can be seen as a distributed system that have to adapt to requirements of companies and customers in a flexible and fast manner. When constructing and planning logistic networks different aspects of complexity have to be considered the number of stores, intermediate stores and transport entities that are required at every stage in a supply chain as well as the sufficient size of every store or transport entity. This paper presents an approach that simulates adaptive logistic networks using a multi-agent system (MAS) based on Evolutionary Computation (EC). Our approach uses fully decentralized operators for reproduction like mutation, recombination and selection, regulated by market mechanisms. The novelty of this approach lies in the decentralized bottom-up adaption method for decentralized systems and we use a logistic scenario as an example. Our proposed method is based on a formal model explaining how adaption occurs in the number and strategies of agents and thus of logistic networks. The implementation and experimental results are given to illustrate the expected outcomes.|Stephan Otto,Stefan Kirn","65740|AAAI|2006|Distributed Interactive Learning in Multi-Agent Systems|Both explanation-based and inductive learning techniques have proven successful in a variety of distributed domains. However, learning in multi-agent systems does not necessarily involve the participation of other agents directly in the inductive process itself. Instead, many systems frequently employ multiple instances of induction separately, or single-agent learning. In this paper we present a new framework, named the Multi-Agent Inductive Learning System (MAILS), that tightly integrates processes of induction between agents. The MAILS framework combines inverse entailment with an epistemic approach to reasoning about knowledge in a multi-agent setting, facilitating a systematic approach to the sharing of knowledge and invention of predicates when required. The benefits of the new approach are demonstrated for inducing declarative program fragments in a multi-agent distributed programming system.|Jian Huang,Adrian R. Pearce","65549|AAAI|2005|Planning for Stream Processing Systems|With the advent of compositional programming models in computer Science, applying planning technologies to automatically build workflows for solving large and complex problems in such a paradigm becomes not only technically appealing but also feasible approach. The application areas that will benefit from automatic composition include, among others, Web services, Grid computing and stream processing systems. Although the classical planning formalism is expressive enough to describe planning problems that arise in a large variety of different applications, it can pose significant limitations on planner performance in compositional applications, in particular, in stream processing systems. In this paper we exlend the classical planning formalism by introducing new language constructs that support the structure of stream processing domains. Exposing this structure to the planner can result in dramatic performance improvements our experiments show exponential planning time reduction in comparison to most recent metric planners.|Anton Riabov,Zhen Liu"],["66006|AAAI|2007|Spatial Representation and Reasoning for Human-Robot Collaboration|How should a robot represent and reason about spatial information when it needs to collaborate effectively with a human The form of spatial representation that is useful for robot navigation may not be useful in higher-level reasoning or working with humans as a team member. To explore this question, we have extended previous work on how children and robots learn to play hide and seek to a human-robot team covertly approaching a moving target. We used the cognitive modeling system, ACT-R, with an added spatial module to support the robot's spatial reasoning. The robot interacted with a team member through voice, gestures, and movement during the team's covert approach of a moving target. This paper describes the new robotic system and its integration of metric, symbolic, and cognitive layers of spatial representation and reasoning for its individual and team behavior.|William G. Kennedy,Magdalena D. Bugajska,Matthew Marge,William Adams,Benjamin R. Fransen,Dennis Perzanowski,Alan C. Schultz,J. Gregory Trafton","16227|IJCAI|2005|Temporal Context Representation and Reasoning|This paper demonstrates how a model for temporal context reasoning can be implemented. The approach is to detect temporally related events in natural language text and convert the events into an enriched logical representation. Reasoning is provided by a first order logic theorem prover adapted to text. Results show that temporal context reasoning boosts the performance of a Question Answering system.|Dan I. Moldovan,Christine Clark,Sanda M. Harabagiu","66133|AAAI|2007|Logical Generative Models for Probabilistic Reasoning about Existence Roles and Identity|In probabilistic reasoning, the problems of existence and identity are important to many different queries for example, the probability that something that fits some description exists, the probability that some description refers to an object you know about or to a new object, or the probability that an object fulfils some role. Many interesting queries reduce to reasoning about the role of objects. Being able to talk about the existence of parts and sub-parts and the relationships between these parts, allows for probability distributions over complex descriptions. Rather than trying to define a new language, this paper shows how the integration of multiple objects, ontologies and roles can be achieved cleanly. This solves two main problems reasoning about existence and identity while preserving the clarity principle that specifies that probabilities must be over well defined propositions, and the correspondence problem that means that we don't need to search over all possible correspondences between objects said to exist and things in the world.|David Poole","16283|IJCAI|2005|Probabilistic Reasoning for Plan Robustness|A planning system must reason about the uncertainty of continuous variables in order to accurately project the possible system state over time. A method is devised for directly reasoning about the uncertainty in continuous activity duration and resource usage for planning problems. By representing random variables as parametric distributions, computing projected system state can be simplified. Common approximations and novel methods are compared for over-constrained and lightly constrained domains within an iterative repair planner. Results show improvements in robustness over the conventional non-probabilistic representation by reducing the number of constraint violations during execution. The improvement is more significant for larger problems and those with higher resource subscription levels but diminishes as the system is allowed to accept higher risk levels.|Steve R. Schaffer,Bradley J. Clement,Steve A. Chien","16156|IJCAI|2005|Data Complexity of Reasoning in Very Expressive Description Logics|Data complexity of reasoning in description logics (DLs) estimates the performance of reasoning algorithms measured in the size of the ABox only. We show that, even for the very expressive DL SHIQ, satisfiability checking is data complete for NP. For applications with large ABoxes, this can be a more accurate estimate than the usually considered combined complexity, which is EXPTIME-complete. Furthermore, we identify an expressive fragment, Horn-SHIQ, which is data complete for P, thus being very appealing for practical usage.|Ullrich Hustadt,Boris Motik,Ulrike Sattler","65496|AAAI|2005|Complexity-Guided Case Discovery for Case Based Reasoning|The distribution of cases in the case base is critical to the performance of a Case Based Reasoning system. The case author is given little support in the positioning of new cases during the development stage of a case base. In this paper we argue that classification boundaries represent important regions of the problem space. They are used to identify locations where new cases should be acquired. We introduce two complexity-guided algorithms which use a local complexity measure and boundary identification techniques to actively discover cases close to boundaries. The ability of these algorithms to discover new cases that significantly improve the accuracy of case bases is demonstrated on five public domain classification datasets.|Stewart Massie,Susan Craw,Nirmalie Wiratunga","66073|AAAI|2007|Representing and Reasoning about Commitments in Business Processes|A variety of business relationships in open settings can be understood in terms of the creation and manipulation of commitments among the participants. These include BC and BB contracts and processes, as realized via Web services and other such technologies. Business protocols, an interaction-oriented approach for modeling business processes, are formulated in terms of the commitments. Commitments can support other forms of semantic service composition as well. This paper shows how to represent and reason about commitments in a general manner. Unlike previous formalizations, the proposed formalization accommodates complex and nested commitment conditions, and concurrent commitment operations. In this manner, a rich variety of open business scenarios are enabled.|Nirmit Desai,Amit K. Chopra,Munindar P. Singh","65364|AAAI|2005|Reasoning about Intended Actions|In most research on reasoning about actions and reasoning about narratives one either reasons about hypothetical execution of actions, or about actions that actually occurred. In this paper we develop a high level language that allows the expression of intended or planned action sequences. Unlike observed action occurrences, planned or intended action occurrences may not actually take place. But often when they do not take place, they persist, and happen at an opportune future time. We give the syntax and semantics for expressing such intentions. We then give a logic programming axiomatization and show the correspondence between the semantics of a description in the high level language, and the answer sets of the corresponding logic programming axiomatization. We illustrate the application of our formalism with respect to reasoning about trips.|Chitta Baral,Michael Gelfond","16292|IJCAI|2005|Probabilistic Reasoning with Hierarchically Structured Variables|Many practical problems have random variables with a large number of values that can be hierarchically structured into an abstraction tree of classes. This paper considers how to represent and exploit hierarchical structure in probabilistic reasoning. We represent the distribution for such variables by specifying, for each class, the probability distribution over its immediate subclasses. We represent the conditional probability distribution of any variable conditioned on hierarchical variables using inheritance. We present an approach for reasoning in Bayesian networks with hierarchically structured variables that dynamically constructs a flat Bayesian network, given some evidence and a query, by collapsing the hierarchies to include only those values necessary to answer the query. This can be done with a single pass over the network. We can answer the query from the flat Bayesian network using any standard probabilistic inference algorithm such as variable elimination or stochastic simulation. The domain size of the variables in the flat Bayesian network is independent of the size of the hierarchies it depends on how many of the classes in the hierarchies are directly associated with the evidence and query. Thus, the representation is applicable even when the hierarchy is conceptually infinite.|Rita Sharma,David Poole","65725|AAAI|2006|Bounded Treewidth as a Key to Tractability of Knowledge Representation and Reasoning|Several forms of reasoning in AI - like abduction, closed world reasoning, circumscription, and disjunctive logic programming - are well known to be intractable. In fact, many of the relevant problems are on the second or third level of the polynomial hierarchy. In this paper, we show how the notion of treewidth can be fruitfully applied to this area. In particular, we show that all these problems become tractable (actually, even solvable in linear time), if the treewidth of the involved formulae or programs is bounded by some constant. Clearly, these theoretical tractability results as such do not immediately yield feasible algorithms. However, we have recently established a new method based on monadic datalog which allowed us to design an efficient algorithm for a related problem in the database area. In this work, we exploit the monadic datalog approach to construct new algorithms for logic-based abduction.|Georg Gottlob,Reinhard Pichler,Fang Wei"],["43176|IEICE Transations|2006|An Adaptive Frame-Based Interpolation Method of Channel Estimation for Space-Time Block Codes in Moderate Fading Channels|The application of Orthogonal Space-Time Block Codes (O-STBC) as the encoding scheme in the presence of \"non-quasi-static\" fading was considered. A simple and efficient adaptive method of channel estimation based on the interpolation of estimates acquired at the pre-amble and post-amble of framed blocks of information is developed. Moreover, the proposed method is proven, both theoretically and by simulations, to outperform the alternative of channel tracking, despite its significant low complexity.|Gabriel Porto Villardi,Giuseppe Thadeu Freitas de Abreu,Ryuji Kohno","43910|IEICE Transations|2007|Global Noise Estimation Based on Tensor Product Expansion with Absolute Error|This paper proposes a novel signal estimation method that uses a tensor product expansion. When a bivariable function, which is expressed by two-dimensional matrix, is subjected to conventional tensor product expansion, two single variable functions are calculated by minimizing the mean square error between the input vector and its outer product. A tensor product expansion is useful for feature extraction and signal compression, however, it is difficult to separate global noise from other signals. This paper shows that global noise, which is observed in almost all input signals, can be estimated by using a tensor product expansion where absolute error is used as the error function.|Akitoshi Itai,Hiroshi Yasukawa,Ichi Takumi,Masayasu Hata","43877|IEICE Transations|2007|Finite Parameter Model for Doubly-Selective Channel Estimation in OFDM|To describe joint time-and frequency-selective (doubly-selective) channels in mobile broadband wireless communications, we propose to use the finite parameter model based on the same Bessel functions for each tap (Bessel model). An expression of channel estimation mean squared error (MSE) based on the finite parameter models in Orthogonal Frequency Division Multiplexing (OFDM) systems is derived. Then, our Bessel model is compared with commonly used finite parameter models in terms of the channel estimation MSE. Even if the channel taps have different channel correlations and some of the taps do not coincide with the Bessel function, the channel estimation MSE of the Bessel model is shown to be comparable or outperform existing models as validated by Monte-Carlo simulations over an ensemble of channels in typical urban and suburban environments.|Kok Ann Donny Teo,Shuichi Ohno","43043|IEICE Transations|2006|Joint Estimation of Frequency Offset and Channel Frequency Response Using EM Algorithm for OFDM Systems|Orthogonal Frequency Division Multiplexing (OFDM) systems are very sensitive to the frequency offset of the local oscillator at the receiver while the symbol timing offset can be absorbed in the guard interval. For the same reason, estimation of the frequency characteristics, needed for OFDM to be adapted to the frequency selective fading, can only be carried out conventionally after the frequency offset has been compensated. And accurate estimation of large frequency offset certainly requires high precision estimate of the frequency characteristics. In this paper, we propose a new joint estimation method of the frequency offset and the channel frequency response using an Expectation-Maximization (EM) algorithm for OFDM systems. The proposed algorithm overcomes the limitation of the thus far proposed algorithm. By computer simulations, we show the proposed algorithm provides estimation accuracy close to its lower bound in a wide range of the frequency offset.|Masahiro Fujii,Makoto Itami,Kohji Itoh","42604|IEICE Transations|2005|Maximum Likelihood Estimation of Trellis Encoder and Modulator Transition Utilizing HMM for Adaptive Channel Coding and Modulation Technique|In order to achieve adaptive channel coding and adaptive modulation, the main causes of degradation to system performance are the decoder selection error and modulator estimation error. The utilization of supplementary information, in an estimation system utilizing channel estimation results, blind modulation estimation, and blind encoder estimation using several decoders information and encoder transitions have been considered to overcome these two problems. There are however many issues in these methods, such as the channel estimation difference between transmitter and receiver, computational complexity and the assumption of perfect Channel State Information (CSI). Our proposal, on the other hand, decreases decoder and demodulator selection error using a Hidden-Markov Model (HMM). In order to estimate the switching patterns of the encoder and modulator, our proposed system selects the maximum likelihood encoder and modulator transition patterns using both encoder and modulator transition probability based on the HMM obtained by CSI and also Decoder and Demodulator Selection Error probabilities. Therefore, the decoder and demodulation results can be achieved efficiently without any restraint on the pattern of switching encoder and modulation.|Kentaro Ikemoto,Ryuji Kohno","42641|IEICE Transations|2005|Recursive Channel Estimation Based on Finite Parameter Model Using Reduced-Complexity Maximum Likelihood Equalizer for OFDM over Doubly-Selective Channels|To take intercarrier interference (ICI) attributed to time variations of the channel into consideration, the time- and frequency-selective (doubly-selective) channel is parameterized by a finite parameter model. By capitalizing on the finite parameter model to approximate the doubly-selective channel, a Kalman filter is developed for channel estimation. The ICI suppressing, reduced-complexity Viterbi-type Maximum Likelihood (RML) equalizer is incorporated into the Kalman filter for recursive channel tracking and equalization to improve the system performance. An enhancement in the channel tracking ability is validated by theoretical analysis, and a significant improvement in BER performance using the channel estimates obtained by the recursive channel estimation method is verified by Monte-Carlo simulations.|Kok Ann Donny Teo,Shuichi Ohno,Takao Hinamoto","43851|IEICE Transations|2007|Low-Complexity Maximum Likelihood Frequency Offset Estimation for OFDM|This letter proposes a low-complexity estimation method of integer frequency offset in orthogonal frequency division multiplexing (OFDM) systems. The performance and complexity of the proposed method are compared with that of Morelli and Mengali's method based on maximum likelihood (ML) technique. The results show that the performance of the proposed method is comparable to that of M&M method with reduced complexity.|Hyun Yang,Hyoung-Kyu Song,Young-Hwan You","43425|IEICE Transations|2006|Robust Talker Direction Estimation Based on Weighted CSP Analysis and Maximum Likelihood Estimation|This paper describes a new talker direction estimation method for front-end processing to capture distant-talking speech by using a microphone array. The proposed method consists of two algorithms One is a TDOA (Time Delay Of Arrival) estimation algorithm based on a weighted CSP (Cross-power Spectrum Phase) analysis with an average speech spectrum and CSP coefficient subtraction. The other is a talker direction estimation algorithm based on ML (Maximum Likelihood) estimation in a time sequence of the estimated TDOAs. To evaluate the effectiveness of the proposed method, talker direction estimation experiments were carried out in an actual office room. The results confirmed that the talker direction estimation performance of the proposed method is superior to that of the conventional methods in both diffused- and directional-noise environments.|Yuki Denda,Takanobu Nishiura,Yoichi Yamashita","43986|IEICE Transations|2007|Analysis of Symmetric Cancellation Coding for OFDM over a Multi-Path Rayleigh Fading Channel|Orthogonal frequency division multiplexing (OFDM) systems for mobile applications suffer from inter-carrier-interference (ICI) due to frequency offset and to time-variation of the channels and from high peak-to-average-power ratio (PAPR). In this paper, we revisit symmetric cancellation coding (SCC) proposed by Sathananthan et al. and compare the effectiveness of SCC with a fixed subtraction combining and the well-known polynomial cancellation coding (PCC) over Rayleigh fading channels with Doppler spread in terms of the signal-to-interference plus noise power ratio (SINR) and bit-error-rate (BER). We also compare SCC with subtraction combining and SCC of Sathananthan et al. with maximum ratio combining (MRC). Our results show that SCC-OFDM with subtraction combining gives higher SINR than PCC-OFDM over the flat Rayleigh fading channel and that this superiority is not maintained under multi-path induced frequency-selective fading unless diversity combining is used. A simulation result shows, however, that SCC-OFDM with subtraction combining may perform better than PCC-OFDM for a certain range of Doppler spread when differential modulation is employed. Finally, we also demonstrate that the SCC-OFDM signal has less PAPR compared to the normal OFDM and PCC-OFDM and hence may be more practical.|Abdullah S. Alaraimi,Takeshi Hashimoto","42713|IEICE Transations|2005|Analysis on Channel Estimation for the Equalization in ATSC DTV Receivers|This paper presents analysis results on finite-impulse response (FIR) channel estimation used for the equalization in Advanced Television Systems Committee digital television receivers. While channel estimation results have been effectively used for the equalization, the conditions of sufficient order and high signal-to-noise ratio (SNR) were assumed in most cases. To compensate for these unrealistic assumptions, we consider diverse probable conditions for channel estimation, such as reduced order and low SNRs, and then theoretically analyze each estimation case. The analysis shows that the adaptive FIR channel estimator provides an unbiased estimation and matches well its corresponding channel coefficients irrespective of the number of taps of the estimator and the non-causality of the unknown channel. Simulation results verify our analysis on the estimation of terrestrial DTV channels.|Hyoung-Nam Kim,Sung Ik Park,Seung Won Kim"],["43211|IEICE Transations|2006|Binary Zero-Correlation Zone Sequence Set Construction Using a Cyclic Hadamard Sequence|The present paper introduces a new construction of a class of binary periodic sequence set having a zero-correlation zone (hereinafter binary ZCA sequence set). The cross-correlation function and the side-lobe of the auto-correlation function of the proposed sequence set is zero for the phase shifts within the zero-correlation zone. The present paper shows that such a construction generates a binary ZCA sequence set by using a cyclic difference set and a collection of mutually orthogonal complementary sets.|Takafumi Hayashi","43383|IEICE Transations|2006|Sequence Set with Three Zero Correlation Zones and Its Application in MC-CDMA System|Sequence set with Three Zero Correlation Zones (T-ZCZ) can efficiently mitigate the Multiple Access Interference (MAI) and Inter Symbol Interference (ISI) caused by multi-path in CDMA system. In this paper, an algorithm for generating T-ZCZ sequence set is presented. Moreover, in order to study the restrictions among the parameters such as the length of the sequence, the number of the sequences and the length of the T-ZCZ etc., the corresponding theoretical bound is investigated and proved. Additionally, the performance of T-ZCZ sequence in MC-CDMA system is evaluated to confirm the capability of interference cancellation as well as system capacity improvement.|Chao Zhang,Xiaoming Tao,Shigeki Yamada,Mitsutoshi Hatori","43164|IEICE Transations|2006|Ternary Sequence Set Having Periodic and Aperiodic Zero-Correlation Zone|A new class of ternary sequence with a zero-correlation zone is introduced. The proposed sequence sets have a zero-correlation zone for both periodic and aperiodic correlation functions. The proposed sequences can be constructed from a pair of Hadamard matrices of size n  n and a Hadamard matrix of size n  n. The constructed sequence set consists of nn ternary sequences, and the length of each sequence is n(m+)(n + ) for a non-negative integer m. The zero-correlation zone of the proposed sequences is  nm-, where  is the phase shift. The sequence member size of the proposed sequence set is equal to nn+ times that of the theoretical upper bound of the member size of a sequence set with a zero-correlation zone.|Takafumi Hayashi","43814|IEICE Transations|2007|Zero-Correlation Zone Sequence Set Constructed from a Perfect Sequence|The present paper introduces the construction of a class of sequence sets with zero-correlation zones called zero-correlation zone sequence sets. The proposed zero-correlation zone sequence set can be generated from an arbitrary perfect sequence, the length of which is longer than . The proposed sets of ternary sequences, which can be constructed from an arbitrary perfect sequence, can successfully provide CDMA communication without co-channel interference. In an ultrasonic synthetic aperture imaging system, the proposed sequence set can improve the signal-to-noise ratio of the acquired image.|Takafumi Hayashi","43974|IEICE Transations|2007|Zero-Correlation Zone Sequence Set Construction Using an Even-Perfect Sequence and an Odd-Perfect Sequence|The present paper introduces a new construction of a class of binary periodic sequence set having a zero-correlation zone sequence set. The cross-correlation function and the side-lobe of the auto-correlation function of the proposed sequence set is zero for the phase shifts within the zero-correlation zone. The present paper shows that such a construction generates a binary zcz sequence set by using an arbitrary pair of an even-perfect sequence and an odd-perfect sequence. The proposed zcz sequence set reaches the theoretical upper bound of the member size of the sequence set.|Takafumi Hayashi","43874|IEICE Transations|2007|An Integrated Sequence Construction of Binary Zero-Correlation Zone Sequences|The present paper introduces an integrated construction of binary sequences having a zero-correlation zone. The cross-correlation function and the side-lobe of the auto-correlation function of the proposed sequence set is zero for the phase shifts within the zero-correlation zone. The proposed method enables more flexible design of the binary zero-correlation zone sequence set with respect to its member size, length, and width of zero-correlation zone. Several previously reported sequence construction methods of binary zero-correlation zone sequence sets can be explained as special cases of the proposed method.|Takafumi Hayashi","43279|IEICE Transations|2006|Families of Sequence Pairs with Zero Correlation Zone|A family of sequences with zero correlation zone, which is shortly called a ZCZ set, can provide CDMA system without co-channel interference nor influence of multipath. This paper presents two types of ZCZ sets of non-binary sequence pairs, which achieve the upper bound of family size for length and zero correlation zone. One, which is produced by use of a perfect complementary pair and an orthogonal code, can change zero correlation zone, while the upper bound is kept. The other, which is generated by use of a newly defined orthogonal pair and an orthogonal code, can offer such CDMA system as a binary ZCZ set seems to be used.|Shinya Matsufuji","43018|IEICE Transations|2006|On Linear Complexity and Schaub Bound for Cyclic Codes by Defining Sequence with Unknown Elements|The Schaub bound is one of well-known lower bounds of the minimum distance for given cyclic code C, and defined as the minimum value, which is a lower bound on rank of matrix corresponding a codeword, in defining sequence for all sub-cyclic codes of given code C. In this paper, we will try to show relationships between the Schaub bound, the Roos bound and the shift bound from numerical experiments. In order to reduce computational time for the Schaub bound, we claim one conjecture, from numerical examples in binary and ternary cases with short code length that the Schaub bound can be set the value from only defining sequence of given code C.|Junru Zheng,Takayasu Kaida","42581|IEICE Transations|2005|Binary Zero-Correlation Zone Sequence Set Construction Using a Primitive Linear Recursion|The present paper introduces a new construction of a class of binary sequence set having a zero-correlation zone (hereafter binary ZCZ sequence set). The cross-correlation function and the side-lobe of the auto-correlation function of the proposed sequence set is zero for the phase shifts within the zero-correlation zone. The present paper shows that such a construction generates a binary ZCZ sequence set by using a primitive linear recursion over GF(), the finite field of integers modulo .|Takafumi Hayashi","43089|IEICE Transations|2006|Binary Zero-Correlation Zone Sequence Set Constructed from an M-Sequence|The present paper introduces an improved construction of a class of binary sequences having a zero-correlation zone (hereafter binary ZCZ sequence set). The cross-correlation function and the side-lobe of the auto-correlation function of the proposed sequence set is zero for the phase shifts within the zero-correlation zone. The present paper shows that such a construction generates a binary ZCZ sequence set from an arbitrary M-sequence. The previously reported sequence construction of binary ZCZ sequence sets from an M-sequence can generate a single series of binary ZCZ sequence sets from an M-sequence. The present paper proposes an improved sequence construction that can generate more than one series of binary ZCZ sequence sets from an M-sequence.|Takafumi Hayashi"],["16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","16602|IJCAI|2007|Natural Language Query Recommendation in Conversation Systems|In this paper, we address a critical problem in conversation systems limited input interpretation capabilities. When an interpretation error occurs, users often get stuck and cannot recover due to a lack of guidance from the system. To solve this problem, we present a hybrid natural language query recommendation framework that combines natural language generation with query retrieval. When receiving a problematic user query, our system dynamically recommends valid queries that are most relevant to the current user request so that the user can revise his request accordingly. Compared with existing methods, our approach offers two main contributions first, improving query recommendation quality by combining query generation with query retrieval second, adapting generated recommendations dynamically so that they are syntactically and lexically consistent with the original user input. Our evaluation results demonstrate the effectiveness of this approach.|Shimei Pan,James Shaw","42400|IEICE Transations|2005|An Objective Method for Evaluating Speech Translation System Using a Second Language Learners Corpus|In this paper we propose an objective method for assessing the capability of a speech translation system. It automates the translation paired comparison method, which gives a simple, easy to understand TOEIC score proposed by Sugaya et al., to succinctly evaluate a speech translation system. To avoid the expensive evaluation cost of the original method where large manual effort is required, the new objective method automates the procedure by employing an objective metric such as BLEU and DP-based measure. The evaluation results obtained by the proposed method are similar to those of the original method. Also, the proposed method is used to evaluate the usefulness of a speech translation system. It is then found that our speech translation system is useful in general, even to users with higher TOEIC score than the system's.|Keiji Yasuda,Fumiaki Sugaya,Toshiyuki Takezawa,Gen-ichiro Kikui,Seiichi Yamamoto,Masuzo Yanagida","16582|IJCAI|2007|On Natural Language Processing and Plan Recognition|The research areas of plan recognition and natural language parsing share many common features and even algorithms. However, the dialog between these two disciplines has not been effective. Specifically, significant recent results in parsing mildly context sensitive grammars have not been leveraged in the state of the art plan recognition systems. This paper will outline the relations between natural language processing(NLP) and plan recognition(PR), argue that each of them can effectively inform the other, and then focus on key recent research results in NLP and argue for their applicability to PR.|Christopher W. Geib,Mark Steedman","80558|VLDB|2005|Using a Fuzzy Classification Query Language for Customer Relationship Management|A key challenge for companies is to manage customer relationships as an asset. To create an effective toolkit for the analysis of customer relationships, a combination of relational databases and fuzzy logic is proposed. The fuzzy Classification Query Language allows marketers to improve customer equity, launch loyalty programs, automate mass customization, and refine marketing campaigns.|Andreas Meier,Nicolas Werro,Martin Albrecht,Miltiadis Sarakinos","65871|AAAI|2006|Deeper Natural Language Processing for Evaluating Student Answers in Intelligent Tutoring Systems|This paper addresses the problem of evaluating students' answers in intelligent tutoring environments with mixed-initiative dialogue by modelling it as a textual entailment problem. The problem of meaning representation and inference is a pervasive challenge in any integrated intelligent system handling communication. For intelligent tutorial dialogue systems, we show that entailment cases can be detected at various dialog turns during a tutoring session. We report the performance of a lexico-syntactic approach on a set of entailment cases that were collected from a previous study we conducted with AutoTutor.|Vasile Rus,Arthur C. Graesser","65579|AAAI|2005|Natural Language Generation for Text-to-Text Applications Using an Information-Slim Representation|I propose a representation formalism and algorithms to be used in a new language generation mechanism for text-to-text applications. The generation process is driven by both text-specific information encoded via probability distributions over words and phrases derived from the input text, and general language knowledge captured by n-gram and syntactic language models.|Radu Soricut","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons","65530|AAAI|2005|Identifying Similar Words and Contexts in Natural Language with SenseClusters|SenseClusters is a freely available intelligent system that clusters together similar contexts in natural language text. Thereafter it assigns identifying labels to these clusters based on their content. It is a purely unsupervised approach that is language independent, and uses no knowledge other than what is available in raw un-annotated corpora. In addition to clustering similar contexts, it can be used to identify synonyms and sets of related words. It has been applied to a diverse range of problems, including proper name disambiguation, word sense discrimination, email organization, and document clustering. SenseClusters is a complete system that supports feature selection from large corpora, several different context representation schemes, various clustering algorithms, the creation of descriptive and discriminating labels for the discovered clusters, and evaluation relative to gold standard data.|Ted Pedersen,Anagha Kulkarni","65952|AAAI|2007|Enabling Domain-Awareness for a Generic Natural Language Interface|In this paper, we present a learning-based approach for enabling domain-awareness for a generic natural language interface. Our approach automatically acquires domain knowledge from user Interactions and Incorporates the knowledge learned to improve the generic system. We have embedded our approach in a generic natural language interface and evaluated the extended system against two benchmark datasets. We found that the performance of the original generic system can be substantially improved through automatic domain knowledge extraction and incorporation. We also show that the generic system with domain-awareness enabled by our approach can achieve performance similar to that of previous learning-based domain-specific systems.|Yunyao Li,Ishan Chaudhuri,Huahai Yang,Satinder Singh,H. V. Jagadish"],["43065|IEICE Transations|2006|Real-Time Human Object Extraction Method for Mobile Systems Based on Color Space Segmentation|Since a human object is an important element of the moving pictures being processed by mobile terminals, establishing a human object extraction method encourages dissemination of new applications. In accordance with the requirement of mobile applications, this paper proposes a low-cost human object extraction method, which consists of a face object and a hair object extraction based on their color information and a simple body extraction utilizing the position information of the face object. In the proposed method, skin color and hair color are estimated through color space segmentation, and a human object is effectively extracted by using a radial active contour model. Simulation results of the human object extraction with the use of XScale processor claims that QCIF  fps video sequences can be processed in real time.|Gen Fujita,Takaaki Imanaka,Hyunh Van Nhat,Takao Onoye,Isao Shirakawa","44325|IEICE Transations|2007|Object Tracking with Target and Background Samples|In this paper, we present a general object tracking method based on a newly proposed pixel-wise clustering algorithm. To track an object in a cluttered environment is a challenging issue because a target object may be in concave shape or have apertures (e.g. a hand or a comb). In those cases, it is difficult to separate the target from the background completely by simply modifying the shape of the search area. Our algorithm solves the problem by ) describing the target object by a set of pixels ) using a K-means based algorithm to detect all target pixels. To realize stable and reliable detection of target pixels, we firstly use a D feature vector to describe both the color (\"Y, U, V\") and the position (\"x, y\") of each pixel uniformly. This enables the simultaneous adaptation to both the color and geometric features during tracking. Secondly, we use a variable ellipse model to describe the shape of the search area and to model the surrounding background. This guarantees the stable object tracking under various geometric transformations. The robust tracking is realized by classifying the pixels within the search area into \"target\" and \"background\" groups with a K-means clustering based algorithm that uses the \"positive\" and \"negative\" samples. We also propose a method that can detect the tracking failure and recover from it during tracking by making use of both the \"positive\" and \"negative\" samples. This feature makes our method become a more reliable tracking algorithm because it can discover the target once again when the target has become lost. Through the extensive experiments under various environments and conditions, the effectiveness and efficiency of the proposed algorithm is confirmed.|Chunsheng Hua,Haiyuan Wu,Qian Chen,Toshikazu Wada","16487|IJCAI|2007|A New Approach for Stereo Matching in Autonomous Mobile Robot Applications|We propose a new approach for stereo matching in Autonomous Mobile Robot applications. In this framework an accurate but slow reconstruction of the D scene is not needed rather, it is more important to have a fast localization of the obstacles to avoid them. All the methods in the literature are based on a punctual correspondence, but they are inefficient in realistic contexts for the presence of uniform patterns, or some perturbations between the two images of the stereo pair. Our idea is to face the stereo matching problem as a matching between homologous regions, instead of a point matching. The stereo images are represented as graphs and a graph matching is computed to find homologous regions. We present some results on a standard stereo database and also on a more realistic stereo sequence acquired from a robot moving in an indoor environment, and a performance comparison with other approaches in the literature is reported and discussed. Our method is strongly robust in case of some fluctuations of the stereo pair, homogeneous and repetitive regions, and is fast. The result is a semi-dense disparity map, leaving only a few regions in the scene unmatched.|Pasquale Foggia,Jean-Michel Jolion,Alessandro Limongiello,Mario Vento","65779|AAAI|2006|Object-Sorting-by-Color in a Variety of Lighting Conditions Using Neural Networks and Lego Mindstorms Robot|Recognizing object color in a variety of lighting conditions is a challenging area of pattern-recognition. Neural networks have been found to be a good solution for that problem, and they are also quick and accurate, and can be used in real-time. We use a LEGO Mindstorms  robot to sort objects based on color in a variety of lighting conditions. We will start from simpler objects (LEGO pieces) and move onto more complex objects (apples, oranges, etc). This project is in progress and we hope to achieve classification accuracies of at least %.|Natasa Lazetic,Jianna Zhang","16581|IJCAI|2007|Using a Mobile Robot for Cognitive Mapping|When animals (including humans) first explore a new environment, what they remember is fragmentary knowledge about the places visited. Yet, they have to use such fragmentary knowledge to find their way home. Humans naturally use more powerful heuristics while lower animals have shown to develop a variety of methods that tend to utilize two key pieces of information, namely distance and orientation information. Their methods differ depending on how they sense their environment. Could a mobile robot be used to investigate the nature of such a process, commonly referred to in the psychological literature as cognitive mapping What might be computed in the initial explorations and how is the resulting \"cognitive map\" be used to return home In this paper, we presented a novel approach using a mobile robot to do cognitive mapping. Our robot computes a \"cognitive map\" and uses distance and orientation information to find its way home. The process developed provides interesting insights into the nature of cognitive mapping and encourages us to use a mobile robot to do cognitive mapping in the future, as opposed to its popular use in robot mapping.|Chee K. Wong,Jochen Schmidt,Wai K. Yeap","42679|IEICE Transations|2005|Anchor Frame Detection in News Video Using Anchor Object Extraction|In this paper, an algorithm for anchor frame detection in news video is proposed, which consists of four steps. First, the cumulative histogram method is used to detect shot boundaries in order to segment a news video into video shots. Second, skin color information is used to detect face regions in each video shot. Third, color information of upper body regions is used to extract anchor object. Then, a graph-theoretic cluster analysis algorithm is utilized to classify the news video into anchor-person shots and non-anchor shots. Experimental results have shown the effectiveness of the proposed algorithm.|Ki Tae Park,Doo Sun Hwang,Young Shik Moon","42319|IEICE Transations|2005|Edge-Based Morphological Processing for Efficient and Accurate Video Object Extraction|We consider the edge-linking approach for accurate locating of moving object boundaries in video segmentation. We review the existing methods and propose a scheme designed for efficiency and better accuracy. The scheme first obtains a very rough outline of an object by a suitable means, e.g., change detection. It then forms a relatively compact image region that properly contains the object, through a procedure termed \"mask sketch.\" Finally, the outermost edges in the region are found and linked via a shortest-path algorithm. Experiments show that the scheme yields good performance.|Yih-Haw Jan,David W. Lin","66122|AAAI|2007|Autonomous Development of a Grounded Object Ontology by a Learning Robot|We describe how a physical robot can learn about objects from its own autonomous experience in the continuous world. The robot identifies statistical regularities that allow it to represent a physical object with a cluster of sensations that violate a static world model, track that cluster over time, extract percepts from that cluster, form concepts from similar percepts, and learn reliable actions that can be applied to objects. We present a formalism for representing the ontology for objects and actions, a learning algorithm, and the results of an evaluation with a physical robot.|Joseph Modayil,Benjamin Kuipers","80488|VLDB|2005|On Map-Matching Vehicle Tracking Data|Vehicle tracking data is an essential \"raw\" material for a broad range of applications such as traffic management and control, routing, and navigation. An important issue with this data is its accuracy. The method of sampling vehicular movement using GPS is affected by two error sources and consequently produces inaccurate trajectory data. To become useful, the data has to be related to the underlying road network by means of map matching algorithms. We present three such algorithms that consider especially the trajectory nature of the data rather than simply the current position as in the typical map-matching case. An incremental algorithm is proposed that matches consecutive portions of the trajectory to the road network, effectively trading accuracy for speed of computation. In contrast, the two global algorithms compare the entire trajectory to candidate paths in the road network. The algorithms are evaluated in terms of (i) their running time and (ii) the quality of their matching result. Two novel quality measures utilizing the Fr&eacutechet distance are introduced and subsequently used in an experimental evaluation to assess the quality of matching real tracking data to a road network.|Sotiris Brakatsoulas,Dieter Pfoser,Randall Salas,Carola Wenk","42954|IEICE Transations|2005|Interactive Object Recognition System for a Helper Robot Using Photometric Invariance|We are developing a helper robot that carries out tasks ordered by the user through speech. The robot needs a vision system to recognize the objects appearing in the orders. It is, however, difficult to realize vision systems that can work in various conditions. Thus, we have proposed to use the human user's assistance through speech. When the vision system cannot achieve a task, the robot makes a speech to the user so that the natural response by the user can give helpful information for its vision system. Our previous system assumes that it can segment images without failure. However, if there are occluded objects andor objects composed of multicolor parts, segmentation failures cannot be avoided. This paper presents an extended system that tries to recover from segmentation failures using photometric invariance. If the system is not sure about segmentation results, the system asks the user by appropriate expressions depending on the invariant values. Experimental results show the usefulness of the system.|Md. Altab Hossain,Rahmadi Kurnia,Akio Nakamura,Yoshinori Kuno"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","57683|GECCO|2006|Search--based approaches to the component selection and prioritization problem|This poster paper addresses the problem of choosing sets of software components to combine in component--based software engineering. It formulates both ranking and selection problems as feature subset selection problems to which search based software engineering can be applied. We will consider selection and ranking of elements from a set of software components from the component base of a large telecommunications organisation.|Mark Harman,Alexandros Skaliotis,Kathleen Steinh√∂fel,Paul Baker","43062|IEICE Transations|2006|Time Complexity Analysis of the Legal Firing Sequence Problem of Petri Nets with Inhibitor Arcs|Petri nets with inhibitor arcs are referred to as inhibitor-arc Petri nets. It is shown that modeling capability of inhibitor-arc Petri nets is equivalent to that of Turing machines. The subject of this paper is the legal firing sequence problem (INLFS) for inhibitor-arc Petri nets given an inhibitor-arc Petri net IN, an initial marking M and a firing count vector X, find a firing sequence  such that its firing starts from M and each transition t appears in  exactly X(t) times as prescribed by X. The paper is the first step of research for time complexity analysis and designing algorithms of INLFS, one of the most fundamental problems for inhibitor-arc Petri nets having more modeling capability than ordinary Peri nets. The recognition version of INLFS, denoted as RINLFS, means a decision problem, asking a \"yes\" or \"no\" answer on the existence of a solution  to INLFS. The main results are the following () and (). () Proving (-) and (-) when the underlying Petri net of IN is an unweighted state machine (-) INLFS can be solved in pseudo-polynomial (O(X)) time for IN of non-adjacent type having only one special place called a rivet (-) RINLFS is NP-hard for IN with at least three rivets () Proving that RINLFS for IN whose underlying Petri net is unweighted and forward conflict-free is NP-hard. Heuristic algorithms for solving INLFS are going to be proposed in separate papers.|Satoshi Taoka,Toshimasa Watanabe","57584|GECCO|2005|MRI magnet design search space analysis EDAs and a real-world problem with significant dependencies|This paper introduces the design of superconductive magnet configurations in Magnetic Resonance Imaging (MRI) systems as a challenging real-world problem for Evolutionary Algorithms (EAs). Analysis of the problem structure is conducted using a general statistical method, which could be easily applied to other problems. The results suggest that the problem is highly multimodal and likely to present a significant challenge for many algorithms. Through a series of preliminary experiments, a continuous Estimation of Distribution Algorithm (EDA) is shown to be able to generate promising designs with a small computational effort. The importance of utilizing problem-specific knowledge and the ability of an algorithm to capture dependencies in solving complex real-world problems is also highlighted.|Bo Yuan,Marcus Gallagher,Stuart Crozier","16089|IJCAI|2005|Phase Transitions of Dominating Clique Problem and Their Implications to Heuristics in Satisfiability Search|We study a monotone NP decision problem, the dominating clique problem, whose phase transition occurs at a very dense stage of the random graph evolution process. We establish the exact threshold of the phase transition and propose an efficient search algorithm that runs in super-polynomial time with high probability. Our empirical studies reveal two even more intriguing phenomena in its typical-case complexity () the problem is \"uniformly hard\" with a tiny runtime variance on negative instances. () Our algorithm and its CNF-tailored implementation, outperform several SAT solvers by a huge margin on dominating cliques and some other SAT problems with similar structures.|Joseph C. Culberson,Yong Gao,Calin Anton","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","58236|GECCO|2007|Analyzing the effects of module encapsulation on search space bias|Modularity is thought to improve the evolvability of biological systems , . Recent studies in the field of evolutionary computation show that the use of modularity improves performance and scalability of evolutionary algorithms for certain applications. , , , , . The effects of introducing modularity to evolutionary search, however, are not well understood. This paper focuses on analyzing the effects of modularity on evolutionary computation. In particular, we analyze the effects of modular representations on the search space bias.|Ozlem O. Garibay,Annie S. Wu","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16777|IJCAI|2007|Recent Progress in Heuristic Search A Case Study of the Four-Peg Towers of Hanoi Problem|We integrate a number of new and recent advances in heuristic search, and apply them to the fourpeg Towers of Hanoi problem. These include frontier search, disk-based search, parallel processing, multiple, compressed, disjoint, and additive pattern database heuristics, and breadth-first heuristic search. New ideas include pattern database heuristics based on multiple goal states, a method to reduce coordination among multiple parallel threads, and a method for reducing the number of heuristic calculations. We perform the first complete breadth-first searches of the  and -disc fourpeg Towers of Hanoi problems, and extend the verification of \"presumed optimal solutions\" to this problem from  to  discs. Verification of the -disc problem is in progress.|Richard E. Korf,Ariel Felner","57438|GECCO|2005|The enhanced evolutionary tabu search and its application to the quadratic assignment problem|We describe the Enhanced Evolutionary Tabu Search (EE-TS) local search technique. The EE-TS metaheuristic technique combines Reactive Tabu Search with evolutionary computing elements proven to work well in multimodal search spaces. An initial set of solutions is generated using a stochastic heuristic operator based on Restricted Candidate List. Reactive Tabu Search is augmented with selection and recombination operators that preserve common traits between solutions while maintaining a diverse set of good solutions. EE-TS performance is applied to the Quadratic Assignment Problem using problem instances from the QAPLIB. The results show that EE-TS compares favorably against other known techniques. In most cases, EE-TS was able to find the known optimal solutions in fewer iterations. We conclude by describing the main benefits and limitations of EE-TS.|John F. McLoughlin III,Walter Cede√±o"],["57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","58008|GECCO|2007|Multi-objective particle swarm optimization on computer grids|In recent years, a number of authors have successfully extended particle swarmoptimization to problem domains with multiple objec-tives. This paper addresses theissue of parallelizing multi-objec-tive particle swarms. We propose and empirically comparetwo parallel versions which differ in the way they divide the swarminto subswarms that can be processed independently on differentprocessors. One of the variants works asynchronouslyand is thus particularly suitable for heterogeneous computer clusters asoccurring e.g. in moderngrid computing platforms.|Sanaz Mostaghim,J√ºrgen Branke,Hartmut Schmeck","58025|GECCO|2007|A heuristic particle swarm optimization|A heuristic version of the particle swarm optimization (PSO) is introduced in this paper. In this new method called \"The heuristic particle swarm optimization(HPSO)\", we use heuristics to choose the next particle to update its velocity and position. By using heuristics , the convergence rate to local minimum is faster. To avoid premature convergence of the swarm, the particles are re-initialized with random velocity when moving too close to the global best position. The combination of heuristics and re-initialization mechanism make HPSO outperform the basic PSO and recent versions of PSO.|Hoang Thanh Lam,Popova Nina Nicolaevna,Nguyen Thoi Minh Quan","58085|GECCO|2007|MRPSO MapReduce particle swarm optimization|In optimization problems involving large amounts of data, Particle Swarm Optimization (PSO) must be parallelized because individual function evaluations may take minutes or even hours. However, large-scale parallelization is difficult because programs must communicate efficiently, balance workloads and tolerate node failures. To address these issues, we present Map Reduce Particle Swarm Optimization(MRPSO), a PSO implementation based on Google's Map Reduce parallel programming model.|Andrew W. McNabb,Christopher K. Monson,Kevin D. Seppi","58032|GECCO|2007|Applying particle swarm optimization to software testing|Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with  small artificial test objects and  more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.|Andreas Windisch,Stefan Wappler,Joachim Wegener","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","58150|GECCO|2007|Geometric particle swarm optimization for the sudoku puzzle|Geometric particle swarm optimization (GPSO) is a recentlyintroduced generalization of traditional particle swarm optimization(PSO) that applies to all combinatorial spaces. The aim of thispaper is to demonstrate the applicability of GPSO to non-trivialcombinatorial spaces. The Sudoku puzzle is a perfect candidate totest new algorithmic ideas because it is entertaining andinstructive as well as a non-trivial constrained combinatorialproblem. We apply GPSO to solve the sudoku puzzle.|Alberto Moraglio,Julian Togelius","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty"]]}}