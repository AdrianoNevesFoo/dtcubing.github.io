{"abstract":{"entropy":6.379369925804556,"topics":["machine learning, learning classifier, planning domains, solving problem, bayesian networks, reinforcement learning, learning, support machine, present learning, address problem, markov model, probabilistic model, temporal planning, probabilistic planning, planning, classification used, learning approach, algorithms planning, learning temporal, learning networks","genetic algorithms, evolutionary algorithms, algorithms, particle swarm, optimization problem, present algorithms, evolutionary optimization, optimization, fitness function, particle pso, algorithms optimization, evolutionary problem, algorithms problem, present approach, swarm pso, negative selection, estimation distribution, differential evolution, evolutionary computation, algorithms search","based reasoning, learning systems, classifier systems, natural language, combinatorial auctions, supervised learning, systems, reasoning research, xcs systems, systems increasingly, systems based, research, systems tasks, need systems, given, important, information, knowledge, current, context","genetic programming, genetic algorithms, neural networks, systems complex, form genetic, search space, genetic evolve, control robots, genetic code, algorithms distributed, agents, systems model, model genetic, search techniques, robots, genetic control, systems agents, networks, algorithms networks, genetic networks","temporal planning, planning, due, gene, important, structure, consider, shown, significant, planners, solutions, challenging, activity, useful, extension, problem","solving problem, constraints problem, domains, recent, work, decision, constraints, satisfiability, graph, linear, large, sat, finding, representation, value, state, general, concept, combines, algorithms","evolutionary problem, performance algorithms, application optimization, approach evolutionary, algorithms solve, application algorithms, algorithms problem, approach problem, application evolutionary, application generation, solve problem, proposes algorithms, multi-objective problem, problem different, optimization problem, application, problem, well, different, known","present algorithms, selection algorithms, evolution optimization, present approach, estimation algorithms, algorithms based, estimation distribution, selection genetic, negative selection, differential evolution, present novel, distribution algorithms, algorithms mechanism, present, present model, present genetic, novel approach, present based, feature selection, novel selection","based reasoning, natural language, systems based, knowledge, current, context, complexity, sense, supervised, challenges, applying, common, processing","information, combinatorial auctions, game, sentences, negotiation, landscape, automated, sensor","control robots, genetic control, algorithms search, search space, search techniques, search, design, techniques, control, developed, programs, study, improve, interactive, constraints, measure, user","neural networks, networks, model, present, artificial, use, immune, novel, detect, time, generic, learn, mobile, systems, algorithms"],"ranking":[["65556|AAAI|2005|Semantic Place Classification of Indoor Environments with Mobile Robots Using Boosting|Indoor environments can typically be divided into places with different functionalities like kitchens, offices, or seminar rooms. We believe that such semantic information enables a mobile robot to more efficiently accomplish a variety of tasks such as human-robot interaction, path-planning, or localization. This paper presents a supervised learning approach to label different locations using boosting. We train a classifier using features extracted from vision and laser range data. Furthermore, we apply a Hidden Markov Model to increase the robustness of the final classification. Our technique has been implemented and tested on real robots as well as in simulation. The experiments demonstrate that our approach can be utilized to robustly classify places into semantic categories. We also present an example of localization using semantic labeling.|Axel Rottmann,√\u201Cscar Mart√≠nez Mozos,Cyrill Stachniss,Wolfram Burgard","57363|GECCO|2005|Co-evolving recurrent neurons learn deep memory POMDPs|Recurrent neural networks are theoretically capable of learning complex temporal sequences, but training them through gradient-descent is too slow and unstable for practical use in reinforcement learning environments. Neuroevolution, the evolution of artificial neural networks using genetic algorithms, can potentially solve real-world reinforcement learning tasks that require deep use of memory, i.e. memory spanning hundreds or thousands of inputs, by searching the space of recurrent neural networks directly. In this paper, we introduce a new neuroevolution algorithm called Hierarchical Enforced SubPopulations that simultaneously evolves networks at two levels of granularity full networks and network components or neurons. We demonstrate the method in two POMDP tasks that involve temporal dependencies of up to thousands of time-steps, and show that it is faster and simpler than the current best conventional reinforcement learning system on these tasks.|Faustino J. Gomez,J√ºrgen Schmidhuber","65576|AAAI|2005|Discriminative Training of Markov Logic Networks|Many machine learning applications require a combination of probability and first-order logic. Markov logic networks (MLNs) accomplish this by attaching weights to first-order clauses, and viewing these as templates for features of Markov networks. Model parameters (i.e., clause weights) can be learned by maximizing the likelihood of a relational database, but this can be quite costly and lead to suboptimal results for any given prediction task. In this paper we propose a discriminative approach to training MLNs, one which optimizes the conditional likelihood of the query predicates given the evidence ones, rather than the joint likelihood of all predicates. We extend Collins's () voted perceptron algorithm for HMMs to MLNs by replacing the Viterbi algorithm with a weighted satisfiability solver. Experiments on entity resolution and link prediction tasks show the advantages of this approach compared to generative MLN training, as well as compared to purely probabilistic and purely logical approaches.|Parag Singla,Pedro Domingos","65608|AAAI|2005|Learning Planning Rules in Noisy Stochastic Worlds|We present an algorithm for learning a model of the effects of actions in noisy stochastic worlds. We consider learning in a D simulated blocks world with realistic physics. To model this world, we develop a planning representation with explicit mechanisms for expressing object reference and noise. We then present a learning algorithm that can create rules while also learning derived predicates, and evaluate this algorithm in the blocks world simulator, demonstrating that we can learn rules that effectively model the world dynamics.|Luke S. Zettlemoyer,Hanna Pasula,Leslie Pack Kaelbling","65613|AAAI|2005|Learning Measures of Progress for Planning Domains|We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress (parmar ), which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results.|Sung Wook Yoon,Alan Fern,Robert Givan","65482|AAAI|2005|Prottle A Probabilistic Temporal Planner|Planning with concurrent durative actions and probabilistic effects, or probabilistic temporal planning, is a relatively new area of research. The challenge is to replicate the success of modern temporal and probabilistic planners with domains that exhibit an interaction between time and uncertainty. We present a general framework for probabilistic temporal planning in which effects, the time at which they occur, and action durations are all probabilistic. This framework includes a search space that is designed for solving probabilistic temporal planning problems via heuristic search, an algorithm that has been tailored to work with it and an effective heuristic based on an extension of the planning graph data structure. Prottle is a planner that implements this framework, and can solve problems expressed in an extension of PDDL.|Iain Little,Douglas Aberdeen,Sylvie Thi√©baux","65586|AAAI|2005|Partial Pathfinding Using Map Abstraction and Refinement|Classical search algorithms such as A* or IDA* are useful for computing optimal solutions in a single pass, which can then be executed. But in many domains agents either do not have the time to compute complete plans before acting, or should not spend the time to do so, due to the dynamic nature of the environment. Extensions to A* such as LRTA* address this problem by gradually learning an exact heuristic function, but the learning process is quite slow. In this paper we introduce Partial-Refinement A* (PRA*), which can fully interleave planning and acting through path abstraction and refinement. We demonstrate the etfectiveness of PRA* in the domain of real-time strategy (RTS) games. In maps taken from popular RTS games. we show that PRA* is not only able to cleanly interleave planning and execution. but it is also able to do so with only minimal losses of optimality.|Nathan R. Sturtevant,Michael Buro","65600|AAAI|2005|Improving Reinforcement Learning Function Approximators via Neuroevolution|Reinforcement learning problems are commonly tackled with temporal difference methods, which use dynamic programming and statistical sampling to estimate the long-term value of taking each action in each state. In most problems of real-world interest, learning this value function requires a function approximator. which represents the mapping from stateaction pairs to values via a concise, parameterized function and uses supervised learning methods to set its parameters. Function approximators make it possible to use temporal difference methods on large problems but, in practice, the feasibility of doing so depends on the ability of the human designer to select an appropriate representation for the value function. My thesis presents a new approach to function approximation that automates some of these difficult design choices by coupling temporal difference methods with policy search methods such as evolutionary computation. It also presents a particular implementation which combines NEAT, a neuroevolutionary policy search method, and Q-learning, a popular temporal difference method, to yield a new method called NEAT+Q that automatically learns effective representations for neural network function approximators. Empirical results in a server job scheduling task demonstrate that NEAT+Q can outperform both NEAT and Q-learning with manually designed neural networks.|Shimon Whiteson","65437|AAAI|2005|Transforming between Propositions and Features Bridging the Gap|It is notoriously difficult to simultaneously deal with both probabilistic and structural representations in A.I., particularly because probability necessitates a uniform representation of the training examples. In this paper, we show how to build fully-specified probabilistic models from arbitrary propositional case descriptions about terrorist activities. Our method facilitates both reasoning and learning. Our solution is to use structural analogy to build probabilistic generalizations about those cases. We use these generalizations as a framework for mapping the structural representations, which are well-suited for reasoning, into features, which are well-suited for learning, and back again. Finally, we demonstrate how probabilistic generalizations are an excellent bridge for joining reasoning and learning by using them to perform a traditional machine learning technique, Bayesian network modeling, over arbitrarily high order structural data about terrorist actions, and further, we discuss how this might be used to facilitate automatic knowledge acquisition.|Daniel T. Halstead,Kenneth D. Forbus","65490|AAAI|2005|Distribution-Free Learning of Bayesian Network Structure in Continuous Domains|In this paper we present a method for learning the structure of Bayesian networks (BNs) without making any assumptions on the probability distribution of the domain. This is mainly useful for continuous domains, where there is little guidance and many choices for the parametric distribution families to be used for the local conditional probabilities of the Bayesian network, and only a few have been examined analytically. We therefore focus on BN structure learning in continuous domains. We address the problem by developing a conditional independence test for continuous variables, which can be readily used by any existing independence-based BN structure learning algorithm. Our test is non-parametric, making no assumptions on the distribution of the domain. We also provide an effective and computationally efficient method for calculating it from data. We demonstrate the learning of the structure of graphical models in continuous domains from real-world data, to our knowledge for the first time using independence-based methods and without distributional assumptions. We also experimentally show that our test compares favorably with existing statistical approaches which use prediscretization, and verify desirable properties such as statistical consistency.|Dimitris Margaritis"],["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57461|GECCO|2005|Minimum spanning trees made easier via multi-objective optimization|Many real-world problems are multi-objective optimization problems and evolutionary algorithms are quite successful on such problems. Since the task is to compute or approximate the Pareto front, multi-objective optimization problems are considered as more difficult than single-objective problems. One should not forget that the fitness vector with respect to more than one objective contains more information that in principle can direct the search of evolutionary algorithms. Therefore, it is possible that a single-objective problem can be solved more efficiently via a generalized multi-objective model of the problem. That this is indeed the case is proved by investigating the computation of minimum spanning trees.|Frank Neumann,Ingo Wegener","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["65537|AAAI|2005|Word Sense Disambiguation with Semi-Supervised Learning|Current word sense disambiguation (WSD) systems based on supervised learning are still limited in that they do not work well for all words in a language. One of the main reasons is the lack of sufficient training data. In this paper, we investigate the use of unlabeled training data for WSD, in the framework of semi-supervised learning. Four semisupervised leaming algorithms are evaluated on  nouns of Senseval- (SE) English lexical sample task and SE English all-words task. Empirical results show that unlabeled data can bring significant improvement in WSD accuracy.|Thanh Phong Pham,Hwee Tou Ng,Wee Sun Lee","57305|GECCO|2005|Extracted global structure makes local building block processing effective in XCS|Michigan-style learning classifier systems (LCSs), such as the accuracy-based XCS system, evolve distributed problem solutions represented by a population of rules. Recently, it was shown that decomposable problems may require effective processing of subsets of problem attributes, which cannot be generally assured with standard crossover operators. A number of competent crossover operators capable of effective identification and processing of arbitrary subsets of variables or string positions were proposed for genetic and evolutionary algorithms. This paper effectively introduces two competent crossover operators to XCS by incorporating techniques from competent genetic algorithms (GAs) the extended compact GA (ECGA) and the Bayesian optimization algorithm (BOA). Instead of applying standard crossover operators, here a probabilistic model of the global population is built and sampled to generate offspring classifiers locally. Various offspring generation methods are introduced and evaluated. Results indicate that the performance of the proposed learning classifier systems XCSECGA and XCSBOA is similar to that of XCS with informed crossover operators that is given all information about problem structure on input and exploits this knowledge using problem-specific crossover operators.|Martin V. Butz,Martin Pelikan,Xavier Llor√†,David E. Goldberg","65469|AAAI|2005|Description Logic-Ground Knowledge Integration and Management|This abstract describes ongoing work in developing large-scale knowledge repositories. The project addresses three primary aspects of such systems integration of knowledge sources access and retrieval of stored knowledge scalable, effective repositories. Previous results have shown the effectiveness of description logic-based representations in integrating knowledge sources and the role of non-standard inferences in supporting repository reasoning tasks. Current efforts include developing general-purpose mechanisms for adapting reasoning algorithms for optimized inference under known domain structure and effective use of database technology as a large-scale knowledge base backend.|Joseph Kopena","57312|GECCO|2005|Autonomous navigation system applied to collective robotics with ant-inspired communication|Research in collective robotics is motivated mainly by the possibility of achieving an efficient solution to multi-objective navigation tasks when multiple robots are employed, instead of a single robot. Several approaches have already been tried in multi-robot systems, but the bio-inspired ones are the most frequent. This paper proposes to augment an autonomous navigation system based on learning classifier systems for using in collective robotics, introducing an inter-robot communication mechanism inspired by ant stigmergy, with each robot acting independently and cooperatively. The navigation system has no innate basic behavior and all knowledge necessary to compose the decision-making artifact is evolved as a function of the environmental feedback only, during navigation. Repulsive andor attractive pheromone trails are produced by the robots along navigation, following very simple rules. Basically, each robot has to perform obstacle avoidance and target search, and the status of the pheromone level at the position currently occupied by each robot will influence the coordination of the two fundamental behaviors. Experiments are performed in simulation, with comparative results indicating that the presence of the pheromone trails is responsible for significant improvements in the capture rate and in the length of the route adopted by each robot.|Renato Reder Cazangi,Fernando J. Von Zuben,Maur√≠cio F. Figueiredo","65520|AAAI|2005|Interactive Knowledge Validation and Query Refinement in CBR|In most case-based reasoning (CBR) systems there has been little research done on validating new knowledge, specifically on how previous knowledge differs from current knowledge as a result of conceptual change. This paper proposes two methods that enable the domain expert, who is nonexpert in artificial intelligence (AI), to interactively supervise the knowledge validation process in a CBR system, and to enable dynamic updating of the system, to provide the best diagnostic questions. The first method is based on formal concept analysis which involves a graphical representation and comparison of the concepts, and a summary description highlighting the conceptual differences. We propose a dissimilarity metric for measuring the degree of variation between the previous and current concepts when a new case is added to the knowledge base. The second method involves determining unexpected classification-based association rules to form critical questions as the knowledge base gets updated.|Monica H. Ou,Geoff A. W. West,Mihai Lazarescu,Chris Clay","57445|GECCO|2005|A first order logic classifier system|Motivated by the intention to increase the expressive power of learning classifier systems, we developed a new Xcs derivative, Fox-cs, where the classifier and observation languages are a subset of first order logic. We found that Fox-cs was viable at tasks in two relational task domains, poker and blocks world, which cannot be represented easily using traditional bit-string classifiers and inputs. We also found that for these tasks, the level of generality obtained by Fox-cs in the portion of population that produces optimal behaviour is consistent with Wilson's generality hypothesis.|Drew Mellor","65604|AAAI|2005|Software Testing by Active Learning for Commercial Games|As software systems have become larger, exhaustive testing has become increasingly onerous. This has rendered statistical software testing and machine learning techniques increasingly attractive. Drawing from both of these, we present an active learning framework for blackbox software testing. The active learning approach samples inputoutput pairs from a blackbox and learns a model of the system's behaviour. This model is then used to select new inputs for sampling. This framework has been developed in the context of commercial video games, complex virtual worlds with high-dimensional state spaces, too large for exhaustive testing. Beyond its correctness, developers need to evaluate the gameplay of a game, properties such as difficulty. We use the learned model not only to guide sampling but also to summarize the game's behaviour for the developer to evaluate. We present results from our semi-automated gameplay analysis by machine learning (SAGA-ML) tool applied to Electronics Arts' FIFA Soccer game.|Gang Xiao,Finnegan Southey,Robert C. Holte,Dana F. Wilkinson","57553|GECCO|2005|Hyper-heuristics and classifier systems for solving D-regular cutting stock problems|This paper presents a method for combining concepts of Hyper-heuristics and Learning Classifier Systems for solving D Cutting Stock Problems. The idea behind Hyper-heuristics is to discover some combination of straightforward heuristics to solve a wide range of problems. To be worthwhile, such combination should outperform the single heuristics. In this paper, the Hyper-heuristic is formed using a XCS-type Learning Classifier System which learns a solution procedure when solving individual problems. The XCS evolves a behavior model which determines the possible actions (selection and placement heuristics) for given states of the problem. When tested with a collection of different problems, the method finds very competitive results for most of the cases. The testebed is composed of problems used in other similar studies in the literature. Some additional instances of the testbed were randomly generated.|Hugo Terashima-Mar√≠n,E. J. Flores-√?lvarez,Peter Ross","65517|AAAI|2005|Recommender Systems Attack Types and Strategies|In the research to date, the performance of recommender systems has been extensively evaluated across various dimensions. Increasingly, the issue of robustness against malicious attack is receiving attention from the research community. In previous work, we have shown that knowledge of certain domain statistics is sufficient to allow successful attacks to be mounted against recommender systems. In this paper, we examine the extent of domain knowledge that is actually required and find that, even when little such knowledge is known, it remains possible to mount successful attacks.|Michael P. O'Mahony,Neil J. Hurley,Guenole C. M. Silvestre","65399|AAAI|2005|Cross-Modal Clustering|This paper presents a self-supervised algorithm for learning perceptual structures based upon correlations in different sensory modalities. The brain and cognitive sciences have gathered an enormous body of neurological and phenomenological evidence in the past half century that demonstrates the extraordinary degree of interaction between sensory modalities during the course of ordinary perception. This paper presents a new framework for creating artificial perceptual systems inspired by these findings, where the primary architectural motif is the cross-modal transmission of perceptual information to enhance each sensory channel individually. The basic hypothesis underlying this approach is that the world has regularities - natural laws tend to correlate physical properties - and biological perceptory systems have evolved to take advantage of this. They share information continually and opportunistically across seemingly disparate perceptual channels, not epiphenomenologically, but rather as a fundamental component of normal perception. It is therefore essential that their artificial counterparts be able to share information synergistically within their perceptual channels, if they are to approach degrees of biological sophistication. This paper is a preliminary step in that direction.|Michael H. Coen"],["57470|GECCO|2005|Evolution of multi-loop controllers for fixed morphology with a cyclic genetic algorithm|Cyclic genetic algorithms can be used to generate single loop control programs for robots. While successful in generating controllers for individual leg movement, gait generation, and area search path finding, cyclic genetic algorithms have had limited use when dealing with control problems that require different behaviors in response to sensor inputs. For such behaviors, there is a need for modifications that will allow the generation of multi-loop control programs, which can properly react to sensor input. In this work, we present modifications to the standard cyclic genetic algorithm that enables it to learn multi-loop control programs with branching that allows the control to jump from one loop to another. Preliminary tests show the success of our modification.|Gary B. Parker,Ramona Georgescu","57268|GECCO|2005|Efficient credit assignment through evaluation function decomposition|Evolutionary methods are powerful tools in discovering solutions for difficult continuous tasks. When such a solution is encoded over multiple genes, a genetic algorithm faces the difficult credit assignment problem of evaluating how a single gene in a chromosome contributes to the full solution. Typically a single evaluation function is used for the entire chromosome, implicitly giving each gene in the chromosome the same evaluation. This method is inefficient because a gene will get credit for the contribution of all the other genes as well. Accurately measuring the fitness of individual genes in such a large search space requires many trials. This paper instead proposes turning this single complex search problem into a multi-agent search problem, where each agent has the simpler task of discovering a suitable gene. Gene-specific evaluation functions can then be created that have better theoretical properties than a single evaluation function over all genes. This method is tested in the difficult double-pole balancing problem, showing that agents using gene-specific evaluation functions can create a successful control policy in % fewer trials than the best existing genetic algorithms. The method is extended to more distributed problems, achieving % performance gains over tradition methods in the multi-rover domain.|Adrian K. Agogino,Kagan Tumer,Risto Miikkulainen","57535|GECCO|2005|The Push execution stack and the evolution of control|The Push programming language was developed for use in genetic and evolutionary computation systems, as the representation within which evolving programs are expressed. It has been used in the production of several significant results, including results that were awarded a gold medal in the Human Competitive Results competition at GECCO-. One of Push's attractive features in this context is its transparent support for the expression and evolution of modular architectures and complex control structures, achieved through explicit code self-manipulation. The latest version of Push, Push, enhances this feature by permitting explicit manipulation of an execution stack that contains the expressions that are queued for execution in the interpreter. This paper provides a brief introduction to Push and to execution stack manipulation in Push. It then presents a series of examples in which Push was used with a simple genetic programming system (PushGP) to evolve programs with non-trivial control structures.|Lee Spector,Jon Klein,Maarten Keijzer","57363|GECCO|2005|Co-evolving recurrent neurons learn deep memory POMDPs|Recurrent neural networks are theoretically capable of learning complex temporal sequences, but training them through gradient-descent is too slow and unstable for practical use in reinforcement learning environments. Neuroevolution, the evolution of artificial neural networks using genetic algorithms, can potentially solve real-world reinforcement learning tasks that require deep use of memory, i.e. memory spanning hundreds or thousands of inputs, by searching the space of recurrent neural networks directly. In this paper, we introduce a new neuroevolution algorithm called Hierarchical Enforced SubPopulations that simultaneously evolves networks at two levels of granularity full networks and network components or neurons. We demonstrate the method in two POMDP tasks that involve temporal dependencies of up to thousands of time-steps, and show that it is faster and simpler than the current best conventional reinforcement learning system on these tasks.|Faustino J. Gomez,J√ºrgen Schmidhuber","57454|GECCO|2005|Optimizing parameters of a mobile ad hoc network protocol with a genetic algorithm|Mobile ad hoc networks are typically designed and evaluated in generic simulation environments. However the real conditions in which these networks are deployed can be quite different in terms of RF attentution, topology, and traffic load. Furthermore, specific situations often have a need for a network that is optimized along certain characteristics such as delay, energy or overhead. In response to the variety of conditions and requirements, ad hoc networking protocols are often designed with many modifiable parameters. However, there is currently no methodical way for choosing values for the parameters other than intuition and broad experience. In this paper we investigate the use of genetic algorithms for automated selection of parameters in an ad hoc networking system. We provide experimental results demonstrating that the genetic algorithm can optimize for different classes of operating conditions. We also compare our genetic algorithm optimization against hand-tuning in a complex, realistic scenario and show how the genetic algorithm provides better performance.|David J. Montana,Jason Redi","57385|GECCO|2005|Open-ended robust design of analog filters using genetic programming|Most existing research on robust design using evolutionary algorithms (EA) follows the paradigm of traditional robust design, in which parameters of a design solution are tuned to improve the robustness of the system. However, the topological structure of a system may set a limit on the possible robustness achievable through parameter tuning. This paper proposes a new robust design paradigm that exploits the open-ended topological synthesis capability of genetic programming to evolve more robust systems. As a case study, a methodology for automated synthesis of dynamic systems, based on genetic programming and bond graph modeling (GPBG), is applied to evolve robust low-pass and high-pass analog filters. Compared with a traditional robust design approach based on a state-of-the-art real-parameter genetic algorithm (GA), it is shown that open-ended topology search by genetic programming with a fitness criterion rewarding robustness can evolve more robust systems with respect to parameter perturbations than what was achieved through parameter tuning alone, for our test problems.|Jianjun Hu,Xiwei Zhong,Erik D. Goodman","57451|GECCO|2005|Evolutionary models for maternal effects in simulated developmental systems|Maternal influence on offspring goes beyond strict nuclear (DNA) inheritance inherited maternal mRNA, mitochondria, caring and nurturing are all additional sources that affect offspring development, and they can be also shaped by evolution. These additional factors are called maternal effects, and their important role in evolution is well established experimentally. This paper presents two models for maternal effects, based on a genetic algorithm and simulated development of neural networks. We extended a model by Eggenberger by adding two mechanisms for maternal effects the first mechanism attempts to replicate maternal cytoplasmic control, while the second mechanism replicates interactions between the fetus and the uterine environment. For examining the role of maternal effects in artificial evolution, we evolved networks for the odd--parity problem, using increasing rates of maternal influence. Experiments have shown that maternal effects increase adaptiveness in the latter model.|Artur Matos,Reiji Suzuki,Takaya Arita","57427|GECCO|2005|Nonlinear feature extraction using a neuro genetic hybrid|Feature extraction is a process that extracts salient features from observed variables. It is considered a promising alternative to overcome the problems of weight and structure optimization in artificial neural networks. There were many nonlinear feature extraction methods using neural networks but they still have the same difficulties arisen from the fixed network topology. In this paper, we propose a novel combination of genetic algorithm and feedforward neural networks for nonlinear feature extraction. The genetic algorithm evolves the feature space by utilizing characteristics of hidden neurons. It improved remarkably the performance of neural networks on a number of real world regression and classification problems.|Yung-Keun Kwon,Byung Ro Moon","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57437|GECCO|2005|Learning computer programs with the bayesian optimization algorithm|We describe an extension of the Bayesian Optimization Algorithm (BOA), a probabilistic model building genetic algorithm, to the domain of program tree evolution. The new system, BOA programming (BOAP), improves significantly on previous probabilistic model building genetic programming (PMBGP) systems in terms of the articulacy and open-ended flexibility of the models learned, and hence control over the distribution of instances generated. Innovations include a novel tree representation and a generalized program evaluation scheme.|Moshe Looks,Ben Goertzel,Cassio Pennachin"],["65408|AAAI|2005|State Agnostic Planning Graphs and the Application to Belief-Space Planning|Planning graphs have been shown to be a rich source of heuristic information for many kinds of planners. In many cases, planners must compute a planning graph for each element of a set of states. The naive technique enumerates the graphs individually. This is equivalent to solving an all-pairs shortest path problem by iterating a single-source algorithm over each source. We introduce a structure, the state agnostic planning graph, that directly, solves the all-pairs problem for the relaxation introduced by planning graphs. The technique can also be characterized as exploiting the overlap present in sets of planning graphs. For the purpose of exposition, we first present the technique in classical planning. The more prominent application of tnis technique is in belief-space planning, where an optimization results in drastically improved theoretical complexity. Our experimental evaluation quantifies this performance boost. and demonstrates that heuristic belief-space progression planning using our technique is competitive with the state of t the art.|William Cushing,Daniel Bryce","65426|AAAI|2005|Validating Plans in the Context of Processes and Exogenous Events|Complex planning domains push the boundaries of the expressive power of planning domain modelling languages. Recent extensions to the standard planning languages have included expressions for temporal, metric and resource structures. Other work has also considered how process models can be incorporated into domain models. In this paper we consider the problem of expressing and validating models containing events which are triggered as a consequence of the action of physical processes. We focus, primarily, on the validation of plans in the context of exogenous events, discussing the modelling, semantic and implementation issues that arise. Events impact not only on plans but on domain models as a whole and we also consider the problems that arise in considering the validation of event structures in domain models.|Maria Fox,Richard Howey,Derek Long","65614|AAAI|2005|Exploiting the Structure of Hierarchical Plans in Temporal Constraint Propagation|Quantitative temporal constraints are an essential requirement for many planning domains. The HTN planning paradigm has proven to be better suited than other approaches to many applications. To date, however, efficiently integrating temporal reasoning with HTN planning has been little explored. This paper describes a means to exploit the structure of a HTN plan in performing temporal propagation on an associated Simple Temporal Network. By exploiting the natural restriction on permitted temporal constraints, the time complexity of propagation can be sharply reduced, while completeness of the inference is maintained. Empirical results indicate an order of magnitude improvement on real-world plans.|Neil Yorke-Smith","65413|AAAI|2005|A Particle Filtering Based Approach to Approximating Interactive POMDPs|POMDPs provide a principled framework for sequential planning in single agent settings. An extension of POMDPs to multi agent settings, called interactive POMDPs (I-POMDPs), replaces POMDP belief spaces with interactive hierarchical belief systems which represent an agent's belief about the physical world, about beliefs of the other agent(s), about their beliefs about others' beliefs, and so on. This modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute. We describe a method for obtaining approximate solutions to IPOMDPs based on particle filtering (PF). We utilize the interactive PF which descends the levels of interactive belief hierarchies and samples and propagates beliefs at each level. The interactive PF is able to deal with the belief space complexity, but it does not address the policy space complexity. We provide experimental results and chart future work.|Prashant Doshi,Piotr J. Gmytrasiewicz","57584|GECCO|2005|MRI magnet design search space analysis EDAs and a real-world problem with significant dependencies|This paper introduces the design of superconductive magnet configurations in Magnetic Resonance Imaging (MRI) systems as a challenging real-world problem for Evolutionary Algorithms (EAs). Analysis of the problem structure is conducted using a general statistical method, which could be easily applied to other problems. The results suggest that the problem is highly multimodal and likely to present a significant challenge for many algorithms. Through a series of preliminary experiments, a continuous Estimation of Distribution Algorithm (EDA) is shown to be able to generate promising designs with a small computational effort. The importance of utilizing problem-specific knowledge and the ability of an algorithm to capture dependencies in solving complex real-world problems is also highlighted.|Bo Yuan,Marcus Gallagher,Stuart Crozier","57495|GECCO|2005|Mission planning for joint suppression of enemy air defenses using a genetic algorithm|In this paper we present a genetic algorithm applied to the problem of mission planning for Joint Suppression of Enemy Air Defenses (JSEAD) in support of air strike operations. The stochastic nature of JSEAD scenarios and the complexity of JSEAD operations and interactions make this an especially challenging problem within the military domain. JSEAD planners and analysts stand to benefit from any advances in tools that address this problem. While our interest in this subject is broad, in this paper we are specifically investigating methods for developing robust plans that include routes for JSEAD assets, target types, firing ranges, and take off time, subject to multiple objective functions that capture different aspects of mission performance. The multi-objective optimization is performed by the Dynamic Non-Dominated Sorting GA (DNSGA), a non-elitist variant of NSGA-II. The objective functions are evaluated using a stochastic agent-based JSEAD simulation, and we assess the quality of mission plans produced by the GA in a set of test scenarios. The results from these tests indicate that our approach has significant promise as a component of a JSEAD mission planning tool.|Jeffrey P. Ridder,Jason C. HandUber","65482|AAAI|2005|Prottle A Probabilistic Temporal Planner|Planning with concurrent durative actions and probabilistic effects, or probabilistic temporal planning, is a relatively new area of research. The challenge is to replicate the success of modern temporal and probabilistic planners with domains that exhibit an interaction between time and uncertainty. We present a general framework for probabilistic temporal planning in which effects, the time at which they occur, and action durations are all probabilistic. This framework includes a search space that is designed for solving probabilistic temporal planning problems via heuristic search, an algorithm that has been tailored to work with it and an effective heuristic based on an extension of the planning graph data structure. Prottle is a planner that implements this framework, and can solve problems expressed in an extension of PDDL.|Iain Little,Douglas Aberdeen,Sylvie Thi√©baux","65586|AAAI|2005|Partial Pathfinding Using Map Abstraction and Refinement|Classical search algorithms such as A* or IDA* are useful for computing optimal solutions in a single pass, which can then be executed. But in many domains agents either do not have the time to compute complete plans before acting, or should not spend the time to do so, due to the dynamic nature of the environment. Extensions to A* such as LRTA* address this problem by gradually learning an exact heuristic function, but the learning process is quite slow. In this paper we introduce Partial-Refinement A* (PRA*), which can fully interleave planning and acting through path abstraction and refinement. We demonstrate the etfectiveness of PRA* in the domain of real-time strategy (RTS) games. In maps taken from popular RTS games. we show that PRA* is not only able to cleanly interleave planning and execution. but it is also able to do so with only minimal losses of optimality.|Nathan R. Sturtevant,Michael Buro","65510|AAAI|2005|Temporal Dynamic Controllability Revisited|An important issue for temporal planners is the ability to handle temporal uncertainty. We revisit the question of how to determine whether a given set of temporal requirements are feasible in the light of uncertain durations of some processes. In particular, we consider how best to determine whether a network is Dynamically Controllable, i.e., whether a dynamic strategy exisls for executing the network that is guaranteed to satisfy the requirements. Previous work has shown the existence of a pseudo-polynomial algorithm for testing Dynamic Controllability. Here, we simplify the previous framework, and present a strongly polynomial algorithm with a termination criterion based on the structure of the network.|Paul H. Morris,Nicola Muscettola","65549|AAAI|2005|Planning for Stream Processing Systems|With the advent of compositional programming models in computer Science, applying planning technologies to automatically build workflows for solving large and complex problems in such a paradigm becomes not only technically appealing but also feasible approach. The application areas that will benefit from automatic composition include, among others, Web services, Grid computing and stream processing systems. Although the classical planning formalism is expressive enough to describe planning problems that arise in a large variety of different applications, it can pose significant limitations on planner performance in compositional applications, in particular, in stream processing systems. In this paper we exlend the classical planning formalism by introducing new language constructs that support the structure of stream processing domains. Exposing this structure to the planner can result in dramatic performance improvements our experiments show exponential planning time reduction in comparison to most recent metric planners.|Anton Riabov,Zhen Liu"],["65480|AAAI|2005|A Fast Arc Consistency Algorithm for n-ary Constraints|The GAC-Scheme has become a popular general purpose algorithm for solving n-ary constraints, although it may scan an exponential number of supporting tuples. In this paper, we develop a major improvement of this scheme. When searching for a support, our new algorithm is able to skip over a number of tuples exponential in the arity of the constraint by exploiting knowledge about the current domains of the variables. We demonstrate the effectiveness of the method for large table constraints.|Olivier Lhomme,Jean-Charles R√©gin","65553|AAAI|2005|SymChaff A Structure-Aware Satisfiability Solver|We present a novel low-overhead framework for encoding and utilizing structural symmetry in propositional satisfiability algorithms (SAT solvers). We use the notion of complete multi-class symmetry and demonstrate the efficacy of our technique through a solver SymChaff that achieves exponential speedup by using simple tags in the specification of problems from both theory and practice. Efficient implementations of DPLL-based SAT solvers are routinely used in areas as diverse as planning, scheduling, design automation, model checking, verification, testing, and algebra. A natural feature of many application domains is the presence of symmetry, such as that amongst all trucks at a certain location in logistics planning and all wires connecting two switch boxes in an FPGA circuit. Many of these problems turn out to have a concise description in many-sorted first order logic. This description can be easily specified by the problem designer and almost as easily inferred automatically. SymChaff, an extension of the popular SAT solver zChaff, uses information obtained from the \"sorts\" in the first order logic constraints to create symmetry sets that are used to partition variables into classes and to maintain and utilize symmetry information dynamically. Current approaches designed to handle symmetry include (A) symmetry breaking predicates (SBPs), (B) pseudo-Boolean solvers with implicit representation for counting, (C) modifications of DPLL that handle symmetry dynamically, and (D) techniques based on ZBDDs. SBPs are prohibitively many, often large, and expensive to compute for problems such as the ones we report experimental results for. Pseudo-Boolean solvers are provably exponentially slow in certain symmetric situations and their implicit counting representation is not always appropriate. Suggested modifications of DPLL either work on limited global symmetry and are difficult to extend, or involve expensive algebraic group computations. Finally, techniques based on ZBDDs often do not compare well even with ordinary DPLL-based solvers. Sym-Chaff addresses and overcomes most of these limitations.|Ashish Sabharwal","65538|AAAI|2005|SAT-Based versus CSP-Based Constraint Weighting for Satisfiability|Recent research has focused on bridging the gap between the satisfiability (SAT) and constraint satisfaction problem (CSP) formalisms. One approach has been to develop a many-valued SAT formula (MV-SAT) as an intermediate paradigm between SAT and CSP, and then to translate existing highly efficient SAT solvers to the MV-SAT domain. Experimental results have shown this approach can achieve significant improvements in performance compared with the traditional SAT and CSP approaches. In this paper, we follow a different route, developing SAT solvers that can automatically recognise CSP structure hidden in SAT encodings. This allows us to look more closely at how constraint weighting can be implemented in the SAT and CSP domains. Our experimental results show that a SAT-based approach to handle weights, together with CSP-based approach to variable instantiation, is superior to other combinations of SAT and CSP-based approaches. A further experiment on the round robin scheduling problem indicates that this many-valued constraint weighting approach outperforms other state-of-the-art solvers.|Duc Nghia Pham,John Thornton,Abdul Sattar,Abdelraouf Ishtaiwi","65351|AAAI|2005|The Achilles Heel of QBF|In recent years we have seen significant progress in the area of Boolean satisfiability (SAT) solving and its applications. As a new challenge, the community is now moving to investigate whether similar advances can be made in the use of Quantified Boolean Formulas (QBF). QBF provides a natural framework for capturing problem solving and planning in multi-agent settings. However, contrarily to single-agent planning, which can be effectively formulated as SAT, we show that a QBF approach to planning in a multi-agent setting leads to significant unexpected computational difficulties. We identify as a key difficulty of the QBF approach the fact that QBF solvers often end up exploring a much larger search space than the natural search space of the original problem. This is in contrast to the experience with SAT approaches. We also show how one can alleviate these problems by introducing two special QBF formulations and a new QBF solution strategy. We present experiments that show the effectiveness of our approach in terms of a significant improvement in performance compared to earlier work in this area. Our work also provides a general methodology for formulating adversarial scenarios in QBF.|Carlos Ans√≥tegui,Carla P. Gomes,Bart Selman","65395|AAAI|2005|Constrained Decision Diagrams|A general n-ary constraint is usually represented explicitly as a set of its solution tuples, which may need exponential space. In this paper, we introduce a new representation for general n-ary constraints called Constrained Decision Diagram (CDD). CDD generalizes BDD-style representations and the main feature is that it combines constraint reasoningconsistency techniques with a compact data structure. We present an application of CDD for recording all solutions of a conjunction of constraints. Instead of an explicit representation, we can implicitly encode the solutions by means of constraint propagation. Our experiments confirm the scalability and demonstrate that CDDs can drastically reduce the space needed over explicit and ZBDD representations.|Kenil C. K. Cheng,Roland H. C. Yap","65467|AAAI|2005|Heterogeneous Multirobot Coordination with Spatial and Temporal Constraints|Existing approaches to multirobot coordination separate scheduling and task allocation, but finding the optimal schedule with joint tasks and spatial constraints requires robots to simultaneously solve the scheduling, task allocation, and path planning problems. We present a formal description of the multirobot joint task allocation problem with heterogeneous capabilities and spatial constraints and an instantiation of the problem for the search and rescue domain. We introduce a novel declarative framework for modeling the problem as a mixed integer linear programming (MILP) problem and present a centralized anytime algorithm with error bounds. We demonstrate that our algorithm can outperform standard MILP solving techniques, greedy heuristics, and a market based approach which separates scheduling and task allocation.|Mary Koes,Illah R. Nourbakhsh,Katia P. Sycara","57272|GECCO|2005|Advanced models of cellular genetic algorithms evaluated on SAT|Cellular genetic algorithms (cGAs) are mainly characterized by their spatially decentralized population, in which individuals can only interact with their neighbors. In this work, we study the behavior of a large number of different cGAs when solving the well-known -SAT problem. These cellular algorithms differ in the policy of individuals update and the population shape, since these two features affect the balance between exploration and exploitation of the algorithm. We study in this work both synchronous and asynchronous cGAs, having static and dynamically adaptive shapes for the population. Our main conclusion is that the proposed adaptive cGAs outperform other more traditional genetic algorithms for a well known benchmark of -SAT.|Enrique Alba,Hugo Alfonso,Bernab√© Dorronsoro","65502|AAAI|2005|A Framework for Representing and Solving NP Search Problems|NP search and decision problems occur widely in AI, and a number of general-purpose methods for solving them have been developed. The dominant approaches include propositional satisfiability (SAT), constraint satisfaction problems (CSP), and answer set programming (ASP). Here, we propose a declarative constraint programming framework which we believe combines many strengths of these approaches, while addressing weaknesses in each of them. We formalize our approach as a model extension problem, which is based on the classical notion of extension of a structure by new relations. A parameterized version of this problem captures NP. We discuss properties of the formal framework intended to support effective modelling, and prospects for effective solver design.|David G. Mitchell,Eugenia Ternovska","65558|AAAI|2005|Performing Bayesian Inference by Weighted Model Counting|Over the past decade general satisfiability testing algorithms have proven to be surprisingly effective at solving a wide variety of constraint satisfaction problem, such as planning and scheduling (Kautz and Selman ). Solving such NP-complete tasks by \"compilation to SAT\" has turned out to be an approach that is of both practical and theoretical interest. Recently, (Sang et al. ) have shown that state of the art SAT algorithms can be efficiently extended to the harder task of counting the number of models (satisfying assignments) of a formula, by employing a technique called component caching. This paper begins to investigate the question of whether \"compilation to model-counting\" could be a practical technique for solving real-world P-complete problems, in particular Bayesian inference. We describe an efficient translation from Bayesian networks to weighted model counting, extend the best model-counting algorithms to weighted model counting, develop an efficient method for computing all marginals in a single counting pass, and evaluate the approach on computationally challenging reasoning problems.|Tian Sang,Paul Beame,Henry A. Kautz","65565|AAAI|2005|Constraint-Based Entity Matching|Entity matching is the problem of deciding if two given mentions in the data, such as \"Helen Hunt\" and \"H. M. Hunt\", refer to the same real-world entity. Numerous solutions have been developed, but they have not considered in depth the problem of exploiting integrity constraints that frequently exist in the domains. Examples of such constraints include \"a mention with age two cannot match a mention with salary K\" and \"if two paper citations match, then their authors are likely to match in the same order\". In this paper we describe a probabilistic solution to entity matching that exploits such constraints to improve matching accuracy. At the heart of the solution is a generative model that takes into account the constraints during the generation process, and provides well-defined interpretations of the constraints. We describe a novel combination of EM and relaxation labeling algorithms that efficiently learns the model, thereby matching mentions in an unsupervised way, without the need for annotated training data. Experiments on several real-world domains show that our solution can exploit constraints to significantly improve matching accuracy, by -% F-, and that the solution scales up to large data sets.|Warren Shen,Xin Li,AnHai Doan"],["57581|GECCO|2005|An evolutionary lagrangian method for the  multiple knapsack problem|We propose a new evolutionary approach to solve the  multiple knapsack problem. We approach the problem from a new viewpoint different from traditional methods. The most remarkable feature is the Lagrangian method. Lagrange multipliers transform the problem, keeping the optimality as well as decreasing the complexity. However, it is not easy to find Lagrange multipliers nearest to the constraints of the problem. We propose an evolution strategy to find the optimal Lagrange multipliers. Also, we improve the evolution strategy by adjusting its objective function properly. We show the efficiency of the proposed methods by the experiments. We make comparisons with existing general approach on well-known benchmark data.|Yourim Yoon,Yong-Hyuk Kim,Byung Ro Moon","57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","57560|GECCO|2005|Hybrid real-coded mutation for genetic algorithms applied to graph layouts|In this paper we introduce an application of real-coded genetic algorithms to the problem of consistent graph layout and exploring the role of mutation for this particular problem. We introduce several forms of mutation, some of which being specific to this problem, and show that the choice of this operator can have a great impact on the performance of the algorithm.|Dana Vrajitoru,Jason DeBoni","57315|GECCO|2005|Quality-time analysis of multi-objective evolutionary algorithms|A quality-time analysis of multi-objective evolutionary algorithms (MOEAs) based on schema theorem and building blocks hypothesis is developed. A bicriteria OneMax problem, a hypothesis of niche and species, and a definition of dissimilar schemata are introduced for the analysis. In this paper, the convergence time, the first and last hitting time models are constructed for analyzing the performance of MOEAs. Population sizing model is constructed for determining appropriate population sizes. The models are verified using the bicriteria OneMax problem. The theoretical results indicate how the convergence time and population size of a MOEA scale up with the problem size, the dissimilarity of Pareto-optimal solutions, and the number of Pareto-optimal solutions of a multi-objective optimization problem.|Jian-Hung Chen,Shinn-Ying Ho,David E. Goldberg","57485|GECCO|2005|Understanding cooperative co-evolutionary dynamics via simple fitness landscapes|Cooperative co-evolution is often used to solve difficult optimization problems by means of problem decomposition. Its performance for such tasks can vary widely from good to disappointing. One of the reasons for this is that attempts to improve co-evolutionary performance using traditional EC analysis techniques often fail to provide the necessary insights into the dynamics of co-evolutionary systems, a key factor affecting performance. In this paper we use two simple fitness landscapes to illustrate the importance of taking a dynamical systems approach to analyzing co-evolutionary algorithms in order to understand them better and to improve their problem solving performance.|Elena Popovici,Kenneth A. De Jong","57369|GECCO|2005|Statistical analysis of heuristics for evolving sorting networks|Designing efficient sorting networks has been a challenging combinatorial optimization problem since the early 's. The application of evolutionary computing to this problem has yielded human-competitive results in recent years. We build on previous work by presenting a genetic algorithm whose parameters and heuristics are tuned on a small instance of the problem, and then scaled up to larger instances. Also presented are positive and negative results regarding the efficacy of several domain-specific heuristics.|Lee K. Graham,Hassan Masum,Franz Oppacher","57459|GECCO|2005|Morphing methods in evolutionary design optimization|Design optimization is a well established application field of evolutionary computation. However, standard recombination operators acting on the genotypic representation of the design or shape are often too disruptive to be useful during optimization. In this work, we will analyze whether morphing methods between two shapes can be used as recombination operators acting on the phenotype space, thus directly on the shape or design. We introduce three different morphing methods and employ them as recombination operators in a standard evolution strategy (es). We compare their performance with an evolution strategy without any recombination operators on two target shape approximation problem. We can conclude that two of the three morphing methods can be useful during search although all morphing methods still turn out to hinder the self-adaptation of the step sizes of the evolution strategy.|Michael Nashvili,Markus Olhofer,Bernhard Sendhoff","57461|GECCO|2005|Minimum spanning trees made easier via multi-objective optimization|Many real-world problems are multi-objective optimization problems and evolutionary algorithms are quite successful on such problems. Since the task is to compute or approximate the Pareto front, multi-objective optimization problems are considered as more difficult than single-objective problems. One should not forget that the fitness vector with respect to more than one objective contains more information that in principle can direct the search of evolutionary algorithms. Therefore, it is possible that a single-objective problem can be solved more efficiently via a generalized multi-objective model of the problem. That this is indeed the case is proved by investigating the computation of minimum spanning trees.|Frank Neumann,Ingo Wegener","57479|GECCO|2005|Evolutionary optimization of dynamic control problems accelerated by progressive step reduction|In this paper, we describe the use of an evolutionary algorithm (EA) to solve dynamic control optimization problems in engineering. In this class of problems, a set of control variables must be manipulated over time to optimize the outcome, which is obtained by solving a set of differential equations for the state variables. A new problem-specific technique, progressive step reduction (PSR), is shown to considerably improve the efficiency of the algorithm for this application. Factorial experimentation and rigorous statistical analysis are used to determine the effects of PSR and tune the parameters of the algorithm.|Q. Tuan Pham","57378|GECCO|2005|Three dimensional evolutionary aerodynamic design optimization with CMA-ES|In this paper, we present the application of evolutionary optimization methods to a demanding, industrially relevant engineering domain, the three-dimensional optimization of gas turbine stator blades. This optimization problem is high-dimensional search and computationally very expensive. We show that, despite of its difficulty, the problem is feasible. Our approach not only successfully optimizes the aerodynamic design but also yields interesting results from an engineering point of view.|Martina Hasenj√§ger,Bernhard Sendhoff,Toyotaka Sonoda,Toshiyuki Arima"],["57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57339|GECCO|2005|Not all linear functions are equally difficult for the compact genetic algorithm|Estimation of distribution algorithms (EDAs) try to solve an optimization problem by finding a probability distribution focussed around its optima. For this purpose they conduct a sampling-evaluation-adjustment cycle, where search points are sampled with respect to a probability distribution, which is adjusted according to the evaluation of the sampled points. Although there are many successful experiments suggesting the usefulness of EDAs, there are only few rigorous theoretical results apart from convergence results without time bounds. Here we present first rigorous runtime analyses of a simple EDA, the compact genetic algorithm, for linear pseudo-boolean functions on n variables. We prove a number of results showing that not all linear functions have the same asymptotical runtime.|Stefan Droste","57501|GECCO|2005|Real-coded crossover as a role of kernel density estimation|This paper presents a kernel density estimation method by means of real-coded crossovers. Estimation of density algorithms (EDAs) are evolutionary optimization techniques, which determine the sampling strategy by means of a parametric probabilistic density function estimated from the population. Real-coded Genetic Algorithm (RCGA) does not explicitly estimate any probabilistic distribution, however, the probabilistic model of the population is implicitly estimated by crossovers and the sampling strategy is determined by this implicit probabilistic model. Based on this understanding, we propose a novel density estimation algorithm by using crossovers as nonparametric kernels and apply this kernel density estimation to the Gaussian Mixture modeling. We show that the proposed method is superior in the robustness of the computation and in the accuracy of the estimation by the comparison of conventional EM estimation.|Jun Sakuma,Shigenobu Kobayashi","57304|GECCO|2005|Estimating the detector coverage in a negative selection algorithm|This paper proposes a statistical mechanism to analyze the detector coverage in a negative selection algorithm, namely a quantitative measurement of a detector set's capability to detect nonself data. This novel method has the advantage of statistical confidence in the estimation of the actual coverage. Furthermore, unlike the existing analysis works of negative selection, it doesn't depend on specific detector representation and generation algorithm. Not only can it be implemented as a procedure independent from the steps to generate detectors, the experiments in this paper showed that it can also be tightly integrated into the detector generation algorithm to control the number of detectors.|Zhou Ji,Dipankar Dasgupta","57361|GECCO|2005|Takeover time curves in random and small-world structured populations|We present discrete stochastic mathematical models for the growth curves of synchronous and synchronous evolutionary algorithms with populations structured ccording to a random graph. We show that, to good approximation, randomly structured and panmictic populations have the some growth behavior. Furthermore, we show that global selection intensity depends on the update policy. The validity of the models is confirmed by comparison with experimental results of simulations. We also present experimental results on small-world nd scale-free population graph topologies. We show that they lead to qualitatively similar results. However, the different nature of the nodes can be exploited to obtain more varied evolutionary behavior.|Mario Giacobini,Marco Tomassini,Andrea Tettamanzi","57375|GECCO|2005|Applying both positive and negative selection to supervised learning for anomaly detection|This paper presents a novel approach of applying both positive selection and negative selection to supervised learning for anomaly detection. It first learns the patterns of the normal class via co-evolutionary genetic algorithm, which is inspired from the positive selection, and then generates synthetic samples of the anomaly class, which is based on the negative selection in the immune system. Two algorithms about synthetic generation of the anomaly class are proposed. One deals with data sets containing a few anomalous samples while the other deals with data sets containing no anomalous samples at all. The experimental results on some benchmark data sets from UCI data set repertory show that the detection rate is improved evidently, accompanied by a slight increase in false alarm rate via introducing novel synthetic samples of the anomaly class. The advantages of our method are the increased ability of classifiers in identifying both previously known and innovative anomalies, and the maximal degradation of overfitting phenomenon.|Xiaoshu Hang,Honghua Dai","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","57415|GECCO|2005|Total synthesis of algorithmic chemistries|Algorithmic Chemistries are Artificial Chemistries that aim at algorithms. In this contribution we present a new algorithm to execute Algorithmic Chemistries during evolution. This algorithm ensures synthesizes of the whole program and cuts off execution of unneeded instructions without restricting the stochastic way of execution. We demonstrate benefits of the new algorithm for evolution of Algorithmic Chemistries and discuss the relation of Algorithmic Chemistries with Estimation of Distribution Algorithms.|Christian Lasarczyk,Wolfgang Banzhaf","57589|GECCO|2005|Molecular programming evolving genetic programs in a test tube|We present a molecular computing algorithm for evolving DNA-encoded genetic programs in a test tube. The use of synthetic DNA molecules combined with biochemical techniques for variation and selection allows for various possibilities for building novel evolvable hardware. Also, the possibility of maintaining a huge number of individuals and their massively parallel manipulation allows us to make robust decisions by the \"molecular\" genetic programs evolved within a single population. We evaluate the potentials of this \"molecular programming\" approach by solving a medical diagnosis problem on a simulated DNA computer. Here the individual genetic program represents a decision list of variable length and the whole population takes part in making probabilistic decisions. Tested on a real-life leukemia diagnosis data, the evolved molecular genetic programs showed a comparable performance to decision trees. The molecular evolutionary algorithm can be adapted to solve problems in bio-technology and nano-technology where the physico-chemical evolution of target molecules is of pressing importance.|Byoung-Tak Zhang,Ha-Young Jang"],["65537|AAAI|2005|Word Sense Disambiguation with Semi-Supervised Learning|Current word sense disambiguation (WSD) systems based on supervised learning are still limited in that they do not work well for all words in a language. One of the main reasons is the lack of sufficient training data. In this paper, we investigate the use of unlabeled training data for WSD, in the framework of semi-supervised learning. Four semisupervised leaming algorithms are evaluated on  nouns of Senseval- (SE) English lexical sample task and SE English all-words task. Empirical results show that unlabeled data can bring significant improvement in WSD accuracy.|Thanh Phong Pham,Hwee Tou Ng,Wee Sun Lee","57338|GECCO|2005|The predictive basis of situated and embodied artificial intelligence|While classic AI systems still struggle to properly incorporate common-sense knowledge, Situated and Embodied Artificial Intelligence (SEAI) aims to build animats that acquire a common-sense understanding of the world via interactions between simulated brains, bodies and environments. Neuroscientists believe that much of this common sense involves predictive models for physical activities, but the transfer of sensorimotor skill knowledge to cognition is non-trivial, indicating that SEAI may meet a daunting challenge of its own. This paper considers the neurological basis for procedural common sense and the possibilities for its transfer to conscious reasoning. This helps assess the prospects for SEAI to eventually surpass classic AI in the quest for generally intelligence systems.|Keith L. Downing","65469|AAAI|2005|Description Logic-Ground Knowledge Integration and Management|This abstract describes ongoing work in developing large-scale knowledge repositories. The project addresses three primary aspects of such systems integration of knowledge sources access and retrieval of stored knowledge scalable, effective repositories. Previous results have shown the effectiveness of description logic-based representations in integrating knowledge sources and the role of non-standard inferences in supporting repository reasoning tasks. Current efforts include developing general-purpose mechanisms for adapting reasoning algorithms for optimized inference under known domain structure and effective use of database technology as a large-scale knowledge base backend.|Joseph Kopena","65528|AAAI|2005|SenseRelate  TargetWord-A Generalized Framework for Word Sense Disambiguation|Many words in natural language have different meanings when used in different contexts. Sense Relate Target Word is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet Similarity measure of relatedness.|Siddharth Patwardhan,Satanjeev Banerjee,Ted Pedersen","57305|GECCO|2005|Extracted global structure makes local building block processing effective in XCS|Michigan-style learning classifier systems (LCSs), such as the accuracy-based XCS system, evolve distributed problem solutions represented by a population of rules. Recently, it was shown that decomposable problems may require effective processing of subsets of problem attributes, which cannot be generally assured with standard crossover operators. A number of competent crossover operators capable of effective identification and processing of arbitrary subsets of variables or string positions were proposed for genetic and evolutionary algorithms. This paper effectively introduces two competent crossover operators to XCS by incorporating techniques from competent genetic algorithms (GAs) the extended compact GA (ECGA) and the Bayesian optimization algorithm (BOA). Instead of applying standard crossover operators, here a probabilistic model of the global population is built and sampled to generate offspring classifiers locally. Various offspring generation methods are introduced and evaluated. Results indicate that the performance of the proposed learning classifier systems XCSECGA and XCSBOA is similar to that of XCS with informed crossover operators that is given all information about problem structure on input and exploits this knowledge using problem-specific crossover operators.|Martin V. Butz,Martin Pelikan,Xavier Llor√†,David E. Goldberg","65498|AAAI|2005|Searching for Common Sense Populating Cyc from the Web|The Cyc project is predicated on the idea that effective machine learning depends on having a core of knowledge that provides a context for novel learned information - what is known informally as \"common sense.\" Over the last twenty years, a sufficient core of common sense knowledge has been entered into Cyc to allow it to begin effectively and flexibly supporting its most important task increasing its own store of world knowledge. In this paper, we present initial work on a method of using a combination of Cyc and the World Wide Web, accessed via Google, to assist in entering knowledge into Cyc. The long-term goal is automating the process of building a consistent, formalized representation of the world in the Cyc knowledge base via machine learning. We present preliminary results of this work and describe how we expect the knowledge acquisition process to become more accurate, faster, and more automated in the future.|Cynthia Matuszek,Michael J. Witbrock,Robert C. Kahlert,John Cabral,David Schneider,Purvesh Shah,Douglas B. Lenat","65365|AAAI|2005|Mathematical Domain Reasoning Tasks in Natural Language Tutorial Dialog on Proofs|We study challenges that are imposed to mathematical domain reasoning in the context of natural language tutorial dialog on mathematical proofs. The focus is on proof step evaluation (i) How can mathematical domain reasoning support the resolution of ambiguities and underspecified parts in proof steps uttered by a student (ii) How can mathematical domain reasoning support the evaluation of a proof step with respect to the criteria soundness, granularity, and relevance.|Christoph Benzm√ºller,Quoc Bao Vo","65520|AAAI|2005|Interactive Knowledge Validation and Query Refinement in CBR|In most case-based reasoning (CBR) systems there has been little research done on validating new knowledge, specifically on how previous knowledge differs from current knowledge as a result of conceptual change. This paper proposes two methods that enable the domain expert, who is nonexpert in artificial intelligence (AI), to interactively supervise the knowledge validation process in a CBR system, and to enable dynamic updating of the system, to provide the best diagnostic questions. The first method is based on formal concept analysis which involves a graphical representation and comparison of the concepts, and a summary description highlighting the conceptual differences. We propose a dissimilarity metric for measuring the degree of variation between the previous and current concepts when a new case is added to the knowledge base. The second method involves determining unexpected classification-based association rules to form critical questions as the knowledge base gets updated.|Monica H. Ou,Geoff A. W. West,Mihai Lazarescu,Chris Clay","57572|GECCO|2005|Use of a genetic algorithm in brills transformation-based part-of-speech tagger|The tagging problem in natural language processing is to find a way to label every word in a text as a particular part of speech, e.g., proper noun. An effective way of solving this problem with high accuracy is the transformation-based or \"Brill\" tagger. In Brill's system, a number of transformation templates are specified a priori that are instantiated and ranked during a greedy search-based algorithm. This paper describes a variant of Brill's implementation that instead uses a genetic algorithm to generate the instantiated rules and provide an adaptive ranking. Based on tagging accuracy, the new system provides a better hybrid evolutionary computation solution to the part-of-speech (POS) problem than the previous attempt. Although not able to make up for the use of a priori knowledge utilized by Brill, the method appears to point the way for an improved solution to the tagging problem.|Garnett Carl Wilson,Malcolm I. Heywood","65530|AAAI|2005|Identifying Similar Words and Contexts in Natural Language with SenseClusters|SenseClusters is a freely available intelligent system that clusters together similar contexts in natural language text. Thereafter it assigns identifying labels to these clusters based on their content. It is a purely unsupervised approach that is language independent, and uses no knowledge other than what is available in raw un-annotated corpora. In addition to clustering similar contexts, it can be used to identify synonyms and sets of related words. It has been applied to a diverse range of problems, including proper name disambiguation, word sense discrimination, email organization, and document clustering. SenseClusters is a complete system that supports feature selection from large corpora, several different context representation schemes, various clustering algorithms, the creation of descriptive and discriminating labels for the discovered clusters, and evaluation relative to gold standard data.|Ted Pedersen,Anagha Kulkarni"],["57302|GECCO|2005|Information landscapes and problem hardness|In  we introduced a new concept of a landscape the information landscape. We showed that for problems of very small size (e.g. a -bit problem), it can be used to generally and accurately predict the performance of a GA. Based on this framework, in this paper we develop a method to predict GA hardness on realistic landscapes. We give empirical results which support our approach.|Yossi Borenstein,Riccardo Poli","65400|AAAI|2005|Expressive Negotiation in Settings with Externalities|In recent years, certain formalizations of combinatorial negotiation settings, most notably combinatorial auctions, have become an important research topic in the AI community. A pervasive assumption has been that of no externalities the agents deciding on a variable (such as whether a trade takes place between them) are the only ones affected by how this variable is set. To date, there has been no widely studied formalization of combinatorial negotiation settings with externalities. In this paper, we introduce such a formalization. We show that in a number of key special cases, it is NP-complete to find a feasible nontrivial solution (and therefore the maximum social welfare is completely inapproximable). However, for one important special case, we give an algorithm which converges to the solution with the maximal concession by each agent (in a linear number of rounds for utility functions that decompose into piecewise constant functions). Maximizing social welfare, however, remains NP-complete even in this setting. We also demonstrate a special case which can be solved in polynomial time by linear programming.|Vincent Conitzer,Tuomas Sandholm","65353|AAAI|2005|Mechanism Design for Single-Value Domains|In \"Single-Value domains\", each agent has the same private value for all desired outcomes. We formalize this notion and give new examples for such domains. including a \"SAT domain\" and a \"single-value combinatorial auctions\" domain. We study two informational models where the set of desired outcomes is public information (the \"known\" case). and where it is private information (the \"unknown\" case). Under the \"known\" assumption, we present several truthful approximation mechanisms. Additionally, we suggest a general technique to convert any bitonic approximation algorithm for an unweighted domain (where agent values are either zero or one) to a truthful mechanism, with only a small approximation loss. In contrast, we show that even positive results from the \"unknown single minded combinatorial auctions\" literature fail to extend to the \"unknown\" single-value case. We give a characterization of truthfulness in this case, demonstrating that the difference is subtle and surprising.|Moshe Babaioff,Ron Lavi,Elan Pavlov","65446|AAAI|2005|Weighted Super Solutions for Constraint Programs|Super solutions to constraint programs guarantee that if a limited number of variables lose their values, repair solutions can be found by modifying a bounded number of assignments. However, in many application domains the classical super solutions framework is not expressive enough since it only reasons about the number of breaks in a solution and the number of changes that are necessary to find a repair. For example, in combinatorial auctions we may wish to guarantee that we can always find a repair solution whose revenue exceeds some threshold while limiting the cost associated with forming such a repair. In this paper we present the weighted super solution framework that involves two important extensions. Firstly, the set of variables that may lose their values is determined using a probabilistic approach enabling us to find repair solutions for assignments that are most likely to fail. Secondly, we include a mechanism for reasoning about the cost of repair. The proposed framework has been successfully used to find robust solutions to combinatorial auctions.|Alan Holland,Barry O'Sullivan","65483|AAAI|2005|Approximating Revenue-Maximizing Combinatorial Auctions|Designing revenue-maximizing combinatorial auctions (CAs) is a recognized open problem in mechanism design. It is unsolved even for two bidders and two items for sale. Rather than attempting to characterize the optimal auction, we focus on designing approximations (suboptimal auction mechanisms which yield high revenue). Our approximations belong to the family of virtual valuations combinatorial auctions (VVCA). VVCA is a Vickrey-Clarke-Groves (VCG) mechanism run on virtual valuations that are linear transformations of the bidders' real valuations. We pursue two approaches to constructing approximately optimal CAs. The first is to construct a VVCA with worst-case and average-case performance guarantees. We give a logarithmic approximation auction for basic important special cases of the problem ) limited supply of items on sale with additive valuations and ) unlimited supply. The second approach is to search the parameter space of VVCAs in order to obtain high-revenue mechanisms for the general problem. We introduce a series of increasingly sophisticated algorithms that use economic insights to guide the search and thus reduce the computational complexity. Our experiments demonstrate that in many cases these algorithms perform almost as well as the optimal VVCA, yield a substantial increase in revenue over the VCG mechanism and drastically outperform the straightforward algorithms in run-time.|Anton Likhodedov,Tuomas Sandholm","57546|GECCO|2005|Applying metaheuristic techniques to search the space of bidding strategies in combinatorial auctions|Many non-cooperative settings that could potentially be studied using game theory are characterized by having very large strategy spaces and payoffs that are costly to compute. Best response dynamics is a method of searching for pure-strategy equilibria in games that is attractive for its simplicity and scalability (relative to more analytical approaches). However, when the cost of determining the outcome of a particular set of joint strategies is high, it is impractical to compute the payoffs of all possible responses to the other players actions. Thus, we study metaheuristic approaches--genetic algorithms and tabu search in particular--to explore the strategy space. We configure the parameters of metaheuristics to adapt to the problem of finding the best response strategy and present how it can be helpful in finding Nash equilibria of combinatorial auctions which is an important solution concept in game theory.|Ashish Sureka,Peter R. Wurman","65615|AAAI|2005|Sensor Selection for Active Information Fusion|Active information fusion is to selectively choose the sensors so that the information gain can compensate the cost spent in information gathering. However, determining the most informative and cost-effective sensors requires an evaluation of all possible sensor combinations, which is computationally intractable, particularly, when information-theoretic criterion is used. This paper presents a methodology to actively select a sensor subset with the best tradeoff between information gain and sensor cost by exploiting the synergy among sensors. Our approach includes two aspects a method for efficient mutual information computation and a graph-theoretic approach to reduce search space. The approach can reduce the time complexity significantly in searching for a near optimal sensor subset.|Yongmian Zhang,Qiang Ji","65552|AAAI|2005|Exploiting Subjectivity Classification to Improve Information Extraction|Information extraction (IE) systems are prone to false hits for a variety of reasons and we observed that many of these false hi ts occur in sentences that contain subjective language (e.g., opinions, emotions, and sentiments). Motivated by these observations, we explore the idea of using subjectivity analysis to improve the precision of information extraction systems. In this paper, we describe an IE system that uses a subjective sentence classifier to filter its extractions. We experimented with several different strategies for using the subjectivity classifications, including an aggressive strategy that discards all extractions found in subjective sentences and more complex strategies that selectively discard extractions. We evaluated the performance of these different approaches on the MUC- terrorism data set. We found that indiscriminately filtering extractions from subjective sentences was overly aggressive, but more selective filtering strategies improved IE precision with minimal recall loss.|Ellen Riloff,Janyce Wiebe,William Phillips","65402|AAAI|2005|Combinatorial Auctions with wise Dependent Valuations|We analyze the computational and communication complexity of combinatorial auctions from a new perspective the degree of interdependency between the items for sale in the bidders' preferences. Denoting by Gk the class of valuations displaying up to k-wise dependencies, we consider the hierarchy G  G  ...  Gm, where m is the number of items for sale. We show that the minimum non-trivial degree of interdependency (-wise dependency) is sufficient to render NP-hard the problem of computing the optimal allocation (but we also exhibit a restricted class of such valuations for which computing the optimal allocation is easy). On the other hand, bidders' preferences can be communicated efficiently (i.e., exchanging a polynomial amount of information) as long as the interdependencies between items are limited to sets of cardinality up to k, where k is an arbitrary constant. The amount of communication required to transmit the bidders' preferences becomes super-polynomial (under the assumption that only value queries are allowed) when interdependencies occur between sets of cardinality g(m), where g(m) is an arbitrary function such that g(m)   as m  . We also consider approximate elicitation, in which the auctioneer learns, asking polynomially many value queries, an approximation of the bidders' actual preferences.|Vincent Conitzer,Tuomas Sandholm,Paolo Santi","65573|AAAI|2005|Profit Sharing Auction|Auctions are a class of multi-party negotiation protocols. Classical auctions try to maximize social welfare by selecting the highest bidder as the winner. If bidders are rational, this ensures that the sum of profits for all bidders and the seller is maximized. In all such auctions, however, only the winner and the seller make any profit. We believe that \"social welfare distribution\" is a desired goal of any multiparty protocol. In the context of auctions, this goal translates into a rather radical proposal of profit sharing between all bidders and the seller. We propose a Profit Sharing Auction (PSA) where a part of the selling price paid by the winner is paid back to the bidders. The obvious criticism of this mechanism is the incentive for the seller to share its profit with nonwinning bidders. We claim that this loss can be compensated by attracting more bidders to such an auction, resulting in an associated increase in selling price. We run several sets of experiments where equivalent items are concurrently sold at a First Price Sealed Bid, a Vickrey, and a PSA auction. A population of learning bidders repeatedly choose to go to one of these auctions based on their valuation for the good being auctioned and their learned estimates of profits from these auctions. Results show that sellers make more or equivalent profits by using PSA as compared to the classical auctions. Additionally, PSA always attracts more bidders, which might create auxiliary revenue streams, and a desirable lower variability in selling prices. Interestingly then, a rational seller has the incentive to share profits and offer an auction like PSA which maximizes and distributes social welfare.|Sandip Sen,Teddy Candale,Susnata Basak"],["57470|GECCO|2005|Evolution of multi-loop controllers for fixed morphology with a cyclic genetic algorithm|Cyclic genetic algorithms can be used to generate single loop control programs for robots. While successful in generating controllers for individual leg movement, gait generation, and area search path finding, cyclic genetic algorithms have had limited use when dealing with control problems that require different behaviors in response to sensor inputs. For such behaviors, there is a need for modifications that will allow the generation of multi-loop control programs, which can properly react to sensor input. In this work, we present modifications to the standard cyclic genetic algorithm that enables it to learn multi-loop control programs with branching that allows the control to jump from one loop to another. Preliminary tests show the success of our modification.|Gary B. Parker,Ramona Georgescu","57548|GECCO|2005|Collaborative interactive evolution|This paper examines the efficacy of genetic algorithms (GAs) in combining input from multiple users to control a single interactive system, such as an educational exhibit at a museum. Specifically, the idea of collaborative interactive evolution (that is, interactive evolution with input from multiple users) is introduced for this purpose. Two fitness functions are proposed to guide the collaborative interactive evolution, as well as two non-GA methods for combining user input. The usefulness and success of each of these methods is examined, and the GA is shown to be a viable means for combining user input for the control of a single interactive system.|Sean R. Szumlanski,Annie S. Wu,Charles E. Hughes","57268|GECCO|2005|Efficient credit assignment through evaluation function decomposition|Evolutionary methods are powerful tools in discovering solutions for difficult continuous tasks. When such a solution is encoded over multiple genes, a genetic algorithm faces the difficult credit assignment problem of evaluating how a single gene in a chromosome contributes to the full solution. Typically a single evaluation function is used for the entire chromosome, implicitly giving each gene in the chromosome the same evaluation. This method is inefficient because a gene will get credit for the contribution of all the other genes as well. Accurately measuring the fitness of individual genes in such a large search space requires many trials. This paper instead proposes turning this single complex search problem into a multi-agent search problem, where each agent has the simpler task of discovering a suitable gene. Gene-specific evaluation functions can then be created that have better theoretical properties than a single evaluation function over all genes. This method is tested in the difficult double-pole balancing problem, showing that agents using gene-specific evaluation functions can create a successful control policy in % fewer trials than the best existing genetic algorithms. The method is extended to more distributed problems, achieving % performance gains over tradition methods in the multi-rover domain.|Adrian K. Agogino,Kagan Tumer,Risto Miikkulainen","57429|GECCO|2005|The molecule evoluator an interactive evolutionary algorithm for designing drug molecules|To help chemists design new drugs, we created a tool that uses interactive evolution to design drug molecules, the \"Molecule Evoluator\". In contrast to most other evolutionary de novo design programs, the molecule representation and the set of mutations enable it to both search the chemical space of all drug like molecules extensively and to fine-tune molecular structures to the problem at hand. Additionally, we use interaction with the user as a fitness function, which is new in evolutionary algorithms in drug design. This interactivity allows the Molecule Evoluator to use the domain knowledge of the chemist to estimate the ease of synthesis and the biological activity of the compound. This knowledge can guide the optimization process and thereby improve its results. Chemists of our department using the Molecule Evoluator were able to find six novel and synthesizable druglike core structures, indicating that the Molecule Evoluator can be used as a tool to enhance the chemist's creativity.|Eric-Wubbo Lameijer,Adriaan P. IJzerman,Joost N. Kok","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","57408|GECCO|2005|New topologies for genetic search space|We propose three distance measures for genetic search space. One is a distance measure in the population space that is useful for understanding the working mechanism of genetic algorithms. Another is a distance measure in the solution space for K-grouping problems. This can be used for normalization in crossover. The third is a level distance measure for genetic algorithms, which is useful for measuring problem difficulty with respect to genetic algorithms. We show that the proposed measures are metrics and the measures are efficiently computed.|Yong-Hyuk Kim,Byung Ro Moon","57267|GECCO|2005|Search space modulation in genetic algorithms evolving the search space by sinusoidal transformations|An experimental form of Modulation (Reinterpretation) of the Search Space is presented. This modulation is developed as a mathematical method that can be implemented directly into existing evolutionary algorithms without writing special operators, changing the program loop etc. The main mathematical principle behind this method is the dynamic sinusoidal envelope of the search space. This method is presented in order to solve some theoretical and practical issues in evolutionary algorithms like numerical bounded variables, dynamic focalized search, dynamic control of diversity, feasible region analysis etc.|Jos√© Antonio Martin H.","57465|GECCO|2005|The application of antigenic search techniques to time series forecasting|Time series have been a major topic of interest and analysis for hundreds of years, with forecasting a central problem. A large body of analysis techniques has been developed, particularly from methods in statistics and signal processing. Evolutionary techniques have only recently have been applied to time series problems. To date, applications of artificial immune system (AIS) techniques have been in the area of anomaly detection. In this paper we apply AIS techniques to the forecasting problem. We characterize a class of search algorithms we call antigenic search and show their ability to give a good forecast of next elements in series generated from Mackey-Glass and Lorenz equations.|Ian Nunn,Tony White","65544|AAAI|2005|Towards Learning Stochastic Logic Programs from Proof-Banks|Stochastic logic programs combine ideas from probabilistic grammars with the expressive power of definite clause logic as such they can be considered as an extension of probabilistic context-free grammars. Motivated by an analogy with learning tree-bank grammars, we study how to learn stochastic logic programs from proof-trees. Using proof-trees as examples imposes strong logical constraints on the structure of the target stochastic logic program. These constraints can be integrated in the least general generalization (lgg) operator, which is employed to traverse the search space. Our implementation employs a greedy search guided by the maximum likelihood principle and failure-adjusted maximization. We also report on a number of simple experiments that show the promise of the approach.|Luc De Raedt,Kristian Kersting,Sunna Torge","65473|AAAI|2005|Using Domain-Configurable Search Control for Probabilistic Planning|We describe how to improve the performance of MDP planning algorithms by modifying them to use the search-control mechanisms of planners such as TLPlan, SHOP, and TALplanner. In our experiments, modified versions of RTDP, LRTDP, and Value Iteration were exponentially faster than the original algorithms. On the largest problems the original algorithms could solve, the modified ones were about , times faster. On another set. of problems whose state spaces were more than , times larger than the original algorithms could solve, the modified algorithms took only about  second.|Ugur Kuter,Dana S. Nau"],["65606|AAAI|2005|Using Modified Lasso Regression to Learn Large Undirected Graphs in a Probabilistic Framework|Learning the structures of large undirected graphs with thousands of nodes from data has been an open challenge. In this paper, we use graphical Gaussian model (GGM) as the underlying model and propose a novel ARD style Wishart prior for the precision matrix of the GGM. which encodes the graph structure we want to learn. With this prior, we can get the MAP estimation of the precision matrix by solving (a modified version of) Lasso regressions and achieve a sparse solution. We use our approach to learn genetic regulatory networks from genome-wide expression microarray data and protein-binding location analysis data. Evaluated on the basis of consistency with the GO annotations, the experiments show that our approach has a much better performance than the clustering-based approaches and BN learning approaches in discovering gene regulatory modules.|Fan Li,Yiming Yang","57363|GECCO|2005|Co-evolving recurrent neurons learn deep memory POMDPs|Recurrent neural networks are theoretically capable of learning complex temporal sequences, but training them through gradient-descent is too slow and unstable for practical use in reinforcement learning environments. Neuroevolution, the evolution of artificial neural networks using genetic algorithms, can potentially solve real-world reinforcement learning tasks that require deep use of memory, i.e. memory spanning hundreds or thousands of inputs, by searching the space of recurrent neural networks directly. In this paper, we introduce a new neuroevolution algorithm called Hierarchical Enforced SubPopulations that simultaneously evolves networks at two levels of granularity full networks and network components or neurons. We demonstrate the method in two POMDP tasks that involve temporal dependencies of up to thousands of time-steps, and show that it is faster and simpler than the current best conventional reinforcement learning system on these tasks.|Faustino J. Gomez,J√ºrgen Schmidhuber","57454|GECCO|2005|Optimizing parameters of a mobile ad hoc network protocol with a genetic algorithm|Mobile ad hoc networks are typically designed and evaluated in generic simulation environments. However the real conditions in which these networks are deployed can be quite different in terms of RF attentution, topology, and traffic load. Furthermore, specific situations often have a need for a network that is optimized along certain characteristics such as delay, energy or overhead. In response to the variety of conditions and requirements, ad hoc networking protocols are often designed with many modifiable parameters. However, there is currently no methodical way for choosing values for the parameters other than intuition and broad experience. In this paper we investigate the use of genetic algorithms for automated selection of parameters in an ad hoc networking system. We provide experimental results demonstrating that the genetic algorithm can optimize for different classes of operating conditions. We also compare our genetic algorithm optimization against hand-tuning in a complex, realistic scenario and show how the genetic algorithm provides better performance.|David J. Montana,Jason Redi","57565|GECCO|2005|BeeAdHoc an energy efficient routing algorithm for mobile ad hoc networks inspired by bee behavior|In this paper we present BeeAdHoc, a new routing algorithm for energy efficient routing in mobile ad hoc networks. The algorithm is inspired by the foraging principles of honey bees. The algorithm mainly utilizes two types of agents, scouts and foragers, for doing routing in mobile ad hoc networks. BeeAdHoc is a reactive source routing algorithm and it consumes less energy as compared to existing state-of-the-art routing algorithms because it utilizes less control packets to do routing. The results of our extensive simulation experiments show that BeeAdHoc consumes significantly less energy as compared to DSR, AODV, and DSDV, which are state-of-the-art routing algorithms, without making any compromise on traditional performance metrics (packet delivery ratio, delay and throughput).|Horst Wedde,Muddassar Farooq,Thorsten Pannenbaecker,Bjoern Vogel,Christian Mueller,Johannes Meth,Rene Jeruschkat","57367|GECCO|2005|Discriminating and visualizing anomalies using negative selection and self-organizing maps|An immune inspired model that can detect anomalies, even when trained only with normal samples, and can learn from encounters with new anomalies is presented. The model combines a negative selection algorithm and a self-organizing map (SOM) in an immune inspired architecture. The proposed system is able to produce a visual representation of the selfnon-self feature space, thanks to the topological -dimensional map produced by the SOM. Some experiments were performed on classification data the results are presented and discussed.|Fabio A. Gonz√°lez,Juan Carlos Galeano,Diego Alexander Rojas,Ang√©lica Veloza-Suan","65523|AAAI|2005|Markov Decision Processes for Control of a Sensor Network-based Health Monitoring System|Optimal use of energy is a primary concern in fielddeployable sensor networks. Artificial intelligence algorithms offer the capability to improve the performance or sensor networks in dynamic environments by minimizing energy utilization while not compromising overall performance. However, they have been used only to a limited extent in sensor networks primarily due to their expensive computing requirements. We describe the use of Markov decision processes for the adaptive control of sensor sampling rates in a sensor network used for human health monitoring. The MDP controller is designed to gather optimal information about the patient's health while guaranteeing a minimum lifetime of the system. At every control step, the MDP controller varies the frequency at which the data is collected according to the criticality of the patient's health at that time. We present a stochastic model that is used to generate the optimal policy offline. In cases where a model of the observed process is not available a-priori. we descrihe a Q-learning technique to learn the control policy, by using a pre-existing master controller. Simulation results that illustrate the performance of the controller are presented.|Anand Panangadan,Syed Muhammad Ali,Ashit Talukder","57427|GECCO|2005|Nonlinear feature extraction using a neuro genetic hybrid|Feature extraction is a process that extracts salient features from observed variables. It is considered a promising alternative to overcome the problems of weight and structure optimization in artificial neural networks. There were many nonlinear feature extraction methods using neural networks but they still have the same difficulties arisen from the fixed network topology. In this paper, we propose a novel combination of genetic algorithm and feedforward neural networks for nonlinear feature extraction. The genetic algorithm evolves the feature space by utilizing characteristics of hidden neurons. It improved remarkably the performance of neural networks on a number of real world regression and classification problems.|Yung-Keun Kwon,Byung Ro Moon","57558|GECCO|2005|Constructing good learners using evolved pattern generators|Self-organization of brain areas in animals begins prenatally, evidently driven by spontaneously generated internal patterns. The neural structures continue to develop postnatally when the sensory systems are exposed to stimuli from the environment. In this process, prenatal training may give the neural system the appropriate bias so that it can learn reliably under changing environmental stimuli. This paper evaluates the hypothesis that an artificial learning system can benefit from a similar approach, consisting of initial training with patterns from an evolved generator followed by training with the actual training set. Competitive learning networks were trained in recognizing handwritten digits in three ways through environmental learning only, through evolution only, and through prenatal training with evolved pattern generators followed by environmental learning. The results demonstrate that the evolved pattern generator approach leads to better learning performance, suggesting that complex systems can be constructed effectively in this way.|Vinod K. Valsalam,James A. Bednar,Risto Miikkulainen","57568|GECCO|2005|Modeling systems with internal state using evolino|Existing Recurrent Neural Networks (RNNs) are limited in their ability to model dynamical systems with nonlinearities and hidden internal states. Here we use our general framework for sequence learning, EVOlution of recurrent systems with LINear Outputs (Evolino), to discover good RNN hidden node weights through evolution, while using linear regression to compute an optimal linear mapping from hidden state to output. Using the Long Short-Term Memory RNN Architecture, Evolino outperforms previous state-of-the-art methods on several tasks ) context-sensitive languages, ) multiple superimposed sine waves.|Daan Wierstra,Faustino J. Gomez,J√ºrgen Schmidhuber","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule"]]},"title":{"entropy":6.021567277534487,"topics":["evolutionary for, solving problem, artificial immune, for function, evolutionary the, differential evolution, evolutionary optimization, from data, vector machines, for scheduling, support vector, evolutionary and, dynamic environments, support machines, evolutionary algorithm, evolutionary computation, for optimization, evolution strategies, the function, the artificial","genetic algorithm, algorithm for, genetic for, genetic programming, algorithm the, using genetic, the problem, and genetic, using algorithm, genetic the, for problem, with genetic, search space, evolutionary algorithm, with algorithm, word disambiguation, combinatorial auction, and algorithm, word sense, the search","particle swarms, particle optimization, swarms optimization, classifier system, bayesian network, framework for, and constraints, the plans, for constraints, knowledge for, multiobjective optimization, for inference, for and, analysis and, and system, inference and, and the, and gene, reasoning, optimization with","learning for, for network, system for, negative selection, natural language, planning for, for, markov models, neural network, agents and, for control, network training, planning domains, planning with, for and, and planning, selection for, models for, for domains, with environments","for function, differential evolution, evolution strategies, evolution for, multimodal function, and strategies, for multimodal, differential for, function and, using function, using evolution, strategies for, for using, feature, using, efficient, user, prediction, recognition, extraction","for scheduling, for dynamic, dynamic environments, algorithm scheduling, the scheduling, the environments, dynamic, fitness, simple, large-scale, dimensional, data, case, network","algorithm the, for problem, the problem, genetic the, for the, and the, algorithm problem, and its, genetic problem, and problem, evolutionary the, the application, evolutionary problem, algorithm for, genetic for, the, crossover, mutation, applied, exploration","genetic algorithm, algorithm for, algorithm the, with algorithm, genetic for, search space, optimization algorithm, with search, parallel genetic, and algorithm, estimation distribution, and search, based algorithm, hybrid for, genetic the, genetic search, the search, hybrid algorithm, hybrid genetic, parallel algorithm","framework for, for and, and, towards, diagnosis, mapping, comparison, from, solutions, interactive","and constraints, bayesian network, for constraints, optimization with, and evolution, and gene, with, inference, programs, global, temporal, pomdps, probabilistic, using, learning","system for, planning for, new for, and planning, heuristic for, planning with, approach for, and system, with for, application, search, communication, modeling, monitoring","natural language, state, value, applying, testing, semantic, finite, error, representation, the, for"],"ranking":[["65605|AAAI|2005|Unsupervised and Semi-Supervised Multi-Class Support Vector Machines|We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.|Linli Xu,Dale Schuurmans","57555|GECCO|2005|Using evolutionary computation methods to support analytical models for the evolution and maintenance of conditional strategies in |Biologists have developed models to explain why different environmentally induced morphs of the same organism exist over time. Such conditional strategies are a common form of adaptation to variable environments, whereby an environmental cue allows some individuals to respond to the cue and develop into a morph that is different from the morph of individuals that do not receive the cue. Recently, these efforts have resulted in two different analytical models that give somewhat different predictions. Here we apply evolutionary computation methods to test the two analytical models. The results bear a remarkable similarity to the results of one of the two analytical models. The paper that follows presents the details of a biological application involving snails and barnacles (that occur naturally in two different morphs), moving then to an explanation of two competing mathematical models of the application. Finally, the interdisciplinary paper, which coordinates three separate research projects of a biologist, a mathematician and a computer scientist, describes the evolutionary computation methods used to support one of the two competing analytical models.|Gloria Childress Townsend,Wade N. Hazel,Rick Smock","57480|GECCO|2005|Evolutionary strategies for multi-scale radial basis function kernels in support vector machines|In support vector machines (SVM), the kernel functions which compute dot product in feature space significantly affect the performance of classifiers. Each kernel function is suitable for some tasks. A universal kernel is not possible, and the kernel must be chosen for the tasks under consideration by hand. In order to obtain a flexible kernel function, a family of radial basis function (RBF) kernels is proposed. Multi-scale RBF kernels are combined by including weights. Then, the evolutionary strategies are used to adjust these weights and the widths of the RBF kernels. The proposed kernel is proved to be a Mercer's kernel. The experimental results show that the use of multi-scale RBF kernels result in better performance than that of a single Gaussian RBF on benchmarks.|Tanasanee Phienthrakul,Boonserm Kijsirikul","57354|GECCO|2005|An artificial immune network for multimodal function optimization on dynamic environments|Multimodal optimization algorithms inspired by the immune system are generally characterized by a dynamic control of the population size and by diversity maintenance along the search. One of the most popular proposals is denoted opt-aiNet (artificial immune network for optimization) and is extended here to deal with time-varying fitness functions. Additional procedures are designed to improve the overall performance and the robustness of the immune-inspired approach, giving rise to a version for dynamic optimization, denoted dopt-aiNet. Firstly, challenging benchmark problems in static multimodal optimization are considered to validate the new proposal. No parameter adjustment is necessary to adapt the algorithm according to the peculiarities of each problem. In the sequence, dynamic environments are considered, and usual evaluation indices are adopted to assess the performance of dopt-aiNet and compare with alternative solution procedures available in the literature.|Fabr√≠cio Olivetti de Fran√ßa,Fernando J. Von Zuben,Leandro Nunes de Castro","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57459|GECCO|2005|Morphing methods in evolutionary design optimization|Design optimization is a well established application field of evolutionary computation. However, standard recombination operators acting on the genotypic representation of the design or shape are often too disruptive to be useful during optimization. In this work, we will analyze whether morphing methods between two shapes can be used as recombination operators acting on the phenotype space, thus directly on the shape or design. We introduce three different morphing methods and employ them as recombination operators in a standard evolution strategy (es). We compare their performance with an evolution strategy without any recombination operators on two target shape approximation problem. We can conclude that two of the three morphing methods can be useful during search although all morphing methods still turn out to hinder the self-adaptation of the step sizes of the evolution strategy.|Michael Nashvili,Markus Olhofer,Bernhard Sendhoff","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","57444|GECCO|2005|Using evolutionary optimization to improve Markov-based classification with limited training data|Bayesian classification using Markov model analysis of token strings is used in many areas such as computational linguistics, speech recognition, and bioinformatics. Unfortunately, for many problems, the available data sets are too small to accurately estimate the large number of parameters in a Markov model. In our work, we explore the possibility of using string space transformations to reduce the perplexity of the modeling problem and thereby improve model performance. The set of all possible string-to-string transformation functions is very large. By using a genetic algorithm to search for transformation functions that improve the performance of a Markov-based classifier, we are able to construct a classifier system that performs better than the Markov classifier alone. We go on to demonstrate the improved performance on the problem of classifying English and Spanish character strings, where training set size is arbitrarily limited.|Timothy Meekhof,Robert B. Heckendorn","57479|GECCO|2005|Evolutionary optimization of dynamic control problems accelerated by progressive step reduction|In this paper, we describe the use of an evolutionary algorithm (EA) to solve dynamic control optimization problems in engineering. In this class of problems, a set of control variables must be manipulated over time to optimize the outcome, which is obtained by solving a set of differential equations for the state variables. A new problem-specific technique, progressive step reduction (PSR), is shown to considerably improve the efficiency of the algorithm for this application. Factorial experimentation and rigorous statistical analysis are used to determine the effects of PSR and tune the parameters of the algorithm.|Q. Tuan Pham","57422|GECCO|2005|Evolutionary algorithms for the self-organized evolution of networks|While the evolution of biological networks can be modeled sensefully as a series of mutation and selection, evolution of other networks such as the social network in a city or the network of streets in a country is not determined by selection since there is no alternative network with which these singular networks have to compete. Nonetheless, these singular networks do evolve due to dynamic changes of vertices and edges. In this article we present a formal, analyzable framework for the evolution of singular networks. We show that the careful design of adaptation rules can lead to the emergence of network topologies with satisfying performance in polynomial time while other adaptation rules yield exponential runtime. We further show by example how the framework could be applied to some ad-hoc communication scenarios.|Katharina Anna Lehmann,Michael Kaufmann"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","57269|GECCO|2005|Inexact pattern matching using genetic algorithm|A Genetic Algorithm for graphical pattern matching based on angle matching had been proposed. It has proven quite effective in matching simple patterns. However, the algorithm needs some modifications to enhance its accuracy on pattern matching when there are some differences between two patterns in terms of numbers of nodes, shapes and rotations. This paper presents the modifications, such as the introduction of node exemption, inexact matching between straight lines and curves in the patterns, and consideration of rotational degrees of the patterns. Each angle is also given with a weight to indicate the significant degree of the angle. A multi-objective function is used to reflect the similarity between two patterns. The experiments designed to evaluate the algorithm have shown very promising results. It is highly accurate on patterns matching with dissimilarities in shapes, numbers of nodes and rotational degrees.|Surapong Auwatanamongkol","57322|GECCO|2005|Directional self-learning of genetic algorithm|In order to overcome the low convergence speed and prematurity of classical genetic algorithm, an improved method named directional self-learning of genetic algorithm (DSLGA) is proposed in this paper. Through the self-learning operator directional information was introduced in local search process. The search direction was guided by the false derivative of the function fitness. Using the four operators among the individuals, the best solution was updated continuously. In experiments, DSLGA was tested on  unconstrained benchmark problems, and the results were compared with the algorithms presented recently. It showed that DSLGA performs much better than the other algorithms both in the quality of the solutions and in the computational complexity.|Lin Cong,Yuheng Sha,Licheng Jiao,Fang Liu","57314|GECCO|2005|MDGA motif discovery using a genetic algorithm|Computationally identifying transcription factor binding sites in the promoter regions of genes is an important problem in computational biology and has been under intensive research for a decade. To predict the binding site locations efficiently, many algorithms that incorporate either approximate or heuristic techniques have been developed. However, the prediction accuracy is not satisfactory and binding site prediction thus remains a challenging problem. In this paper, we develop an approach that can be used to predict binding site motifs using a genetic algorithm. Based on the generic framework of a genetic algorithm, the approach explores the search space of all possible starting locations of the binding site motifs in different target sequences with a population that undergoes evolution. Individuals in the population compete to participate in the crossovers and mutations occur with a certain probability. Initial experiments demonstrated that our approach could achieve high prediction accuracy in a small amount of computation time. A promising advantage of our approach is the fact that the computation time does not explicitly depend on the length of target sequences and hence may not increase significantly when the target sequences become very long.|Dongsheng Che,Yinglei Song,Khaled Rasheed","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57474|GECCO|2005|A hybrid genetic algorithm with pattern search for finding heavy atoms in protein crystals|One approach for determining the molecular structure of proteins is a technique called iso-morphous replacement, in which crystallographers dope protein crystals with heavy atoms, such as mercury or platinum. By comparing measured amplitudes of diffracted x-rays through protein crystals with and without the heavy atoms, the locations of the heavy atoms can be estimated. Once the locations of the heavy atoms are known, the phases of the diffracted x-rays through the protein crystal can be estimated, which in turn enables the structure of the protein to be estimated. Unfortunately, the key step in this process is the estimation of the locations of the heavy atoms, and this is a multi-modal, non-linear inverse problem. We report results of a pilot study that show that a -stage hybrid algorithm, using a stochastic genetic algorithm for stage  followed by a deterministic pattern search algorithm for stage , can successfully locate up to  heavy atoms in computer simulated crystals using noise free data. We conclude that the method may be a viable approach for finding heavy atoms in protein crystals, and suggest ways in which the approach can be scaled up to larger problems.|Joshua L. Payne,Margaret J. Eppstein","57428|GECCO|2005|Multiplex PCR primer design for gene family using genetic algorithm|The multiplex PCR experiment is to amplify multiple regions of a DNA sequence at the same time by using different primer pairs. Designing feasible primer pairs for multiplex PCR is a tedious task since there are too many constraints to be satisfied. In this paper, a new method for multiplex PCR primer design strategy using genetic algorithm is proposed. The proposed algorithm is able to find a set of suitable primer pairs more efficient and uses a MAP model to speed up the examination of the specificity constraint that is important for gene family sequences. The dry-dock experiment shows that the proposed algorithm finds several sets of primer pairs of gene family sequences for multiplex PCR that not only obey the design properties, but also have specificity.|Hong-Long Liang,Chungnan Lee,Jain-Shing Wu","57432|GECCO|2005|Primer design for multiplex PCR using a genetic algorithm|Multiplex Polymerase Chain Reaction (PCR) experiments are used for amplifying several segments of the target DNA simultaneously and thereby to conserve template DNA, reduce the experimental time, and minimize the experimental expense. The success of the experiment is dependent on primer design. However, this can be a dreary task as there are many constrains such as melting temperatures, primer length, GC content and complementarity that need to be optimized to obtain a good PCR product. Motivated by the lack of primer design tools for multiplex PCR genotypic assay, we propose a multiplex PCR primer design tool using a genetic algorithm, which is a stochastic approach based on the concept of biological evolution, biological genetics and genetic operations on chromosomes, to find an optimal selection of primer pairs for multiplex PCR experiments. The presented experimental results indicate that the proposed algorithm is capable of finding a series of primer pairs that obeies the design properties in the same tube.|Feng-Mao Lin,Hsien-Da Huang,Hsi-Yuan Huang,Jorng-Tzong Horng","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57492|GECCO|2005|Particle swarm optimization for analysis of mass spectral serum profiles|Serum profiling using mass spectrometry is an emerging technology with a great potential to provide biomarkers for complex diseases such as cancer. However, protein profiles obtained from current mass spectrometric technologies are characterized by their high dimensionality and complex spectra with substantial level of noise. These characteristics have generated challenges in discovery of proteins and protein-profiles that distinguish cancer patients from healthy individuals. This paper proposes a novel machine learning method that combines support vector machines with particle swarm optimization for biomarker discovery. Prior to applying the proposed biomarker selection algorithm, low-level analysis methods are used for smoothing, baseline correction, normalization, and peak detection. The proposed method is applied for biomarker discovery from serum mass spectral profiles of liver cancer patients and controls.|Habtom W. Ressom,Rency S. Varghese,Daniel Saha,Eduard Orvisky,Lenka Goldman,Emanuel F. Petricoin,Thomas P. Conrads,Timothy D. Veenstra,Mohamed Abdel-Hamid,Christopher A. Loffredo,Radoslav Goldman","57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","65559|AAAI|2005|Development of a Hybrid Knowledge-Based System for Multiobjective Optimization of Power Distribution System Operations|The development of a hybrid knowledge-based system with a coupling between knowledge-based and numerical methods for multiobjective optimization of power distribution operations is described. The advantages of a hybrid knowledge-based system are described followed by the system objectives, means of control, and constraints. A framework is provided that describes the necessary development stages of a commercial knowledge-based package. An overview of the utility knowledge acquisition procedure is provided to appreciate the complexity of defining the rule base. This is followed by a description of the flow of information in a three-level hierarchical rule base and a summary of network radiality, parameter. and performance rules employed in this rule base. After a heuristic preprocessor identifies a list of switch closures that would seem to reduce total system losses, network radiality rules assess if a particular search path has identified a switch that can be closed and a corresponding switch opened to maintain the radiality of the system or if the path is worth pursuing further. Network parameter rules ensure the system operates within original design parameters. Network performance rules assess the reduction in total system losses of each proposed switching operation. Where there is a coupling between knowledge-based and numerical methods, the integration of numerical methods is described. Finally, the validation and simulations as well as the benefits of this hybrid knowledge-based system are described.|Robert J. S√°rfi,A. M. G. Solo","57476|GECCO|2005|Multiobjective shape optimization with constraints based on estimation distribution algorithms and correlated information|A new approach based on Estimation Distribution Algorithms for constrained multiobjective shape optimization is proposed in this article. Pareto dominance and feasibility rules are used to handle constraints. The algorithm uses feasible and infeasible individuals to estimate the probability distribution of evolving designs. Additionally, correlation among problem design variables is used to improve exploration. The design objectives are minimum weight and minimum nodal displacement. Also, the resulting structures must fulfill three design constraints a) maximum permissible Von Misses stress, b)connectedness of the structure elements, and c) small holes are not allowed in the structure. The finite element method is used to evaluate the objective functions and stress constraint.|Sergio Ivvan Valdez Pe√±a,Salvador Botello Rionda,Arturo Hern√°ndez Aguirre","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty"],["65429|AAAI|2005|Fast Planning in Domains with Derived Predicates An Approach Based on Rule-Action Graphs and Local Search|The ability to express \"derived predicates\" in the formalization of a planning domain is both practically and theoretically important. In this paper, we propose an approach to planning with derived predicates where the search space consists of \"Rule-Action Graphs\", particular graphs of actions and rules representing derived predicates. We present some techniques for representing rules and reasoning with them, which are integrated into a method for planning through local search and rule-action graphs. We also propose some new heuristics for guiding the search, and some experimental results illustrating the performance of our approach. Our proposed techniques are implemented in a planner that took part in the fourth International Planning Competition showing good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina,Paolo Toninelli","65362|AAAI|2005|Using SAT and Logic Programming to Design Polynomial-Time Algorithms for Planning in Non-Deterministic Domains|We show that a Horn SAT and logic programming approach to obtain polynomial time algorithms for problem solving can be fruitfully applied to finding plans for various kinds of goals in a non-deterministic domain. We particularly focus on finding weak, strong, and strong cyclic plans for planning problems, as they are the most studied ones in the literature. We describe new algorithms for these problems and show how non-monotonic logic programming can be used to declaratively compute strong cyclic plans. As a further benefit, preferred plans among alternative candidate plans may be singled out this way. We give complexity results for weak. strong, and strong cyclic planning. Finally, we briefly discuss some of the kinds of goals in non-deterministic domains for which the approach in the paper can be used.|Chitta Baral,Thomas Eiter,Jicheng Zhao","65453|AAAI|2005|A Discourse Planning Approach to Cinematic Camera Control for Narratives in Virtual Environments|As the complexity of narrative-based virtual environments grows, the need for effective communication of information to the users of these systems increase. Effective camera control for narrative-oriented virtual worlds involves decision making at three different levels choosing cinematic geometric composition, choosing the best camera parameters for conveying affective information, and choosing camera shots and transitions to maintain thetorical coherence. We propose a camera planning system that mirrors the film production pipeline we describe our formalization of film idioms used to communicate affective information. Our representation of idioms captures their hierarchical nature, represents the causal motivation for selection of shots, and provides a way for the system designer to specify the ranking of candidate shot sequences.|Arnav Jhala,R. Michael Young","65578|AAAI|2005|Conformant Planning for Domains with Constraints-A New Approach|The paper presents a pair of new conformant planners, CPApc and CPAph, based on recent developments in theory of action and change. As an input the planners take a domain description D in action language AL which allows state constraints (non-stratified axioms), together with a set of CNF formulae describing the initial state, and a set of literals representing the goal. We propose two approximations of the transition diagram T defined by D. Both approximations are deterministic transition functions and can be computed efficiently. Moreover they are sound (and sometimes complete) with respect to T. In its search for a plan, an approximation based planner analyses paths of an approximation instead of that of T. CPApc and CPAph are forward, best first search planners based on this idea. We compare them with two state-of-the-art conformant planners, KACMBP and Conformant-FF (CFF), over benchmarks in the literature, and over two new domains. One has large number of state constraints and another has a high degree of incompleteness. Our planners perform reasonably well in benchmark domains and outperform KACMBP and CFF in the first domain while still working well with the second one. Our experimental result shows that having an integral part of a conformant planner to deal with state constraints directly can significantly improve its performance extending a similar claim for classical planners in (Thiebaux. Hoffmann, & Nebel ).|Tran Cao Son,Phan Huy Tu,Michael Gelfond,A. Ricardo Morales","65613|AAAI|2005|Learning Measures of Progress for Planning Domains|We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress (parmar ), which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results.|Sung Wook Yoon,Alan Fern,Robert Givan","65451|AAAI|2005|Planning in Models that Combine Memory with Predictive Representations of State|Models of dynamical systems based on predictive state representations (PSRs) use predictions of future observations as their representation of state. A main departure from traditional models such as partially observable Markov decision processes (POMDPs) is that the PSR-model state is composed entirely of observable quantities. PSRs have recently been extended to a class of models called memory-PSRs (mPSRs) that use both memory of past observations and predictions of future observations in their state representation. Thus, mPSRs preserve the PSR-property of the state being composed of observable quantities while potentially revealing structure in the dynamical system that is not exploited in PSRs. In this paper, we demonstrate that the structure captured by mPSRs can be exploited quite naturally for stochastic planning based on value-iteration algorithms. In particular, we adapt the incremental-pruning (IP) algorithm defined for planning in POMDPs to mPSRs. Our empirical results show that our modified IP on mPSRs outperforms, in most cases, IP on both PSRs and POMDPs.|Michael R. James,Satinder P. Singh","65577|AAAI|2005|Minimizing Environmental Swings with a Recurrent Neural Network Control System|Maintaining environmental stability in a dynamic system is a difficult challenge. In your living room, when you set your thermostat to  degrees the actual temperature cycles above and below  degrees. We attempt to use a Recurrent Neural Network (RNN) in an Aquarium Control System that reduces such environmental swings.|Sam Skrivan,Jianna Zhang,Debra S. Jusak","65523|AAAI|2005|Markov Decision Processes for Control of a Sensor Network-based Health Monitoring System|Optimal use of energy is a primary concern in fielddeployable sensor networks. Artificial intelligence algorithms offer the capability to improve the performance or sensor networks in dynamic environments by minimizing energy utilization while not compromising overall performance. However, they have been used only to a limited extent in sensor networks primarily due to their expensive computing requirements. We describe the use of Markov decision processes for the adaptive control of sensor sampling rates in a sensor network used for human health monitoring. The MDP controller is designed to gather optimal information about the patient's health while guaranteeing a minimum lifetime of the system. At every control step, the MDP controller varies the frequency at which the data is collected according to the criticality of the patient's health at that time. We present a stochastic model that is used to generate the optimal policy offline. In cases where a model of the observed process is not available a-priori. we descrihe a Q-learning technique to learn the control policy, by using a pre-existing master controller. Simulation results that illustrate the performance of the controller are presented.|Anand Panangadan,Syed Muhammad Ali,Ashit Talukder","57469|GECCO|2005|Evolving neural network ensembles for control problems|In neuroevolution, a genetic algorithm is used to evolve a neural network to perform a particular task. The standard approach is to evolve a population over a number of generations, and then select the final generation's champion as the end result. However, it is possible that there is valuable information present in the population that is not captured by the champion. The standard approach ignores all such information. One possible solution to this problem is to combine multiple individuals from the final population into an ensemble. This approach has been successful in supervised classification tasks, and in this paper, it is extended to evolutionary reinforcement learning in control problems. The method is evaluated on a challenging extension of the classic pole balancing task, demonstrating that an ensemble can achieve significantly better performance than the champion alone.|David Pardoe,Michael S. Ryoo,Risto Miikkulainen","65490|AAAI|2005|Distribution-Free Learning of Bayesian Network Structure in Continuous Domains|In this paper we present a method for learning the structure of Bayesian networks (BNs) without making any assumptions on the probability distribution of the domain. This is mainly useful for continuous domains, where there is little guidance and many choices for the parametric distribution families to be used for the local conditional probabilities of the Bayesian network, and only a few have been examined analytically. We therefore focus on BN structure learning in continuous domains. We address the problem by developing a conditional independence test for continuous variables, which can be readily used by any existing independence-based BN structure learning algorithm. Our test is non-parametric, making no assumptions on the distribution of the domain. We also provide an effective and computationally efficient method for calculating it from data. We demonstrate the learning of the structure of graphical models in continuous domains from real-world data, to our knowledge for the first time using independence-based methods and without distributional assumptions. We also experimentally show that our test compares favorably with existing statistical approaches which use prediscretization, and verify desirable properties such as statistical consistency.|Dimitris Margaritis"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57512|GECCO|2005|Using gene deletion and gene duplication in evolution strategies|Self-adaptation of the mutation strengths is a powerful mechanism in evolution strategies (ES), but it can fail. As a consequence premature convergence or ending up in a local optimum in multi-modal fitness landscapes can occur. In this article a new approach controlling the process of self-adaptation is proposed. This approach combines the old ideas of gene deletion and gene duplication with the self-adaptation mechanism of the ES. Gene deletion and gene duplication is used to vary the number of independent mutation strengths. In order to demonstrate the practicability of the new approach several multi-modal test functions are used. Methods from statistical design of experiments and regression tree methods are applied to improve the performance of a specific heuristic-problem combination.|Karlheinz Schmitt","57463|GECCO|2005|Enhancing differential evolution performance with local search for high dimensional function optimization|In this paper, we proposed Fittest Individual Refinement (FIR), a crossover based local search method for Differential Evolution (DE). The FIR scheme accelerates DE by enhancing its search capability through exploration of the neighborhood of the best solution in successive generations. The proposed memetic version of DE (augmented by FIR) is expected to obtain an acceptable solution with a lower number of evaluations particularly for higher dimensional functions. Using two different implementations DEfirDE and DEfirSPX we showed that proposed FIR increases the convergence velocity of DE for well known benchmark functions as well as improves the robustness of DE against variation of population. Experiments using multimodal landscape generator showed our proposed algorithms consistently outperformed their parent algorithms. A performance comparison with reported results of well known real coded memetic algorithms is also presented.|Nasimul Noman,Hitoshi Iba","57555|GECCO|2005|Using evolutionary computation methods to support analytical models for the evolution and maintenance of conditional strategies in |Biologists have developed models to explain why different environmentally induced morphs of the same organism exist over time. Such conditional strategies are a common form of adaptation to variable environments, whereby an environmental cue allows some individuals to respond to the cue and develop into a morph that is different from the morph of individuals that do not receive the cue. Recently, these efforts have resulted in two different analytical models that give somewhat different predictions. Here we apply evolutionary computation methods to test the two analytical models. The results bear a remarkable similarity to the results of one of the two analytical models. The paper that follows presents the details of a biological application involving snails and barnacles (that occur naturally in two different morphs), moving then to an explanation of two competing mathematical models of the application. Finally, the interdisciplinary paper, which coordinates three separate research projects of a biologist, a mathematician and a computer scientist, describes the evolutionary computation methods used to support one of the two competing analytical models.|Gloria Childress Townsend,Wade N. Hazel,Rick Smock","57513|GECCO|2005|Using predators and preys in evolution strategies|This poster presents an evolution strategy for single- and multi-objective optimization. The model uses the predator-prey approach from ecology to scale between both cases. Furthermore the main issue of adaptation working for single- and multi-objective problem-instances equally is discussed. Particular, the well proved self-adaptation mechanism for the mutation strengths in the single-objective case is adopted for the multi-objective one. This self-adaptation process is supported by a new strategy of competition between predators and preys. Six test functions are used to demonstrate the practicability of the model.|Karlheinz Schmitt,J√∂rn Mehnen,Thomas Michelitsch","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","57468|GECCO|2005|A hardware pipeline for function optimization using genetic algorithms|Genetic Algorithms (GAs) are very commonly used as function optimizers, basically due to their search capability. A number of different serial and parallel versions of GA exist. In this paper, a pipelined version of the commonly used Genetic Algorithms and a corresponding hardware platform is described. The main idea of achieving pipelined execution of different operations of GA is to use a stochastic selection function which works with the fitness value of the candidate chromosome only. The modified algorithm is termed PLGA (Pipelined Genetic Algorithm). When executed in a CGA (Classical Genetic Algorithm) framework, the stochastic selection gives comparable performances with the roulette-wheel selection. In the pipelined hardware environment, PLGA will be much faster than the CGA. When executed on similar hardware platforms, PLGA may attain a maximum speedup of four over CGA. However, if CGA is executed in a uniprocessor system the speedup is much more. A comparison of PLGA against PGA (Parallel Genetic Algorithms) shows that PLGA may be even more effective than PGAs. A scheme for realizing the hardware pipeline is also presented. Since a general function evaluation unit is essential, a detailed description of one such unit is presented.|Malay Kumar Pakhira,Rajat K. De","57525|GECCO|2005|Niching in evolution strategies|EAs have the tendency to converge quickly into a single solution. Niching methods, the extension of EAs to address this issue, have been investigated up to date mainly within the field of Genetic Algorithms (GAs). In our study we investigate the basis for niching methods within Evolution Strategies (ES), and propose the first ES niching method. Results show that this method can reliably find and maintain multiple niches even for high-dimensional problems.|Ofer M. Shir,Thomas B√§ck","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li","57277|GECCO|2005|Adaptive isolation model using data clustering for multimodal function optimization|In this paper, we propose a GA model called Adaptive Isolation Model(AIM), for multimodal optimization. It uses a data clustering algorithm to detect clusters in GA population, which identifies the attractors in the fitness landscape. Then, subpopulations which makes-up the clusters are isolated and optimized independently. Meanwhile, the region of the isolated subpopulations in the original landscape are suppressed. The isolation increases comprehensiveness, i.e., the probability of finding weaker attractors, and the overall efficiency of multimodal search. The advantage of the AIM is that it does not require distance between the optima as a presumed parameter, as it is estimated from the variancecovariance matrix of the subpopulation.Further, AIM's behavior and efficiency is equivalent to basic GA in unimodal landscape, in terms of number of evaluation. Therefore, it is applied recursively to all subpopulations until they converge to a suboptima. This makes AIM suitable for locally-multimodal landscapes, which have closely located attractors that are difficult to distinguish in the initial run.The performance of AIM is evaluated in several benchmark problems and compared to iterated hill-climbing methods.|Shin Ando,Jun Sakuma,Shigenobu Kobayashi"],["57577|GECCO|2005|Memory-based immigrants for genetic algorithms in dynamic environments|Investigating and enhancing the performance of genetic algorithms in dynamic environments have attracted a growing interest from the community of genetic algorithms in recent years. This trend reflects the fact that many real world problems are actually dynamic, which poses serious challenge to traditional genetic algorithms. Several approaches have been developed into genetic algorithms for dynamic optimization problems. Among these approches, random immigrants and memory schemes have shown to be beneficial in many dynamic problems. This paper proposes a hybrid memory and random immigrants scheme for genetic algorithms in dynamic environments. In the hybrid scheme, the best solution in memory is retrieved and acts as the base to create random immigrants to replace the worst individuals in the population. In this way, not only can diversity be maintained but it is done more efficiently to adapt the genetic algorithm to the changing environment. The experimental results based on a series of systematically constructed dynamic problems show that the proposed memory-based immigrants scheme efficiently improves the performance of genetic algorithms in dynamic environments.|Shengxiang Yang","57354|GECCO|2005|An artificial immune network for multimodal function optimization on dynamic environments|Multimodal optimization algorithms inspired by the immune system are generally characterized by a dynamic control of the population size and by diversity maintenance along the search. One of the most popular proposals is denoted opt-aiNet (artificial immune network for optimization) and is extended here to deal with time-varying fitness functions. Additional procedures are designed to improve the overall performance and the robustness of the immune-inspired approach, giving rise to a version for dynamic optimization, denoted dopt-aiNet. Firstly, challenging benchmark problems in static multimodal optimization are considered to validate the new proposal. No parameter adjustment is necessary to adapt the algorithm according to the peculiarities of each problem. In the sequence, dynamic environments are considered, and usual evaluation indices are adopted to assess the performance of dopt-aiNet and compare with alternative solution procedures available in the literature.|Fabr√≠cio Olivetti de Fran√ßa,Fernando J. Von Zuben,Leandro Nunes de Castro","65562|AAAI|2005|Dependency Parsing with Dynamic Bayesian Network|Exact parsing with finite state automata is deemed in-apropriate because of the unbounded non-locality languages overwhelmingly exhibit. We propose a way to structure the parsing task in order to make it amenable to local classification methods. This allows us to build a Dynamic Bayesian Network which uncovers the syntactic dependency structure of English sentences. Experiments with the Wall Street Journal demonstrate that the model successfully learns from labeled data.|Virginia Savova,Leonid Peshkin","57285|GECCO|2005|Towards an analysis of dynamic environments|Although the interest in nature-inspired optimization of dynamic problems has been growing constantly over the past decade, very little has been done to analyze and characterize a changing fitness landscape. However, it would be very helpful for algorithm development to have a better understanding of the nature of fitness changes in dynamic real-world problems. In this paper, we propose a number of measures that can be used to analyze and characterize the dynamism in a problem changing over time. Additionally, we introduce a new dynamic multi-dimensional knapsack problem as a close-to-real-world test problem.|J√ºrgen Branke,Erdem Salihoglu,Sima Uyar","65457|AAAI|2005|The Deep Space Network Scheduling Problem|We describe the Deep Space Network's scheduling problem based on a user requirement language. The problem is difficult to encode by almost all existing planning and scheduling systems. We describe how it can be mapped into a system that supports metric resources, durative action, simple temporal network constraints, and task hierarchy among other language features. We also describe how we adapted a local search scheduler to generate schedules. However, we argue that the application will best serve the users if local search is combined with systematic search. We describe how an implemented systematic search can be effectively applied to rescheduling.|Bradley J. Clement,Mark D. Johnston","57373|GECCO|2005|On the analysis of the approximation capability of simple evolutionary algorithms for scheduling problems|Two of the major difficulties dealing with real-world problems nowadays are their increasing complexity and the decreasing available timespan to create \"acceptable\" solutions. Due to this and the strongly decreasing costs of CPU-power, non specialized (random) search heuristics gain more and more importance. In this paper we analyze the behavior of two very simple search heuristics on a strongly NP-hard scheduling problem. Although both find feasible solutions in pseudo-polynomial time, at least one of them is not able to present an (+)-approximation for arbitrary  with constant probability. Despite this, one of the two presented search heuristics can even compete with a problem-specific algorithm on a certain class of inputs and deliver solutions convergent to optimality for increasing problem size.|Christian Gunia","57556|GECCO|2005|Coordinating multi-rover systems evaluation functions for dynamic and noisy environments|This paper addresses the evolution of control strategies for a collective a set of entities that collectively strives to maximize a global evaluation function that rates the performance of the full system. Directly addressing such problems by having a population of collectives and applying the evolutionary algorithm to that population is appealing, but the search space is prohibitively large in most cases. Instead, we focus on evolving control policies for each member of the collective. The main difficulty with this approach is creating an evaluation function for each member of the collective that is both aligned with the global evaluation function and sensitive to the fitness changes of the member. We show how to construct evaluation functions in dynamic, noisy and communication-limited collective environments. On a rover coordination problem, a control policy evolved using aligned and member-sensitive evaluations outperforms global evaluation methods by up to %. More notably, in the presence of a larger number of rovers or rovers with noisy and communication limited sensors, the improvements due to the proposed method become significantly more pronounced.|Kagan Tumer,Adrian K. Agogino","57296|GECCO|2005|Diversity as a selection pressure in dynamic environments|Evolutionary algorithms (EAs) are widely used to deal with optimization problems in dynamic environments (DE) . When using EAs to solve DE problems, we are usually interested in the algorithm's ability to adapt and recover from the changes. One of the main problems facing an evolutionary method when solving DE problems is the loss of genetic diversity.In this paper, we investigate the use of evolutionary multi-objective optimization methods (EMOs) for single-objective DE problems. For that purpose, we introduce an artificial second objective with the aim to maintain useful diversity in the population. Six different artificial objectives are examined and compared.All the results will be compared against a traditional GA and the random immigrants algorithm. NSGA is employed as the evolutionary multi-objective technique.|Lam Thu Bui,J√ºrgen Branke,Hussein A. Abbass","65501|AAAI|2005|On the Evaluation of Dynamic Critiquing A Large-Scale User Study|Critiquing is an important form of feedback in conversational recommender systems. However, in these systems the user is usually limited to critiquing a single product feature at a time. Recently dynamic critiquing has been proposed to address this shortcoming, by automatically generating compound critiques over multiple features that may be presented to the user at recommendation time. To date a number of different versions of dynamic critiquing have been evaluated in isolation, and with reference to artificial users. In this paper we bring together the main flavors of dynamic critiquing and perform a large-scale comparative evaluation as part of an extensive real-user trial. This evaluation reveals some interesting facts about the way real users interact with critique-based recommenders.|Kevin McCarthy,Lorraine McGinty,Barry Smyth,James Reilly","57328|GECCO|2005|GATS  a novel GA-based scheduling algorithm for task scheduling on heterogeneous processor nets|We present a novel GA-based scheduling algorithm for heterogeneous processor networks that succeeds in generating task schedules with completion times that are % and .% shorter than those produced by two of the best existing scheduling algorithms for heterogeneous networks of processors HEFT  and DLS . The new algorithm (GATS .) achieves these results by employing an innovative genotype to phenotype encoding scheme and matching crossover and mutation operators. In addition, GATS . uses a simple fitness evaluation function and a small population, which makes it efficient (relative to classic GA implementations), as well as effective.|Mohammad I. Daoud,Nawwaf N. Kharma"],["57306|GECCO|2005|A hybrid evolutionary algorithm for the p-median problem|A hybrid evolutionary algorithm (EA) for the p-median problem consist of two stages, each of which is a steady-state hybrid EA. These EAs encode selections of medians as subsets of the candidate sites, apply a recombination operator tailored to the problem, and select symbols in chromosomes to mutate based on an explicit collective memory (named virtual loser). They also apply a sequence of two or three local search procedures to each new solution. Tests e.g. on the benchmark problem instances of ORLIB returned results within .% of the best solutions known.|Istv√°n Borgulya","57581|GECCO|2005|An evolutionary lagrangian method for the  multiple knapsack problem|We propose a new evolutionary approach to solve the  multiple knapsack problem. We approach the problem from a new viewpoint different from traditional methods. The most remarkable feature is the Lagrangian method. Lagrange multipliers transform the problem, keeping the optimality as well as decreasing the complexity. However, it is not easy to find Lagrange multipliers nearest to the constraints of the problem. We propose an evolution strategy to find the optimal Lagrange multipliers. Also, we improve the evolution strategy by adjusting its objective function properly. We show the efficiency of the proposed methods by the experiments. We make comparisons with existing general approach on well-known benchmark data.|Yourim Yoon,Yong-Hyuk Kim,Byung Ro Moon","57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","57358|GECCO|2005|Genetic algorithms for the sailor assignment problem|This paper examines a real-world application of genetic algorithms -- solving the United States Navy's Sailor Assignment Problem (SAP). The SAP is a complex assignment problem in which each of n sailors must be assigned one job drawn from a set of m jobs. The goal is to find a set of these assignments such that the overall desirability of the match is maximized while the cost of the match is minimized. We compare genetic algorithms to an existing algorithm, the Gale-Shapley algorithm, for generating these assignments and present empirical results showing that the GA is able to produce good solutions with significant savings in cost. Finally, we examine the possibility of using the GA to generate multiple different solutions for presentation to a human decision maker called a detailer, and we show that the GA can be used to provide a sample of good solutions.|Deon Garrett,Joseph Vannucci,Rodrigo Silva,Dipankar Dasgupta,James Simien","57341|GECCO|2005|A low-level hybridization between memetic algorithm and VNS for the max-cut problem|The Max-Cut problem consists of finding a partition of the graph nodes into two subsets, such that the sum of the edge weights having endpoints in different subsets is maximized. This NP-hard problem for non planar graphs has different applications in areas such as VLSI and ASIC design. This paper proposes an evolutionary hybrid algorithm based on low-level hybridization between Memetic Algorithms and Variable Neighborhood Search. This algorithm is tested and compared with the results, found in the bibliography, obtained by other hybrid metaheuristics for the same problem. Achieved experimental results show the suitability of the approach, and that the proposed hybrid evolutionary algorithm finds near-optimal solutions. Moreover, on a set of standard test problems, new best known solutions were produced for several instances.|Abraham Duarte,√?ngel S√°nchez,Felipe Fern√°ndez,Ra√∫l Cabido","57326|GECCO|2005|Probing for limits to building block mixing with a tunably-difficult problem for genetic programming|This paper describes a tunably-difficult problem for genetic programming (GP) that probes for limits to building block mixing and assembly. The existence of such a problem can be used to garner insight into the dynamics of what happens during the course of a GP run. The results indicate that the amount of mixing is fairly low in comparison to the amount of content that could be present in an initial population.|Jason M. Daida,Michael E. Samples,Matthew J. Byom","57392|GECCO|2005|Greedy genetic and greedy genetic algorithms for the quadratic knapsack problem|Augmenting an evolutionary algorithm with knowledge of its target problem can yield a more effective algorithm, as this presentation illustrates. The Quadratic Knapsack Problem extends the familiar Knapsack Problem by assigning values not only to individual objects but also to pairs of objects. In these problems, an object's value density is the sum of the values associated with it divided by its weight. Two greedy heuristics for the quadratic problem examine objects for inclusion in the knapsack in descending order of their value densities. Two genetic algorithms encode candidate selections of objects as binary strings and generate only strings whose selections of objects have total weight no more than the knapsack's capacity. One GA is naive its operators apply no information about the values associated with objects. The second extends the naive GA with greedy techniques from the non-evolutionary heuristics. Its operators examine objects for inclusion in the knapsack in orders determined by tournaments based on objects' value densities. All four algorithms are tested on twenty problem instances whose optimum knapsack values are known. The greedy heuristics do well, as does the naive GA, but the greedy GA exhibits the best performance. In repeated trials on the test instances, it identifies optimum solutions more than nine times out of every ten.|Bryant A. Julstrom","57557|GECCO|2005|Improvements to penalty-based evolutionary algorithms for the multi-dimensional knapsack problem using a gene-based adaptive mutation approach|Knapsack problems are among the most common problems in literature tackled with evolutionary algorithms (EA). Their major advantage lies in the fact that they are relatively simple to implement while they allow generalizations for a wide range of real world problems. The multi-dimensional knapsack problem (MKP), which belongs to the class of NP-complete combinatorial optimization problems, is one of the variations of the knapsack problem. The MKP has a wide range of real world applications such as cargo loading, selecting projects to fund, budget management, cutting stock, etc. The MKP has been studied quite extensively in the EA community. Due to the constrained nature of the problem, constraint handling techniques gain great importance in the performance of the proposed EA approaches. In this study, the applicability of a generational EA that uses a penalty-based constraint handling technique and a gene locus based, asymmetric, adaptive mutation scheme is explored for the MKP. The effects of the parameters of the explored approach is determined through tests. Further experiments, using large MKP instances from commonly used benchmarks available through the Internet are performed. Comparison tables are given for the performance of the explored approach and other good performing EAs found in literature for the MKP. Results show that performance improves greatly when compared with other penalty-based techniques, but the explored approach is still not the best performer among all. However, unlike the explored technique, the EAs using the other constraint handling techniques require a great amount of extra computational effort and need heuristic information specific to the optimization problem. Based on these observations, and the fact that the performance difference between the explored scheme and the better performers is not too high, research on improving the explored approach is still in progress.|Sima Uyar,G√ºlsen Eryigit","57274|GECCO|2005|Heuristic rules embedded genetic algorithm to solve in-core fuel management optimization problem|Because of the large number of possible combinations for the fuel assembly loading in the core, the design of the loading pattern (LP) is a complex optimization problem. It requires finding an optimal fuel arrangement in order to achieve maximum cycle length while satisfying the safety constraints. The objective of this study is to develop a loading pattern optimization code. Generally in-core fuel management codes are written for specific cores and limited fuel inventory. One of the goals of this study is to develop a loading pattern optimization code, which is applicable for all types of Pressurized Water Reactor (PWR) core structures with unlimited number of fuel assembly types in the inventory. To reach this goal an innovative genetic algorithm is developed with modifying the classical representation of the genotype. To obtain the best result in a shorter time not only the representation is changed but also the algorithm is changed to use in-core fuel management heuristics rules. The improved GA code was tested demonstrating the advantages of the introduced enhancements. The core physics code used in this research is Moby-Dick, which was developed to analyze the VVER reactors by SKODA Inc.|Fatih Alim,Kostadin Ivanov","57438|GECCO|2005|The enhanced evolutionary tabu search and its application to the quadratic assignment problem|We describe the Enhanced Evolutionary Tabu Search (EE-TS) local search technique. The EE-TS metaheuristic technique combines Reactive Tabu Search with evolutionary computing elements proven to work well in multimodal search spaces. An initial set of solutions is generated using a stochastic heuristic operator based on Restricted Candidate List. Reactive Tabu Search is augmented with selection and recombination operators that preserve common traits between solutions while maintaining a diverse set of good solutions. EE-TS performance is applied to the Quadratic Assignment Problem using problem instances from the QAPLIB. The results show that EE-TS compares favorably against other known techniques. In most cases, EE-TS was able to find the known optimal solutions in fewer iterations. We conclude by describing the main benefits and limitations of EE-TS.|John F. McLoughlin III,Walter Cede√±o"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","57322|GECCO|2005|Directional self-learning of genetic algorithm|In order to overcome the low convergence speed and prematurity of classical genetic algorithm, an improved method named directional self-learning of genetic algorithm (DSLGA) is proposed in this paper. Through the self-learning operator directional information was introduced in local search process. The search direction was guided by the false derivative of the function fitness. Using the four operators among the individuals, the best solution was updated continuously. In experiments, DSLGA was tested on  unconstrained benchmark problems, and the results were compared with the algorithms presented recently. It showed that DSLGA performs much better than the other algorithms both in the quality of the solutions and in the computational complexity.|Lin Cong,Yuheng Sha,Licheng Jiao,Fang Liu","57382|GECCO|2005|Genetic drift in univariate marginal distribution algorithm|Like Darwinian-type genetic algorithms, there also exists genetic drift in Univariate Marginal Distribution Algorithm (UMDA). Since the universal analysis of genetic drift in UMDA is very difficult, in this paper, we just approach a certain kind of problem (WOneMax Problem). For WOneMax Problem, The individual space in UMDA can be denoted as a full binary tree, and the selecting process in UMDA can be considered as a process of cutting branch. We employ this binary tree to calculate the probability change of each variable between two adjacent generations. Comparing this change with our experimental data, we find that when the population size is limited, there exists genetic drift in UMDA. In order to avoid genetic drift, we model the probability of each variable as a signal with noise, and then use smoothing filter to eliminate genetic drift. Numerical results show this method is effective.|Yi Hong,Qingsheng Ren,Jin Zeng","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57578|GECCO|2005|Flight midcourse guidance control based on genetic algorithm|An advanced flight midcourse guidance law based on genetic algorithm (GA) is proposed. The proposed midcourse guidance formulation minimizes the flight time and maximizes the terminal energy subject to a terminal intercept condition. GA is used to search the optimal attack angle for the flight trajectory. By combining GA and singular perturbation technique (SPT), the optimal flight guidance law is obtained consequently. SPT is applied to approximate the terminal flight time. Meanwhile, the paper completely eliminates the need for solving two-point boundary-value problems (TBPVP), which is too complex for derivation and implementation. The simulation results show that the resulting guidance law is near-optimal and the proposed method is valid. Especially, the GA guidance law can apply to intercept the maneuver targets successfully.|Zhao-hua Yang,Jian-cheng Fang,Zhen-qiang Qi","57474|GECCO|2005|A hybrid genetic algorithm with pattern search for finding heavy atoms in protein crystals|One approach for determining the molecular structure of proteins is a technique called iso-morphous replacement, in which crystallographers dope protein crystals with heavy atoms, such as mercury or platinum. By comparing measured amplitudes of diffracted x-rays through protein crystals with and without the heavy atoms, the locations of the heavy atoms can be estimated. Once the locations of the heavy atoms are known, the phases of the diffracted x-rays through the protein crystal can be estimated, which in turn enables the structure of the protein to be estimated. Unfortunately, the key step in this process is the estimation of the locations of the heavy atoms, and this is a multi-modal, non-linear inverse problem. We report results of a pilot study that show that a -stage hybrid algorithm, using a stochastic genetic algorithm for stage  followed by a deterministic pattern search algorithm for stage , can successfully locate up to  heavy atoms in computer simulated crystals using noise free data. We conclude that the method may be a viable approach for finding heavy atoms in protein crystals, and suggest ways in which the approach can be scaled up to larger problems.|Joshua L. Payne,Margaret J. Eppstein","57569|GECCO|2005|The impact of pseudorandom number quality on  a parallel genetic algorithm for RNA secondary structure prediction|This paper presents a parallel version of RnaPredict, a genetic algorithm (GA) for RNA secondary structure prediction. The research presented here builds on previous work and examines the impact of three different pseudorandom number generators (PRNGs) on the GA's performance. The three generators tested are the C standard library PRNG RAND, a parallelized multiplicative congruential generator (MCG), and a parallelized Mersenne Twister (MT). A fully parallel version of RnaPredict using the Message Passing Interface (MPI) was implemented. The PRNG comparison tests were performed with known structures that are , , , and  nucleotides in length. The effects of the PRNGs are investigated and the predicted structures are compared to known structures.|Kay C. Wiese,Andrew Hendriks,Alain Desch√™nes,Belgacem Ben Youssef","57574|GECCO|2005|A scalable parallel genetic algorithm for x-ray spectroscopic analysis|We use a parallel multi-objective genetic algorithm to drive a search and reconstruction spectroscopic analysis of plasma gradients in inertial confinement fusion (ICF) implosion cores. In previous work, we had shown that our serial multi-objective Genetic Algorithm was a good method to solve two-criteria X-ray spectroscopy diagnostics problems. However, this serial version was slow and we therefore could not incorporate better physics and more criteria to solve larger problems and handle larger data sets. In this paper, we develop and use a parallel multi-objective genetic algorithm based on a master-slave model to solve three criteria spectroscopic analysis problems. The algorithm works well in reconciling experimental observations with theoretical physics model parameters. In addition, theoretical analysis and experimental results on the parallelized version show good scalability with up to  processors. This reduces the time for running the GA from . hours to . minutes.|Kai Xu,Sushil J. Louis,Roberto C. Mancini","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["65507|AAAI|2005|A Brochette of Socially Interactive Robots|The design of interactive mobile robots is a multidisciplinary endeavor that profits from putting robots with people and studying their effects and impacts. To do so, two main issues must be addressed giving robots capabilities in order to interact in meaningful and efficient ways with people, and the ability to move in human settings. This paper briefly describes four robotic platforms that are going to be demonstrated at the AAAI  Robot Competition.|Fran√ßois Michaud,Dominic L√©tourneau,Pierre Lepage,Yan Morin,Fr√©d√©ric Gagnon,Patrick Gigu√®re,Eric Beaudry,Yannick Brosseau,Carle C√¥t√©,Audrey Duquette,Jean-Fran√ßois Laplante,Marc-Antoine Legault,Pierre Moisan,Arnaud Ponchon,Cl√©ment Ra√Øevsky,Marc-Andr√© Roux,Tamie Salter,Jean-Marc Valin,Serge Caron,Patrice Masson,Froduald Kabanza,Michel Lauria","65458|AAAI|2005|Towards Model-Based Diagnosis of Coordination Failures|With increasing deployment of multi-agent and distributed systems, there is an increasing need for failure diagnosis systems. While successfully tackling key challenges in multi-agent settings, model-based diagnosis has left open the diagnosis of coordination failures, where failures often lie in the boundaries between agents, and thus the inputs to the model--with which the diagnoser simulates the system to detect discrepancies--are not known. However, it is possible to diagnose such failures using a model of the coordination between agents. This paper formalizes model-based coordination diagnosis, using two coordination primitives (concurrence and mutual exclusion). We define the consistency-based and abductive diagnosis problems within this formalization, and show that both are NP-Hard by mapping them to other known problems.|Meir Kalech,Gal A. Kaminka","57548|GECCO|2005|Collaborative interactive evolution|This paper examines the efficacy of genetic algorithms (GAs) in combining input from multiple users to control a single interactive system, such as an educational exhibit at a museum. Specifically, the idea of collaborative interactive evolution (that is, interactive evolution with input from multiple users) is introduced for this purpose. Two fitness functions are proposed to guide the collaborative interactive evolution, as well as two non-GA methods for combining user input. The usefulness and success of each of these methods is examined, and the GA is shown to be a viable means for combining user input for the control of a single interactive system.|Sean R. Szumlanski,Annie S. Wu,Charles E. Hughes","57379|GECCO|2005|Towards a self-stopping evolutionary algorithm using coupling from the past|In this paper a stopping criterion for a particular class of evolutionary algorithms is devised. First, a model of a generic evolutionary algorithm using iterated random maps is presented. The model allows the exploration of a connection between coupling from the past, and a stopping criterion for evolutionary algorithms. Accordingly, a method to stop a generic evolutionary algorithm is proposed. Some computational experiments are carried out to test the stopping criterion, using a modified version of coupling from the past. Empirical evidence is shown to support the suitability of the criterion.|German Hernandez,Kenneth Wilder,Fernando Ni√±o,Julian Garcia","65446|AAAI|2005|Weighted Super Solutions for Constraint Programs|Super solutions to constraint programs guarantee that if a limited number of variables lose their values, repair solutions can be found by modifying a bounded number of assignments. However, in many application domains the classical super solutions framework is not expressive enough since it only reasons about the number of breaks in a solution and the number of changes that are necessary to find a repair. For example, in combinatorial auctions we may wish to guarantee that we can always find a repair solution whose revenue exceeds some threshold while limiting the cost associated with forming such a repair. In this paper we present the weighted super solution framework that involves two important extensions. Firstly, the set of variables that may lose their values is determined using a probabilistic approach enabling us to find repair solutions for assignments that are most likely to fail. Secondly, we include a mechanism for reasoning about the cost of repair. The proposed framework has been successfully used to find robust solutions to combinatorial auctions.|Alan Holland,Barry O'Sullivan","57460|GECCO|2005|A comparison of evolutionary algorithms for system-level diagnosis|The size and complexity of systems based on multiple processing units demand techniques for the automatic diagnosis of their state. System-level diagnosis consists in determining which units of a system are faulty and which are fault-free. Elhadef and Ayeb have proposed a specialized genetic algorithm (GA) that can be used to accomplish diagnosis. This work extends their approach, describing and comparing several evolutionary algorithms for system-level diagnosis. Implemented algorithms include a simple genetic algorithm, a specialized GA both with and without crossover and specialized versions of the compact GA and Population-Based Incremental Learning both with and without negative examples. These algorithms had their performance evaluated using four metrics the average number of generations needed to find the solution, the average fitness after up to  generations, the percentage of tests that found the optimal solution and the average time until the solution was found. An analysis of experimental results shows that more sophisticated algorithms converge faster to the optimal solution.|Bogdan Tomoyuki Nassu,Elias Proc√≥pio Duarte Jr.,Aurora Trinidad Ramirez Pozo","57285|GECCO|2005|Towards an analysis of dynamic environments|Although the interest in nature-inspired optimization of dynamic problems has been growing constantly over the past decade, very little has been done to analyze and characterize a changing fitness landscape. However, it would be very helpful for algorithm development to have a better understanding of the nature of fitness changes in dynamic real-world problems. In this paper, we propose a number of measures that can be used to analyze and characterize the dynamism in a problem changing over time. Additionally, we introduce a new dynamic multi-dimensional knapsack problem as a close-to-real-world test problem.|J√ºrgen Branke,Erdem Salihoglu,Sima Uyar","65584|AAAI|2005|Using the GEMS System for Cancer Diagnosis and Biomarker Discovery from Microarray Gene Expression Data|We will demonstrate the GEMS system for automated development and evaluation of high-quality cancer diagnostic models and biomarker discovery from microarray gene expression data. The development of GEMS was informed by the results of an extensive algorithmic evaluation using  microarray datasets. The system was further evaluated in two cross-dataset applications and using  microarray datasets. The performance of models produced by GEMS is comparable or better than the results obtained by human analysts, and these models generalize well to independent samples in cross-dataset applications. The system is freely available for download from httpwww.gems-system.org for noncommercial use.|Alexander R. Statnikov,Ioannis Tsamardinos,Constantin F. Aliferis","65531|AAAI|2005|A Framework for Bayesian Network Mapping|This research is motivated by the need to support inference across multiple intelligence systems involving uncertainty. Our objective is to develop a theoretical framework and related inference methods to map semantically similar variables between separate Bayesian networks in a principled way. The work is to be conducted in two steps. In the first step, we investigate the problem of formalizing the mapping between variables in two separate BNs with different semantics and distributions as pair-wise linkages. In the second step, we aim to justify the mapping between networks as a set of selected variable linkages, and then conduct inference along it.|Rong Pan,Yun Peng","65544|AAAI|2005|Towards Learning Stochastic Logic Programs from Proof-Banks|Stochastic logic programs combine ideas from probabilistic grammars with the expressive power of definite clause logic as such they can be considered as an extension of probabilistic context-free grammars. Motivated by an analogy with learning tree-bank grammars, we study how to learn stochastic logic programs from proof-trees. Using proof-trees as examples imposes strong logical constraints on the structure of the target stochastic logic program. These constraints can be integrated in the least general generalization (lgg) operator, which is employed to traverse the search space. Our implementation employs a greedy search guided by the maximum likelihood principle and failure-adjusted maximization. We also report on a number of simple experiments that show the promise of the approach.|Luc De Raedt,Kristian Kersting,Sunna Torge"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","65503|AAAI|2005|Augmenting Disjunctive Temporal Problems with Finite-Domain Constraints|We present a general framework for augmenting instances of the Disjunctive Temporal Problem (DTP) with finite-domain constraints. In this new formalism, the bounds of the temporal constraints become conditional on the finite-domain assignment. This hybridization makes it possible to reason simultaneously about temporal relationships between events as well as their nontemporal properties. We provide a special case of this hybridization that allows reasoning about a limited form of spatial constraints namely, the travel time induced by the locations of a set of activities. We develop a least-commitment algorithm for efficiently finding solutions to this combined constraint system and provide empirical results demonstrating the effectiveness of our approach.|Michael D. Moffitt,Bart Peintner,Martha E. Pollack","57512|GECCO|2005|Using gene deletion and gene duplication in evolution strategies|Self-adaptation of the mutation strengths is a powerful mechanism in evolution strategies (ES), but it can fail. As a consequence premature convergence or ending up in a local optimum in multi-modal fitness landscapes can occur. In this article a new approach controlling the process of self-adaptation is proposed. This approach combines the old ideas of gene deletion and gene duplication with the self-adaptation mechanism of the ES. Gene deletion and gene duplication is used to vary the number of independent mutation strengths. In order to demonstrate the practicability of the new approach several multi-modal test functions are used. Methods from statistical design of experiments and regression tree methods are applied to improve the performance of a specific heuristic-problem combination.|Karlheinz Schmitt","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","65487|AAAI|2005|Properties of Programs with Monotone and Convex Constraints|We study properties of programs with monotone and convex constraints. We extend to these formalisms concepts and results from normal logic programming. They include tight programs and Fages Lemma, program completion and loop formulas, and the notions of strong and uniform equivalence with their characterizations. Our results form an abstract account of properties of some recent extensions of logic programming with aggregates, especially the formalism of smodels.|Lengning Liu,Miroslaw Truszczynski","65467|AAAI|2005|Heterogeneous Multirobot Coordination with Spatial and Temporal Constraints|Existing approaches to multirobot coordination separate scheduling and task allocation, but finding the optimal schedule with joint tasks and spatial constraints requires robots to simultaneously solve the scheduling, task allocation, and path planning problems. We present a formal description of the multirobot joint task allocation problem with heterogeneous capabilities and spatial constraints and an instantiation of the problem for the search and rescue domain. We introduce a novel declarative framework for modeling the problem as a mixed integer linear programming (MILP) problem and present a centralized anytime algorithm with error bounds. We demonstrate that our algorithm can outperform standard MILP solving techniques, greedy heuristics, and a market based approach which separates scheduling and task allocation.|Mary Koes,Illah R. Nourbakhsh,Katia P. Sycara","65595|AAAI|2005|Improving Simultaneous Mapping and Localization in D Using Global Constraints|Recently, the problem of learning volumetric maps from three-dimenisional range data has become quite popular in the context of mobile robotics. One of the key challenges in this context is to reduce the overall amount of data. The smaller the namber of data points, however, the fewer information is available to register the scans and to conputer a consistent map. In this paper we present a novel approach that estimates global constaints from the data and utilizes these contraints to improve the registration process. In our current system we simultaneously minimize the distance between scans and the distance of edges from planes extracted from the edges to obtain highly accurate three-dimensional modele of the environment. Several experiments carried out in simulation as well as with three-dimensional data obtained with a mobile robot in an outdoor environment we show that our approach yields seriously more accurate models compared to a standard apporach that does not utilize the global constraints.|Rudolph Triebel,Wolfram Burgard","65482|AAAI|2005|Prottle A Probabilistic Temporal Planner|Planning with concurrent durative actions and probabilistic effects, or probabilistic temporal planning, is a relatively new area of research. The challenge is to replicate the success of modern temporal and probabilistic planners with domains that exhibit an interaction between time and uncertainty. We present a general framework for probabilistic temporal planning in which effects, the time at which they occur, and action durations are all probabilistic. This framework includes a search space that is designed for solving probabilistic temporal planning problems via heuristic search, an algorithm that has been tailored to work with it and an effective heuristic based on an extension of the planning graph data structure. Prottle is a planner that implements this framework, and can solve problems expressed in an extension of PDDL.|Iain Little,Douglas Aberdeen,Sylvie Thi√©baux","57476|GECCO|2005|Multiobjective shape optimization with constraints based on estimation distribution algorithms and correlated information|A new approach based on Estimation Distribution Algorithms for constrained multiobjective shape optimization is proposed in this article. Pareto dominance and feasibility rules are used to handle constraints. The algorithm uses feasible and infeasible individuals to estimate the probability distribution of evolving designs. Additionally, correlation among problem design variables is used to improve exploration. The design objectives are minimum weight and minimum nodal displacement. Also, the resulting structures must fulfill three design constraints a) maximum permissible Von Misses stress, b)connectedness of the structure elements, and c) small holes are not allowed in the structure. The finite element method is used to evaluate the objective functions and stress constraint.|Sergio Ivvan Valdez Pe√±a,Salvador Botello Rionda,Arturo Hern√°ndez Aguirre","57437|GECCO|2005|Learning computer programs with the bayesian optimization algorithm|We describe an extension of the Bayesian Optimization Algorithm (BOA), a probabilistic model building genetic algorithm, to the domain of program tree evolution. The new system, BOA programming (BOAP), improves significantly on previous probabilistic model building genetic programming (PMBGP) systems in terms of the articulacy and open-ended flexibility of the models learned, and hence control over the distribution of instances generated. Innovations include a novel tree representation and a generalized program evaluation scheme.|Moshe Looks,Ben Goertzel,Cassio Pennachin"],["65408|AAAI|2005|State Agnostic Planning Graphs and the Application to Belief-Space Planning|Planning graphs have been shown to be a rich source of heuristic information for many kinds of planners. In many cases, planners must compute a planning graph for each element of a set of states. The naive technique enumerates the graphs individually. This is equivalent to solving an all-pairs shortest path problem by iterating a single-source algorithm over each source. We introduce a structure, the state agnostic planning graph, that directly, solves the all-pairs problem for the relaxation introduced by planning graphs. The technique can also be characterized as exploiting the overlap present in sets of planning graphs. For the purpose of exposition, we first present the technique in classical planning. The more prominent application of tnis technique is in belief-space planning, where an optimization results in drastically improved theoretical complexity. Our experimental evaluation quantifies this performance boost. and demonstrates that heuristic belief-space progression planning using our technique is competitive with the state of t the art.|William Cushing,Daniel Bryce","65429|AAAI|2005|Fast Planning in Domains with Derived Predicates An Approach Based on Rule-Action Graphs and Local Search|The ability to express \"derived predicates\" in the formalization of a planning domain is both practically and theoretically important. In this paper, we propose an approach to planning with derived predicates where the search space consists of \"Rule-Action Graphs\", particular graphs of actions and rules representing derived predicates. We present some techniques for representing rules and reasoning with them, which are integrated into a method for planning through local search and rule-action graphs. We also propose some new heuristics for guiding the search, and some experimental results illustrating the performance of our approach. Our proposed techniques are implemented in a planner that took part in the fourth International Planning Competition showing good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina,Paolo Toninelli","65440|AAAI|2005|New Admissible Heuristics for Domain-Independent Planning|Admissible heuristics are critical for effective domain-independent planning when optimal solutions must be guaranteed. Two useful heuristics are the hm heuristics, which generalize the reachability heuristic underlying the planning graph, and pattern database heuristics. These heuristics, however, have serious limitations reachability heuristics capture only the cost of critical paths in a relaxed problem, ignoring the cost of other relevant paths, while PDB heuristics, additive or not, cannot accommodate too many variables in patterns, and methods for automatically selecting patterns that produce good estimates are not known. We introduce two refinements of these heuristics First, the additive hm heuristic which yields an admissible sum of hm heuristics using a partitioning of the set of actions. Second, the constrained PDB heuristic which uses constraints from the original problem to strengthen the lower bounds obtained from abstractions. The new heuristics depend on the way the actions or problem variables are partitioned. We advance methods for automatically deriving additive hm and PDB heuristics from STRIPS encodings. Evaluation shows improvement over existing heuristics in several domains, although, not surprisingly, no heuristic dominates all the others over all domains.|Patrik Haslum,Blai Bonet,Hector Geffner","65453|AAAI|2005|A Discourse Planning Approach to Cinematic Camera Control for Narratives in Virtual Environments|As the complexity of narrative-based virtual environments grows, the need for effective communication of information to the users of these systems increase. Effective camera control for narrative-oriented virtual worlds involves decision making at three different levels choosing cinematic geometric composition, choosing the best camera parameters for conveying affective information, and choosing camera shots and transitions to maintain thetorical coherence. We propose a camera planning system that mirrors the film production pipeline we describe our formalization of film idioms used to communicate affective information. Our representation of idioms captures their hierarchical nature, represents the causal motivation for selection of shots, and provides a way for the system designer to specify the ranking of candidate shot sequences.|Arnav Jhala,R. Michael Young","65358|AAAI|2005|Reactive Planning in a Motivated Behavioral Architecture|To operate in natural environmental settings, autonomous mobile robots need more than just the ability to navigate in the world, react to perceived situations or follow pre-determined strategies they must be able to plan and to adapt those plans according to the robot's capabilities and the situations encountered. Navigation, simultaneous localization and mapping, perception, motivations, planning, etc., are capabilities that contribute to the decision-making processes of an autonomous robot. How can they be integrated while preserving their underlying principles, and not make the planner or other capabilities a central element on which everything else relies on In this paper, we address this question with an architectural methodology that uses a planner along with other independent motivational sources to influence the selection of behavior-producing modules. Influences of the planner over other motivational sources are demonstrated in the context of the AAAI Challenge.|Eric Beaudry,Yannick Brosseau,Carle C√¥t√©,Cl√©ment Ra√Øevsky,Dominic L√©tourneau,Froduald Kabanza,Fran√ßois Michaud","65578|AAAI|2005|Conformant Planning for Domains with Constraints-A New Approach|The paper presents a pair of new conformant planners, CPApc and CPAph, based on recent developments in theory of action and change. As an input the planners take a domain description D in action language AL which allows state constraints (non-stratified axioms), together with a set of CNF formulae describing the initial state, and a set of literals representing the goal. We propose two approximations of the transition diagram T defined by D. Both approximations are deterministic transition functions and can be computed efficiently. Moreover they are sound (and sometimes complete) with respect to T. In its search for a plan, an approximation based planner analyses paths of an approximation instead of that of T. CPApc and CPAph are forward, best first search planners based on this idea. We compare them with two state-of-the-art conformant planners, KACMBP and Conformant-FF (CFF), over benchmarks in the literature, and over two new domains. One has large number of state constraints and another has a high degree of incompleteness. Our planners perform reasonably well in benchmark domains and outperform KACMBP and CFF in the first domain while still working well with the second one. Our experimental result shows that having an integral part of a conformant planner to deal with state constraints directly can significantly improve its performance extending a similar claim for classical planners in (Thiebaux. Hoffmann, & Nebel ).|Tran Cao Son,Phan Huy Tu,Michael Gelfond,A. Ricardo Morales","65418|AAAI|2005|Genome Rearrangement and Planning|The genome rearrangement problem is to find the most economical explanation for observed differences between the gene orders of two genomes. Such an explanation is provided in terms of events that change the order of genes in a genome. We present a new approach to the genome rearrangement problem, according to which this problem is viewed as the problem of planning rearrangement events that transform one genome to the other. This method differs from the existing ones in that we can put restrictions on the number of events, specify the cost of events with functions, possibly based on the length of the gene fragment involved, and add constraints controlling search. With this approach. We have described genome rearrangements in the action description language ADL. and studied the evolution of Metazoan mitochondrial genomes and the evolution of Campanulaceae chloroplast genomes using the planner TLPLAN. We have observed that the phylogenies reconstructed using this approach conform with the most widely accepted ones.|Esra Erdem,Elisabeth R. M. Tillier","65617|AAAI|2005|Planning and Execution with Phase Transitions|We consider a special type of continuous-time Markov decision processes (MDPs) that arise when phase-type distributions are used to model the timing of non-Markovian events and actions. We focus, primarily, on the execution of phase-dependent policies. Phases are introduced into a model to represent relevant execution history, but there is no physical manifestation of phases in the real world. We treat phases as partially observable state features and show how a belief distribution over phase configurations can be derived from observable state features through the use of transient analysis for Markov chains. This results in an efficient method for phase tracking during execution that can be combined with the QMDP value method for POMDPs to make action choices. We also discuss, briefly, how the structure of MDPs with phase transitions can be exploited in structured value iteration with symbolic representation of vectors and matrices.|H√•kan L. S. Younes","65473|AAAI|2005|Using Domain-Configurable Search Control for Probabilistic Planning|We describe how to improve the performance of MDP planning algorithms by modifying them to use the search-control mechanisms of planners such as TLPlan, SHOP, and TALplanner. In our experiments, modified versions of RTDP, LRTDP, and Value Iteration were exponentially faster than the original algorithms. On the largest problems the original algorithms could solve, the modified ones were about , times faster. On another set. of problems whose state spaces were more than , times larger than the original algorithms could solve, the modified algorithms took only about  second.|Ugur Kuter,Dana S. Nau","65549|AAAI|2005|Planning for Stream Processing Systems|With the advent of compositional programming models in computer Science, applying planning technologies to automatically build workflows for solving large and complex problems in such a paradigm becomes not only technically appealing but also feasible approach. The application areas that will benefit from automatic composition include, among others, Web services, Grid computing and stream processing systems. Although the classical planning formalism is expressive enough to describe planning problems that arise in a large variety of different applications, it can pose significant limitations on planner performance in compositional applications, in particular, in stream processing systems. In this paper we exlend the classical planning formalism by introducing new language constructs that support the structure of stream processing domains. Exposing this structure to the planner can result in dramatic performance improvements our experiments show exponential planning time reduction in comparison to most recent metric planners.|Anton Riabov,Zhen Liu"],["57280|GECCO|2005|The impact of cellular representation on finite state agents for prisoners dilemma|The iterated prisoner's dilemma is a widely used computational model of cooperation and conflict. Many studies report emergent cooperation in populations of agents trained to play prisoner's dilemma with an evolutionary algorithm. Cellular representation is the practice of evolving a set of instructions for constructing a desired structure. This paper presents a cellular encoding for finite state automata and specializes it to play the iterated prisoner's dilemma. The impact on the character and behavior of finite state agents that results from using the cellular representation is investigated. For the cellular representation presented a statistically significant drop in the level of cooperation is found. Other differences in the character of the automaton generated with a direct and cellular representation are reported. This paper forms part of an ongoing study of the impact of representation on evolved agents for playing prisoner's dilemma.|Daniel A. Ashlock,Eun-Youn Kim","65511|AAAI|2005|Error Bounds for Approximate Value Iteration|Approximate Value Iteration (AVI) is an method for solving a Markov Decision Problem by making successive calls to a supervised learning (SL) algorithm. Sequence of value representations Vn are processed iteratively by Vn+  ATVn where T is the Bellman operator and A an approximation operator. Bounds on the error between the performance of the policies induced by the algorithm and the optimal policy are given as a function of weighted Lp-norms (p  ) of the approximation errors. The results extend usual analysis in L-norm, and allow to relate the performance of AVI to the approximation power (usually expressed in Lp-norm, for p   or ) of the SL algorithm. We illustrate the tightness of these bounds on an optimal replacement problem.|R√©mi Munos","65607|AAAI|2005|Finite Sample Error Bound for Parzen Windows|Parzen Windows as a nonparametric method has been applied to a variety of density estimation as well as classification problems. Similar to nearest neighbor methods. Parzen Windows does not involve learning. While it converges to true but unknown probability densities in the asymptotic limit, there is a lack of theoretical analysis on its performance with finite samples. In this paper we establish a finite sample error bound for Parzen Windows. We first show that Parzen Windows is an approximation to regularized least squares (RLS) methods that have been well studied in statistical learning theory. We then derive the finite sample error bound for Parzen Windows, and discuss the properties of the error bound and its relationship to the error bound for RLS. This analysis provides interesting insight to Parzen Windows as well as the nearest neighbor method from the point of view of learning theory. Finally, we provide empirical results on the performance of Parzen Windows and other methods such as nearest neighbors, RLS and SVMs on a number of real data sets. These results corroborate well our theoretical analysis.|Peng Zhang,Jing Peng,Norbert Riedel","57580|GECCO|2005|Preservation of genetic redundancy in the existence of developmental error and fitness assignment error|Conservation of functionally identical copies of the same gene throughout the generations is not an easy task. In this study, based on the biological evidence that suggests the existence of the developmental error as one of the ways to preserve redundancy, our goal is to investigate the impact of developmental error on a simple problem using a genetic algorithm(GA). Developmental errors exist during the biological development of an individual. The biological models with developmental errors have demonstrated that it is possible to maintain redundant copies in the existence of proper mutation rates and developmental error rates. Our preliminary results with a simple problem demonstrates that using developmental error helps preserving the redundant copies and maintaining a better solution quality for the redundant copies of a gene. Besides the developmental error, we propose a new error type that comes into play during the fitness assignment and enhances the quality of the solutions when used together with developmental error.|Ayse S. Yilmaz,Annie S. Wu","65365|AAAI|2005|Mathematical Domain Reasoning Tasks in Natural Language Tutorial Dialog on Proofs|We study challenges that are imposed to mathematical domain reasoning in the context of natural language tutorial dialog on mathematical proofs. The focus is on proof step evaluation (i) How can mathematical domain reasoning support the resolution of ambiguities and underspecified parts in proof steps uttered by a student (ii) How can mathematical domain reasoning support the evaluation of a proof step with respect to the criteria soundness, granularity, and relevance.|Christoph Benzm√ºller,Quoc Bao Vo","65579|AAAI|2005|Natural Language Generation for Text-to-Text Applications Using an Information-Slim Representation|I propose a representation formalism and algorithms to be used in a new language generation mechanism for text-to-text applications. The generation process is driven by both text-specific information encoded via probability distributions over words and phrases derived from the input text, and general language knowledge captured by n-gram and syntactic language models.|Radu Soricut","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons","65530|AAAI|2005|Identifying Similar Words and Contexts in Natural Language with SenseClusters|SenseClusters is a freely available intelligent system that clusters together similar contexts in natural language text. Thereafter it assigns identifying labels to these clusters based on their content. It is a purely unsupervised approach that is language independent, and uses no knowledge other than what is available in raw un-annotated corpora. In addition to clustering similar contexts, it can be used to identify synonyms and sets of related words. It has been applied to a diverse range of problems, including proper name disambiguation, word sense discrimination, email organization, and document clustering. SenseClusters is a complete system that supports feature selection from large corpora, several different context representation schemes, various clustering algorithms, the creation of descriptive and discriminating labels for the discovered clusters, and evaluation relative to gold standard data.|Ted Pedersen,Anagha Kulkarni","57440|GECCO|2005|Evolutionary testing of state-based programs|The application of Evolutionary Algorithms to structural test data generation, known as Evolutionary Testing, has to date largely focused on programs with input-output behavior. However, the existence of state behavior in test objects presents additional challenges for Evolutionary Testing, not least because certain test goals may require a search for a sequence of inputs to the test object. Furthermore, state-based test objects often make use of internal variables such as boolean flags, enumerations and counters for managing or querying their internal state. These types of variables can lead to a loss of information in computing fitness values, producing coarse or flat fitness landscapes. This results in the search receiving less guidance, and the chances of finding required test data are decreased.This paper proposes an extended approach based on previous works. Input sequences are generated, and internal variable problems are addressed through hybridization with an extended Chaining Approach. The basic idea of the Chaining Approach is to find a sequence of statements, involving internal variables, which need to be executed prior to the test goal. By requiring these statements are executed, information previously unavailable to the search can be made use of, possibly guiding it into potentially promising and unexplored areas of the test object's input domain. A number of experiments demonstrate the value of the approach.|Phil McMinn,Mike Holcombe","65499|AAAI|2005|Samuel Meets Amarel Automating Value Function Approximation Using Global State Space Analysis|Most work on value function approximation adheres to Samuel's original design agents learn a task-specific value function using parameter estimation, where the approximation architecture (e.g, polynomials) is specified by a human designer. This paper proposes a novel framework generalizing Samuel's paradigm using a coordinate-free approach to value function approximation. Agents learn both representations and value functions by constructing geometrically customized task-independent basis functions that form an orthonormal set for the Hilbert space of smooth functions on the underlying state space manifold. The approach rests on a technical result showing that the space of smooth functions on a (compact) Riemanian manifold has a discrete spectrum associated with the Laplace-Beltrami operator. In the discrete setting, spectral analysis of the graph Laplacian yields a set of geometrically customized basis functions for approximating and decomposing value functions. The proposed framework generalizes Samuel's value function approximation paradigm by combining it with a formalization of Saul Amarel's paradigm of representation learning through global state space analysis.|Sridhar Mahadevan"]]}}