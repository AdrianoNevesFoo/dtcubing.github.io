{"abstract":{"entropy":6.355753379092426,"topics":["learning classifier, classifier system, evolution strategies, system, learning system, xcs fault, ant colony, immune system, quality software, artificial immune, last decades, detection problem, software evolution, learning xcs, recent years, presents self-adaptive, analyze xcs, classifier xcs, first xcs, search heuristics","evolutionary computation, data mining, novel approach, presents approach, testing test, neural network, data classification, presents novel, machine learning, selection autonomous, presents evolutionary, selection form, mining classification, finding gene, testing approaches, task classification, genetic approach, data, evolutionary approach, approach","evolutionary algorithm, differential evolution, estimation distribution, evolutionary search, algorithm search, paper algorithm, genetic algorithm, real world, distribution algorithm, paper genetic, support vector, spanning tree, crossover operators, stock market, adaptive algorithm, estimation algorithm, paper describe, estimation edas, local search, evolutionary solutions","genetic programming, genetic algorithm, particle swarm, optimization problem, optimization algorithm, solving problem, swarm optimization, particle optimization, algorithm problem, problem, genetic problem, multi-objective optimization, hierarchical bayesian, solve problem, multi-objective algorithm, multi-objective evolutionary, multi-objective moea, building blocks, programming cartesian, algorithm applied","evolution strategies, quality software, evolution, software evolution, evolution strategy, software, study, analysis, process, space, evolve, adaptation, control, distributed, model","xcs fault, learning xcs, xcs system, classifier xcs, learning classifier, xcs, first xcs, concept, behavior, development, cell, introduced, body, developmental, xcsf, standard","novel approach, presents evolutionary, presents approach, testing test, genetic approach, presents novel, approach based, evolutionary approach, approach problem, dynamic evolutionary, presents algorithm, evolutionary testing, approach, presents dynamic, dynamic, presents, complex, structural, development, simulated","evolutionary computation, neural network, finding gene, evolutionary techniques, paper network, evolutionary network, network, techniques, large, finding, robot, experimental, interaction, characteristics, dna, state, computing, artificial, main, information","addresses problem, algorithm crossover, algorithm random, genetic crossover, class algorithm, introduced crossover, crossover, representation, class, called, shown, convergence, single, given, encoding, objective, investigates, direct, types, proposes","real world, evolutionary studies, algorithm fitness, evolutionary solutions, problem solutions, fitness landscape, fitness function, algorithm solutions, fitness, solutions, function, optimal, number, robust, neutrality, provides, allows, effects, values, designed","optimization problem, optimization algorithm, solving problem, multi-objective algorithm, evolutionary algorithm, multi-objective problem, multi-objective evolutionary, multi-objective optimization, multi-objective moea, algorithm solving, multiobjective optimization, solving multi-objective, evolutionary problem, genetic optimization, evolutionary moea, algorithm moea, algorithm problem, multiobjective algorithm, solving optimization, evolutionary optimization","solve problem, algorithm used, scheduling problem, solve optimization, hierarchical bayesian, algorithm hierarchical, building blocks, hierarchical optimization, used problem, bayesian optimization, used optimization, algorithm solve, genetic used, widely algorithm, hierarchical problem, used, widely used, algorithm problem, genetic algorithm, optimization problem"],"ranking":[["57615|GECCO|2006|Hyper-ellipsoidal conditions in XCS rotation linear approximation and solution structure|The learning classifier system XCS is an iterative rule-learning system that evolves rule structures based on gradient-based prediction and rule quality estimates. Besides classification and reinforcement learning tasks, XCS was applied as an effective function approximator. Hereby, XCS learns space partitions to enable a maximally accurate and general function approximation. Recently, the function approximation approach was improved by replacing () hyperrectangular conditions with hyper-ellipsoids and () iterative linear approximation with the recursive least squares method. This paper combines the two approaches assessing the usefulness of each. The evolutionary process is further improved by changing the mutation operator implementing an angular mutation that rotates ellipsoidal structures explicitly. Both enhancements improve XCS performance in various non-linear functions. We also analyze the evolving ellipsoidal structures confirming that XCS stretches and rotates the evolving ellipsoids according to the shape of the underlying function. The results confirm that improvements in both the evolutionary approach and the gradient approach can result in significantly better performance.|Martin V. Butz,Pier Luca Lanzi,Stewart W. Wilson","58097|GECCO|2007|Mining breast cancer data with XCS|In this paper, we describe the use of a modern learning classifier system to a data mining task. In particular, in collaboration with a medical specialist, we apply XCS to a primary breast cancer data set. Our results indicate more effective knowledge discovery than with C..|Faten Kharbat,Larry Bull,Mohammed Odeh","58133|GECCO|2007|MILCS a mutual information learning classifier system|This paper introduces a new variety of learning classifier system (LCS), called MILCS, which utilizes mutual information as fitness feedback. Unlike most LCSs, MILCS is specifically designed for supervised learning. MILCS's design draws on an analogy to the structural learning approach of cascade correlation networks. We present preliminary results, and contrast them to results from XCS. We discuss the explanatory power of the resulting rule sets, and introduce a new technique for visualizing explanatory power. Final comments include future directions for this research, including investigations in neural networks and other systems.|Robert Elliott Smith,Max Kun Jiang","57777|GECCO|2006|Bounding XCSs parameters for unbalanced datasets|This paper analyzes the behavior of the XCS classifier system on imbalanced datasets. We show that XCS with standard parameter settings is quite robust to considerable class imbalances. For high class imbalances, XCS suffers from biases toward the majority class. We analyze XCS's behavior under such extreme imbalances and prove that appropriate parameter tuning improves significantly XCS's performance. Specifically, we counterbalance the imbalance ratio by equalizing the reproduction probabilities of the most occurring and least occurring niches. The study provides guidelines to tune XCS's parameters for unbalanced datasets, based on the dataset imbalance ratio. We propose a method to estimate the imbalance ratio during XCS's training and adapt XCS's parameters online.|Albert Orriols-Puig,Ester Bernadó-Mansilla","58011|GECCO|2007|Introducing fault tolerance to XCS|In this paper, we introduce fault tolerance to XCS and propose a new XCS framework called XCS with Fault Tolerance (XCSFT). As an important branch of learning classifier systems, XCS has been proven capable of evolving maximally accurate, maximally general problem solutions. However, in practice, it oftentimes generates a lot of rules, which lower the readability of the evolved classification model, and thus, people may not be able to get the desired knowledge or useful information out of the model. Inspired by the fault tolerance mechanism proposed in field of data mining, we devise a new XCS framework by integrating the concept and mechanism of fault tolerance into XCS in order to reduce the number of classification rules and therefore to improve the readability of the generated prediction model. A series of $N$-multiplexer experiments, including -bit, -bit, -bit, and -bit multiplexers, are conducted to examine whether XCSFT can accomplish its goal of design. According to the experimental results, XCSFT can offer the same level of prediction accuracy on the test problems as XCS can, while the prediction model evolved by XCSFT consists of significantly fewer classification rules.|Hong-Wei Chen,Ying-Ping Chen","57733|GECCO|2006|Fast rule matching for learning classifier systems via vector instructions|Over the last ten years XCS has become the standard for Michigan-style learning classifier systems (LCS). Since the initial CS- work conceived by Holland, classifiers (rules) have widely used a ternary condition alphabet ,, for binary input problems. Most of the freely available implementations of this ternary alphabet in XCS rely on character-based encodings---easy to implement, not memory efficient, and expensive to compute. Profiling of freely available XCS implementations shows that most of their execution time is spent determining whether a rule is match or not, posing a serious threat to XCS scalability. In the last decade, multimedia and scientific applications have pushed CPU manufactures to include native support for vector instruction sets. This paper presents how to implement efficient condition encoding and fast rule matching strategies using vector instructions. The paper elaborates on Altivec (PowerPC G, G) and SSE (Intel PXeon and AMD Opteron) instruction sets producing speedups of XCS matching process beyond ninety times. Moreover, such a vectorized matching code will allow to easily scale beyond tens of thousands of conditions in a reasonable time. The proposed fast matching scheme also fits in any other LCS other than XCS.|Xavier Llorà,Kumara Sastry","57616|GECCO|2006|Studying XCSBOA learning in Boolean functions structure encoding and random Boolean functions|Recently, studies with the XCS classifier system on Boolean functions have shown that in certain types of functions simple crossover operators can lead to disruption and, consequently, a more effective recombination mechanism is required. Simple crossover operators were replaced by recombination based on estimation of distribution algorithms (EDAs). The combination showed that XCS with such a statistics-based crossover operator can solve challenging hierarchical functions more efficiently. This study elaborates the gained competence further investigating the coding scheme for the EDA component (BOA in our case) of XCS as well as performance in randomly generated Boolean function problems. Results in hierarchical Boolean functions show that the originally used -bit coding scheme induces a certain learning bias that stresses additional diversity in the evolving XCS population. A -bit coding scheme as well as a restricted -bit coding scheme confirm the suspected bias. The alternative encodings decrease the unnecessary bias towards specificity and increase performance robustness. The paper concludes with a discussion on the challenges ahead for XCS in Boolean function problems as well as on the implications of the obtained results for real-valued and multiple-valued classification problems, multi-step problems, and function approximation problems.|Martin V. Butz,Martin Pelikan","58001|GECCO|2007|Comparing two models to generate hyper-heuristics for the d-regular bin-packing problem|The idea behind hyper-heuristics is to discover some combination of straightforward heuristics to solve a wide range of problems. To be worthwhile, such combination should outperform the single heuristics. This paper presents two Evolutionary-Computation-based Models to producehyper-heuristics that solve two-dimensional bin-packing problems. The first model uses an XCS-type Learning Classifier System which learns a solution procedure when solving individual problems. The second model is based on a GA that uses a variable-length representation, which evolves combinations of condition-action rules producing hyper-heuristics after going through alearning process which includes training and testing phases.Both approaches, when tested and compared using a large set ofbenchmark problems, perform better than the combinations ofsingle heuristics. The testbed is composed of problems used inother similar studies in the literature. Some additional instances of the testbed were randomly generated.|Hugo Terashima-Marín,Cláudia J. Farías Zárate,Peter Ross,Manuel Valenzuela-Rendón","58137|GECCO|2007|Classifier systems that compute action mappings|The learning in a niche based learning classifier system depends both on the complexity of the problem space and on the number of available actions. In this paper, we introduce a version of XCS with computed actions, briefly XCSCA, that can be applied to problems involving a large number of actions. We report experimental results showing that XCSCA can evolve accurate and compact representations of binary functions which would be challenging for typical learning classifier system models.|Pier Luca Lanzi,Daniele Loiacono","58230|GECCO|2007|Mixing independent classifiers|In this study we deal with the mixing problem, which concerns combining the prediction of independently trained local models to form a global prediction. We deal with it from the perspective of Learning Classifier Systems where a set of classifiers provide the local models. Firstly, we formalise the mixing problem and provide both analytical and heuristic approaches to solving it. The analytical approaches are shown to not scale well with the number of local models, but are nevertheless compared to heuristic models in a set of function approximation tasks. These experiments show that we can design heuristics that exceed the performance of the current state-of-the-art Learning Classifier System XCS, and are competitive when compared to analytical solutions. Additionally, we provide an upper bound on the prediction errors for the heuristic mixing approaches.|Jan Drugowitsch,Alwyn Barry"],["57636|GECCO|2006|A specification-based fitness function for evolutionary testing of object-oriented programs|Encapsulation of states in object-oriented programs hinders the search for test data using evolutionary testing. As client code is oblivious to the internal state of a server object, no guidance is available to test the client code using evolutionary testing i.e., it is difficult to determine the fitness or goodness of test data, as it may depend on the hidden internal state. Nevertheless, evolutionary testing is a promising new approach of which effectiveness has been shown by several researchers. We propose a specification-based fitness function for evolutionary testing of object-oriented programs. Our approach is modular in that fitness value calculation doesn't depend on source code of server classes, thus it works even if the server implementation is changed or no code is available----which is frequently the case for reusable object-oriented class libraries and frameworks.|Yoonsik Cheon,Myoung Kim","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","57752|GECCO|2006|Information preserving multi-objective feature selection for unsupervised learning|In this work we propose a novel, sound framework for evolutionary feature selection in unsupervised machine learning problems. We show that unsupervised feature selection is inherently multi-objective and behaves differently from supervised feature selection in that the number of features must be maximized instead of being minimized. Although this might sound surprising from a supervised learning point of view, we exemplify this relationship on the problem of data clustering and show that existing approaches do not pose the optimization problem in an appropriate way. Another important consequence of this paradigm change is a method which segments the Pareto sets produced by our approach. Inspecting only prototypical points from these segments drastically reduces the amount of work for selecting a final solution. We compare our methods against existing approaches on eight data sets.|Ingo Mierswa,Michael Wurst","58139|GECCO|2007|Ensemble learning for free with evolutionary algorithms|Evolutionary Learning proceeds by evolving a population of classifiers, from which it generally returns (with some notable exceptions) the single best-of-run classifier as final result. In the meanwhile, Ensemble Learning, one of the most efficient approaches in supervised Machine Learning for the last decade, proceeds by building a population of diverse classifiers. Ensemble Learning with Evolutionary Computation thus receives increasing attention. The Evolutionary Ensemble Learning (EEL) approach presented in this paper features two contributions. First, a new fitness function, inspired by co-evolution and enforcing the classifier diversity, is presented. Further, a new selection criterion based on the classification margin is proposed. This criterion is used to extract the classifier ensemble from the final population only (Off-EEL) or incrementally along evolution (On-EEL). Experiments on a set of benchmark problems show that Off-EEL outperforms single-hypothesis evolutionary learning and state-of-art Boosting and generates smaller classifier ensembles.|Christian Gagné,Michèle Sebag,Marc Schoenauer,Marco Tomassini","57855|GECCO|2006|On-line evolutionary computation for reinforcement learning in stochastic domains|In reinforcement learning, an agent interacting with its environment strives to learn a policy that specifies, for each state it may encounter, what action to take. Evolutionary computation is one of the most promising approaches to reinforcement learning but its success is largely restricted to off-line scenarios. In on-line scenarios, an agent must strive to maximize the reward it accrues while it is learning. Temporal difference (TD) methods, another approach to reinforcement learning, naturally excel in on-line scenarios because they have selection mechanisms for balancing the need to search for better policies exploration) with the need to accrue maximal reward (exploitation). This paper presents a novel way to strike this balance in evolutionary methods by borrowing the selection mechanisms used by TD methods to choose individual actions and using them in evolution to choose policies for evaluation. Empirical results in the mountain car and server job scheduling domains demonstrate that these techniques can substantially improve evolution's on-line performance in stochastic domains.|Shimon Whiteson,Peter Stone","57902|GECCO|2007|Towards better than human capability in diagnosing prostate cancer using infrared spectroscopic imaging|Cancer diagnosis is essentially a human task. Almost universally, the process requires the extraction of tissue (biopsy) and examination of its microstructure by a human. To improve diagnoses based on limited and inconsistent morphologic knowledge, a new approach has recently been proposed that uses molecular spectroscopic imaging to utilize microscopic chemical composition for diagnoses. In contrast to visible imaging, the approach results in very large data sets as each pixel contains the entire molecular vibrational spectroscopy data from all chemical species. Here, we propose data handling and analysis strategies to allow computer-based diagnosis of human prostate cancer by applying a novel genetics-based machine learning technique (tt NAX). We apply this technique to demonstrate both fast learning and accurate classification that, additionally, scales well with parallelization. Preliminary results demonstrate that this approach can improve current clinical practice in diagnosing prostate cancer.|Xavier Llorà,Rohith Reddy,Brian Matesic,Rohit Bhargava","57701|GECCO|2006|Multiobjective genetic rule selection as a data mining postprocessing procedure|In this paper, we show the usefulness of multiobjective genetic rule selection as a postprocessing procedure in data mining for pattern classification problems. First we extract a prespecified number of rules using a data mining technique. Then we apply multiobjective genetic rule selection to the extracted rules. Experimental results show that multiobjective genetic rule selection significantly decreases the number of extracted rules while improving their classification accuracy.|Hisao Ishibuchi,Yusuke Nojima,Isao Kuwajima","58059|GECCO|2007|Automatic mutation test input data generation via ant colony|Fault-based testing is often advocated to overcome limitations ofother testing approaches however it is also recognized as beingexpensive. On the other hand, evolutionary algorithms have beenproved suitable for reducing the cost of data generation in the contextof coverage based testing. In this paper, we propose a newevolutionary approach based on ant colony optimization for automatictest input data generation in the context of mutation testingto reduce the cost of such a test strategy. In our approach the antcolony optimization algorithm is enhanced by a probability densityestimation technique. We compare our proposal with otherevolutionary algorithms, e.g., Genetic Algorithm. Our preliminaryresults on JAVA testbeds show that our approach performed significantlybetter than other alternatives.|Kamel Ayari,Salah Bouktif,Giuliano Antoniol","58075|GECCO|2007|A platform for the selection of genes in DNA microarraydata using evolutionary algorithms|This paper presents a flexible framework to the task of featureselection in classification of DNA microarray data. Theuser can select a number of filter methods in the preprocessingstage and choose from a wide set of classifiers (models and algorithms from WEKA  are available) and accuracy estimation methods. This approach implements wrapper methods, where Evolutionary Algorithms, with variable sized set based representations are used to reduce the number of attributes. Two case studies were used to validate the approach, with three distinct classifiers (-nearest neighbour, decision trees, SVMs), a filter method based on discriminant fuzzy patterns and k-fold cross-validation to estimate the generalization error.|Miguel Rocha,Rui Mendes,Paulo Maia,Daniel Glez-Peña,Florentino Fdez-Riverola","58029|GECCO|2007|Hybrid coevolutionary algorithms vs SVM algorithms|As a learning method support vector machine is regarded as one of the best classifiers with a strong mathematical foundation. On the other hand, evolutionary computational technique is characterized as a soft computing learning method with its roots in the theory of evolution. During the past decade, SVM has been commonly used as a classifier for various applications. The evolutionary computation has also attracted a lot of attention in pattern recognition and has shown significant performance improvement on a variety of applications. However, there has been no comparison of the two methods. In this paper, first we propose an improvement of a coevolutionary computational classification algorithm, called Improved Coevolutionary Feature Synthesized EM (I-CFS-EM) algorithm. It is a hybrid of coevolutionary genetic programming and EM algorithm applied on partially labeled data. It requires less labeled data and it makes the test in a lower dimension, which speeds up the testing. Then, we provide a comprehensive comparison between SVM with different kernel functions and I-CFS-EM on several real datasets. This comparison shows that I-CFS-EM outperforms SVM in the sense of both the classification performance and the computational efficiency in the testing phase. We also give an intensive analysis of the pros and cons of both approaches.|Rui Li,Bir Bhanu,Krzysztof Krawiec"],["57951|GECCO|2007|An estimation of distribution algorithm with guided mutation for a complex flow shop scheduling problem|An Estimation of Distribution Algorithm (EDA) is proposed toapproach the Hybrid Flow Shop with Sequence Dependent Setup Times and Uniform Machines in parallel (HFS-SDST-UM) problem. The latter motivated by the needs of a real world company. The proposed EDA implements a fairly new mechanism to improve the search of more traditional EDAs. This is the Guided Mutation (GM). EDA-GM generates new solutions by using the information from a probability model, as all EDAs, and the local information from a good known solution. The approach is tested on several instances of HFS-SDST-UM and compared with adaptations of meta-heuristics designed for very similarproblems. Encouraging results are reported.|Abdellah Salhi,José Antonio Vázquez Rodríguez,Qingfu Zhang","57771|GECCO|2006|An effective genetic algorithm for the minimum-label spanning tree problem|Given a connected, undirected graph G with labeled edges, the minimum label spanning tree problem seeks a spanning tree on G to whose edges are attached the smallest possible number of labels. A greedy heuristic for this NP-hard problem greedily chooses labels so as to reduce the number of components in the subgraphs they induce as quickly as possible. A genetic algorithm for the problem encodes candidate solutions as per mutations of the labels an initial segment of such a chromosome lists the labels that appear on the edges in the chromosome's tree. Three versions of the GA apply generic or heuristic crossover and mutation operators and a local search step. In tests on  randomly-generated instances of the minimum-label spanning tree problem, versions of the GA that apply generic operators, with and without the local search step, perform less well than the greedy heuristic, but a version that applies the local search step and operators tailored to the problem returns solutions that require on average  fewer labels than the heuristic's.|Jeremiah Nummela,Bryant A. Julstrom","57887|GECCO|2007|An application of EDA and GA to dynamic pricing|E-commerce has transformed the way firms develop their pricing strategies, producing shift away from fixed pricing to dynamic pricing. In this paper, we use two different Estimation of distribution algorithms (EDAs), a Genetic Algorithm (GA) and a Simulated Annealing (SA) algorithm for solving two different dynamic pricing models. Promising results were obtained for an EDA confirming its suitability for resource management in the proposed model. Our analysis gives interesting insights into the application of population based optimization techniques for dynamic pricing.|Siddhartha Shakya,Fernando Oliveira,Gilbert Owusu","57946|GECCO|2007|SDR a better trigger for adaptive variance scaling in normal EDAs|Recently, advances have been made in continuous, normal-distribution-based Estimation-of-DistributionAlgorithms (EDAs) by scaling the variance upfrom the maximum-likelihood estimate. When doneproperly, such scaling has been shown to preventpremature convergence on slope-like regions ofthe search space. In this paper we specificallyfocus on one way of scaling that was previouslyintroduced as Adaptive Variance Scaling (AVS). It wasfound that when using AVS, the average number offitness evaluations grows subquadratically withthe dimensionality on a wide range of unimodaltest-problems, competitively with the CMA-ES.Still, room for improvement exists because thevariance doesn't always have to be scaled. Apreviously introduced trigger based on correlationthat determines when to apply scaling was shownto fail on higher dimensional problems. Here weprovide a new solution called the Standard-DeviationRatio (SDR) trigger that is integrated with theIterated Density-Estimation Evolutionary Algorithm(IDEA). Intuitively put, scaling istriggered with SDR only if improvements are foundto be far away from the mean. SDR works even inhigh dimensions as a result of factorizing thedecision rule behind the trigger according to theestimated Bayesian factorization. We evaluateSDR-AVS-IDEA on the same set ofbenchmark problems and compare it with AVS-IDEAand CMA-ES. We find that the addition of SDR givesAVS-IDEA an important extra edgefor it to be used in future research and inapplications both in single-objective optimizationas well as in multi-objective and dynamicoptimization. In addition, we provide practical rulesof thumb for parameter settings for usingSDR-AVS-IDEA that result in anasymptotic scale-up behavior that is sublinearfor the population size (O(l.)) andsubquadratic (O(l.)) for thenumber of evaluations.|Peter A. N. Bosman,Jörn Grahl,Franz Rothlauf","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","57860|GECCO|2006|The LEM implementation of learnable evolution model and its testing on complex function optimization problems|Learnable Evolution Model (LEM) is a form of non-Darwinian evolutionary computation that employs machine learning to guide evolutionary processes. Its main novelty are new type of operators for creating new individuals, specifically, hypothesis generation, which learns rules indicating subareas in the search space that likely contain the optimum, and hypothesis instantiation, which populates these subspaces with new individuals. This paper briefly describes the newest and most advanced implementation of learnable evolution, LEM, its novel features, and results from its comparison with a conventional, Darwinian-type evolutionary computation program (EA), a cultural evolution algorithm (CA), and the estimation of distribution algorithm (EDA) on selected function optimization problems (with the number of variables varying up to ). In every experiment, LEM outperformed the compared programs in terms of the evolution length (the number of fitness evaluations needed to achieved a desired solution), sometimes more than by one order of magnitude.|Janusz Wojtusiak,Ryszard S. Michalski","58010|GECCO|2007|Global multiobjective optimization via estimation of distribution algorithm with biased initialization and crossover|Multiobjective optimization problems with many local Pareto fronts is a big challenge to evolutionary algorithms. In this paper, two operators, biased initialization and biased crossover, are proposed to improve the global search ability of RM-MEDA, a recently proposed multiobjective estimation of distribution algorithm. Biased initialization inserts several globally Pareto optimal solutions into the initial population biased crossover combines the location information of some best solutions found so far and globally statistical information extracted from current population. Experiments have been conducted to study the effects of these two operators.|Aimin Zhou,Qingfu Zhang,Yaochu Jin,Bernhard Sendhoff,Edward P. K. Tsang","57674|GECCO|2006|The correlation-triggered adaptive variance scaling IDEA|It has previously been shown analytically and experimentally that continuous Estimation of Distribution Algorithms (EDAs) based on the normal pdf can easily suffer from premature convergence. This paper takes a principled first step towards solving this problem. First, prerequisites for the successful use of search distributions in EDAs are presented. Then, an adaptive variance scaling theme is introduced that aims at reducing the risk of premature convergence. Integrating the scheme into the iterated density--estimation evolutionary algorithm (IDEA) yields the correlation-triggered adaptive variance scaling IDEA (CT-AVS-IDEA). The CT-AVS-IDEA is compared to the original IDEA and the Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) on a wide range of unimodal test-problems by means of a scalability analysis. It is found that the average number of fitness evaluations grows subquadratically with the dimensionality, competitively with the CMA-ES. In addition, CT-AVS-IDEA is indeed found to enlarge the class of problems that continuous EDAs can solve reliably.|Jörn Grahl,Peter A. N. Bosman,Franz Rothlauf","57969|GECCO|2007|Dependency trees permutations and quadratic assignment problem|This paper describes and analyzes an estimation of distribution algorithm based on dependency tree models (dtEDA), which can explicitly encode probabilistic models for permutations. dtEDA is tested on deceptive ordering problems and a number of instances of the quadratic assignment problem. The performance of dtEDA is compared to that of the standard genetic algorithm with the partially matched crossover (PMX) and the linear order crossover (LOX). In the quadratic assignment problem, the robust tabu search is also included in the comparison.|Martin Pelikan,Shigeyoshi Tsutsui,Rajiv Kalapala","57685|GECCO|2006|A new proposal for multi-objective optimization using differential evolution and rough sets theory|This paper presents a new multi-objective evolutionary algorithm (MOEA) based on differential evolution and rough sets theory. The proposed approach adopts an external archive in order to retain the nondominated solutions found during the evolutionary process. Additionally, the approach also incorporates the concept of pa-dominance to get a good distribution of the solutions retained. The main idea of the approach is to use differential evolution (DE) as our main search engine, trying to translate its good convergence properties exhibited in single-objective optimization to the multi-objective case. Rough sets theory is adopted in a second stage of the search in order to improve the spread of the nondominated solutions that have been found so far. Our hybrid approach is validated using standard test functions and metrics commonly adopted in the specialized literature. Our results are compared with respect to the NSGA-II, which is a MOEA representative of the state-of-the-art in the area.|Alfredo García Hernández-Díaz,Luis V. Santana-Quintero,Carlos A. Coello Coello,Rafael Caballero,Julián Molina Luque"],["58180|GECCO|2007|Alternative techniques to solve hard multi-objective optimization problems|In this paper, we propose the combination of different optimization techniques in order to solve \"hard\" two- and three-objective optimization problems at a relatively low computational cost. First, we use the -constraint method in order to obtain a few points over (or very near of) the true Pareto front, and then we use an approach based on rough sets to spread these solutions, so that the entire Pareto front can be covered. The constrained single-objective optimizer required by the -constraint method, is the cultured differential evolution, which is an efficient approach for approximating the global optimum of a problem with a low number of fitness function evaluations. The proposed approach is validated using several difficult multi-objective test problems, and our results are compared with respect to a multi-objective evolutionary algorithm representative of the state-of-the-art in the area the NSGA-II.|Ricardo Landa Becerra,Carlos A. Coello Coello,Alfredo García Hernández-Díaz,Rafael Caballero,Julián Molina Luque","57890|GECCO|2007|Optimal antenna placement using a new multi-objective chc algorithm|Radio network design (RND) is a fundamental problem in cellular networks for telecommunications. In these networks, the terrain must be covered by a set of base stations (or antennae), each of which defines a covered area called cell. The problem may be reduced to figure out the optimal placement of antennae out of a list of candidate sites trying to satisfy two objectives to maximize the area covered by the radio signal and to reduce the number of used antennae. Consequently, RND is a bi-objective optimization problem. Previous works have solved the problem by using single-objective techniques which combine the values of both objectives. The used techniques have allowed to find optimal solutions according to the defined objective, thus yielding a unique solution instead of the set of Pareto optimal solutions. In this paper, we solve the RND problem using a multi-objective version of the algorithm CHC, which is the metaheuristic having reported the best results when solving the single-objective formulation of RND. This new algorithm, called MOCHC, is compared against a binary-coded NSGA-II algorithm and also against the provided results in the literature. Our experiments indicate that MOCHC outperfoms NSGA-II and, more importantly, it is more efficient finding the optimal solutions than single-objectives techniques.|Antonio J. Nebro,Enrique Alba,Guillermo Molina,J. Francisco Chicano,Francisco Luna,Juan José Durillo","57700|GECCO|2006|Incorporating directional information within a differential evolution algorithm for multi-objective optimization|The field of Differential Evolution (DE) has demonstrated important advantages in single objective optimization. To date, no previous research has explored how the unique characteristics of DE can be applied to multi-objective optimization. This paper explains and demonstrates how DE can provide advantages in multi-objective optimization using directional information. We present three novel DE variants for multi-objective optimization, and a report of their performance on four multi-objective problems with different characteristics. The DE variants are compared with the NSGA-II (Nondominated Sorting Genetic Algorithm). The results suggest that directional information yields improvements in convergence speed and spread of solutions.|Antony W. Iorio,Xiaodong Li","57670|GECCO|2006|On the effect of populations in evolutionary multi-objective optimization|Multi-objective evolutionary algorithms (MOEAs) have become increasingly popular as multi-objective problem solving techniques. An important open problem is to understand the role of populations in MOEAs. We present a simple bi-objective problem which emphasizes when populations are needed. Rigorous runtime analysis point out an exponential runtime gap between the population-based algorithm Simple Evolutionary Multi-objective Optimizer (SEMO) and several single individual-based algorithms on this problem. This means that among the algorithms considered, only the population-based MOEA is successful and all other algorithms fail.|Oliver Giel,Per Kristian Lehre","58190|GECCO|2007|Multi-objective hybrid PSO using -fuzzy dominance|This paper describes a PSO-Nelder Mead Simplex hybrid multi-objective optimization algorithm based on a numerical metric called  -fuzzy dominance. Within each iteration of this approach, in addition to the position and velocity update of each particle using PSO, the k-means algorithm is applied to divide the population into smaller sized clusters. The Nelder-Mead simplex algorithm is used separately within each cluster for added local search. The proposed algorithm is shown to perform better than MOPSO on several test problems as well as for the optimization of a genetic model for flowering time control in Arabidopsis. Adding the local search achieves faster convergence, an important feature in computationally intensive optimization of gene networks.|Praveen Koduru,Sanjoy Das,Stephen Welch","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57919|GECCO|2007|Parallel skeleton for multi-objective optimization|Many real-world problems are based on the optimization of more than one objective function. This work presents a tool for the resolution of multi-objective optimization problems based on the cooperation of a set of algorithms. The invested time in the resolution is decreased by means of a parallel implementation of an evolutionary team algorithm. This model keeps the advantages of heterogeneous island models but also allows to assign more computational resources to the algorithms with better expectations. The elitist scheme applied aims to improve the results obtained with single executions of independent evolutionary algorithms. The user solves the problem without the need of knowing the internal operation details of the used evolutionary algorithms. The computational results obtained on a cluster of PCs for some tests available in the literature are presented.|Coromoto León,Gara Miranda,Carlos Segura","58186|GECCO|2007|A multi-objective imaging scheduling approach for earth observing satellites|EOSs (Earth Observing Satellites) circle the earth to take shotswhich are requested by customers. To make replete use of resourcesof EOSs, it is required to deal with the problem of united imagingscheduling of EOSs in a given scheduling horizon, which is acomplicated multi-objective combinatorial optimization problem. Inthis paper, we construct a mathematical model for the problem byabstracting imaging constraints of different EOSs. Then we propose anovel multi-objective EOSs imaging scheduling method, which is basedon the Strength Pareto Evolutionary Algorithm . The specialencoding technique and imaging constraint control are applied toguarantee feasibility of solutions. The approach is tested upon fourreal application problems of CBERS EOSs series. From the results, itis confirmed that the proposed approach is effective in solvingmulti-objective EOSs imaging scheduling problems.|Jun Wang,Ning Jing,Jun Li,Zhong Hui Chen","57699|GECCO|2006|Rotated test problems for assessing the performance of multi-objective optimization algorithms|This paper presents four rotatable multi-objective test problems that are designed for testing EMO (Evolutionary Multi-objective Optimization) algorithms on their ability in dealing with parameter interactions. Such problems can be solved efficiently only through simultaneous improvements to each decision variable. Evaluation of EMO algorithms with respect to this class of problem has relevance to real-world problems, which are seldom separable. However, many EMO test problems do not have this characteristic. The proposed set of test problems in this paper is intended to address this important requirement. The design principles of these test problems and a description of each new test problem are presented. Experimental results on these problems using a Differential Evolution Multi-objective Optimization algorithm are presented and contrasted with the Non-dominated Sorting Genetic Algorithm II (NSGA-II).|Antony W. Iorio,Xiaodong Li","57996|GECCO|2007|Why is parity hard for estimation of distribution algorithms|We describe a k-bounded and additively separable test problem on which the hierarchical Bayesian Optimization Algorithm (hBOA) scales exponentially.|David Jonathan Coffin,Robert Elliott Smith"],["57829|GECCO|2006|Evolution of driving agent remotely operating a scale model of a car with obstacle avoidance capabilities|We present an approach for evolutionary design of an agent, remotely operating a scale model of a car running in a fastest possible way. The agent perceives the environment from a video camera and conveys its actions to the car via standard radio control transmitter. In order to cope with the video feed latency we propose an anticipatory modeling in which the agent considers its current actions based on the anticipated intrinsic (rather than currently available, outdated) state of the car and its surrounding. The agent is first evolved on software models of the car and tracks, and then adapted to the real world. During the adaptation, the lap times improve steadily to the values close to the values obtained from the evolution on the models. An evolutionary optimization of the avoidance of a small obstacle results in lap times that are virtually the same as the best lap times achieved on the same track without obstacles. Presented work can be viewed as a step towards developing a racing game in which the human competes against a computer, both operating scale models of racing cars.|Ivan Tanev,Michal Joachimczak,Katsunori Shimohara","57605|GECCO|2006|Hierarchically organised evolution strategies on the parabolic ridge|Organising evolution strategies hierarchically has been proposed as a means for adapting strategy parameters such as step lengths. Experimental research has shown that on ridge functions, hierarchically organised strategies can significantly outperform strategies that rely on mutative self-adaptation. This paper presents a first theoretical analysis of the behaviour of a hierarchically organised evolution strategy. Quantitative results are derived for the parabolic ridge that describe the dependence on the length of the isolation periods of the mutation strength and the progress rate. The issue of choosing an appropriate length of the isolation periods is discussed and comparisons with recent results for cumulative step length adaptation are drawn.|Dirk V. Arnold,Alexander MacLeod","57766|GECCO|2006|A dynamically constrained genetic algorithm for hardware-software partitioning|In this article, we describe the application of an enhanced genetic algorithm to the problem of hardware-software codesign. Starting from a source code written in a high level language our algorithm determines, using a dynamically-weighted fitness function, the most interesting code parts of the program to be implemented in hardware, given a limited amount of resources, in order to achieve the greatest overall execution speedup. The novelty of our approach resides in the tremendous reduction of the search space obtained by specific optimizations passes that are conducted on each generation. Moreover, by considering different granularities during the evolution process, very fast and effective convergence (in the order of a few seconds) can thus be attained. The partitioning obtained can then be used to build the different functional units of a processor well suited for a large customization, thanks to its architecture that uses only one instruction, Move.|Pierre-André Mudry,Guillaume Zufferey,Gianluca Tempesti","58151|GECCO|2007|Performance analysis of niching algorithms based on derandomized-ES variants|A survey of niching algorithms, based on  variants of derandomized Evolution Strategies (ES), is introduced. This set of niching algorithms, ranging from the very first derandomized approach to self-adaptation of ES to the sophisticated ( +over, ) Covariance Matrix Adaptation (CMA), is applied to multimodal continuous theoretical test functions, of different levels of difficulty and various dimensions, and compared with the MPR performance analysis tool. While characterizing the performance of the different derandomized variants in the context of niching, some conclusions concerning the niching formation process of the different mechanisms are drawn, and the hypothesis of a tradeoff between learning time and niching acceleration is numerically confirmed. Niching with (+)-CMA core mechanism is shown to experimentally outperform all the other variants. Some theoretical arguments supporting the advantage of a plus-strategy for niching are discussed.|Ofer M. Shir,Thomas Bäck","58212|GECCO|2007|On the use of evolution strategies for optimising certain positive definite quadratic forms|This paper studies the performance of multi-recombinative evolution strategies using isotropically distributed mutations on a class of convex quadratic objective functions that is characterised by the presence of only two different eigenvalues of their Hessian. A simplified model of the strategy's behaviour is developed. Using it, expressions that approximately describe the stationary state that is attained when the mutation strength is adapted are derived. The performance achieved when using cumulative step length adaptation is compared with that obtained when using optimally adapted step lengths.|Dirk V. Arnold","57623|GECCO|2006|Simulated annealing for improving software quality prediction|In this paper, we propose an approach for the combination and adaptation of software quality predictive models. Quality models are decomposed into sets of expertise. The approach can be seen as a search for a valuable set of expertise that when combined form a model with an optimal predictive accuracy. Since, in general, there will be several experts available and each expert will provide his expertise, the problem can be reformulated as an optimization and search problem in a large space of solutions.We present how the general problem of combining quality experts, modeled as Bayesian classifiers, can be tackled via a simulated annealing algorithm customization. The general approach was applied to build an expert predicting object-oriented software stability, a facet of software quality. Our findings demonstrate that, on available data, composed expert predictive accuracy outperforms the best available expert and it compares favorably with the expert build via a customized genetic algorithm.|Salah Bouktif,Houari A. Sahraoui,Giuliano Antoniol","57989|GECCO|2007|Sex and death towards biologically inspired heuristics for constraint handling|Constrained continuous optimization is still an interesting field of research. Many heuristics have been proposed in the last decade. Most of them are based on penalty functions. Here, we experimentally investigate the two constraint handling heuristics proposed by Kramer and Schwefel. The two sexes evolution strategy (TSES) is inspired by the biological concept of sexual selection and pairing. The death penalty step control evolution strategy (DSES) is based on the controlled reduction of a minimum step size depending on the distance to the infeasible search space. These two methods are able to overcome the problem of premature mutation strength reduction, a result of the self-adaptation mechanism of evolution strategies in constrained environments. All methods are experimentally evaluated on a couple of typical constrained test problems. These experiments offer recommendations for the TSES population ratios and the speed of the -reduction process of the DSES.|Oliver Kramer,Stephan Brügger,Dejan Lazovic","57622|GECCO|2006|A novel approach to optimize clone refactoring activity|Software evolution and software quality are ever changing phenomena. As software evolves, evolution impacts software quality. On the other hand, software quality needs may drive software evolution strategies.This paper presents an approach to schedule quality improvement under constraints and priority. The general problem of scheduling quality improvement has been instantiated into the concrete problem of planning duplicated code removal in a geographical information system developed in C throughout the last  years. Priority and constraints arise from development team and from the adopted development process. The developer team long term goal is to get rid of duplicated code, improve software structure, decrease coupling, and improve cohesion.We present our problem formulation, the adopted approach, including a model of clone removal effort and preliminary results obtained on a real world application.|Salah Bouktif,Giuliano Antoniol,Ettore Merlo,Markus Neteler","57697|GECCO|2006|A computational efficient covariance matrix update and a -CMA for evolution strategies|First, the covariance matrix adaptation (CMA) with rank-one update is introduced into the (+)-evolution strategy. An improved implementation of the -th success rule is proposed for step size adaptation, which replaces cumulative path length control. Second, an incremental Cholesky update for the covariance matrix is developed replacing the computational demanding and numerically involved decomposition of the covariance matrix. The Cholesky update can replace the decomposition only for the update without evolution path and reduces the computational effort from O(n) to O(n). The resulting (+)-Cholesky-CMA-ES is an elegant algorithm and the perhaps simplest evolution strategy with covariance matrix and step size adaptation. Simulations compare the introduced algorithms to previously published CMA versions.|Christian Igel,Thorsten Suttorp,Nikolaus Hansen","57929|GECCO|2007|The second harmonic generation case-study as a gateway for es to quantum control problems|The Second Harmonic Generation (SHG), a process that turns out to be a good test case in the physics lab, can also be considered as a fairly simple theoretical test function for global optimization. Despite its symmetry properties, that will be derived here analytically, it seems to capture the complexity of the Fourier transform between the decision space to the evaluation space, and by that to challenge optimization routines. And indeed, counter-intuitively to some extent, locating its global maximum seems to be not an easy task for Evolutionary Algorithms (EAs). Although this research originates from the real-world applications domain, it aims to introduce a theoretical test case to Evolution Strategies (ES), being a possible theoretical gateway to the real-world physics regime of quantum control problems. After presenting some theoretical results, this paper introduces the study of the scalability of the decision space subject to optimization by specific variants of Derandomized Evolution Strategies. We show that the Evolution Strategy in use requires a quasi-quadratic increase of function evaluations for locating the global maximum as the dimensionality increases.|Ofer M. Shir,Thomas Bäck"],["57615|GECCO|2006|Hyper-ellipsoidal conditions in XCS rotation linear approximation and solution structure|The learning classifier system XCS is an iterative rule-learning system that evolves rule structures based on gradient-based prediction and rule quality estimates. Besides classification and reinforcement learning tasks, XCS was applied as an effective function approximator. Hereby, XCS learns space partitions to enable a maximally accurate and general function approximation. Recently, the function approximation approach was improved by replacing () hyperrectangular conditions with hyper-ellipsoids and () iterative linear approximation with the recursive least squares method. This paper combines the two approaches assessing the usefulness of each. The evolutionary process is further improved by changing the mutation operator implementing an angular mutation that rotates ellipsoidal structures explicitly. Both enhancements improve XCS performance in various non-linear functions. We also analyze the evolving ellipsoidal structures confirming that XCS stretches and rotates the evolving ellipsoids according to the shape of the underlying function. The results confirm that improvements in both the evolutionary approach and the gradient approach can result in significantly better performance.|Martin V. Butz,Pier Luca Lanzi,Stewart W. Wilson","57883|GECCO|2007|XCS for adaptive user-interfaces|We outline our context learning framework that harnesses information from a user's environment to learn user preferences for application actions. Within this framework, we employ XCS in a real world application for personalizing user-interface actions to individual users. Sycophant, our context aware calendaring application and research test-bed, uses XCS to adaptively generate user-preferred alarms for ten users in our study. Our results show that XCS' alarm prediction performance equals or surpasses the performance of One-R and a decision tree algorithm for all the users. XCS' average performance is close to $$ percent on the alarm prediction task for all ten users. These encouraging results further highlight the feasibility of using XCS for predictive data mining tasks and the promise of a classifier systems based approach to personalize user interfaces.|Anil Shankar,Sushil J. Louis,Sergiu Dascalu,Ramona Houmanfar,Linda J. Hayes","58097|GECCO|2007|Mining breast cancer data with XCS|In this paper, we describe the use of a modern learning classifier system to a data mining task. In particular, in collaboration with a medical specialist, we apply XCS to a primary breast cancer data set. Our results indicate more effective knowledge discovery than with C..|Faten Kharbat,Larry Bull,Mohammed Odeh","57712|GECCO|2006|Standard and averaging reinforcement learning in XCS|This paper investigates reinforcement learning (RL) in XCS. First, it formally shows that XCS implements a method of generalized RL based on linear approximators, in which the usual input mapping function translates the state-action space into a niche relative fitness space. Then, it shows that, although XCS has always been related to standard RL, XCS is actually a method of averaging RL. More precisely, XCS with gradient descent can be actually derived from the typical update of averaging RL. It is noted that the use of averaging RL in XCS introduces an intrinsic preference toward classifiers with a smaller fitness in the niche. It is argued that, because of the accuracy pressure in XCS, this results in an additional preference toward specificity. A very simple experiment is presented to support this hypothesis. The same approach is applied to XCS with computed prediction (XCSF) and similar conclusions are drawn.|Pier Luca Lanzi,Daniele Loiacono","57777|GECCO|2006|Bounding XCSs parameters for unbalanced datasets|This paper analyzes the behavior of the XCS classifier system on imbalanced datasets. We show that XCS with standard parameter settings is quite robust to considerable class imbalances. For high class imbalances, XCS suffers from biases toward the majority class. We analyze XCS's behavior under such extreme imbalances and prove that appropriate parameter tuning improves significantly XCS's performance. Specifically, we counterbalance the imbalance ratio by equalizing the reproduction probabilities of the most occurring and least occurring niches. The study provides guidelines to tune XCS's parameters for unbalanced datasets, based on the dataset imbalance ratio. We propose a method to estimate the imbalance ratio during XCS's training and adapt XCS's parameters online.|Albert Orriols-Puig,Ester Bernadó-Mansilla","58011|GECCO|2007|Introducing fault tolerance to XCS|In this paper, we introduce fault tolerance to XCS and propose a new XCS framework called XCS with Fault Tolerance (XCSFT). As an important branch of learning classifier systems, XCS has been proven capable of evolving maximally accurate, maximally general problem solutions. However, in practice, it oftentimes generates a lot of rules, which lower the readability of the evolved classification model, and thus, people may not be able to get the desired knowledge or useful information out of the model. Inspired by the fault tolerance mechanism proposed in field of data mining, we devise a new XCS framework by integrating the concept and mechanism of fault tolerance into XCS in order to reduce the number of classification rules and therefore to improve the readability of the generated prediction model. A series of $N$-multiplexer experiments, including -bit, -bit, -bit, and -bit multiplexers, are conducted to examine whether XCSFT can accomplish its goal of design. According to the experimental results, XCSFT can offer the same level of prediction accuracy on the test problems as XCS can, while the prediction model evolved by XCSFT consists of significantly fewer classification rules.|Hong-Wei Chen,Ying-Ping Chen","57733|GECCO|2006|Fast rule matching for learning classifier systems via vector instructions|Over the last ten years XCS has become the standard for Michigan-style learning classifier systems (LCS). Since the initial CS- work conceived by Holland, classifiers (rules) have widely used a ternary condition alphabet ,, for binary input problems. Most of the freely available implementations of this ternary alphabet in XCS rely on character-based encodings---easy to implement, not memory efficient, and expensive to compute. Profiling of freely available XCS implementations shows that most of their execution time is spent determining whether a rule is match or not, posing a serious threat to XCS scalability. In the last decade, multimedia and scientific applications have pushed CPU manufactures to include native support for vector instruction sets. This paper presents how to implement efficient condition encoding and fast rule matching strategies using vector instructions. The paper elaborates on Altivec (PowerPC G, G) and SSE (Intel PXeon and AMD Opteron) instruction sets producing speedups of XCS matching process beyond ninety times. Moreover, such a vectorized matching code will allow to easily scale beyond tens of thousands of conditions in a reasonable time. The proposed fast matching scheme also fits in any other LCS other than XCS.|Xavier Llorà,Kumara Sastry","57917|GECCO|2007|XCSF with computed continuous action|Wilson introduced XCSF as a successor to XCS. The major development of XCSF is the concept of a computed prediction. The efficiency of XCSF in dealing with numerical input and continuous payoff has been demonstrated. However, the possible actions must always be determined in advance. Yet domains such as robot control require numerical actions, so that neither XCS nor XCSF with their discrete actions can yield high performance. This paper studies computed action in XCSF, where the action is continuous with respect to the input state. In comparison with Wilson's architecture for continuous action, our XCSF version, called XCSFCA, proves to be more efficient.|Trung Hau Tran,Cédric Sanza,Yves Duthen,Thuc Dinh Nguyen","58137|GECCO|2007|Classifier systems that compute action mappings|The learning in a niche based learning classifier system depends both on the complexity of the problem space and on the number of available actions. In this paper, we introduce a version of XCS with computed actions, briefly XCSCA, that can be applied to problems involving a large number of actions. We report experimental results showing that XCSCA can evolve accurate and compact representations of binary functions which would be challenging for typical learning classifier system models.|Pier Luca Lanzi,Daniele Loiacono","57601|GECCO|2006|A Bayesian approach to learning classifier systems in uncertain environments|In this paper we propose a Bayesian framework for XCS , called BXCS. Following , we use probability distributions to represent the uncertainty over the classifier estimates of payoff. A novel interpretation of classifier and an extension of the accuracy concept are presented. The probabilistic approach is aimed at increasing XCS learning capabilities and tendency to evolve accurate, maximally general classifiers, especially when uncertainty affects the environment or the reward function. We show that BXCS can approximate optimal solutions in stochastic environments with a high level of uncertainty.|Davide Aliprandi,Alex Mancastroppa,Matteo Matteucci"],["58086|GECCO|2007|A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design|This paper presents a hybrid evolutionary programming algorithm to solve the spread spectrum radar polyphase code design problem. The proposed algorithm uses an Evolutionary Programming (EP) approach as global search heuristic. This EP is hybridized with a gradient-based local search procedure which includes a dynamic step adaptation procedure to perform accurate and efficient local search for better solutions. Numerical examples demonstrate that the algorithm outperforms existing approaches for this problem.|?ngel M. Pérez-Bellido,Sancho Salcedo-Sanz,Emilio G. Ortíz-García,Antonio Portilla-Figueras","57948|GECCO|2007|Automated trading on financial instruments with evolved neural networks|This paper presents an approach to single-position, intraday automated trading based on a neuro-genetic algorithm.An artificial neural network is evolved which provides trading signals to a very unsophisticated automated trading agent.|Antonia Azzini,Andrea Tettamanzi","58032|GECCO|2007|Applying particle swarm optimization to software testing|Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with  small artificial test objects and  more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.|Andreas Windisch,Stefan Wappler,Joachim Wegener","58152|GECCO|2007|Estimation of fitness landscape contours in EAs|Evolutionary algorithms applied in real domain should profit from information about the local fitness function curvature. This paper presents an initial study of an evolutionary strategy with a novel approach for learning the covariance matrix of a Gaussian distribution. The learning method is based one stimation of the fitness landscape contour line between the selected and discarded individuals. The distribution learned this way is then used to generate new population members. The algorithm presented here is the first attempt to construct the Gaussian distribution this way and should beconsidered only a proof of concept nevertheless, the empirical comparison on low-dimensional quadratic functions shows that our approach is viable and with respect to the number of evaluations needed to find a solution of certain quality, it is comparable to the state-of-the-art CMA-ES incase of sphere function and outperforms the CMA-ES in case of elliptical function.|Petr Posík,Vojtech Franc","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","57971|GECCO|2007|Towards clustering with XCS|This paper presents a novel approach to clustering using an accuracy-based Learning Classifier System. Our approach achieves this by exploiting the generalization mechanisms inherent to such systems. The purpose of the work is to develop an approach to learning rules which accurately describe clusters without prior assumptions as to their number within a given dataset. Favourable comparisons to the commonly used k-means algorithm are demonstrated on a number of synthetic datasets.|Kreangsak Tamee,Larry Bull,Ouen Pinngern","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao","58059|GECCO|2007|Automatic mutation test input data generation via ant colony|Fault-based testing is often advocated to overcome limitations ofother testing approaches however it is also recognized as beingexpensive. On the other hand, evolutionary algorithms have beenproved suitable for reducing the cost of data generation in the contextof coverage based testing. In this paper, we propose a newevolutionary approach based on ant colony optimization for automatictest input data generation in the context of mutation testingto reduce the cost of such a test strategy. In our approach the antcolony optimization algorithm is enhanced by a probability densityestimation technique. We compare our proposal with otherevolutionary algorithms, e.g., Genetic Algorithm. Our preliminaryresults on JAVA testbeds show that our approach performed significantlybetter than other alternatives.|Kamel Ayari,Salah Bouktif,Giuliano Antoniol","57685|GECCO|2006|A new proposal for multi-objective optimization using differential evolution and rough sets theory|This paper presents a new multi-objective evolutionary algorithm (MOEA) based on differential evolution and rough sets theory. The proposed approach adopts an external archive in order to retain the nondominated solutions found during the evolutionary process. Additionally, the approach also incorporates the concept of pa-dominance to get a good distribution of the solutions retained. The main idea of the approach is to use differential evolution (DE) as our main search engine, trying to translate its good convergence properties exhibited in single-objective optimization to the multi-objective case. Rough sets theory is adopted in a second stage of the search in order to improve the spread of the nondominated solutions that have been found so far. Our hybrid approach is validated using standard test functions and metrics commonly adopted in the specialized literature. Our results are compared with respect to the NSGA-II, which is a MOEA representative of the state-of-the-art in the area.|Alfredo García Hernández-Díaz,Luis V. Santana-Quintero,Carlos A. Coello Coello,Rafael Caballero,Julián Molina Luque","58075|GECCO|2007|A platform for the selection of genes in DNA microarraydata using evolutionary algorithms|This paper presents a flexible framework to the task of featureselection in classification of DNA microarray data. Theuser can select a number of filter methods in the preprocessingstage and choose from a wide set of classifiers (models and algorithms from WEKA  are available) and accuracy estimation methods. This approach implements wrapper methods, where Evolutionary Algorithms, with variable sized set based representations are used to reduce the number of attributes. Two case studies were used to validate the approach, with three distinct classifiers (-nearest neighbour, decision trees, SVMs), a filter method based on discriminant fuzzy patterns and k-fold cross-validation to estimate the generalization error.|Miguel Rocha,Rui Mendes,Paulo Maia,Daniel Glez-Peña,Florentino Fdez-Riverola"],["57678|GECCO|2006|Exploring network topology evolution through evolutionary computations|We present an evolutionary methodology that explores the evolution of network topology when a uniform growth of the network traffic is considered. The network redesign problem is formulated as an optimization problem, subject to a set of design and performance constraints, while minimizing the redesign cost by maintaining as many as possible of the network devices that constitute the original topology. The experimental results for a -level network redesign problem (consisting of  client nodes) demonstrate the value of the search technique within the genetic algorithms in finding good solutions with respect to redesign cost and time.|Sami J. Habib,Alice C. Parker","57961|GECCO|2007|Heuristic speciation for evolving neural network ensemble|Speciation is an important concept in evolutionary computation. It refers to an enhancements of evolutionary algorithms to generate a set ofdiverse solutions. The concept is studied intensively in the evolutionary design of neural network ensembles. Thediversity and cooperation of individual networks are among the essential criteria of the design.This paper proposes a speciation framework for ensemble design which integratesa collection of new techniques. Its characteristic features are(a) the population of networks are speciated as such thatthe mutual information between the networks' outputs and genotypic representations is preserved. (b) The ensemble is designed incrementally,upon discovery of a species of networks which enhances the ensembleperformance. (c) Multiple species are evolved andindividual networks are evaluated according to therole of their respective species in the ensemble.This framework provides an implementation of evolutionary algorithm which performs simultaneous single-objective optimizations.The new algorithm is evaluated with a series of classification benchmarks andshows an improvement over other evolutionary training strategiesand a statistical algorithm.|Shin Ando","58176|GECCO|2007|A study on metamodeling techniques ensembles and multi-surrogates in evolutionary computation|Surrogate-Assisted Memetic Algorithm (SAMA) is a hybrid evolutionary algorithm, particularly a memetic algorithm that employs surrogate models in the optimization search. Since most of the objective function evaluations in SAMA are approximated, the search performance of SAMA is likely to be affected by the characteristics of the models used. In this paper, we study the search performance of using different meta modeling techniques, ensembles, and multi-surrogates in SAMA. In particular, we consider the SAMA-TRF, a SAMA model management framework that incorporates a trust region scheme for interleaving use of exact objective function with computationally cheap local meta models during local searches. Four different metamodels, namely Gaussian Process (GP), Radial Basis Function (RBF), Polynomial Regression (PR), and Extreme Learning Machine (ELM) neural network are used in the study. Empirical results obtained show that while some metamodeling techniques perform best on particular benchmark problems, ensemble of metamodels and multisurrogates yield robust and improved solution quality on the benchmark problems in general, for the same computational budget.|Dudy Lim,Yew-Soon Ong,Yaochu Jin,Bernhard Sendhoff","58071|GECCO|2007|A novel generative encoding for exploiting neural network sensor and output geometry|A significant problem for evolving artificial neural networks is that the physical arrangement of sensors and effectors is invisible to the evolutionary algorithm. For example, in this paper, directional sensors and effectors are placed around the circumference of a robot in analogous arrangements. This configuration ensures that there is a useful geometric correspondence between sensors and effectors. However, if sensors are mapped to a single input layer and the effectors to a single output layer (as is typical), evolution has no means to exploit this fortuitous arrangement. To address this problem, this paper presents a novel generative encoding called connective Compositional Pattern Producing Networks (connective CPPNs) that can effectively detect and capitalize on geometric relationships among sensors and effectors. The key insight is that sensors and effectors with consistent geometric relationships can be exploited by a repeating motif in the neural architecture. Thus, by employing an encoding that can discover such motifs as a function of network geometry, it becomes possible to exploit it. In this paper, a method for evolving connective CPPNs called Hypercube-based Neuroevolution of Augmenting Topologies (HyperNEAT) discovers sensible repeating motifs that take advantage of two different placement schemes, demonstrating the utility of such an approach.|David B. D'Ambrosio,Kenneth O. Stanley","57769|GECCO|2006|Inference of genetic networks using S-system information criteria for model selection|In this paper we present an evolutionary approach for inferring the structure and dynamics in gene circuits from observed expression kinetics. For representing the regulatory interactions in a genetic network the decoupled S-system formalism has been used. We proposed an Information Criteria based fitness evaluation for model selection instead of the traditional Mean Squared Error (MSE) based fitness evaluation. A hill climbing local search method has been incorporated in our evolutionary algorithm for attaining the skeletal architecture which is most frequently observed in biological networks. Using small and medium-scale artificial networks we verified the implementation. The reconstruction method identified the correct network topology and predicted the kinetic parameters with high accuracy.|Nasimul Noman,Hitoshi Iba","57980|GECCO|2007|A multi-objective approach to discover biclusters in microarray data|The main motivation for using a multi-objective evolutionary algorithm for finding biclusters in gene expression data is motivated by the fact that when looking for biclusters in gene expression matrix, several objectives have to be optimized simultaneously, and often these objectives are in conflict with each other. Moreover, the use of evolutionary computation is justified by the huge dimensionality of the search space, since it is known that evolutionary algorithms have great exploration power. We focus our attention on finding biclusters of high quality with large variation. This is because, in expression data analysis, the most important goal may not be finding biclusters containing many genes and conditions, as it might be more interesting to find a set of genes showing similar behavior under a set of conditions. Experimental results confirm the validity of the proposed technique.|Federico Divina,Jesús S. Aguilar-Ruiz","57819|GECCO|2006|Comparing mathematical models on the problem of network inference|In this paper we address the problem of finding gene regulatory networks from experimental DNA microarray data. We focus on the evaluation of the performance of different mathematical models on the inference problem. They are used to model the underlying dynamic system of artificial regulatory networks. The dynamics of the artificial systems represent different basic types of behavior,dimensionality and mathematical properties. They are all created with three commonly used approaches, namely linear weight matrices, H-systems, and S-systems. Due to the complexity of the inference problem, some researchers suggested evolutionary algorithms for this purpose. However, in many publications only one algorithm is used without any comparison to other optimization methods. Thus, we introduce a framework to systematically apply evolutionary algorithms for further comparative analysis.|Christian Spieth,Nadine Hassis,Felix Streichert","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","58196|GECCO|2007|Why your mates shouldnt date|The structural characteristics of an inter-individual interaction topology have a large impact on the flow of genetic information throughout an evolving population. In this study, we systematically investigate the relationship between clustering in the network of observed mating events and the evolutionary dynamics of a panmictic genetic algorithm. This is achieved through the introduction of a new selection mechanism, which allows for a tunable degree of clustering in the emergent mating topology.|Joshua L. Payne,Margaret J. Eppstein","57763|GECCO|2006|Genomic computing networks learn complex POMDPs|A genomic computing network is a variant of a neural network for which a genome encodes all aspects, both structural and functional, of the network. The genome is evolved by a genetic algorithm to fit particular tasks and environments. The genome has three portions one for specifying links and their initial weights, a second for specifying how a node updates its internal state, and a third for specifying how a node updates the weights on its links. Preliminary experiments demonstrate that genomic computing networks can use node internal state to solve POMDPs more complex than those solved previously using neural networks.|David J. Montana,Eric Van Wyk,Marshall Brinn,Joshua Montana,Stephen Milligan"],["57743|GECCO|2006|Using context-aware crossover to improve the performance of GP|This paper describes the use of a recently introduced crossover operator for GP, context-aware crossover. Given a randomly selected subtree from one parent, context-aware crossover will always find the best location to place the subtree in the other parent.We examine the performance of GP when context-aware crossover is used as an extra crossover operator, and show that standard crossover is far more destructive, and that performance is better when only context-aware crossover is used.There is still a place for standard crossover, however, and results suggest that using standard crossover in the initial part of the run and then switching to context-aware crossover yields the best performance.We show that, across a range of standard GP benchmark problems, context-aware crossover produces a higher best fitness as well as a higher mean fitness, and even manages to solve the -bit multiplexer problem without ADFs. Furthermore, the individuals produced this way are much smaller than standard GP, and far fewer individual evaluations are required, so GP achieves a higher fitness by evaluating fewer and smaller individuals.|Hammad Majeed,Conor Ryan","57935|GECCO|2007|On the constructiveness of context-aware crossover|Crossover in Genetic Programming is mostly a destructive operator, generally producing children worse than the parents and occasionally producing those who are better. A recently introduced operator, Context-Aware Crossover, which implicitly discovers the best possible crossover site for a subtree has been shown to consistently attain higher fitnesses while processing fewer individuals.It has been observed that context-aware crossover is similar to Brood Crossover in that multiple children are produced during each crossover event. This paper performs a thorough analysis of these crossover operators and compares the performance of the two and demonstrates that, although they do work similarly, context-aware crossover performs a far better sampling of the search space and thus performs much better.We also demonstrate that context-aware crossover benefits from a speed up of almost an order of magnitude when using a simple and very small cache, which is over two orders of magnitute smaller than caches typically used.|Hammad Majeed,Conor Ryan","57666|GECCO|2006|A new approach for shortest path routing problem by random key-based GA|In this paper, we propose a Genetic Algorithm (GA) approach using a new paths growth procedure by the random key-based encoding for solving Shortest Path Routing (SPR) problem. And we also develop a combined algorithm by arithmetical crossover, swap mutation, and immigration operator as genetic operators. Numerical analysis for various scales of SPR problems shows the proposed random key-based genetic algorithm (rkGA) approach has a higher search capability that enhanced rate of reaching optimal solutions and improve computation time than other GA approaches using different genetic representation methods.|Mitsuo Gen,Lin Lin","58122|GECCO|2007|Lets get ready to rumble redux crossover versus mutation head to head on exponentially scaled problems|This paper analyzes the relative advantages between crossover and mutation on a class of deterministic and stochastic additively separable problems with substructures of non-uniform salience. This study assumes that the recombination and mutation operators have the knowledge of the building blocks (BBs) and effectively exchange or search among competing BBs. Facetwise models of convergence time and population sizing have been used to determine the scalability of each algorithm. The analysis shows that for deterministic exponentially-scaled additively separable, problems, the BB-wise mutation is more efficient than crossover yielding a speedup of o(llogl), where l is the problem size. For the noisy exponentially-scaled problems, the outcome depends on whether scaling on noise is dominant. When scaling dominates, mutation is more efficient than crossover yielding a speedup of o(llogl). On the other hand, when noise dominates, crossover is more efficient than mutation yielding a speedup of o(l).|Kumara Sastry,David E. Goldberg","58245|GECCO|2007|Effects of the use of non-geometric binary crossover on evolutionary multiobjective optimization|In the design of evolutionary multiobjective optimization (EMO) algorithms, it is important to strike a balance between diversity and convergence. Traditional mask-based crossover operators for binary strings (e.g., one-point and uniform) tend to decrease the diversity of solutions in EMO algorithms while they improve the convergence to the Pareto front. This is because such a crossover operator, which is called geometric crossover, always generates an offspring in the segment between its two parents under the Hamming distance in the genotype space. That is, the sum of the distances from the generated offspring to its two parents is always equal to the distance between the parents. In this paper, first we propose a non-geometric binary crossover operator to generate an offspring outside the segment between its parents. Next we examine the effect of the use of non-geometric binary crossover on single-objective genetic algorithms. Experimental results show that non-geometric binary crossover improves their search ability. Then we examine its effect on EMO algorithms. Experimental results show that non-geometric binary crossover drastically increases the diversity of solutions while it slightly degrades their convergence to the Pareto front. As a result, some performance measures such as hypervolume are clearly improved.|Hisao Ishibuchi,Yusuke Nojima,Noritaka Tsukamoto,Ken Ohara","57960|GECCO|2007|A new crossover technique for Cartesian genetic programming|Genetic Programming was first introduced by Koza using tree representation together with a crossover technique in which random sub-branches of the parents' trees are swapped to create the offspring. Later Miller and Thomson introduced Cartesian Genetic Programming, which uses directed graphs as a representation to replace the tree structures originally introduced by Koza. Cartesian Genetic Programming has been shown to perform better than the traditional Genetic Programming but it does not use crossover to create offspring, it is implemented using mutation only. In this paper a new crossover method in Genetic Programming is introduced. The new technique is based on an adaptation of the Cartesian Genetic Programming representation and is tested on two simple regression problems. It is shown that by implementing the new crossover technique, convergence is faster than that of using mutation only in the Cartesian Genetic Programming method.|Janet Clegg,James Alfred Walker,Julian Francis Miller","57667|GECCO|2006|Solving identification problem for asynchronous finite state machines using genetic algorithms|A Genetic Algorithm, embedded in a simulation-based method, is applied to the identification of Asynchronous Finite State Machines. Two different coding schemes and their associated crossover operations are examined. It is shown that one operator  coding pair outperforms the other in that the scheme reduces noticeably the production of invalid chromosomes thus increasing the efficiency and the convergence rate of the evolution process.|Xiaojun Geng","57710|GECCO|2006|Geometric crossover for multiway graph partitioning|Geometric crossover is a representation-independent generalization of the traditional crossover defined using the distance of the solution space. Using a distance tailored to the problem at hand, the formal definition of geometric crossover allows to design new problem-specific crossovers that embed problem-knowledge in the search. The standard encoding for multiway graph partitioning is highly redundant each solution has a number of representations, one for each way of labeling the represented partition. Traditional crossover does not perform well on redundant encodings. We propose a new geometric crossover for graph partitioning based on a labeling-independent distance that filters the redundancy of the encoding. A correlation analysis of the fitness landscape based on this distance shows that it is well suited to graph partitioning. Our new genetic algorithm outperforms existing ones.|Yong-Hyuk Kim,Yourim Yoon,Alberto Moraglio,Byung Ro Moon","57885|GECCO|2007|Empirical analysis of ideal recombination on random decomposable problems|This paper analyzes the behavior of a selectorecombinative genetic algorithm (GA) with an ideal crossover on a class of random additively decomposable problems (rADPs). Specifically, additively decomposable problems of order k whose subsolution fitnesses are sampled from the standard uniform distribution U, are analyzed. The scalability of the selectorecombinative GA is investigated for , rADP instances. The validity of facetwise models in bounding the population size, run duration, and the number of function evaluations required to successfully solve the problems is also verified. Finally, rADP instances that are easiest and most difficult are also investigated.|Kumara Sastry,Martin Pelikan,David E. Goldberg","58095|GECCO|2007|Efficiency updates for the restricted growth function GA for grouping problems|Problems that require the partitioning of a set of variables in order to compute a solution such as bin packing or line balancing are typically NP-hard. Hence, researchers have focused on producing heuristic methods for finding appropriate partitions. Many of the representations used in optimisation algorithms including those in GA methods suffer from degeneracy . Furthermore, Falkenauer has found that representations with less degeneracy result in more efficient GAs with respect to grouping problems . Previously we developed a new representation for grouping genetic algorithms called the Restricted Growth Function GA (RGFGA) . The RGFGA effectively removes all degeneracy, resulting in a more efficient search. However, one flaw of the RGFGA is that it converges too quickly resulting in a population with very little diversity. We exploit visualistion techniques, which can be used in conjunction with the Hamming distance, as well as introducing a novel population generator and a crossover operator which exploits the notion of extrema within grouping problems, to ensure diversity within the population. A restricted growth function is a function f  n  n such that f()  , f(i + ) - max f(), . . . , f(i)+. Note that there is a one-to-one correspondence between the set of RGFs and the set of partitions of n. In particular, the RGF represents a partition into m - n groups, where  by convention belongs to the first group, i belongs to the f(i)th group, and max f(), . . . , f(n)  m. The one-to-one correspondence means that there is no degeneracy in the representation of a partition using an RGF. We introduce a new random RGF generator to create a better coverage of the search space, and a new crossover operator for the RGFGA in order to prevent premature convergence. The grouping problem search space contains two extrema one occurs when all elements belong to a single group the other when each group contains a single element. We choose two distinct RGFs as parents as in the original RGFGA, f and g. However, one child (rather than two) is chosen using an existing path linking method  between f and g. The other child is generated from the path generated between one extremum chosen at random and one of the parents chosen at random. It is hoped that this modified crossover will ensure that a subset of children will be 'pulled away' from any local maxima toward the extrema in order to prevent premature convergence. A visualisation of this new crossover with the extrema points along with the old crossover used in  can be plotted within the search space using multidimensional scaling with Hamming distance between RGFs. The original RGF generator in  meant that at each iteration, the probability of a new group being generated decreases as the number of groups increases. Visualisation shows how the RGF generator biases individuals to be closer to the extrema with only one group.Therefore, we propose a new algorithm for generating RGFs that ensures an equal probability of creating a new group or using existing groups, whenever a new variable is assigned. Visualisation illustrates the resulting distribution of RGFs with individuals less clustered around one extremum than before. We tested the old RGFGA crossover with different combinations of the new one and the new random population generator as well as testing straw men approaches on a binpacking dataset and a multivariate time-series dataset that were outlined in . Our hypothesis was that the two updates to our previous RGFGA would reduce the premature convergence of the algorithm. The results appear to suggest that either new update to the RGFGA improves upon the original in terms of controlling premature convergence, resulting in a more efficient search. However, the combination does not appear to add any further improvement. Future work will involve applying the RGFGA to consensus clustering algorithms for gene expression data which currently use simple heuristic search techniques in order to cluster data without the biases of standard clustering techniques. We also intend to explore the parallelisation of the RGFGA using different distributed GA architectures.|Allan Tucker,Stephen Swift,Jason Crampton"],["57875|GECCO|2006|Growth of self-canceling code in evolutionary systems|This research examines the behavior of inoperative code (introns) in the evolution of genetically robust solutions. Genetically robust solutions are solutions that are less likely to be degraded by genetic operators, such as crossover. Previous work has shown that there is significant evolutionary pressure in favor of genetically robust solutions and that evolving programs adopt a number of strategies to increase genetic robustness, notably an increase in inoperative 'genes' (individual genetic units that don't influence fitness) and a preference for 'genes' with a relatively small effect on fitness.Here we examine the role of genes that cancel each other out. We find that allowing such 'canceling genes' leads to an overall increase in the rate of code growth, both through the inclusion of self-canceling code and through a general increase in introns. Finally, we find that the evolution generally follows a two-step process. Initially the operative code evolves rapidly to achieve a (near) optimal fitness. Then, the inoperative code begins to evolve most rapidly to increase robustness. In an extreme case of a problem that can be solved with no operative genes, individuals evolve by losing all operative genes and then losing all inoperative genes.|Xue Zhong,Terence Soule","57870|GECCO|2006|Both robust computation and mutation operation in dynamic evolutionary algorithm are based on orthogonal design|A robust dynamic evolutionary algorithm (labeled RODEA), where both the robust calculation and mutation operator are based on an orthogonal design, is proposed in this paper. Previous techniques calculate the mean effective objective (for robust) by using samples without much evenly distributing over the neighborhood. The samples by using orthogonal array distribute evenly. Therefore the calculation of mean effective objective more robust. The new technique is generalized from the ODEA algorithm . An orthogonal design method is employed on the niches for the mutation operator to find a potentially good solution that may become the representative in the niche. The fitness of the offspring is therefore likely to be higher than that of its parent. We propose a complex benchmark, consisting of moving function peaks, to test our new approach. Numerical experiments show that the moving solutions of the algorithm are a little worse in objective value but robust.|Sanyou Y. Zeng,Rui Wang,Hui Shi,Guang Chen,Hugo de Garis,Lishan Kang,Lixin X. Ding","57692|GECCO|2006|Comparing genetic robustness in generational vs steady state evolutionary algorithms|Previous research has shown that evolutionary systems not only try to develop solutions that satisfy a fitness requirement, but indirectly attempt to develop genetically robust solutions as well -solutions where average loss of fitness due to crossover and other genetic variation operators is minimized. It has been shown that in a simple \"two peaks\" problem, where the fitness landscape consists of a broad, low peak, and a narrow, high peak, individuals initially converge on the lower (less fit), but broader peak, and that increasing an individual's genetic robustness through growth is a necessary prerequisite for convergence on the higher, narrower peak . If growth is restricted, the population remains converged on the less fit solution. We tested whether this result holds true only for generational algorithms, or whether it applies to steady state algorithms as well. We conclude that although growth occurs with both algorithms, the steady state algorithm is able to converge on the higher peak without this growth. This result shows that the role of genetic robustness in the evolutionary process is significantly different in generational versus steady state algorithms.|Josh Jones,Terry Soule","57799|GECCO|2006|Selecting for evolvable representations|Evolutionary algorithms tend to produce solutions that are not evolvable Although current fitness may be high, further search is impeded as the effects of mutation and crossover become increasingly detrimental. In nature, in addition to having high fitness, organisms have evolvable genomes phenotypic variation resulting from random mutation is structured and robust. Evolvability is important because it allows the population to produce meaningful variation, leading to efficient search. However, because evolvability does not improve immediate fitness, it must be selected for indirectly. One way to establish such a selection pressure is to change the fitness function systematically. Under such conditions, evolvability emerges only if the representation allows manipulating how genotypic variation maps onto phenotypic variation and if such manipulations lead to detectable changes in fitness. This research forms a framework for understanding how fitness function and representation interact to produce evolvability. Ultimately evolvable encodings may lead to evolutionary algorithms that exhibit the structured complexity and robustness found in nature.|Joseph Reisinger,Risto Miikkulainen","57606|GECCO|2006|Deceptiveness and neutrality the ND family of fitness landscapes|When a considerable number of mutations have no effects on fitness values, the fitness landscape is said neutral. In order to study the interplay between neutrality, which exists in many real-world applications, and performances of metaheuristics, it is useful to design landscapes which make it possible to tune precisely neutral degree distribution. Even though many neutral landscape models have already been designed, none of them are general enough to create landscapes with specific neutral degree distributions. We propose three steps to design such landscapes first using an algorithm we construct a landscape whose distribution roughly fits the target one, then we use a simulated annealing heuristic to bring closer the two distributions and finally we affect fitness values to each neutral network. Then using this new family of fitness landscapes we are able to highlight the interplay between deceptiveness and neutrality.|William Beaudoin,Sébastien Vérel,Philippe Collard,Cathy Escazut","58074|GECCO|2007|The effects of solution density in the search space on finding spatially robust solutions|The common definition for robust solutions considers a solution robust if it remains optimal (or near optimal) when the parameters defining the fitness function are perturbed. We call this parameter robustness or temporal robustness. In this paper we propose an alternate definition for robustness, which we call spatial or solution robustness, if both the solution and the neighbourhood around the solution has high fitness. With this definition, we created a set of functions with useful properties to allow for the testing of solution robustness. We then focus on the effect of the precision (density) of the search space and find that it has a drastic effect on both the number of solutions and their quality.|Grzegorz Drzadzewski,Mark Wineberg","57792|GECCO|2006|Dynamics of evolutionary robustness|Recently there has been considerable interest in determining whether, and how much, evolutionary pressure for genetic robustness influences evolutionary processes. In this paper, we attempt to show that this evolutionary pressure does have a significant effect in typical genetic programming problems. Specifically we demonstrate that in a standard genetic programming implementation to solve a symbolic regression problem, pressure for genetic robustness forces the population away from high fitness, but less robust, solutions in favor of solutions with lower fitness, but higher genetic robustness.|Alan Piszcz,Terence Soule","57815|GECCO|2006|Single and multi-objective genetic operators in object-oriented conceptual software design|This poster paper investigates the potential of single and multi-objective genetic operators with an object-oriented conceptual design space. Using cohesion as an objective fitness function, genetic operators inspired by genetic algorithms and evolutionary programming are compared against a simple case study. Also, using both cohesion and coupling as objective fitness functions, multi-objective genetic operators inspired by a non-dominated sorting algorithm have been developed. Cohesion and coupling values achieved are similar to human performed designs and a large number and variety of optimal solutions are arrived at, which could not have been produced by the human software engineer. We conclude that this mass of optimal design variants offers significant potential for design support when integrated with user-centric, computationally intelligent tools.|Christopher L. Simons,Ian C. Parmee","57679|GECCO|2006|Fitness function for finding out robust solutions on time-varying functions|Evolutionary Computations in dynamicuncertain environments have attracted much attention. Studies regarding this research subjects can be classified into four categories Noise, Robustness, Fitness approximation, and Time-Varying function. In research on Time-Varying function, the tracking property over changes of fitness landscape has been broadly and deeply researched so far. In this paper, instead of tracking new peaks, robust solution to Time-Varying functions is introduced. Moreover, two weighted fitness functions, Exponential Weight and Linear Weight, are proposed. Experiments on modified Branke's benchmark problems on Time-Varying function reveal the effectiveness of the weighted approaches.|Hisashi Handa","57738|GECCO|2006|An empirical investigation of how and why neutrality affects evolutionary search|The effects of neutrality on evolutionary search have been considered in a number of studies, the results of which, however, have been contradictory. Some have found neutrality to be beneficial to aid evolution whereas others have argued that neutrality in the evolutionary process is useless. We believe that this confusion is due to several reasons many studies have based their conclusions on performance statistics rather than a more in-depth analysis of population dynamics, studies often consider problems, representations and search algorithms that are relatively complex and so results represent the compositions of multiple effects, there is not a single definition of neutrality and different studies have added neutrality to problems in radically different ways. In this paper, we try to shed some light on neutrality by addressing these problems. That is, we use the simplest possible definition of neutrality (a neutral network of constant fitness, identically distributed in the whole search space), we consider one of the simplest possible algorithms (a mutation based, binary genetic algorithm) applied to two simple problems (a unimodal landscape and a deceptive landscape), and analyse both performance figures and, critically, population flows from and to the neutral network and the basins of attraction of the optima.|Edgar Galván López,Riccardo Poli"],["58200|GECCO|2007|SNDL-MOEA stored non-domination level MOEA|There exist a number of high-performance Multi-Objective Evolutionary Algorithms (MOEAs) for solving Multi-Objective Optimization (MOO) problems two of the best are NSGA-II and epsilon-MOEA. However, they lack an archive population sorted into levels of non-domination, making them unsuitable for construction problems where some type of backtracking to earlier intermediate solutions is required. In this paper we introduce our Stored Non-Domination Level (SNDL) MOEA for solving such construction problems. SNDL-MOEA combines some of the best features of NSGA-II and epsilon-MOEA with the ability to store and recall intermediate solutions necessary for construction problems. We present results for applying SNDL-MOEA to the Tight Single Change Covering Design (TSCCD) construction problem, demonstrating its applicability. Furthermore, we show with a detailed performance comparison between SNDL-MOEA, NSGA-II, and epsilon-MOEA on two standard test series that SNDL-MOEA is capable of outperforming NSGA-II and is competitive with epsilon-MOEA.|Matt D. Johnson,Daniel R. Tauritz,Ralph W. Wilkerson","58180|GECCO|2007|Alternative techniques to solve hard multi-objective optimization problems|In this paper, we propose the combination of different optimization techniques in order to solve \"hard\" two- and three-objective optimization problems at a relatively low computational cost. First, we use the -constraint method in order to obtain a few points over (or very near of) the true Pareto front, and then we use an approach based on rough sets to spread these solutions, so that the entire Pareto front can be covered. The constrained single-objective optimizer required by the -constraint method, is the cultured differential evolution, which is an efficient approach for approximating the global optimum of a problem with a low number of fitness function evaluations. The proposed approach is validated using several difficult multi-objective test problems, and our results are compared with respect to a multi-objective evolutionary algorithm representative of the state-of-the-art in the area the NSGA-II.|Ricardo Landa Becerra,Carlos A. Coello Coello,Alfredo García Hernández-Díaz,Rafael Caballero,Julián Molina Luque","57670|GECCO|2006|On the effect of populations in evolutionary multi-objective optimization|Multi-objective evolutionary algorithms (MOEAs) have become increasingly popular as multi-objective problem solving techniques. An important open problem is to understand the role of populations in MOEAs. We present a simple bi-objective problem which emphasizes when populations are needed. Rigorous runtime analysis point out an exponential runtime gap between the population-based algorithm Simple Evolutionary Multi-objective Optimizer (SEMO) and several single individual-based algorithms on this problem. This means that among the algorithms considered, only the population-based MOEA is successful and all other algorithms fail.|Oliver Giel,Per Kristian Lehre","58103|GECCO|2007|An analysis of the effects of population structure on scalable multiobjective optimization problems|Multiobjective evolutionary algorithms (MOEA) are an effective tool for solving search and optimization problems containing several incommensurable and possibly conflicting objectives. Unfortunately, many MOEAs face difficulties in solving problems when the number of objectives increases. In this paper, we investigate the efficacy of spatially structured MOEAs for scalable multiobjective problems. The algorithm is an extension of the standard cellular evolutionary algorithm, where the population is mapped to nodes of alternative complex networks. A selection regime based on a non-dominance rating and a crowding mechanism guides the evolutionary trajectory and an -dominance external archive is used to maintain a spread of solutions across the Pareto-optimal front. An important outcome of this work is the classification of the network models based on their impact on convergence speed and solution quality as the number of objectives increases for a given problem.|Michael Kirley,Robert L. Stewart","57621|GECCO|2006|Combining gradient techniques for numerical multi-objective evolutionary optimization|Recently, gradient techniques for solving numerical multi-objective optimization problems have appeared in the literature. Although promising results have already been obtained when combined with multi-objective evolutionary algorithms (MOEAs), an important question remains what is the best way to integrate the use of gradient techniques in the evolutionary cycle of a MOEA. In this paper, we present an adaptive resource-allocation scheme that uses three gradient techniques in addition to the variation operator in a MOEA. During optimization, the effectivity of the gradient techniques is monitored and the available computational resources are redistributed to allow the (currently) most effective operator to spend the most resources. In addition, we indicate how the multi-objective search can be stimulated to also search $mboxemphalong $ the Pareto front, ultimately resulting in a better and wider spread of solutions. We perform tests on a few well-known benchmark problems as well as two novel benchmark problems with specific gradient properties. We compare the results of our adaptive resource-allocation scheme with the same MOEA without the use of gradient techniques and a scheme in which resource allocation is constant. The results show that our proposed adaptive resource-allocation scheme makes proper use of the gradient techniques only when required and thereby leads to results that are close to the best results that can be obtained by fine-tuning the resource allocation for a specific problem.|Peter A. N. Bosman,Edwin D. de Jong","57919|GECCO|2007|Parallel skeleton for multi-objective optimization|Many real-world problems are based on the optimization of more than one objective function. This work presents a tool for the resolution of multi-objective optimization problems based on the cooperation of a set of algorithms. The invested time in the resolution is decreased by means of a parallel implementation of an evolutionary team algorithm. This model keeps the advantages of heterogeneous island models but also allows to assign more computational resources to the algorithms with better expectations. The elitist scheme applied aims to improve the results obtained with single executions of independent evolutionary algorithms. The user solves the problem without the need of knowing the internal operation details of the used evolutionary algorithms. The computational results obtained on a cluster of PCs for some tests available in the literature are presented.|Coromoto León,Gara Miranda,Carlos Segura","58186|GECCO|2007|A multi-objective imaging scheduling approach for earth observing satellites|EOSs (Earth Observing Satellites) circle the earth to take shotswhich are requested by customers. To make replete use of resourcesof EOSs, it is required to deal with the problem of united imagingscheduling of EOSs in a given scheduling horizon, which is acomplicated multi-objective combinatorial optimization problem. Inthis paper, we construct a mathematical model for the problem byabstracting imaging constraints of different EOSs. Then we propose anovel multi-objective EOSs imaging scheduling method, which is basedon the Strength Pareto Evolutionary Algorithm . The specialencoding technique and imaging constraint control are applied toguarantee feasibility of solutions. The approach is tested upon fourreal application problems of CBERS EOSs series. From the results, itis confirmed that the proposed approach is effective in solvingmulti-objective EOSs imaging scheduling problems.|Jun Wang,Ning Jing,Jun Li,Zhong Hui Chen","57699|GECCO|2006|Rotated test problems for assessing the performance of multi-objective optimization algorithms|This paper presents four rotatable multi-objective test problems that are designed for testing EMO (Evolutionary Multi-objective Optimization) algorithms on their ability in dealing with parameter interactions. Such problems can be solved efficiently only through simultaneous improvements to each decision variable. Evaluation of EMO algorithms with respect to this class of problem has relevance to real-world problems, which are seldom separable. However, many EMO test problems do not have this characteristic. The proposed set of test problems in this paper is intended to address this important requirement. The design principles of these test problems and a description of each new test problem are presented. Experimental results on these problems using a Differential Evolution Multi-objective Optimization algorithm are presented and contrasted with the Non-dominated Sorting Genetic Algorithm II (NSGA-II).|Antony W. Iorio,Xiaodong Li","57797|GECCO|2006|A multi-objective evolutionary algorithm with weighted-sum niching for convergence on knee regions|A knee region on the Pareto-optimal front of a multi-objective optimization problem consists of solutions with the maximum marginal rates of return, i.e. solutions for which an improvement on one objective is accompanied by a severe degradation in another. The trade-off characteristic renders such solutions of particular interest in practical applications. This paper presents a multi-objective evolutionary algorithm focused on the knee regions. The algorithm facilitates better decision making in contexts where high marginal rates of return are desirable for Decision Makers. The proposed approach computes a transformation of the original objectives based on weighted-sum functions. The transformed functions identify niches which correspond to knee regions in the objective space. The extent and density of coverage of the knee regions are controllable by the niche strength and pool size parameters. Although based on weighted-sums, the algorithm is capable of finding solutions in the non-convex regions of the Pareto-front.|Lily Rachmawati,Dipti Srinivasan","57685|GECCO|2006|A new proposal for multi-objective optimization using differential evolution and rough sets theory|This paper presents a new multi-objective evolutionary algorithm (MOEA) based on differential evolution and rough sets theory. The proposed approach adopts an external archive in order to retain the nondominated solutions found during the evolutionary process. Additionally, the approach also incorporates the concept of pa-dominance to get a good distribution of the solutions retained. The main idea of the approach is to use differential evolution (DE) as our main search engine, trying to translate its good convergence properties exhibited in single-objective optimization to the multi-objective case. Rough sets theory is adopted in a second stage of the search in order to improve the spread of the nondominated solutions that have been found so far. Our hybrid approach is validated using standard test functions and metrics commonly adopted in the specialized literature. Our results are compared with respect to the NSGA-II, which is a MOEA representative of the state-of-the-art in the area.|Alfredo García Hernández-Díaz,Luis V. Santana-Quintero,Carlos A. Coello Coello,Rafael Caballero,Julián Molina Luque"],["57787|GECCO|2006|Sporadic model building for efficiency enhancement of hierarchical BOA|This paper describes and analyzes sporadic model building, which can be used to enhance the efficiency of the hierarchical Bayesian optimization algorithm (hBOA) and other advanced estimation of distribution algorithms (EDAs) that use complex multivariate probabilistic models. With sporadic model building, the structure of the probabilistic model is updated once every few iterations (generations), whereas in the remaining iterations only model parameters (conditional and marginal probabilities) are updated. Since the time complexity of updating model parameters is much lower than the time complexity of learning the model structure, sporadic model building decreases the overall time complexity of model building. The paper shows that for boundedly difficult nearly decomposable and hierarchical optimization problems, sporadic model building leads to a significant model-building speedup that decreases the asymptotic time complexity of model building in hBOA by a factor of (n .) to (n .), where n is the problem size. On the other hand, sporadic model building also increases the number of evaluations until convergence nonetheless, the evaluation slowdown is insignificant compared to the gains in the asymptotic complexity of model building.|Martin Pelikan,Kumara Sastry,David E. Goldberg","57879|GECCO|2007|Adopting dynamic operators in a genetic algorithm|Genetic Algorithms have been used to solve difficult optimization problems in a number of fields. However, in order to solve a problem with GA, the user has to specify a number of parameters.allThis parameter tuning is a difficult task as different genetic operators are suitable in different application areas. This paper proposes a scheme for genetic algorithms where the genetic operators are changed randomly. The information of gender and age is also incorporated in this approach to maintain population diversity. The experimental result of the proposed algorithm based on a mechanical design problem shows promising result.|Khadiza Tahera,Raafat N. Ibrahim,Paul B. Lochert","58046|GECCO|2007|Obtaining ground states of ising spin glasses via optimizing bonds instead of spins|Frustrated Ising spin glasses represent a rich class of challenging optimization problems that share many features with other complex, highly multimodal optimization and combinatorial problems. This paper shows that transforming candidate solutions to an alternative representation that is strongly tied to the energy function simplifies the exploration of the space of potential spin configurations and that it significantly improves performance of evolutionary algorithms with simple variation operators on Ising spin glasses. The proposed techniques are incorporated into the simple genetic algorithm, the univariate marginal distribution algorithm, and the hierarchical Bayesian optimization algorithm.|Martin Pelikan,Alexander K. Hartmann","57873|GECCO|2006|Design synthesis of microelectromechanical systems using genetic algorithms with component-based genotype representation|An automated design synthesis system based on a multi-objective genetic algorithm (MOGA) has been developed for the optimization of surface micromachined MEMS devices. A hierarchical component-based genotype representation is used, which incorporates specific engineering knowledge into the design and optimization process. Each MEMS component is represented by a gene with its own parameters defining its geometry and the way it can be modified from one generation to the next. The object-oriented genotype structures efficiently describe the hierarchical nature typical of engineering designs. They also prevent MOGA from wasting time exploring inappropriate regions of the search space. The automated MEMS design synthesis is demonstrated with surface-micromachined resonator and accelerometer designs.|Ying Zhang,Raffi R. Kamalian,Alice M. Agogino,Carlo H. Séquin","58243|GECCO|2007|Analyzing probabilistic models in hierarchical BOA on traps and spin glasses|The hierarchical Bayesian optimization algorithm (hBOA) can solve nearly decomposable and hierarchical problems of bounded difficulty in a robust and scalable manner by building and sampling probabilistic models of promising solutions. This paper analyzes probabilistic models in hBOA on two common test problems concatenated traps and D Ising spin glasses with periodic boundary conditions. We argue that although Bayesian networks with local structures can encode complex probability distributions, analyzing these models in hBOA is relatively straightforward and the results of such analyses may provide practitioners with useful information about their problems. The results show that the probabilistic models in hBOA closely correspond to the structure of the underlying optimization problem, the models do not change significantly in subsequent iterations of BOA, and creating adequate probabilistic models by hand is not straightforward even with complete knowledge of the optimization problem.|Mark Hauschild,Martin Pelikan,Cláudio F. Lima,Kumara Sastry","58203|GECCO|2007|Hybrid evolutionary algorithms on minimum vertex cover for random graphs|This paper analyzes the hierarchical Bayesian optimization algorithm (hBOA) on minimum vertex cover for standard classes of random graphs and transformed SAT instances. The performance of hBOA is compared with that of the branch-and-bound problem solver (BB), the simple genetic algorithm (GA) and the parallel simulated annealing (PSA). The results indicate that BB is significantly outperformed by all the other tested methods, which is expected as BB is a complete search algorithm and minimum vertex cover is an NP-complete problem. The best performance is achieved with hBOA nonetheless, the performance differences between hBOA and other evolutionary algorithms are relatively small, indicating that mutation-based search and recombination-based search lead to similar performance on the tested problem instances.|Martin Pelikan,Rajiv Kalapala,Alexander K. Hartmann","57845|GECCO|2006|Heterogeneous cooperative coevolution strategies of integration between GP and GA|Cooperative coevolution has proven to be a promising technique for solving complex combinatorial optimization problems. In this paper, we present four different strategies which involve cooperative coevolution of a genetic program and of a population of constants evolved by a genetic algorithm. The genetic program evolves expressions that solve a problem, while the genetic algorithm provides \"good\" values for the numeric terminal symbols used by those expressions. Experiments have been performed on three symbolic regression problems and on a \"real-world\" biomedical application. Results are encouraging and confirm that our coevolutionary algorithms can be used effectively in different domains.|Leonardo Vanneschi,Giancarlo Mauri,Andrea Valsecchi,Stefano Cagnoni","57758|GECCO|2006|Conquering hierarchical difficulty by explicit chunking substructural chromosome compression|This paper proposes a chromosome compression scheme which represents subsolutions by the most expressive schemata. The proposed chromosome compression scheme is combined with the dependency structure matrix genetic algorithm and the restricted tournament replacement to create a scalable optimization tool which optimizes problems via hierarchical decomposition. One important feature of the proposed method is that at the end of the run, the problem structure obtained from the proposed method is comprehensible to human researchers and is reusable for larger-scale problems. The empirical result shows that the proposed method scales sub-quadratically with the problem size on hierarchical problems and is able to capture the problem structures accurately.|Tian-Li Yu,David E. Goldberg","57996|GECCO|2007|Why is parity hard for estimation of distribution algorithms|We describe a k-bounded and additively separable test problem on which the hierarchical Bayesian Optimization Algorithm (hBOA) scales exponentially.|David Jonathan Coffin,Robert Elliott Smith","58016|GECCO|2007|An artificial immune system with partially specified antibodies|Artificial Immune System algorithms use antibodies which fully specify the solution of an optimization, learning, or pattern recognition problem. By being restricted to fully specified antibodies, an AIS algorithm can not make use of schemata or classes of partial solutions. This paper presents a symbiotic artificial immune system (SymbAIS) algorithm which is an extension of CLONALG algorithm. It uses partially specified antibodies and gradually builds up building blocks of suitable sub-antibodies. The algorithm is compared with CLONALG on multimodal function optimization and combinatorial optimization problems and it is shown that it can solve problems that CLONALG is unable to solve.|Ramin Halavati,Saeed Bagheri Shouraki,Mojdeh Jalali Heravi,Bahareh Jafari Jashmi"]]},"title":{"entropy":5.767045983594711,"topics":["genetic and, genetic algorithm, analysis the, programming and, building blocks, and for, and, spanning tree, variance scaling, protein prediction, genetic design, the and, population for, adaptive variance, adaptive scaling, for design, and algorithm, analysis and, selection and, genetic the","the effects, the, multiobjective optimization, and its, the and, evolutionary computation, the problem, algorithm the, dynamic environments, and evolutionary, the dynamic, the case, cellular automata, study the, for the, evolutionary algorithm, evolutionary approach, the evolutionary, information and, quality approach","genetic programming, genetic for, using genetic, genetic algorithm, neural networks, classifier systems, learning classifier, genetic with, learning systems, using programming, artificial immune, ant colony, genetic networks, programming for, for learning, immune systems, for networks, with, automatic generation, algorithm with","algorithm for, particle swarm, genetic algorithm, for problem, the problem, for optimization, evolutionary algorithm, for the, optimization algorithm, algorithm problem, evolutionary for, particle optimization, genetic for, swarm optimization, and flexible, differential evolution, hybrid for, genetic problem, and problem, flexible shop","selection and, genetic design, genetic algorithm, for design, and design, xcs and, and algorithm, for selection, modeling and, distribution algorithm, selection algorithm, genetic selection, using algorithm, and evolutionary, genetic and, using and, algorithm design, distribution and, design, using","variance scaling, adaptive variance, adaptive scaling, synthesis genetic, optimal genetic, genetic algorithm, adaptive, optimal, continuous, robustness, eda, automated","the dynamic, study the, the case, environments the, crossover the, dynamic environments, dynamic optimization, the functions, and diversity, comparative study, case study, and dynamic, for dynamic, study environments, for the, the optimization, study optimization, using the, study dynamic, the and","algorithm the, the effects, the problem, the, the and, the performance, the evolution, the behavior, the model, the spatial, set, comparing, are, stock","neural networks, for networks, evolving for, for neural, for agents, evolving, robot, modular, recognition, use, visual, kernel, discovering, distributed","learning classifier, for systems, classifier systems, learning systems, for learning, artificial immune, immune systems, systems with, automatic generation, systems, test for, artificial systems, automatic for, for machine, test generation, for classifier, generation for, artificial for, approach systems, vector","particle swarm, for optimization, evolution for, particle optimization, swarm optimization, differential evolution, swarm for, particle algorithm, fitness for, swarm algorithm, optimization and, particle for, the evolution, multi-objective optimization, evolution strategies, for differential, evolutionary testing, the swarm, optimization with, evolutionary optimization","for problem, the problem, for the, for multi-objective, new for, solving problem, and problem, multi-objective problem, optimization problem, model for, for planning, for solving, new multi-objective, model problem, new problem, heuristic"],"ranking":[["57705|GECCO|2006|A genetic algorithm with backtracking for protein structure prediction|In this paper, we propose a simple genetic algorithm for finding the optimal conformation of a protein using the three-dimensional square HP model. A backtracking procedure is used to resolve the positional collisions and illegal conformations that occur during the course of genetic search. Backtracking is shown to be a simple and efficient means of collision repair that requires little overhead. Empirical results show that a genetic algorithm using backtracking can obtain the lowest energy structure of an amino acid sequence in fewer energy evaluations than earlier approaches.|Clayton Matthew Johnson,Anitha Katikireddy","57771|GECCO|2006|An effective genetic algorithm for the minimum-label spanning tree problem|Given a connected, undirected graph G with labeled edges, the minimum label spanning tree problem seeks a spanning tree on G to whose edges are attached the smallest possible number of labels. A greedy heuristic for this NP-hard problem greedily chooses labels so as to reduce the number of components in the subgraphs they induce as quickly as possible. A genetic algorithm for the problem encodes candidate solutions as per mutations of the labels an initial segment of such a chromosome lists the labels that appear on the edges in the chromosome's tree. Three versions of the GA apply generic or heuristic crossover and mutation operators and a local search step. In tests on  randomly-generated instances of the minimum-label spanning tree problem, versions of the GA that apply generic operators, with and without the local search step, perform less well than the greedy heuristic, but a version that applies the local search step and operators tailored to the problem returns solutions that require on average  fewer labels than the heuristic's.|Jeremiah Nummela,Bryant A. Julstrom","58222|GECCO|2007|Cross entropy and adaptive variance scaling in continuous EDA|This paper deals with the adaptive variance scaling issue incontinuous Estimation of Distribution Algorithms. A phenomenon is discovered that current adaptive variance scaling method in EDA suffers from imprecise structure learning. A new type of adaptation method is proposed to overcome this defect. The method tries to measure the difference between the obtained population and the prediction of the probabilistic model, then calculate the scaling factor by minimizing the cross entropy between these two distributions. This approach calculates the scaling factor immediately rather than adapts it incrementally. Experiments show that this approach extended the class of problems that can be solved, and improve the search efficiency in some cases. Moreover, the proposed approach features in that each decomposed subspace can be assigned an individual scaling factor, which helps to solve problems with special dimension property.|Yunpeng Cai,Xiaomin Sun,Hua Xu,Peifa Jia","57968|GECCO|2007|An analysis of constructive crossover and selection pressure in genetic programming|A common problem in genetic programming search algorithms is destructive crossover in which the offspring of good parents generally has worse performance than the parents. Designing constructive crossover operators and integrating some local search techniques into the breeding process have been suggested as solutions. This paper reports on experiments demonstrating that premature convergence may happen more often when using these techniques in combination with standard parent selection. It shows that modifying the selection pressure in the parent selection process is necessary to obtain a significant performance improvement.|Huayang Xie,Mengjie Zhang,Peter Andreae","57946|GECCO|2007|SDR a better trigger for adaptive variance scaling in normal EDAs|Recently, advances have been made in continuous, normal-distribution-based Estimation-of-DistributionAlgorithms (EDAs) by scaling the variance upfrom the maximum-likelihood estimate. When doneproperly, such scaling has been shown to preventpremature convergence on slope-like regions ofthe search space. In this paper we specificallyfocus on one way of scaling that was previouslyintroduced as Adaptive Variance Scaling (AVS). It wasfound that when using AVS, the average number offitness evaluations grows subquadratically withthe dimensionality on a wide range of unimodaltest-problems, competitively with the CMA-ES.Still, room for improvement exists because thevariance doesn't always have to be scaled. Apreviously introduced trigger based on correlationthat determines when to apply scaling was shownto fail on higher dimensional problems. Here weprovide a new solution called the Standard-DeviationRatio (SDR) trigger that is integrated with theIterated Density-Estimation Evolutionary Algorithm(IDEA). Intuitively put, scaling istriggered with SDR only if improvements are foundto be far away from the mean. SDR works even inhigh dimensions as a result of factorizing thedecision rule behind the trigger according to theestimated Bayesian factorization. We evaluateSDR-AVS-IDEA on the same set ofbenchmark problems and compare it with AVS-IDEAand CMA-ES. We find that the addition of SDR givesAVS-IDEA an important extra edgefor it to be used in future research and inapplications both in single-objective optimizationas well as in multi-objective and dynamicoptimization. In addition, we provide practical rulesof thumb for parameter settings for usingSDR-AVS-IDEA that result in anasymptotic scale-up behavior that is sublinearfor the population size (O(l.)) andsubquadratic (O(l.)) for thenumber of evaluations.|Peter A. N. Bosman,Jörn Grahl,Franz Rothlauf","58082|GECCO|2007|Parallel genetic algorithm assessment of performance in multidimensional scaling|Visualization of multidimensional data by means of Multidimensional Scaling (MDS) is a popular technique of exploratory data analysis widely usable, e.g. in analysis of bio-medical data, behavioral science, marketing research, etc. Implementations of MDS methods include a subroutine for an auxiliary global optimization problem. The latter is difficult because of high dimensionality, absence of overall smoothness, and a large number of local minima. In such a situation application of a genetic algorithm (GA) seems reasonable. A favorable assessment of application of GAs in MDS in previous publications is based on heuristic arguments without estimating quantitatively the precision of GA while applied to the solution of corresponding global optimization problems. Indeed, the estimation of precision is difficult because of complexity to find the actual global minimum not only in routine use but also in unique research experiments. Quantitatively the precision of GA was estimated, at least in the experimental problems of modest dimensionality, using global minima found by means of the developed parallel version of explicit enumeration algorithm. To cope with high complexity of the minimization problem a parallel version of GA is developed, and its efficiency for problem of higher dimensionality is investigated.|Antanas Zilinskas,Julius Zilinskas","58187|GECCO|2007|Numerical-node building block analysis of genetic programming with simplification|This paper investigates the effects on building blocks of using online simplification in a GP system. Numerical nodes are tracked through individual runs to observe their behaviour. Results show that simplification disrupts building blocks early on, but also creates new building blocks.|Phillip Lee-Ming Wong,Mengjie Zhang","57674|GECCO|2006|The correlation-triggered adaptive variance scaling IDEA|It has previously been shown analytically and experimentally that continuous Estimation of Distribution Algorithms (EDAs) based on the normal pdf can easily suffer from premature convergence. This paper takes a principled first step towards solving this problem. First, prerequisites for the successful use of search distributions in EDAs are presented. Then, an adaptive variance scaling theme is introduced that aims at reducing the risk of premature convergence. Integrating the scheme into the iterated density--estimation evolutionary algorithm (IDEA) yields the correlation-triggered adaptive variance scaling IDEA (CT-AVS-IDEA). The CT-AVS-IDEA is compared to the original IDEA and the Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) on a wide range of unimodal test-problems by means of a scalability analysis. It is found that the average number of fitness evaluations grows subquadratically with the dimensionality, competitively with the CMA-ES. In addition, CT-AVS-IDEA is indeed found to enlarge the class of problems that continuous EDAs can solve reliably.|Jörn Grahl,Peter A. N. Bosman,Franz Rothlauf","58218|GECCO|2007|Adaptive variance scaling in continuous multi-objective estimation-of-distribution algorithms|Recent research into single-objective continuous Estimation-of-Distribution Algorithms (EDAs)has shown that when maximum-likelihood estimationsare used for parametric distributions such as thenormal distribution, the EDA can easily suffer frompremature convergence. In this paper we argue thatthe same holds for multi-objective optimization.Our aim in this paper is to transfer a solutioncalled Adaptive Variance Scaling (AVS) from thesingle-objective case to the multi-objectivecase. To this end, we zoom in on an existing EDAfor continuous multi-objective optimization, theMIDEA, which employs mixturedistributions. We propose a means to combine AVSwith the normal mixture distribution, as opposedto the single normal distribution for which AVS wasintroduced. In addition, we improve the AVS schemeusing the Standard-Deviation Ratio(SDR) trigger. Intuitively put, variance scalingis triggered by the SDR trigger only ifimprovements are found to be far awayfrom the mean. For the multi-objective case,this addition is important to keep the variancefrom being scaled to excessively large values.From experiments performed on five well-knownbenchmark problems, the addition of SDR andAVS is found to enlarge the class of problems thatcontinuous multi-objective EDAs can solve reliably.|Peter A. N. Bosman,Dirk Thierens","57675|GECCO|2006|A tree-based genetic algorithm for building rectilinear Steiner arborescences|A rectilinear Steiner arborescence (RSA) is a tree, whose nodes include a prescribed set of points, termed the vertices, in the first quadrant of the Cartesian plane, and whose tree edges from parent to child nodes must head either straight to the right or straight above. A minimal RSA (a MRSA) is one for which the total path length of the edges in the tree is minimal. RSAs have application in VLSI design. Curiously, although a RSA is a tree, to our knowledge, previous genetic attacks on the MRSA problem have not used tree-based approaches to representation, nor to the operations of crossover and mutation. We show why some care is needed in the choice of such genetic operators. Then we present tree-based operators for crossover and mutation, which are successful in creating true RSAs from source RSAs without the need of repair steps. We compare our results to two earlier researches, and find that our approach gives good results, but not results that are consistently better than those earlier approaches.|William A. Greene"],["57684|GECCO|2006|Dynamic multi-objective optimization with evolutionary algorithms a forward-looking approach|This work describes a forward-looking approach for the solution of dynamic (time-changing) problems using evolutionary algorithms. The main idea of the proposed method is to combine a forecasting technique with an evolutionary algorithm. The location, in variable space, of the optimal solution (or of the Pareto optimal set in multi-objective problems) is estimated using a forecasting method. Then, using this forecast, an anticipatory group of individuals is placed on and near the estimated location of the next optimum. This prediction set is used to seed the population when a change in the objective landscape arrives, aiming at a faster convergence to the new global optimum. The forecasting model is created using the sequence of prior optimum locations, from which an estimate for the next location is extrapolated. Conceptually this approach encompasses advantages of memory methods by making use of information available from previous time steps. Combined with a convergencediversity balance mechanism it creates a robust algorithm for dynamic optimization. This strategy can be applied to single objective and multi-objective problems, however in this work it is tested on multi-objective problems. Initial results indicate that the approach improves algorithm performance, especially in problems where the frequency of objective change is high.|Iason Hatzakis,David Wallace","58004|GECCO|2007|Dimensionality reduction in evolutionary multiobjective design case study|Real-world applications of Pareto-based optimisation commonly involve many objectives. It causes difficulties because of reduced selection pressure for better solutions. Dimensionality Reduction (DR) is a very appealing approach to overcome this problem. A case study of multiobjective Electric Machine (EM) design based on DR of the novel model  is considered.|Piotr Wozniak","57870|GECCO|2006|Both robust computation and mutation operation in dynamic evolutionary algorithm are based on orthogonal design|A robust dynamic evolutionary algorithm (labeled RODEA), where both the robust calculation and mutation operator are based on an orthogonal design, is proposed in this paper. Previous techniques calculate the mean effective objective (for robust) by using samples without much evenly distributing over the neighborhood. The samples by using orthogonal array distribute evenly. Therefore the calculation of mean effective objective more robust. The new technique is generalized from the ODEA algorithm . An orthogonal design method is employed on the niches for the mutation operator to find a potentially good solution that may become the representative in the niche. The fitness of the offspring is therefore likely to be higher than that of its parent. We propose a complex benchmark, consisting of moving function peaks, to test our new approach. Numerical experiments show that the moving solutions of the algorithm are a little worse in objective value but robust.|Sanyou Y. Zeng,Rui Wang,Hui Shi,Guang Chen,Hugo de Garis,Lishan Kang,Lixin X. Ding","58217|GECCO|2007|Learning and anticipation in online dynamic optimization with evolutionary algorithms the stochastic case|The focus of this paper is on how to design evolutionaryalgorithms (EAs) for solving stochastic dynamicoptimization problems online, i.e.as time goes by.For a proper design, the EA must not only be capableof tracking shifting optima, it must also take intoaccount the future consequences of the evolveddecisions or actions. A previousframework describes how to build such EAs in thecase of non-stochastic problems. Most real-worldproblems however are stochastic. In this paper weshow how this framework can be extended to properlytackle stochasticity. We point out how thisnaturally leads to evolving strategiesrather than explicit decisions. We formalizeour approach in a new framework. The newframework and the various sourcesof problem-difficulty at hand are illustratedwith a running example. We also apply ourframework to inventory management problems, an importantreal-world application area in logistics. Our results show,as a proof of principle, the feasibility and benefitsof our novel approach.|Peter A. N. Bosman,Han La Poutré","58091|GECCO|2007|High quality offset printing an evolutionary approach|Print media are still very important for everyone's daily life. Current efforts are concerned with the application of the well-established offset-printing technology to other media, particularly cardboards, which require some substantial adaptations. To this end, this paper proposed a new specific pre-processing stage. This pre-processing stage can be configured by several parameters. This paper optimizes these parameter settings by using evolution strategies. It turns out that this optimization reduces the required energy and the number of wrongly generated pixels by about %, respectively.|Ralf Joost,Ralf Salomon","58036|GECCO|2007|Characteristic determination for solid state devices with evolutionary computation a case study|In this paper, we develop a new optimization framework that consists of the extended compact genetic algorithm (ECGA) and split-on-demand (SoD), an adaptive discretization technique, to tackle the characteristic determination problem for solid state devices. As most decision variables of characteristic determination problems are real numbers due to the modeling of physical phenomena, and ECGA is designed for handling discrete-type problems, a specific mechanism to transform the variable types of the two ends is in order. In the proposed framework, ECGA is used as a back-end optimization engine, and SoD is adopted as the interface between the engine and the problem. Moreover, instead of one mathematical model with various parameters, characteristic determination is in fact a set of problems of which the mathematical formulations may be very different. Therefore, in this study, we employ the proposed framework on three study cases to demonstrate that the technique proposed in the domain of evolutionary computation can provide not only the high quality optimization results but also the flexibility to handle problems of different formulations.|Ping-Chu Hung,Ying-Ping Chen,Hsiao Wen Zan","58245|GECCO|2007|Effects of the use of non-geometric binary crossover on evolutionary multiobjective optimization|In the design of evolutionary multiobjective optimization (EMO) algorithms, it is important to strike a balance between diversity and convergence. Traditional mask-based crossover operators for binary strings (e.g., one-point and uniform) tend to decrease the diversity of solutions in EMO algorithms while they improve the convergence to the Pareto front. This is because such a crossover operator, which is called geometric crossover, always generates an offspring in the segment between its two parents under the Hamming distance in the genotype space. That is, the sum of the distances from the generated offspring to its two parents is always equal to the distance between the parents. In this paper, first we propose a non-geometric binary crossover operator to generate an offspring outside the segment between its parents. Next we examine the effect of the use of non-geometric binary crossover on single-objective genetic algorithms. Experimental results show that non-geometric binary crossover improves their search ability. Then we examine its effect on EMO algorithms. Experimental results show that non-geometric binary crossover drastically increases the diversity of solutions while it slightly degrades their convergence to the Pareto front. As a result, some performance measures such as hypervolume are clearly improved.|Hisao Ishibuchi,Yusuke Nojima,Noritaka Tsukamoto,Ken Ohara","57653|GECCO|2006|Evolutionary design of pseudorandom sequence generators based on cellular automata and its applicability in current cryptosystems|In this work, a genetic algorithm is used to find cellular automata rules that make cellular automata behave like good pseudorandom sequence generators. Pseudorandom sequence generators based on one-dimensional cellular automata with non-homogeneous rules and arbitrary neighbors are proposed. The fitness function combines entropy measures and standard statistical tests for random sequences. The generators found are statistically compared to some well-known pseudorandom sequences generators.|David Delgado,David Vidal,German Hernandez","57598|GECCO|2006|A comparative study of evolutionary optimization techniques in dynamic environments|Genetic Algorithms have widely been used for solving optimization problems in stationary environments. In recent years, there has been a growing interest for investigating and improving the performance of these algorithms in dynamic environments where the fitness landscape changes. In this study, we present an extensive comparison of several algorithms with different characteristics on a common platform by using the moving peaks benchmark and by varying problem parameters.|Demet Ayvaz,Haluk Topcuoglu,Fikret S. Gürgen","58099|GECCO|2007|Automatic analog IC layout generation based on a evolutionary computation approach|This paper describes an innovative analog IC layout generation approach based on evolutionary computation techniques.|Nuno C. Lourenço,Nuno C. G. Horta"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","57595|GECCO|2006|Coordination number prediction using learning classifier systems performance and interpretability|The prediction of the coordination number (CN) of an amino acid in a protein structure has recently received renewed attention. In a recent paper, Kinjo et al. proposed a real-valued definition of CN and a criterion to map it onto a finite set of classes, in order to predict it using classification approaches. The literature reports several kinds of input information used for CN prediction. The aim of this paper is to assess the performance of a state-of-the-art learning method, Learning Classifier Systems (LCS) on this CN definition, with various degrees of precision, based on several combinations of input attributes. Moreover, we will compare the LCS performance to other well-known learning techniques. Our experiments are also intended to determinethe minimum set of input information needed to achieve good predictive performance, so as to generate competent yet simple and interpretable classification rules. Thus, the generated predictors (rule sets) are analyzed for their interpretability.|Jaume Bacardit,Michael Stout,Natalio Krasnogor,Jonathan D. Hirst,Jacek Blazewicz","57965|GECCO|2007|Effects of passengers arrival distribution to double-deck elevator group supervisory control systems using genetic network programming|The Elevator Group Supervisory Control Systems (EGSCS) are the control systems that systematically manage three or more elevators in order to efficiently transport the passengers in buildings. Double-deck elevators, where two cages are connected with each other, are expected to be the next generation elevator systems. Meanwhile, Destination Floor Guidance Systems (DFGS) are also expected in Double-Deck Elevator Systems (DDES). With these, the passengers could be served at two consecutive floors and could input their destinations at elevator halls instead of conventional systems without DFGS. Such systems become more complex than the traditional systems and require new control methods Genetic Network Programming (GNP), a graph-based evolutionary method, has been applied to EGSCS and its advantages are shown in some previous papers. GNP can obtain the strategy of a new hall call assignment to the optimal elevator because it performs crossover and mutation operations to judgment nodes and processing nodes. In studies so far, the passenger's arrival has been assumed to take Exponential distribution for many years. In this paper, we have applied Erlang distribution and Binomial distribution in order to study how the passenger's arrival distribution affects EGSCS. We have found that the passenger's arrival distribution has great influence on EGSCS. It has been also clarified that GNP makes good performances under different conditions.|Lu Yu,Jin Zhou,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu,Sandor Markon","57974|GECCO|2007|Trading rules on stock markets using genetic network programming with sarsa learning|In this paper, the Genetic Network Programming (GNP) for creating trading rules on stocks is described. GNP is an evolutionary computation, which represents its solutions using graph structures and has some useful features inherently. It has been clarified that GNP works well especially in dynamic environments since GNP can create quite compact programs and has an implicit memory function. In this paper, GNP is applied to creating a stock trading model. There are three important points The first important point is to combine GNP with Sarsa Learning which is one of the reinforcement learning algorithms. Evolution-based methods evolve their programs after task execution because they must calculate fitness values, while reinforcement learning can change programs during task execution, therefore the programs can be created efficiently. The second important point is that GNP uses candlestick chart and selects appropriate technical indices to judge the buying and selling timing of stocks. The third important point is that sub-nodes are used in each node to determine appropriate actions (buyingselling) and to select appropriate stock price information depending on the situation. In the simulations, the trading model is trained using the stock prices of  brands in ,  and . Then the generalization ability is tested using the stock prices in . From the simulation results, it is clarified that the trading rules of the proposed method obtain much higher profits than Buy&Hold method and its effectiveness has been confirmed.|Yan Chen,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu","57722|GECCO|2006|Pareto-coevolutionary genetic programming classifier|The conversion and extension of the Incremental Pareto-Coevolution Archive algorithm (IPCA) into the domain of Genetic Programming classifier evolution is presented. In order to accomplish efficiency in regards to classifier evaluation on training data, the coevolutionary aspect of the IPCA algorithm is utilized to simultaneously evolve a subset of the training data that provides distinctions between candidate classifiers. The algorithm is compared in terms of classification \"score\" (equal weight to detection rate, and  - false positive rate), and run-time against a traditional GP classifier using the entirety of the training data for evaluation, and a GP classifier which performs Dynamic Subset Selection. The results indicate that the presented algorithm outperforms the subset selection algorithm in terms of classification score, and outperforms the traditional classifier while requiring roughly over of the wall-clock time.|Michal Lemczyk,Malcolm I. Heywood","57804|GECCO|2006|A dynamic approach to artificial immune systems utilizing neural networks|The purpose of this work is to propose an immune-inspired setup to use a self-organizing map as a computational model for the interaction of antigens and antibodies. The proposed approach may be used as a part in other immune algorithms, or can possibly be used to detect anomalies in time series data.|Stefan Schadwinkel,Werner Dilger","58116|GECCO|2007|Knowledge reuse in genetic programming applied to visual learning|We propose a method of knowledge reuse for an ensemble of genetic programming-based learners solving a visual learning task. First, we introduce a visual learning method that uses genetic programming individuals to represent hypotheses. Individuals-hypotheses process image representation composed of visual primitives derived from the training images that contain objects to be recognized. The process of recognition is generative, i.e., an individual is supposed to restore the shape of the processed object by drawing its reproduction on a separate canvas. This canonical method is extended with a knowledge reuse mechanism that allows a learner to import genetic material from hypotheses that evolved for the other decision classes (object classes). We compare the performance of the extended approach to the basic method on a real-world tasks of handwritten character recognition, and conclude that knowledge reuse leads to significant convergence speedup and, more importantly, significantly reduces the risk of overfitting.|Wojciech Jaskowski,Krzysztof Krawiec,Bartosz Wieloch","58220|GECCO|2007|Initial results from the use of learning classifier systems to control neuronal networks|In this paper we describe the use of a learning classifier system to control the electrical stimulation of cultured neuronal networks. The aim is to manipulate the environment of the cells such that they display elementary learning, i.e., so that they respond to a given input signal in a pre-specified way. Results indicate that this is possible and that the learned stimulation protocols identify seemingly fundamental properties of in vitro neuronal networks.allUse of another learning scheme and simpler stimulation confirms these properties.|Larry Bull,Ivan S. Uroukov","57748|GECCO|2006|A representational ecology for learning classifier systems|The representation used by a learning algorithm introduces a bias which is more or less well-suited to any given learning problem. It is well known that, across all possible problems, one algorithm is no better than any other. Accordingly, the traditional approach in machine learning is to choose an appropriate representation making use of some domain-specific knowledge, and this representation is then used exclusively during the learning process.To reduce reliance on domain-knowledge and its appropriate use it would be desirable for the learning algorithm to select its own representation for the problem.We investigate this with XCS, a Michigan-style Learning Classifier System.We begin with an analysis of two representations from the literature hyperplanes and hyperspheres. We then apply XCS with either one or the other representation to two Boolean functions, the well-known multiplexer function and a function defined by hyperspheres, and confirm that planes are better suited to the multiplexer and spheres to the sphere-based function.Finally, we allow both representations to compete within XCS, which learns the most appropriate representation for problem thanks to the pressure against overlapping rules which its niche GA supplies. The result is an ecology in which the representations are species.|James A. R. Marshall,Tim Kovacs","57781|GECCO|2006|An open-set speaker identification system using genetic learning classifier system|This paper presents the design and implementation of an adaptive open-set speaker identification system with genetic learning classifier systems. One of the challenging problems in using learning classifier systems for numerical problems is the knowledge representation. The voice samples are a series of real numbers that must be encoded in a classifier format. We investigate several different methods for representing voice samples for classifier systems and study the efficacy of the methods. We also identify several challenges for learning classifier systems in the speaker identification problem and introduce new methods to improve the learning and classification abilities of the systems. Experimental results show that our system successfully learns  voice features at the accuracies of % to %, which is considered a strong result in the speaker identification community. This research presents the feasibility of using learning classifier systems for the speaker identification problem.|WonKyung Park,Jae C. Oh,Misty K. Blowers,Matt B. Wolf"],["58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Suárez,Manuel Valenzuela-Rendón,Hugo Terashima-Marín,Eduardo Uresti-Charre","57663|GECCO|2006|A hybrid of genetic algorithm and bottleneck shifting for flexible job shop scheduling problemA hybrid of genetic algorithm and bottleneck shifting for flexible job shop scheduling problem|Flexible job shop scheduling problem (fJSP) is an extension of the classical job shop scheduling problem, which provides a closer approximation to real scheduling problems. We develop a new genetic algorithm hybridized with an innovative local search procedure (bottleneck shifting) for the fJSP problem. The genetic algorithm uses two representation methods to represent solutions of the fJSP problem. Advanced crossover and mutation operators are proposed to adapt to the special chromosome structures and the characteristics of the problem. The bottleneck shifting works over two kinds of effective neighborhood, which use interchange of operation sequences and assignment of new machines for operations on the critical path. In order to strengthen the search ability, the neighborhood structure can be adjusted dynamically in the local search procedure. The performance of the proposed method is validated by numerical experiments on several representative problems.|Jie Gao,Mitsuo Gen,Linyan Sun","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57972|GECCO|2007|Kernel based automatic clustering using modified particle swarm optimization algorithm|This paper introduces a method for clustering complex and linearly non-separable datasets, without any prior knowledge of the number of naturally occurring clusters. The proposed method is based on an improved variant of the Particle Swarm Optimization (PSO) algorithm. In addition, it employs a kernel-induced similarity measure instead of the conventional sum-of-squares distance. Use of the kernel function makes it possible to cluster data that is linearly non-separable in the original input space into homogeneous groups in a transformed high-dimensional feature space. Computer simulations have been undertaken with a test bench of five synthetic and three real life datasets, in order to compare the performance of the proposed method with a few state-of-the-art clustering algorithms. The results reflect the superiority of the proposed algorithm in terms of accuracy, convergence speed and robustness.|Ajith Abraham,Swagatam Das,Amit Konar","57756|GECCO|2006|A fast hybrid genetic algorithm for the quadratic assignment problem|Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the \"fast hybrid genetic algorithm\" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm.|Alfonsas Misevicius","57687|GECCO|2006|A genetic algorithm for the longest common subsequence problem|A genetic algorithm for the longest common subsequence problem encodes candidate sequences as binary strings that indicate subsequences of the shortest or first string. Its fitness function penalizes sequences not found in all the strings. In tests on  sets of three strings, a dynamic programming algorithm returns optimum solutions quickly on smaller instances and increasingly slowly on larger instances. Repeated trials of the GA always identify optimum subsequences, and it runs in reasonable times even on the largest instances.|Brenda Hinkemeyer,Bryant A. Julstrom","57612|GECCO|2006|A new hybrid evolutionary algorithm for the huge -cardinality tree problem|In recent years it has been shown that an intelligent combination of metaheuristics with other optimization techniques can significantly improve over the application of a pure metaheuristic. In this paper, we combine the evolutionary computation paradigm with dynamic programming for the application to the NP-hard k-cardinality tree problem. Given an undirected graph G with node and edge weights, this problem consists of finding a tree in G with exactly k edges such that the sum of the weights is minimal. The genetic operators of our algorithm are based on an existing dynamic programming algorithm from the literature for finding optimal subtrees in a given tree. The simulation results show that our algorithm is able to improve the best known results for benchmark problems from the literature in  cases.|Christian Blum","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao","58219|GECCO|2007|A fuzzy genetic algorithm for the dynamic cell formation problem|This paper deals with a fuzzy genetic algorithm applied to a manufacturing cell formation problem. We discuss the importance of taking into account the dynamic aspect of the problem that has been poorly studied in the related literature. Using a multi-periodic planning horizon modeling, two strategies are considered passive and active. The first strategy consists of maintaining the same composition of machines during the overall planning horizon, while the second allows performing a different composition for each period. When the decision maker wants to choose the most adequate strategy for its environment, there is a need to control the proposed evolutionary solving approach, due to the complexity of the model. For that purpose, we propose an off-line fuzzy logic enhancement. The results, using this enhancement, are better than those obtained using the GA alone.|Menouar Boulif,Karim Atif"],["57669|GECCO|2006|Segmentation of medical images using a genetic algorithm|Segmentation of medical images is challenging due to poor image contrast and artifacts that result in missing or diffuse organtissue boundaries. Consequently, this task involves incorporating as much prior information as possible (e.g., texture, shape, and spatial location of organs) into a single framework. In this paper, we present a genetic algorithm for automating the segmentation of the prostate on two-dimensional slices of pelvic computed tomography (CT) images. In this approach the segmenting curve is represented using a level set function, which is evolved using a genetic algorithm (GA). Shape and textural priors derived from manually segmented images are used to constrain the evolution of the segmenting curve over successive generations.We review some of the existing medical image segmentation techniques. We also compare the results of our algorithm with those of a simple texture extraction algorithm (Laws' texture measures) as well as with another GA-based segmentation tool called GENIE. Our preliminary tests on a small population of segmenting contours show promise by converging on the prostate region. We expect that further improvements can be achieved by incorporating spatial relationships between anatomical landmarks, and extending the methodology to three dimensions.|Payel Ghosh,Melanie Mitchell","58086|GECCO|2007|A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design|This paper presents a hybrid evolutionary programming algorithm to solve the spread spectrum radar polyphase code design problem. The proposed algorithm uses an Evolutionary Programming (EP) approach as global search heuristic. This EP is hybridized with a gradient-based local search procedure which includes a dynamic step adaptation procedure to perform accurate and efficient local search for better solutions. Numerical examples demonstrate that the algorithm outperforms existing approaches for this problem.|?ngel M. Pérez-Bellido,Sancho Salcedo-Sanz,Emilio G. Ortíz-García,Antonio Portilla-Figueras","57627|GECCO|2006|Pareto front genetic programming parameter selection based on design of experiments and industrial data|Symbolic regression based on Pareto Front GP is the key approach for generating high-performance parsimonious empirical models acceptable for industrial applications. The paper addresses the issue of finding the optimal parameter settings of Pareto Front GP which direct the simulated evolution toward simple models with acceptable prediction error. A generic methodology based on statistical design of experiments is proposed. It includes statistical determination of the number of replicates by half-width confidence intervals, determination of the significant inputs by fractional factorial design of experiments, approaching the optimum by steepest ascentdescent, and local exploration around the optimum by Box Behnken or by central composite design of experiments. The results from implementing the proposed methodology to a small-sized industrial data set show that the statistically significant factors for symbolic regression, based on Pareto Front GP, are the number of cascades, the number of generations, and the population size. A second order regression model with high R of . includes the three parameters and their optimal values have been defined. The optimal parameter settings were validated with a separate small sized industrial data set. The optimal settings are recommended for symbolic regression applications using data sets with up to  inputs and up to  data points.|Flor A. Castillo,Arthur K. Kordon,Guido Smits,Ben Christenson,Dee Dickerson","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","58244|GECCO|2007|A self-adaptive multiagent evolutionary algorithm for electrical machine design|This paper presents a self-adaptive algorithm that hybridises evolutionary and multiagent concepts. Each evolutionary individual is implemented as a simple agent capable of re-production and predation. The transitions between these two states depend on the agent's local environment. Thus, no explicit global process is defined to select neither the mates nor the preys. The convergence of the algorithm emerges from the behaviour of the agents. This brings interesting properties, such as population size self-regulation. Two sets of experimental results are provided a comparison with Saw-Tooth Algorithm and micro-GA using four classical functions and an optimisation of the efficiency and the weight of an electrical motor. Some possible evolutions and prospects are finally proposed.|Jean-Laurent Hippolyte,Christelle Bloch,Pascal Chatonnay,Christophe Espanet,Didier Chamagne","58021|GECCO|2007|GARS an improved genetic algorithm with reserve selection for global optimization|This paper investigates how genetic algorithms (GAs) can be improved to solve large-scale and complex problems more efficiently. First of all, we review premature convergence, one of the challenges confronted with when applying GAs to real-world problems. Next, some of the methods now available to prevent premature convergence and their intrinsic defects are discussed. A qualitative analysis is then done on the cause of premature convergence that is the loss of building blocks hosted in less-fit individuals during the course of evolution. Thus, we propose a new improver - GAs with Reserve Selection (GARS), where a reserved area is set up to save potential building blocks and a selection mechanism based on individual uniqueness is employed to activate the potentials. Finally, case studies are done in a few standard problems well known in the literature, where the experimental results demonstrate the effectiveness and robustness of GARS in suppressing premature convergence, and also an enhancement is found in global optimization capacity.|Yang Chen,Jinglu Hu,Kotaro Hirasawa,Songnian Yu","58073|GECCO|2007|Using genetic algorithms for naval subsystem damage assessment and design improvements|Some auxiliary systems of next generation naval ships will utilize distributed automatic control. Such distributed control systems will use interconnected sensors, actuators, controllers and networking components to diagnose and reconfigure the auxiliary systems. Testing these systems will be difficult with traditional methods of fault analysis due to the interconnected and automatic nature of these subsystems. We have designed a suite of genetic algorithms to find interesting and hidden damage scenarios in a testbed of a naval subsystem. Given this knowledge, we use a genetic algorithm to improve upon the design of this subsystem.|Christopher McCubbin,David Scheidt,Oliver Bandte,Steven Marshall,Iavor Trifonov","58135|GECCO|2007|Genetic optimization for yacht design|This paper introduces a procedure for using genetic multi-objective optimization in yacht design. The problem described consists on the optimization of a bulb shape to improve the performance of the yacht. The two objectives considered are the minimization of the drag in calm water together with the minimization of the Vertical Center of Gravity (VCG), all the configurations should satisfy length and volume constraints. Since there is no a single optimum to be found, the MOGA-II was used as multi-objective genetic algorithm. The distributed optimization search exploited the parallelization capabilities of the MOGA-II algorithm which allowed the evaluation of several designs configurations by running concurrent threads of the flow analysis solver. Three bulb shapes of different length are selected between the non-dominated solutions. Using these three solutions, seakeeping tests of a fully appended scale model have been carried out at the towing tank of the University of Trieste. A single hull has been tested for each bulb configurations to check the influence of the bulb shape on the performance of the yacht in waves. The results obtained are very satisfactory, and the procedure described can be applied to even more complex yacht design problems.|Paolo Geremia,Mauro Poian,Silvia Poles","57745|GECCO|2006|A genetic algorithm with a variable-length genotype and embryogeny for microstructured optical fibre design|Microstructured optical fibres are a relatively recent advance in fibre technology which guide light by using arrays of air holes which run the length of the fibre. The internal microstructure of optical fibres can be altered to reshape and transform light for use in medical applications, sensing, long distance and local area network high bandwidth communications. Recent progress in the production of polymer fibres allows designs with complex microstructures consisting of hundreds of holes to be manufactured. In this paper we present a generative (embryogenic) representation which can produce symmetric fibre designs with a variable number of holes. The resulting genetic algorithm has the ability to search designs of varying complexity over time, allowing less or more complex designs to be evolved as required. Various aspects of this representation are discussed in light of the supporting genetic algorithm such as as recombination of designs and the conversion of the variable length binary genotype to the phenotype (optical fibre structure). We include some single objective design results for a high-bandwidth optical fibre along with manufactured designs.|Steven Manos,Leon Poladian,Peter J. Bentley,Maryanne Large","57930|GECCO|2007|Optimal design of ad hoc injection networks by using genetic algorithms|This work aims at optimizing injection networks, which consist in adding a set of long-range links (called bypass links) in mobile multi-hop ad hoc networks so as to improve connectivity and overcome network partitioning. To this end, we rely on small-world network properties, that comprise a high clustering coefficient and a low characteristic path length. We investigate the use of two genetic algorithms (generational and steady-state) to optimize three instances of this topology control problem and present results that show initial evidence of their capacity to solve it.|Grégoire Danoy,Enrique Alba,Pascal Bouvry,Matthias R. Brust"],["58146|GECCO|2007|A synthesis of optimal stopping time in compact genetic algorithm based on real options approach|This paper introduces the real options approach, which is an evaluation tool for investment under uncertainty, to analyze optimal stopping time in genetic algorithms. This paper focuses on the simple model of EDAs named the compact genetic algorithm. This algorithm employs the probability vector as a model that scales well with the problem size. We analyze optimal stopping time of trap problems and propose an optimal stopping criterion as a decision contour. The proposed criterion also provides a stopping boundary, where termination is optimal on one side and continuation is on the other. This region suggests when it is worth continuing the algorithm and helps save computational effort by stopping early. Moreover, when the reset method is applied, the algorithm can reach a higher solution quality. The proposed technique can also be applied to analyze other problems.|Sunisa Rimcharoen,Daricha Sutivong,Prabhas Chongstitvatana","57635|GECCO|2006|Adaptive discretization for probabilistic model building genetic algorithms|This paper proposes an adaptive discretization method, called Split-on-Demand (SoD), to enable the probabilistic model building genetic algorithm (PMBGA) to solve optimization problems in the continuous domain. The procedure, effect, and usage of SoD are described in detail. As an example, the integration of SoD and the extended compact genetic algorithm (ECGA), named real-coded ECGA (rECGA), is presented and numerically examined. The experimental results indicate that rECGA works well and SoD is effective. The behavior of SoD is analyzed and discussed, followed by the potential future work for SoD.|Chao-Hong Chen,Wei-Nan Liu,Ying-Ping Chen","58222|GECCO|2007|Cross entropy and adaptive variance scaling in continuous EDA|This paper deals with the adaptive variance scaling issue incontinuous Estimation of Distribution Algorithms. A phenomenon is discovered that current adaptive variance scaling method in EDA suffers from imprecise structure learning. A new type of adaptation method is proposed to overcome this defect. The method tries to measure the difference between the obtained population and the prediction of the probabilistic model, then calculate the scaling factor by minimizing the cross entropy between these two distributions. This approach calculates the scaling factor immediately rather than adapts it incrementally. Experiments show that this approach extended the class of problems that can be solved, and improve the search efficiency in some cases. Moreover, the proposed approach features in that each decomposed subspace can be assigned an individual scaling factor, which helps to solve problems with special dimension property.|Yunpeng Cai,Xiaomin Sun,Hua Xu,Peifa Jia","57946|GECCO|2007|SDR a better trigger for adaptive variance scaling in normal EDAs|Recently, advances have been made in continuous, normal-distribution-based Estimation-of-DistributionAlgorithms (EDAs) by scaling the variance upfrom the maximum-likelihood estimate. When doneproperly, such scaling has been shown to preventpremature convergence on slope-like regions ofthe search space. In this paper we specificallyfocus on one way of scaling that was previouslyintroduced as Adaptive Variance Scaling (AVS). It wasfound that when using AVS, the average number offitness evaluations grows subquadratically withthe dimensionality on a wide range of unimodaltest-problems, competitively with the CMA-ES.Still, room for improvement exists because thevariance doesn't always have to be scaled. Apreviously introduced trigger based on correlationthat determines when to apply scaling was shownto fail on higher dimensional problems. Here weprovide a new solution called the Standard-DeviationRatio (SDR) trigger that is integrated with theIterated Density-Estimation Evolutionary Algorithm(IDEA). Intuitively put, scaling istriggered with SDR only if improvements are foundto be far away from the mean. SDR works even inhigh dimensions as a result of factorizing thedecision rule behind the trigger according to theestimated Bayesian factorization. We evaluateSDR-AVS-IDEA on the same set ofbenchmark problems and compare it with AVS-IDEAand CMA-ES. We find that the addition of SDR givesAVS-IDEA an important extra edgefor it to be used in future research and inapplications both in single-objective optimizationas well as in multi-objective and dynamicoptimization. In addition, we provide practical rulesof thumb for parameter settings for usingSDR-AVS-IDEA that result in anasymptotic scale-up behavior that is sublinearfor the population size (O(l.)) andsubquadratic (O(l.)) for thenumber of evaluations.|Peter A. N. Bosman,Jörn Grahl,Franz Rothlauf","58082|GECCO|2007|Parallel genetic algorithm assessment of performance in multidimensional scaling|Visualization of multidimensional data by means of Multidimensional Scaling (MDS) is a popular technique of exploratory data analysis widely usable, e.g. in analysis of bio-medical data, behavioral science, marketing research, etc. Implementations of MDS methods include a subroutine for an auxiliary global optimization problem. The latter is difficult because of high dimensionality, absence of overall smoothness, and a large number of local minima. In such a situation application of a genetic algorithm (GA) seems reasonable. A favorable assessment of application of GAs in MDS in previous publications is based on heuristic arguments without estimating quantitatively the precision of GA while applied to the solution of corresponding global optimization problems. Indeed, the estimation of precision is difficult because of complexity to find the actual global minimum not only in routine use but also in unique research experiments. Quantitatively the precision of GA was estimated, at least in the experimental problems of modest dimensionality, using global minima found by means of the developed parallel version of explicit enumeration algorithm. To cope with high complexity of the minimization problem a parallel version of GA is developed, and its efficiency for problem of higher dimensionality is investigated.|Antanas Zilinskas,Julius Zilinskas","58012|GECCO|2007|Variance reduction in meta-EDA|We study the benefit of measurement replication when using the Relevance Estimation and Value Calibration method to calibrate a genetic algorithm. We find that replication is not essential to REVAC, which makes it a strong alternative to existing statistical tools which are computationally costly.|Volker Nannen,A. E. Eiben","58218|GECCO|2007|Adaptive variance scaling in continuous multi-objective estimation-of-distribution algorithms|Recent research into single-objective continuous Estimation-of-Distribution Algorithms (EDAs)has shown that when maximum-likelihood estimationsare used for parametric distributions such as thenormal distribution, the EDA can easily suffer frompremature convergence. In this paper we argue thatthe same holds for multi-objective optimization.Our aim in this paper is to transfer a solutioncalled Adaptive Variance Scaling (AVS) from thesingle-objective case to the multi-objectivecase. To this end, we zoom in on an existing EDAfor continuous multi-objective optimization, theMIDEA, which employs mixturedistributions. We propose a means to combine AVSwith the normal mixture distribution, as opposedto the single normal distribution for which AVS wasintroduced. In addition, we improve the AVS schemeusing the Standard-Deviation Ratio(SDR) trigger. Intuitively put, variance scalingis triggered by the SDR trigger only ifimprovements are found to be far awayfrom the mean. For the multi-objective case,this addition is important to keep the variancefrom being scaled to excessively large values.From experiments performed on five well-knownbenchmark problems, the addition of SDR andAVS is found to enlarge the class of problems thatcontinuous multi-objective EDAs can solve reliably.|Peter A. N. Bosman,Dirk Thierens","57674|GECCO|2006|The correlation-triggered adaptive variance scaling IDEA|It has previously been shown analytically and experimentally that continuous Estimation of Distribution Algorithms (EDAs) based on the normal pdf can easily suffer from premature convergence. This paper takes a principled first step towards solving this problem. First, prerequisites for the successful use of search distributions in EDAs are presented. Then, an adaptive variance scaling theme is introduced that aims at reducing the risk of premature convergence. Integrating the scheme into the iterated density--estimation evolutionary algorithm (IDEA) yields the correlation-triggered adaptive variance scaling IDEA (CT-AVS-IDEA). The CT-AVS-IDEA is compared to the original IDEA and the Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) on a wide range of unimodal test-problems by means of a scalability analysis. It is found that the average number of fitness evaluations grows subquadratically with the dimensionality, competitively with the CMA-ES. In addition, CT-AVS-IDEA is indeed found to enlarge the class of problems that continuous EDAs can solve reliably.|Jörn Grahl,Peter A. N. Bosman,Franz Rothlauf","57630|GECCO|2006|Optimal mutation rates for genetic search|Using a set of model landscapes we examine how different mutation rates affect different search metrics. We show that very universal heuristics, such as N and the error threshold, can generally be improved upon if one has some qualitative information about the landscape. In particular, we show in the case of multiple optima (signals) how mutation affects which signal dominates and how passing between the dominance of one to another depends on the relative height and size of the peaks and their relative positions in the configuration space.|Jorge Cervantes,Christopher R. Stephens","57794|GECCO|2006|Genetic programming optimal population sizes for varying complexity problems|The population size in evolutionary computation is a significant parameter affecting computational effort and the ability to successfully evolve solutions. We find that population size sensitivity - how much a genetic program's efficiency varies with population size - is correlated with problem complexity. An analysis of population sizes was conducted using a unimodal, bimodal and a multi-modal problem with varying levels of difficulty. Specifically we show that a unimodal and bimodal and multimodal problems exhibit an increased sensitivity to population size with increasing levels of difficulty. We demonstrate that as problem complexity increases, determination of the optimal population size becomes more difficult. Conversely, the less complex a problem is the more sensitive the genetic program's efficiency is to population size.|Alan Piszcz,Terence Soule"],["57798|GECCO|2006|The effect of crossover on the behavior of the GA in dynamic environments a case study using the shaky ladder hyperplane-defined functions|One argument as to why the hyperplane-defined functions (hdf's) are a good testbed for the genetic algorithm (GA) is that the hdf's are built in the same way that the GA works. In this paper we test that hypothesis in a new setting by exploring the GA on a subset of the hdf's which are dynamic---the shaky ladder hyperplane-defined functions (sl-hdf's). In doing so we gain insight into how the GA makes use of crossover during its traversal of the sl-hdf search space. We begin this paper by explaining the sl-hdf's. We then conduct a series of experiments with various crossover rates and various rates of environmental change. Our results show that the GA performs better with than without crossover in dynamic environments. Though these results have been shown on some static functions in the past, they are re-confirmed and expanded here for a new type of function (the hdf) and a new type of environment (dynamic environments). Moreover we show that crossover is even more beneficial in dynamic environments than it is in static environments. We discuss how these results can be used to develop a richer knowledge about the use of building blocks by the GA.|William Rand,Rick L. Riolo,John H. Holland","57868|GECCO|2006|A comparative study of immune system based genetic algorithms in dynamic environments|Diversity and memory are two major mechanisms used in biology to keep the adaptability of organisms in the ever-changing environment in nature. These mechanisms can be integrated into genetic algorithms to enhance their performance for problem optimization in dynamic environments. This paper investigates several GAs inspired by the ideas of biological immune system and transformation schemes for dynamic optimization problems. An aligned transformation operator is proposed and combined to the immune system based genetic algorithm to deal with dynamic environments. Using a series of systematically constructed dynamic test problems, experiments are carried out to compare several immune system based genetic algorithms, including the proposed one, and two standard genetic algorithms enhanced with memory and random immigrants respectively. The experimental results validate the efficiency of the proposed aligned transformation and corresponding immune system based genetic algorithm in dynamic environments.|Shengxiang Yang","58004|GECCO|2007|Dimensionality reduction in evolutionary multiobjective design case study|Real-world applications of Pareto-based optimisation commonly involve many objectives. It causes difficulties because of reduced selection pressure for better solutions. Dimensionality Reduction (DR) is a very appealing approach to overcome this problem. A case study of multiobjective Electric Machine (EM) design based on DR of the novel model  is considered.|Piotr Wozniak","58217|GECCO|2007|Learning and anticipation in online dynamic optimization with evolutionary algorithms the stochastic case|The focus of this paper is on how to design evolutionaryalgorithms (EAs) for solving stochastic dynamicoptimization problems online, i.e.as time goes by.For a proper design, the EA must not only be capableof tracking shifting optima, it must also take intoaccount the future consequences of the evolveddecisions or actions. A previousframework describes how to build such EAs in thecase of non-stochastic problems. Most real-worldproblems however are stochastic. In this paper weshow how this framework can be extended to properlytackle stochasticity. We point out how thisnaturally leads to evolving strategiesrather than explicit decisions. We formalizeour approach in a new framework. The newframework and the various sourcesof problem-difficulty at hand are illustratedwith a running example. We also apply ourframework to inventory management problems, an importantreal-world application area in logistics. Our results show,as a proof of principle, the feasibility and benefitsof our novel approach.|Peter A. N. Bosman,Han La Poutré","58022|GECCO|2007|VMEA studies on replacing strategies and diversity in dynamic environments|We investigate some improvements to a memory-based evolutionary algorithm already studied with success in dynamic optimization problems. Two new replacing strategies to incorporate in the algorithm are proposed and a comparative study with previous approaches is made. The results show that the studied mechanisms powerfully improve the efficiency and the adaptability of the evolutionary algorithm.|Anabela Simões,Ernesto Costa","57746|GECCO|2006|A comparative study of differential evolution variants for global optimization|In this paper, we present an empirical comparison of some Differential Evolution variants to solve global optimization problems. The aim is to identify which one of them is more suitable to solve an optimization problem, depending on the problem's features and also to identify the variant with the best performance, regardless of the features of the problem to be solved. Eight variants were implemented and tested on  benchmark problems taken from the specialized literature. These variants vary in the type of recombination operator used and also in the way in which the mutation is computed. A set of statistical tests were performed in order to obtain more confidence on the validity of the results and to reinforce our discussion. The main aim is that this study can help both researchers and practitioners interested in using differential evolution as a global optimizer, since we expect that our conclusions can provide some insights regarding the advantages or limitations of each of the variants studied.|Efrén Mezura-Montes,Jesús Velázquez-Reyes,Carlos A. Coello Coello","57865|GECCO|2006|Behavioural GP diversity for dynamic environments an application in hedge fund investment|We present a new mechanism for preserving phenotypic behavioural diversity in a Genetic Programming application for hedge fund portfolio optimization, and provide experimental results on real-world data that indicate the importance of phenotypic behavioural diversity both in achieving higher fitness and in improving the adaptability of the GP population for continuous learning.|Wei Yan,Christopher D. Clack","57986|GECCO|2007|The defined cliffs variant in dynamic environments a case study using the shaky ladder hyperplane-defined functions|The shaky ladder hyperplane-defined functions (sl-hdfs) are a test suite utilized for exploring the behavior of the genetic algorithm (GA) in dynamic environments. This test suite can generate arbitrary problems with similar levels of difficulty and it provides a platform for systematic controlled observations of the GA in dynamic environments. Previous work has found two factors that contribute to the GA's success on sl-hdfs () short initial building blocks and () significantly changing the reward structure during fitness landscape changes. Therefore a test function that combines these two features should facilitate even better GA performance. This has led to the construction of a new sl-hdf variant, \"Defined Cliffs,\" in which we combine short elementary building blocks with sharp transitions in the environment. We examine this variant with two different levels of dynamics, static and regularly changing, using four different metrics. The results show superior GA performance on the Defined Cliffs over all previous variants (Cliffs, Weight, and Smooth). Our observations and conclusions in this variant further the understanding of the GA in dynamic environments.|Abir Alharbi,William Rand,Rick L. Riolo","57977|GECCO|2007|On the roles of redundancy and neutrality in evolutionary optimization an experimental study|An experimental study was performed to explore whether it is neutrality itself or simply the larger neighborhoods associated with neutral representations that influence the results achieved by evolutionary algorithms on NK fitness landscape problems.Markov chains were used to model the behaviour of a stochastic hill-climber on NK fitness landscapes, using two different types of representation a neutral network representation which exhibits neutrality and a redundant representation without neutrality which implements the same neighborhood induced by the corresponding neutral representation.|Marisol B. Correia,Carlos M. Fonseca","57598|GECCO|2006|A comparative study of evolutionary optimization techniques in dynamic environments|Genetic Algorithms have widely been used for solving optimization problems in stationary environments. In recent years, there has been a growing interest for investigating and improving the performance of these algorithms in dynamic environments where the fitness landscape changes. In this study, we present an extensive comparison of several algorithms with different characteristics on a common platform by using the moving peaks benchmark and by varying problem parameters.|Demet Ayvaz,Haluk Topcuoglu,Fikret S. Gürgen"],["57915|GECCO|2007|A spatial model of the red queen effect|Van Valen first discovered the \"Red Queen Effect\" (RQE), where two species can dramatically co-evolve their phenotypes over time but never gain a relative advantage . In the ideal version of the RQE, regardless of the actual values that the species evolve to obtain, they have not moved in relation to each other. Though previous models of the RQE exist, we developed an agent-based model (ABM) which has a base ontology more similar to real world coevolutionary systems than equation-based models (EBMs). For instance, this model contains spatial information and an individuallevel reproduction mechanism. Yet this model recreates traditional EBM results. For instance Dieckmann et al show that there are three possible outcomes of competitive coevolution predator dominance, prey dominance and evolutionary cycling (RQE) . By reconceptualizing this EBM using an ABM, we make it easier for students and researchers to understand, manipulate, and modify this model . The model is written in the NetLogo agent-based modeling environment . The model is initialized with  predator and  prey agents. Predator agents have a resistance level r and prey agents have a poison p. The agents are initially randomly distributed on a toroidal real-valued  by  grid. The initial resistance and poison values for the predators and prey are drawn from normal distributions with means r and p and a standard deviation of . During a model timestep, each agent moves one unit at a random heading. If at the end of its move a predator is within  unit of a prey, then it will challenge the prey. The predator will compare its resistance value to the prey's poison value and which ever agent has the larger value will win the challenge and the other agent will be killed. At the end of an agent's turn if the total number of agents is less than the maximum carrying capacity the agent will reproduce with a % probability. The new agent's initial poison  resistance will be drawn from a normal distribution with the parent's poison  resistance as the mean value and a standard deviation of . Our goal was to investigate whether this ABMwould replicate the results of the EBM of . Our parameter of interest was p we held r constant at  and varied p from  to  at increments of . For each value we ran the model  times for  timesteps. Figure  illustrates the final average values of both the resistance and the poison for the various initial values. If there are no predators or prey then a value of  is plotted for the respective final trait. In most cases, one species drives the other to extinction, and there is little change in the initial trait values. However when the value of p is similar to r then neither species is completely destroyed, but if there is any significant difference between r and p then one species will die off. The highest final trait values are found when p  r, in this case we see the results of the RQE since the final trait values are much higher than the initial values. These final values are more than . orders of magnitude larger than the initial values. This model reproduces classical models of the RQE, but has two different mobile species interacting on a spatial grid over time which is a closer representation of reality than traditional models. This closer representation makes ABMs excellent teaching and experimental tools because their basic assumptions can easily be manipulated and explored. Acknowledgments We thank the National Science Foundation and NICO for supporting this research.|Jules Ottino-Loffler,William Rand,Uri Wilensky","57795|GECCO|2006|The effects of interaction frequency on the optimization performance of cooperative coevolution|Cooperative coevolution is often used to solve difficult optimization problems by means of problem decomposition. Its performance on this task is influenced by many design decisions. It would be useful to have some knowledge of the performance effects of these decisions, in order to make the more beneficial ones. In this paper we study the effects on performance of the frequency of interaction between populations. We show them to be problem-dependent and use dynamics analysis to explain this dependency.|Elena Popovici,Kenneth A. De Jong","58104|GECCO|2007|Towards understanding the effects of neutrality on the sudoku problem|Over the last years, researchers have added neutrality in the evolutionary search in the hope that it can aid evolution. In this paper, we study the presence of neutrality that is already and to do so, we analised the fitness landscape of the Sudoku problem. How and why neutrality affects evolutionary search is a reasonably well-studied but still not clearly understood topic. Here, we use neutral walks, neutrality trajectories and fitness distance correlation to attempt to throw new light on this topic.|Edgar Galván López,Julian Togelius,Simon M. Lucas","57819|GECCO|2006|Comparing mathematical models on the problem of network inference|In this paper we address the problem of finding gene regulatory networks from experimental DNA microarray data. We focus on the evaluation of the performance of different mathematical models on the inference problem. They are used to model the underlying dynamic system of artificial regulatory networks. The dynamics of the artificial systems represent different basic types of behavior,dimensionality and mathematical properties. They are all created with three commonly used approaches, namely linear weight matrices, H-systems, and S-systems. Due to the complexity of the inference problem, some researchers suggested evolutionary algorithms for this purpose. However, in many publications only one algorithm is used without any comparison to other optimization methods. Thus, we introduce a framework to systematically apply evolutionary algorithms for further comparative analysis.|Christian Spieth,Nadine Hassis,Felix Streichert","58024|GECCO|2007|A discrete differential evolution algorithm for the permutation flowshop scheduling problem|In this paper, a novel discrete differential evolution (DDE) algorithm is presented to solve the permutation flowhop scheduling problem with the makespan criterion. The DDE algorithm is simple in nature such that it first mutates a target population to produce the mutant population. Then the target population is recombined with the mutant population in order to generate a trial population. Finally, a selection operator is applied to both target and trial populations to determine who will survive for the next generation based on fitness evaluations. As a mutation operator in the discrete differential evolution algorithm, a destruction and construction procedure is employed to generate the mutant population. We propose a referenced local search, which is embedded in the discrete differential evolution algorithm to further improve the solution quality. Computational results show that the proposed DDE algorithm with the referenced local search is very competitive to the iterated greedy algorithm which is one of the best performing algorithms for the permutation flowshop scheduling problem in the literature.|Quan-Qe Pan,Mehmet Fatih Tasgetiren,Yun-Chia Liang","57941|GECCO|2007|Inducing a generative expressive performance model using a sequential-covering genetic algorithm|In this paper, we describe an evolutionary approach to inducing a generative model of expressive music performance for Jazz saxophone. We begin with a collection of audio recordings of real Jazz saxophone performances from which we extract a symbolic representation of the musician's expressive performance. We then apply an evolutionary algorithm to the symbolic representation in order to obtain computational models for different aspects of expressive performance. Finally, we use these models to automatically synthesize performances with the expressiveness that characterizes the music generated by a professional saxophonist.|Rafael Ramirez,Amaury Hazan","58061|GECCO|2007|Genetic evolution of hierarchical behavior structures|The development of coherent and dynamic behaviors for mobile robots is an exceedingly complex endeavor ruled by task objectives, environmental dynamics and the interactions within the behavior structure. This paper discusses the use of genetic programming techniques and the unified behavior framework to develop effective control hierarchies using interchangeable behaviors and arbitration components. Given the number of possible variations provided by the framework, evolutionary programming is used to evolve the overall behavior design. Competitive evolution of the behavior population incrementally develops feasible solutions for the domain through competitive ranking. By developing and implementing many simple behaviors independently and then evolving a complex behavior structure suited to the domain, this approach allows for the reuse of elemental behaviors and eases the complexity of development for a given domain. Additionally, this approach has the ability to locate a behavior structure which a developer may not have previously considered, and whose ability exceeds expectations. The evolution of the behavior structure is demonstrated using agents in the Robocode environment, with the evolved structures performing up to  percent better than one crafted by an expert.|Brian G. Woolley,Gilbert L. Peterson","58005|GECCO|2007|Preliminary investigations into the evolution of cooperative strategies in a minimally spatial model|In this paper we outline a simple model of spatially structured populations that is an extension of the replicator dynamics approach used in evolutionary game theory. Using this model, we are able to investigate issues such as how the degree of spatial localisation affects the evolution of cooperative and selfish genotypes in a resource sharing scenario.|Simon T. Powers,Richard A. Watson","57820|GECCO|2006|Comparing evolutionary algorithms on the problem of network inference|In this paper, we address the problem of finding gene regulatory networks from experimental DNA microarray data. We focus on the evaluation of the performance of different evolutionary algorithms on the inference problem. These algorithms are used to evolve an underlying quantitative mathematical model. The dynamics of the regulatory system are modeled with two commonly used approaches, namely linear weight matrices and S-systems and a novel formulation, namely H-systems. Due to the complexity of the inference problem, some researchers suggested evolutionary algorithms for this purpose. However, in many publications only one algorithm is used without any comparison to other optimization methods. Thus, we introduce a framework to systematically apply evolutionary algorithms and different types of mutation and crossover operators to the inference problem for further comparative analysis.|Christian Spieth,Rene Worzischek,Felix Streichert","58109|GECCO|2007|Division blocks and the open-ended evolution of development form and behavior|We present a new framework for artificial life involving physically simulated, three-dimensional blocks called Division Blocks. Division Blocks can grow and shrink, divide and form joints, exert forces on joints, and exchange resources. They are controlled by recurrent neural networks that evolve, along with the blocks, by natural selection. Division Blocks are simulated in an environment in which energy is approximately conserved, and in which all energy derives ultimately from a simulated sun via photosynthesis. In this paper we describe our implementation of Division Blocks and some of the ways that it can support experiments on the open-ended evolution of development, form, and behavior. We also present preliminary data from simulations, demonstrating the reliable emergence of cooperative resource transactions.|Lee Spector,Jon Klein,Mark Feinstein"],["57961|GECCO|2007|Heuristic speciation for evolving neural network ensemble|Speciation is an important concept in evolutionary computation. It refers to an enhancements of evolutionary algorithms to generate a set ofdiverse solutions. The concept is studied intensively in the evolutionary design of neural network ensembles. Thediversity and cooperation of individual networks are among the essential criteria of the design.This paper proposes a speciation framework for ensemble design which integratesa collection of new techniques. Its characteristic features are(a) the population of networks are speciated as such thatthe mutual information between the networks' outputs and genotypic representations is preserved. (b) The ensemble is designed incrementally,upon discovery of a species of networks which enhances the ensembleperformance. (c) Multiple species are evolved andindividual networks are evaluated according to therole of their respective species in the ensemble.This framework provides an implementation of evolutionary algorithm which performs simultaneous single-objective optimizations.The new algorithm is evaluated with a series of classification benchmarks andshows an improvement over other evolutionary training strategiesand a statistical algorithm.|Shin Ando","57828|GECCO|2006|Evolving boolean networks to find intervention points in dengue pathogenesis|We use probabilistic boolean networks to simulate the pathogenesis of Dengue Hemorraghic Fever (DHF). Based on Chaturvedi's work, the strength of cytokine influences are modeled stochastically as inducement probabilities. Two basins of attractors are observed with synchronous updating the Null Infection cycle attractor shows an expected cross-regulation of Th and Th cytokines corresponding to the homeostasis of an uninfected person, while the DHF Infection attractor shows the onset of DHF. With asynchronous updating, our model remains valid with clinical comparisons against qualitative changes in signal durations. In order to find intervention points that could prevent DHF, we design a genetic algorithm to shift the DHF attractor to the DF attractor basin by using the DF final state as the fitness measure. Our simulation results identify TGF-, IL- and IL- as the intervention points which are consistent with known clinical results to prevent DHF from occurring.|Philip Tan,Joc Cing Tay","57948|GECCO|2007|Automated trading on financial instruments with evolved neural networks|This paper presents an approach to single-position, intraday automated trading based on a neuro-genetic algorithm.An artificial neural network is evolved which provides trading signals to a very unsophisticated automated trading agent.|Antonia Azzini,Andrea Tettamanzi","57931|GECCO|2007|Earthquake classifying neural networks trained with random dynamic neighborhood PSOs|This paper investigates the use of Random Dynamic Neighborhoods in Particle Swarm Optimization (PSO) for the purposeof training fixed-architecture neural networks to classify a real-world data set of seismological data.Instead of the ring or fully-connected neighborhoods that are typically used with PSOs, or even more complex graph structures, this work uses directed graphs that are randomly generated using size and uniform out-degree as parameters. Furthermore, the graphs are subjected to dynamism during the course of a run, thereby allowing for varying information exchange patterns. Neighborhood re-structuring is applied with a linearly decreasing probability at each iteration. Several experimental configurations are tested on a training portion of the data set, and are ranked according to their abilities to generalize over the entire set. Comparisons are performed with standard PSOs as well as several static non-random neighborhoods.|Arvind S. Mohais,Rosemarie Mohais,Christopher Ward,Christian Posthoff","57805|GECCO|2006|Modular thinking evolving modular neural networks for visual guidance of agents|This paper investigates whether replacing non-modular artificial neural network brains of visual agents with modular brains improves their ability to solve difficult tasks, specifically, survive in a changing environment. A set of experiments was conducted and confirmed that agents with modular brains are in fact better. Further analysis of the evolved modules characterised their function and determined their mechanism of operation. The results indicate that the greater survival ability is obtained due to functional specialisation of the evolved modules good agents do well because their modules are more specialised at tasks such as reproduction and consumption. Overall, the more specialised the modules, the fitter the agents.|Ehud Schlessinger,Peter J. Bentley,R. Beau Lotto","57804|GECCO|2006|A dynamic approach to artificial immune systems utilizing neural networks|The purpose of this work is to propose an immune-inspired setup to use a self-organizing map as a computational model for the interaction of antigens and antibodies. The proposed approach may be used as a part in other immune algorithms, or can possibly be used to detect anomalies in time series data.|Stefan Schadwinkel,Werner Dilger","57760|GECCO|2006|Coevolution of neural networks using a layered pareto archive|The Layered Pareto Coevolution Archive (LAPCA) was recently proposed as an effective Coevolutionary Memory (CM) which, under certain assumptions, approximates monotonic progress in coevolution. In this paper, a technique is developed that interfaces the LAPCA algorithm with NeuroEvolution of Augmenting Topologies (NEAT), a method to evolve neural networks with demonstrated efficiency in game playing domains. In addition, the behavior of LAPCA is analyzed for the first time in a complex game-playing domain evolving neural network controllers for the game Pong. The technique is shown to keep the total number of evaluations in the order of those required by NEAT, making it applicable to complex domains. Pong players evolved with a LAPCA and with the Hall of Fame (HOF) perform equally well, but the LAPCA is shown to require significantly less space than the HOF. Therefore, combining NEAT and LAPCA is found to be an effective approach to coevolution.|German A. Monroy,Kenneth O. Stanley,Risto Miikkulainen","57957|GECCO|2007|Generating large-scale neural networks through discovering geometric regularities|Connectivity patterns in biological brains exhibit many repeating motifs. This repetition mirrors inherent geometric regularities in the physical world. For example, stimuli that excite adjacent locations on the retina map to neurons that are similarly adjacent in the visual cortex. That way, neural connectivity can exploit geometric locality in the outside world by employing local connections in the brain. If such regularities could be discovered by methods that evolve artificial neural networks (ANNs), then they could be similarly exploited to solve problems that would otherwise require optimizing too many dimensions to solve. This paper introduces such a method, called Hypercube-based Neuroevolution of Augmenting Topologies (HyperNEAT), which evolves a novel generative encoding called connective Compositional Pattern Producing Networks (connective CPPNs) to discover geometric regularities in the task domain. Connective CPPNs encode connectivity patterns as concepts that are independent of the number of inputs or outputs, allowing functional large-scale neural networks to be evolved. In this paper, this approach is tested in a simple visual task for which it effectively discovers the correct underlying regularity, allowing the solution to both generalize and scale without loss of function to an ANN of over eight million connections.|Jason Gauci,Kenneth O. Stanley","58209|GECCO|2007|Evolving distributed agents for managing air traffic|Air traffic management offers an intriguing real world challenge to designing large scale distributed systems using evolutionary computation. The ability to evolve effective air traffic flow strategies depends not only on evolving good local strategies, but also on ensuring that those local strategies result in good global solutions. While traditional, direct evolutionary strategies can be highly effective in certain combinatorial domains, they are not well-suited to complex air traffic flow problems because of the large interdependencies among the local subsystems. In this paper, we propose an evolutionary agent-based solution to the air traffic flow problem. In this approach, we evolve agents both to learn the right local flow strategies to alleviate congestion in their immediate surroundings, and to prevent the creation of congestion \"downstream\" from their local areas. The agent-based approach leads to better and more fault-tolerant solutions. To validate this approach, we use FACET, an air traffic simulator developed at NASA and used extensively by the FAA and industry. On a scenario composed of three hundred aircraft and two points of congestion, our results show that an agent based evolutionary computation method, where each agent uses the system evaluation function, achieves % improvement over a direct evolutionary algorithm. In addition by creating agent-specific \"difference evaluation functions\" we achieve an additional % improvement over agents using the system evaluation.|Adrian K. Agogino,Kagan Tumer","57732|GECCO|2006|Facilitating neural dynamics for delay compensation and prediction in evolutionary neural networks|Delay in the nervous system is a serious issue for an organism that needs to act in real time. For example, during the time a signal travels from a peripheral sensor to the central nervous system, a moving object in the environment can cover a significant distance which can lead to critical errors in the effect of the corresponding motor output. This paper proposes that facilitating synapses which show a dynamic sensitivity to the changing input may play an important role in compensating for neural delays, through extrapolation. The idea was tested in a modified D pole-balancing problem which included sensory delays. Within this domain, we tested the behavior of recurrent neural networks with facilitatory neural dynamics trained via neuroevolution. Analysis of the performance and the evolved network parameters showed that, under various forms of delay, networks utilizing extrapolatory dynamics are at a significant competitive advantage compared to networks without such dynamics. In sum, facilitatory (or extrapolatory) dynamics can be used to compensate for delay at a single-neuron level, thus allowing a developing nervous system to stay in touch with the present environmental state.|Heejin Lim,Yoonsuck Choe"],["57747|GECCO|2006|Multi-step environment learning classifier systems applied to hyper-heuristics|Heuristic Algorithms (HA) are very widely used to tackle practical problems in operations research. They are simple, easy to understand and inspire confidence. Many of these HAs are good for some problem instances while very poor for other cases. While Meta-Heuristics try to find which is the best heuristic andor parameters to apply for a given problem instance Hyper-Heuristics (HH) try to combine several heuristics in the same solution searching process, switching among them whenever the circumstances vary. Besides, instead to solve a single problem instance it tries to find a general algorithm to apply to whole families of problems. HH use evolutionary methods to search for such a problem-solving algorithm and, once produced, to apply it to any new problem instance desired. Learning Classifier Systems (LCS), and in particular XCS, represents an elegant and simple way to try to fabricate such a composite algorithm. This represents a different kind of problem to those already studied by the LCS community. Previous work, using single step environments, already showed the usefulness of the approach. This paper goes further and studies the novel use of multi-step environments for HH and an alternate way to consider states to see if chains of actions can be learnt. A non-trivial, NP-hard family of problems, the Bin Packing one, is used as benchmark for the procedure. Results of the approach are very encouraging, showing outperformance over all HAs used individually and over previously reported work by the authors, including non-LCS (a GA based approach used for the same BP set of problems) and LCS (using single step environments).|Javier G. Marín-Blázquez,Sonia Schulenburg","57595|GECCO|2006|Coordination number prediction using learning classifier systems performance and interpretability|The prediction of the coordination number (CN) of an amino acid in a protein structure has recently received renewed attention. In a recent paper, Kinjo et al. proposed a real-valued definition of CN and a criterion to map it onto a finite set of classes, in order to predict it using classification approaches. The literature reports several kinds of input information used for CN prediction. The aim of this paper is to assess the performance of a state-of-the-art learning method, Learning Classifier Systems (LCS) on this CN definition, with various degrees of precision, based on several combinations of input attributes. Moreover, we will compare the LCS performance to other well-known learning techniques. Our experiments are also intended to determinethe minimum set of input information needed to achieve good predictive performance, so as to generate competent yet simple and interpretable classification rules. Thus, the generated predictors (rule sets) are analyzed for their interpretability.|Jaume Bacardit,Michael Stout,Natalio Krasnogor,Jonathan D. Hirst,Jacek Blazewicz","58145|GECCO|2007|Induction of fuzzy rules with artificial immune systems in acgh based er status breast cancer characterization|Genomic DNA copy number aberrations are frequent in solid tumours although their underlying causes remain obscure. In this paper we show how Artificial Immune System (AIS) paradigm can be successfully employed in the elucidation of biological dynamics of cancerous processes using a novel fuzzy rule induction system for data mining (IFRAIS). Competitive results have been obtained using IFRAIS. A biological interpretation of the results, carried out using Gene Ontology, followed the statistical assessment and put in evidence interesting patterns that are currently under investigation.|Filippo Menolascina,Roberto Teixeira Alves,Stefania Tommasi,Patrizia Chiarappa,Myriam Regattieri Delgado,Giuseppe Mastronardi,Angelo Paradiso,Alex Alves Freitas,Vitoantonio Bevilacqua","58223|GECCO|2007|Modelling danger and anergy in artificial immune systems|Artificial Immune Systems are engineering systems which have been inspired from the functioning of the biological immune system. We present an immune system model which incorporates two biologically motivated mechanisms to protect against autoimmune reactions, or false positives. The first, anergy, has been subject to the intense focus of immunologists as a possible key to autoimmune disease. The second is danger theory, which has attracted much interest as a possible alternative to traditional self-nonself selection models.We adopt a published immunological model, validate and extend it. Using the same calculations and assumptions as the original model, we integrate danger theory into the software.Without anergy, both models - the original and the danger model - produce similar results. When anergy is added, both models' performance improves. However, there seems to be some synergy between the mechanisms anergy has a greater effect on the danger model than the original model. These findings should be of interest both to AIS practitioners and to the immunological community.|Steve Cayzer,Julie Sullivan","57733|GECCO|2006|Fast rule matching for learning classifier systems via vector instructions|Over the last ten years XCS has become the standard for Michigan-style learning classifier systems (LCS). Since the initial CS- work conceived by Holland, classifiers (rules) have widely used a ternary condition alphabet ,, for binary input problems. Most of the freely available implementations of this ternary alphabet in XCS rely on character-based encodings---easy to implement, not memory efficient, and expensive to compute. Profiling of freely available XCS implementations shows that most of their execution time is spent determining whether a rule is match or not, posing a serious threat to XCS scalability. In the last decade, multimedia and scientific applications have pushed CPU manufactures to include native support for vector instruction sets. This paper presents how to implement efficient condition encoding and fast rule matching strategies using vector instructions. The paper elaborates on Altivec (PowerPC G, G) and SSE (Intel PXeon and AMD Opteron) instruction sets producing speedups of XCS matching process beyond ninety times. Moreover, such a vectorized matching code will allow to easily scale beyond tens of thousands of conditions in a reasonable time. The proposed fast matching scheme also fits in any other LCS other than XCS.|Xavier Llorà,Kumara Sastry","57804|GECCO|2006|A dynamic approach to artificial immune systems utilizing neural networks|The purpose of this work is to propose an immune-inspired setup to use a self-organizing map as a computational model for the interaction of antigens and antibodies. The proposed approach may be used as a part in other immune algorithms, or can possibly be used to detect anomalies in time series data.|Stefan Schadwinkel,Werner Dilger","58220|GECCO|2007|Initial results from the use of learning classifier systems to control neuronal networks|In this paper we describe the use of a learning classifier system to control the electrical stimulation of cultured neuronal networks. The aim is to manipulate the environment of the cells such that they display elementary learning, i.e., so that they respond to a given input signal in a pre-specified way. Results indicate that this is possible and that the learned stimulation protocols identify seemingly fundamental properties of in vitro neuronal networks.allUse of another learning scheme and simpler stimulation confirms these properties.|Larry Bull,Ivan S. Uroukov","57748|GECCO|2006|A representational ecology for learning classifier systems|The representation used by a learning algorithm introduces a bias which is more or less well-suited to any given learning problem. It is well known that, across all possible problems, one algorithm is no better than any other. Accordingly, the traditional approach in machine learning is to choose an appropriate representation making use of some domain-specific knowledge, and this representation is then used exclusively during the learning process.To reduce reliance on domain-knowledge and its appropriate use it would be desirable for the learning algorithm to select its own representation for the problem.We investigate this with XCS, a Michigan-style Learning Classifier System.We begin with an analysis of two representations from the literature hyperplanes and hyperspheres. We then apply XCS with either one or the other representation to two Boolean functions, the well-known multiplexer function and a function defined by hyperspheres, and confirm that planes are better suited to the multiplexer and spheres to the sphere-based function.Finally, we allow both representations to compete within XCS, which learns the most appropriate representation for problem thanks to the pressure against overlapping rules which its niche GA supplies. The result is an ecology in which the representations are species.|James A. R. Marshall,Tim Kovacs","58137|GECCO|2007|Classifier systems that compute action mappings|The learning in a niche based learning classifier system depends both on the complexity of the problem space and on the number of available actions. In this paper, we introduce a version of XCS with computed actions, briefly XCSCA, that can be applied to problems involving a large number of actions. We report experimental results showing that XCSCA can evolve accurate and compact representations of binary functions which would be challenging for typical learning classifier system models.|Pier Luca Lanzi,Daniele Loiacono","57601|GECCO|2006|A Bayesian approach to learning classifier systems in uncertain environments|In this paper we propose a Bayesian framework for XCS , called BXCS. Following , we use probability distributions to represent the uncertainty over the classifier estimates of payoff. A novel interpretation of classifier and an extension of the accuracy concept are presented. The probabilistic approach is aimed at increasing XCS learning capabilities and tendency to evolve accurate, maximally general classifiers, especially when uncertainty affects the environment or the reward function. We show that BXCS can approximate optimal solutions in stochastic environments with a high level of uncertainty.|Davide Aliprandi,Alex Mancastroppa,Matteo Matteucci"],["58008|GECCO|2007|Multi-objective particle swarm optimization on computer grids|In recent years, a number of authors have successfully extended particle swarmoptimization to problem domains with multiple objec-tives. This paper addresses theissue of parallelizing multi-objec-tive particle swarms. We propose and empirically comparetwo parallel versions which differ in the way they divide the swarminto subswarms that can be processed independently on differentprocessors. One of the variants works asynchronouslyand is thus particularly suitable for heterogeneous computer clusters asoccurring e.g. in moderngrid computing platforms.|Sanaz Mostaghim,Jürgen Branke,Hartmut Schmeck","58025|GECCO|2007|A heuristic particle swarm optimization|A heuristic version of the particle swarm optimization (PSO) is introduced in this paper. In this new method called \"The heuristic particle swarm optimization(HPSO)\", we use heuristics to choose the next particle to update its velocity and position. By using heuristics , the convergence rate to local minimum is faster. To avoid premature convergence of the swarm, the particles are re-initialized with random velocity when moving too close to the global best position. The combination of heuristics and re-initialization mechanism make HPSO outperform the basic PSO and recent versions of PSO.|Hoang Thanh Lam,Popova Nina Nicolaevna,Nguyen Thoi Minh Quan","58085|GECCO|2007|MRPSO MapReduce particle swarm optimization|In optimization problems involving large amounts of data, Particle Swarm Optimization (PSO) must be parallelized because individual function evaluations may take minutes or even hours. However, large-scale parallelization is difficult because programs must communicate efficiently, balance workloads and tolerate node failures. To address these issues, we present Map Reduce Particle Swarm Optimization(MRPSO), a PSO implementation based on Google's Map Reduce parallel programming model.|Andrew W. McNabb,Christopher K. Monson,Kevin D. Seppi","57994|GECCO|2007|Particle swarm guided evolution strategy|Evolution strategy (ES) and particle swarm optimization (PSO) are two of the most popular research topics for tackling real-parameter optimization problems in evolutionary computation. Both of them have strengths and weaknesses for their different search behaviors and methodologies. In ES, mutation, as the main operator, tries to find good solutions around each individual. While in PSO, particles are moving toward directions determined by certain global information, such as the global best particle. In order to leverage the specialties offered by both sides to our advantage, this paper combines the essential mechanism of ES and the key concept of PSO to develop a new hybrid optimization methodology, called particle swarm guided evolution strategy. We introduce swarm intelligence to the ES mutation framework to create a new mutation operator, called guided mutation, and integrate the guided mutation operator into ES. Numerical experiments are conducted on a set of benchmark functions, and the experimental results indicate that PSGES is a promising optimization methodology as well as an interesting research direction.|Chang-Tai Hsieh,Chih-Ming Chen,Ying-Ping Chen","58032|GECCO|2007|Applying particle swarm optimization to software testing|Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with  small artificial test objects and  more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.|Andreas Windisch,Stefan Wappler,Joachim Wegener","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57972|GECCO|2007|Kernel based automatic clustering using modified particle swarm optimization algorithm|This paper introduces a method for clustering complex and linearly non-separable datasets, without any prior knowledge of the number of naturally occurring clusters. The proposed method is based on an improved variant of the Particle Swarm Optimization (PSO) algorithm. In addition, it employs a kernel-induced similarity measure instead of the conventional sum-of-squares distance. Use of the kernel function makes it possible to cluster data that is linearly non-separable in the original input space into homogeneous groups in a transformed high-dimensional feature space. Computer simulations have been undertaken with a test bench of five synthetic and three real life datasets, in order to compare the performance of the proposed method with a few state-of-the-art clustering algorithms. The results reflect the superiority of the proposed algorithm in terms of accuracy, convergence speed and robustness.|Ajith Abraham,Swagatam Das,Amit Konar","58150|GECCO|2007|Geometric particle swarm optimization for the sudoku puzzle|Geometric particle swarm optimization (GPSO) is a recentlyintroduced generalization of traditional particle swarm optimization(PSO) that applies to all combinatorial spaces. The aim of thispaper is to demonstrate the applicability of GPSO to non-trivialcombinatorial spaces. The Sudoku puzzle is a perfect candidate totest new algorithmic ideas because it is entertaining andinstructive as well as a non-trivial constrained combinatorialproblem. We apply GPSO to solve the sudoku puzzle.|Alberto Moraglio,Julian Togelius","57813|GECCO|2006|Dynamic fitness inheritance proportion for multi-objective particle swarm optimization|In this paper, we propose a dynamic mechanism to vary the probability by which fitness inheritance is applied throughout the run of a multi-objective particle swarm optimizer, in order to obtain a greater reduction in computational cost (than the obtained with a fixed probability), without dramatically affecting the quality of the results. The results obtained show that it is possible to reduce the computational cost by % without affecting the quality of the obtained Pareto front.|Margarita Reyes Sierra,Carlos A. Coello Coello"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","58068|GECCO|2007|Solving the artificial ant on the Santa Fe trail problem in   fitness evaluations|In this paper, we provide an algorithm that systematically considers all small trees in the search space of genetic programming. These small trees are used to generate useful subroutines for genetic programming. This algorithm is tested on the Artificial Ant on the Santa Fe Trail problem, a venerable problem for genetic programming systems. When four levels of iteration are used, the algorithm presented here generates better results than any known published result by a factor of .|Steffen Christensen,Franz Oppacher","57666|GECCO|2006|A new approach for shortest path routing problem by random key-based GA|In this paper, we propose a Genetic Algorithm (GA) approach using a new paths growth procedure by the random key-based encoding for solving Shortest Path Routing (SPR) problem. And we also develop a combined algorithm by arithmetical crossover, swap mutation, and immigration operator as genetic operators. Numerical analysis for various scales of SPR problems shows the proposed random key-based genetic algorithm (rkGA) approach has a higher search capability that enhanced rate of reaching optimal solutions and improve computation time than other GA approaches using different genetic representation methods.|Mitsuo Gen,Lin Lin","57688|GECCO|2006|ORDERTREE a new test problem for genetic programming|In this paper, we describe a new test problem for genetic programming (GP), ORDERTREE. We argue that it is a natural analogue of ONEMAX, a popular GA test problem, and that it also avoids some of the known weaknesses of other benchmark problems for Genetic Programming. Through experiments, we show that the difficulty of the problem can be tuned not only by increasing the size of the problem, but also by increasing the non-linearity in the fitness structure.|Tuan Hao Hoang,Nguyen Xuan Hoai,Nguyen Thi Hien,Robert I. McKay,Daryl Essam","57639|GECCO|2006|Selective self-adaptive approach to ant system for solving unit commitment problem|This paper presents a novel approach to solve the constrained unit commitment problem using Selective Self-Adaptive Ant System (SSAS) for improving search performance by automatically adapting ant populations and their transition probability parameters, which cooperates with Candidate Path Management Module (CPMM) and Effective Repairing Heuristic Module (ERHM) in reducing search space and recovering a feasible optimality region so that a high quality solution can be acquired in a very early iterative. The proposed SSAS algorithm not only enhances the convergence of search process, but also provides a suitable number of the population sharing which conducts a good guidance for trading-off between the importance of the visibility and the pheromone trail intensity. The proposed method has been performed on a test system up to  generating units with a scheduling time horizon of  hours. The numerical results show the most economical saving in the total operating cost when compared to the previous literature results. Moreover, the proposed SSAS topology can remarkably speed up the computation time of ant system algorithms, which is favorable for a large-scale unit commitment problem implementation.|Songsak Chusanapiputt,Dulyatat Nualhong,Sujate Jantarang,Sukumvit Phoomvuthisarn","57667|GECCO|2006|Solving identification problem for asynchronous finite state machines using genetic algorithms|A Genetic Algorithm, embedded in a simulation-based method, is applied to the identification of Asynchronous Finite State Machines. Two different coding schemes and their associated crossover operations are examined. It is shown that one operator  coding pair outperforms the other in that the scheme reduces noticeably the production of invalid chromosomes thus increasing the efficiency and the convergence rate of the evolution process.|Xiaojun Geng","57739|GECCO|2006|MOGE GP classification problem decomposition using multi-objective optimization|A novel approach to classification is proposed in which a Pareto-based ranking of individuals is used to encourage multiple individuals to participate in the solution. To do so, the classification problem is re-expressed as a cluster consistency problem, thus allowing utilization of techniques from multi-objective optimization. Such a formulation enables classification problems to be automatically decomposed and solved by several specialist classifiers rather than by a single 'super' individual. In this paper, we demonstrate the proposed approach to two benchmark binary problems and recommend a natural extension to multi-class problems. Results indicate the general appropriateness of the approach.|Andrew R. McIntyre,Malcolm I. Heywood","58205|GECCO|2007|The multi-objective next release problem|This paper is concerned with the Multi-Objective Next Release Problem (MONRP), a problem in search-based requirements engineering. Previous work has considered only single objective formulations. In the multi-objective formulation, there are at least two (possibly conflicting) objectives that the software engineer wishes to optimize. It is argued that the multi-objective formulation is more realistic, since requirements engineering is characterised by the presence of many complex and conflicting demands, for which the software engineer must find a suitable balance. The paper presents the results of an empirical study into the suitability of weighted and Pareto optimal genetic algorithms, together with the NSGA-II algorithm, presenting evidence to support the claim that NSGA-II is well suited to the MONRP. The paper also provides benchmark data to indicate the size above which the MONRP becomes non--trivial.|Yuanyuan Zhang,Mark Harman,S. Afshin Mansouri","57772|GECCO|2006|Multi-objective optimisation of the protein-ligand docking problem in drug discovery|The pharmaceutical industry is facing an ever-increasing demand to discover novel drugs that are more effective and safer than existing ones. The industry faces huge problem in improving its drug discovery and development processes since formerly used methods have shown their limits. Additionally, tests for safety of drugs are performed at the later end of the drug discovery pipeline instead of earlier. Therefore, the industry is looking for predictive tools that would be useful in testing the behaviour of a drug candidate earlier on in the pipeline before performing the large scale clinical tests. This paper explores the application of evolutionary multi-objective optimisation techniques for achieving such predictive work in protein-ligand docking. The paper reviews the literature of multi-objective optimisation and the drug discovery process and proposes a framework as a predictive tool to calculate good docking configuration for a given target protein and its binding compound. Finally existing models for drug evaluation are used for framework validation.|A. Oduguwa,A. Tiwari,S. Fiorentino,R. Roy","57612|GECCO|2006|A new hybrid evolutionary algorithm for the huge -cardinality tree problem|In recent years it has been shown that an intelligent combination of metaheuristics with other optimization techniques can significantly improve over the application of a pure metaheuristic. In this paper, we combine the evolutionary computation paradigm with dynamic programming for the application to the NP-hard k-cardinality tree problem. Given an undirected graph G with node and edge weights, this problem consists of finding a tree in G with exactly k edges such that the sum of the weights is minimal. The genetic operators of our algorithm are based on an existing dynamic programming algorithm from the literature for finding optimal subtrees in a given tree. The simulation results show that our algorithm is able to improve the best known results for benchmark problems from the literature in  cases.|Christian Blum"]]}}