{"abstract":{"entropy":6.078796730054686,"topics":["constraint satisfaction, constraint problem, search web, local space, satisfaction problem, different ontologies, optimization problem, problem, temporal reasoning, search, planning constraint, quantified problem, search finding, search satisfaction, present models, search constraint, reasoning, search problem, models, finding","learning, learning sequential, machine learning, consider agents, problem agents, knowledge base, machine data, consider problem, learning models, agents, knowledge, knowledge agents, problem learning, describes learning, learning data, data, planning, describes, research, applied","arc consistency, natural language, belief change, natural generation, belief revision, markov decision, language generation, describes system, present approach, describes approach, approach, system, models based, approach based, system based, approach system, based, information, belief, partially","present novel, present algorithms, logic programs, present, logic, introduce framework, present problem, framework, programming, technique, introduce, heuristic, analysis, recently, operators, parsing, allows, description, function, used","local space, reasoning, temporal reasoning, finding, fundamental, performance","paper, representation, mobile, state, formal, point","planning, task, classification, domain, training, information, modeling","problem agents, consider problem, consider agents, agents, human, environment, relational, research, visual, simulation, behavior, automatic, deals, building, actions","arc consistency, belief change, belief, belief revision, provide, simple","first, investigate, semantic, game, problem, information, partially","logic, logic programs, programming, description","present algorithms, present novel, present, analysis, features, technique"],"ranking":[["16209|IJCAI|2005|Identifying Conflicts in Overconstrained Temporal Problems|We describe a strong connection between maximally satisfiable and minimally unsatisfiable subsets of constraint systems. Using this relationship, we develop a two-phase algorithm, employing powerful constraint satisfaction techniques, for the identification of conflicting sets of constraints in infeasible constraint systems. We apply this technique to overconstrained instances of the Disjunctive Temporal Problem (DTP), an expressive form of temporal constraint satisfaction problems. Using randomly-generated benchmarks, we provide experimental results that demonstrate how the algorithm scales with problem size and constraint density.|Mark H. Liffiton,Michael D. Moffitt,Martha E. Pollack,Karem A. Sakallah","16214|IJCAI|2005|ANDOR Branch-and-Bound for Graphical Models|The paper presents and evaluates the power of a new framework for optimization in graphical models, based on ANDOR search spaces. The virtue of the ANDOR representation of the search space is that its size may be far smaller than that of a traditional OR representation. We develop our work on Constraint Optimization Problems (COP) and introduce a new generation of depth-first Branch-and-Bound algorithms that explore an ANDOR search space and use static and dynamic mini-bucket heuristics to guide the search. We focus on two optimization problems, solvingWeighted CSPs (WCSP) and finding theMost Probable Explanation (MPE) in belief networks. We show that the new ANDOR approach improves considerably over the classic OR space, on a variety of benchmarks including random and real-world problems. We also demonstrate the impact of different lower bounding heuristics on Branch-and-Bound exploring ANDOR spaces.|Radu Marinescu 0002,Rina Dechter","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas St√ºtzle","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder","16286|IJCAI|2005|Structural Symmetry Breaking|Symmetry breaking has been shown to be an important method to speed up the search in constraint satisfaction problems that contain symmetry. When breaking symmetry by dominance detection, a computationally efficient symmetry breaking scheme can be achieved if we can solve the dominance detection problem in polynomial time. We study the complexity of dominance detection when value and variable symmetry appear simultaneously in constraint satisfaction problems (CSPs) with single-valued variables and set-CSPs. We devise an efficient dominance detection algorithm for CSPs with single-valued variables that yields symmetry-free search trees and that is based on the abstraction to the actual, intuitive structure of a symmetric CSP.|Meinolf Sellmann,Pascal Van Hentenryck","16299|IJCAI|2005|Value Ordering for Finding All Solutions|In finding all solutions to a constraint satisfaction problem, or proving that there are none, with a search algorithm that backtracks chronologically and forms k-way branches, the order in which the values are assigned is immaterial. However, we show that if the values of a variable are assigned instead via a sequence of binary choice points, and the removal of the value just tried from the domain of the variable is propagated before another value is selected, the value ordering can affect the search effort. We show that this depends on the problem constraints for some types of constraints, we show that the savings in search effort can be significant, given a good value ordering.|Barbara M. Smith,Paula Sturdy"],["16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","16161|IJCAI|2005|State Abstraction Discovery from Irrelevant State Variables|Abstraction is a powerful form of domain knowledge that allows reinforcement-learning agents to cope with complex environments, but in most cases a human must supply this knowledge. In the absence of such prior knowledge or a given model, we propose an algorithm for the automatic discovery of state abstraction from policies learned in one domain for use in other domains that have similar structure. To this end, we introduce a novel condition for state abstraction in terms of the relevance of state features to optimal behavior, and we exhibit statistical methods that detect this condition robustly. Finally, we show how to apply temporal abstraction to benefit safely from even partial state abstraction in the presence of generalization error.|Nicholas K. Jong,Peter Stone","16170|IJCAI|2005|A Novel Approach to Model Generation for Heterogeneous Data Classification|Ensemble methods such as bagging and boosting have been successfully applied to classification problems. Two important issues associated with an ensemble approach are how to generate models to construct an ensemble, and how to combine them for classification. In this paper, we focus on the problem of model generation for heterogeneous data classification. If we could partition heterogeneous data into a number of homogeneous partitions, we will likely generate reliable and accurate classification models over the homogeneous partitions. We examine different ways of forming homogeneous subsets and propose a novel method that allows a data point to be assigned multiple times in order to generate homogeneous partitions for ensemble learning. We present the details of the new algorithm and empirical studies over the UCI benchmark datasets and datasets of image classification, and show that the proposed approach is effective for heterogeneous data classification.|Rong Jin,Huan Liu","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16346|IJCAI|2005|Semi-Supervised Regression with Co-Training|In many practical machine learning and data mining applications, unlabeled training examples are readily available but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. Previous research mainly focuses on semi-supervised classification. In this paper, a co-training style semi-supervised regression algorithm, i.e. COREG, is proposed. This algorithm uses two k-nearest neighbor regressors with different distance metrics, each of which labels the unlabeled data for the other regressor where the labeling confidence is estimated through consulting the influence of the labeling of unlabeled examples on the labeled ones. Experiments show that COREG can effectively exploit unlabeled data to improve regression estimates.|Zhi-Hua Zhou,Ming Li","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","16324|IJCAI|2005|Learning Payoff Functions in Infinite Games|We consider a class of games with real-valued strategies and payoff information available only in the form of data from a given sample of strategy profiles. Solving such games with respect to the underlying strategy space requires generalizing from the data to a complete payoff-function representation. We address payoff-function learning as a standard regression problem, with provision for capturing known structure (symmetry) in the multiagent environment. To measure learning performance, we consider the relative utility of prescribed strategies, rather than the accuracy of payoff functions per se. We demonstrate our approach and evaluate its effectiveness on two examples a two-player version of the first-price sealed-bid auction (with known analytical form), and a five-player marketbased scheduling game (with no known solution).|Yevgeniy Vorobeychik,Michael P. Wellman,Satinder P. Singh","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White","16090|IJCAI|2005|Two-Sided Bandits and the Dating Market|We study the decision problems facing agents in repeated matching environments with learning, or two-sided bandit problems, and examine the dating market, in which men and women repeatedly go out on dates and learn about each other, as an example. We consider three natural matching mechanisms and empirically examine properties of these mechanisms, focusing on the asymptotic stability of the resulting matchings when the agents use a simple learning rule coupled with an -greedy exploration policy. Matchings tend to be more stable when agents are patient in two different ways -- if they are more likely to explore early or if they are more optimistic. However, the two forms of patience do not interact well in terms of increasing the probability of stable outcomes. We also define a notion of regret for the two-sided problem and study the distribution of regrets under the different matching mechanisms.|Sanmay Das,Emir Kamenica","16095|IJCAI|2005|Inferring Image Templates from Classification Decisions|Assuming human image classification decisions are based on estimating the degree of match between a small number of stored internal templates and certain regions of the input images, we present an algorithm which infers observers classification templates from their classification decisions on a set of test images. The problem is formulated as learning prototypes from labeled data under an adjustable, prototype-specific elliptical metric. The matrix of the elliptical metric indicates the pixels that the template responds to. The model was applied to human psychophysical data collected in a simple image classification experiment.|Arnab Dhua,Florin Cutzu"],["16059|IJCAI|2005|Reconstructing an Agents Epistemic State from Observations|We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a \"reverse engineering\" approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that \"best explains\" the observation. Further considerations on this best-explaining model then allow inferences about the agent's epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.|Richard Booth,Alexander Nittka","16122|IJCAI|2005|Feature Generation for Text Categorization Using World Knowledge|We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.|Evgeniy Gabrilovich,Shaul Markovitch","16301|IJCAI|2005|SVM-based Obstacles Recognition for Road Vehicle Applications|This paper describes an obstacle Recognition System based on SVM and vision. The basic components of the detected objects are first located in the image and then combined with a SVM-based classifier. A distributed learning approach is proposed in order to better deal with objects variability, illumination conditions, partial occlusions and rotations. A large database containing thousands of object examples extracted from real road images has been created for learning purposes. We present and discuss the results achieved up to date.|Miguel √?ngel Sotelo,Jes√∫s Nuevo,David Fern√°ndez,I. Parra,Luis Miguel Bergasa,Manuel Oca√±a,Ram√≥n Flores","16136|IJCAI|2005|Learning Strategies for Open-Domain Natural Language Question Answering|We present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources, questions, and answers. Our approach formulates QA as a problem of first order inference over a suitably expressive, learned representation. This framework draws on prior work in learning action and problem-solving strategies, as well as relational learning methods. We describe the design of a system implementing this model in the framework of natural language question answering for story comprehension. Finally, we compare our approach to three prior systems, and present experimental results demonstrating the efficacy of our model.|Eugene Grois,David C. Wilkins","16154|IJCAI|2005|Iterated Belief Change A Transition System Approach|We use a transition system approach to reason about the evolution of an agent's beliefs as actions are executed. Some actions cause an agent to perform belief revision and some actions cause an agent to perform belief update, but the interaction between revision and update can be non-elementary. We present a set of basic postulates describing the interaction of revision and update, and we introduce a new belief evolution operator that gives a plausible interpretation to alternating sequences of revisions and updates.|Aaron Hunter,James P. Delgrande","16233|IJCAI|2005|A Machine Learning Approach to Identification and Resolution of One-Anaphora|We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.|Hwee Tou Ng,Yu Zhou,Robert Dale,Mary Gardiner","16046|IJCAI|2005|A language for functional interpretation of model based simulation|Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.|Jonathan Bell,Neal Snooke,Chris Price","16330|IJCAI|2005|Decision Diagrams for the Computation of Semiring Valuations|This paper describes a new approach to computation in a semiring-based system, which includes semiring-based CSPs (in particular weighted CSPs, fuzzy CSPs and standard CSPs) as well as Bayesian networks. The approach to computation is based on what we call semiring-labelled decision diagrams (SLDDs). These can be generated in a similar way to a standard search tree (decision tree) for solving a CSP, but some nodes are merged, creating a more compact representation for certain classes of CSPs, the number of nodes in the resulting network will be a tiny fraction of the number of nodes in the corresponding search tree. A method is given for generating an SLDD that represents e.g., a particular instance of a semiring-based CSP it is shown how this can be used to perform various computations of interest, such as solving a semiring-based CSP, finding optimal solutions, determining the possible values of each variable and counting solutions of a CSP.|Nic Wilson","16240|IJCAI|2005|Inverse Resolution as Belief Change|Belief change is concerned with modelling the way in which a rational reasoner maintains its beliefs as it acquires new information. Of particular interest is the way in which new beliefs are acquired and determined and old beliefs are retained or discarded. A parallel can be drawn to symbolic machine learning approaches where examples to be categorised are presented to the learning system and a theory is subsequently derived, usually over a number of iterations. It is therefore not surprising that the term 'theory revision' is used to describe this process Ourston and Mooney, . Viewing a machine learning system as a rational reasoner allows us to begin seeing these seemingly disparate mechanisms in a similar light. In this paper we are concerned with characterising the well known inverse resolution operations Muggleton,   (and more recently, inverse entailment Muggleton, ) as AGM-style belief change operations. In particular, our account is based on the abductive expansion operation Pagnucco et al.,  Pagnucco,  and characterised by using the notion of epistemic entrenchment Grdenfors and Makinson,  extended for this operation. This work provides a basis for reconciling work in symbolic machine learning and belief revision. Moreover, it allows machine learning techniques to be understood as forms of nonmonotonic reasoning.|Maurice Pagnucco,David Rajaratnam","16188|IJCAI|2005|A Unified Framework of Propositional Knowledge Base Revision and Update Based on State Transition Models|Belief revision and belief update are two of the most basic types of belief change operations. We need to select either revision or update when we accept new information into the current belief, however, such decision making has not been considered. In this paper, we propose a unified framework of revision and update based on state transition models that enable us to do such decision making. This framework provides a hybrid operation of revision and update, called acceptance.|Yasuo Kudo,Tetsuya Murai"],["16235|IJCAI|2005|Possibilistic Stable Models|In this work, we define a new framework in order to improve the knowledge representation power of Answer Set Programming paradigm. Our proposal is to use notions from possibility theory to extend the stable model semantics by taking into account a certainty level, expressed in terms of necessity measure, on each rule of a normal logic program. First of all, we introduce possibilistic definite logic programs and show how to compute the conclusions of such programs both in syntactic and semantic ways. The syntactic handling is done by help of a fix-point operator, the semantic part relies on a possibility distribution on all sets of atoms and we show that the two approaches are equivalent. In a second part, we define what is a possibilistic stable model for a normal logic program, with default negation. Again, we define a possibility distribution allowing to determine the stable models.|Pascal Nicolas,Laurent Garcia,Igor St√©phan","16315|IJCAI|2005|On the Interaction between Inverse Features and Path-functional Dependencies in Description Logics|We investigate how inverse features can be added to a boolean complete description logic with path-functional dependencies in ways that avoid undecidability of the associated logical implication problem. In particular, we present two conditions that ensure the problem remains EXPTIME-complete. The first is syntactic in nature and limits the form that dependencies may have in argument terminologies. The second is a coherence condition on terminologies that is sufficiently weak to allow the transfer of relational and emerging object-oriented normalization techniques.|David Toman,Grant E. Weddell","16103|IJCAI|2005|A Uniform Integration of Higher-Order Reasoning and External Evaluations in Answer-Set Programming|We introduce HEX programs, which are nonmonotonic logic programs admitting higher-order atoms as well as external atoms, and we extend the well-known answer-set semantics to this class of programs. Higher-order features are widely acknowledged as useful for performing meta-reasoning, among other tasks. Furthermore, the possibility to exchange knowledge with external sources in a fully declarative framework such as Answer-Set Programming (ASP) is nowadays important, in particular in view of applications in the Semantic Web area. Through external atoms, HEX programs can model some important extensions to ASP, and are a useful KR tool for expressing various applications. Finally, complexity and implementation issues for a preliminary prototype are discussed.|Thomas Eiter,Giovambattista Ianni,Roman Schindlauer,Hans Tompits","16338|IJCAI|2005|A Motion Closed World Asumption|Yaman et. al. Yaman et al.,  introduce \"go theories\" to reason about moving objects. In this paper, we show that this logic often does not allow us to infer that an object is not present at a given place or region, even though common sense would dictate that this is a reasonable inference to make. We define a class of models of go-theories called coherent models. We use this concept to define a motion closed world assumption (MCWA) and develop a notion of MCWA-entailment. We show that checking if a go-theory has a coherent model is NP-complete. An in atom checks if a given object is present in a given region sometime in a given time interval. We provide sound and complete algorithms to check if a ground in literal (positive or negative in atom) can be inferred from a go-theory using the MCWA. In our experiments our algorithms answer such queries in less than  second when there are up to , go-atoms per object.|Fusun Yaman,Dana S. Nau,V. S. Subrahmanian","16046|IJCAI|2005|A language for functional interpretation of model based simulation|Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.|Jonathan Bell,Neal Snooke,Chris Price","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","16339|IJCAI|2005|Automation Intelligence for the Smart Environment|Scaling AI algorithms to large problems requires that these algorithms work together to harness their respective strengths. We introduce a method of automatically constructing HHMMs using the output of a sequential data-mining algorithm and sequential prediction algorithm. We present the theory of this technique and demonstrate results using the MavHome intelligent environment.|G. Michael Youngblood,Edwin O. Heierman III,Lawrence B. Holder,Diane J. Cook","16104|IJCAI|2005|On Solution Correspondences in Answer-Set Programming|We introduce a general framework for specifying program correspondence under the answer-set semantics. The framework allows to define different kinds of equivalence notions, including previously defined notions like strong and uniform equivalence, in which programs are extended with rules from a given context, and correspondence is determined by means of a binary relation. In particular, refined equivalence notions based on projected answer sets can be defined within this framework, where not all parts of an answer set are of relevance. We study general characterizations of inclusion and equivalence problems, introducing novel semantical structures. Furthermore, we deal with the issue of determining counterexamples for a given correspondence problem, and we analyze the computational complexity of correspondence checking.|Thomas Eiter,Hans Tompits,Stefan Woltran","16316|IJCAI|2005|Ordering Heuristics for Description Logic Reasoning|We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.|Dmitry Tsarkov,Ian Horrocks","16108|IJCAI|2005|Strong Equivalence for Logic Programs with Preferences|Recently, strong equivalence for Answer Set Programming has been studied intensively, and was shown to be beneficial for modular programming and automated optimization. In this paper we define the novel notion of strong equivalence for logic programs with preferences. Based on this definition we give, for several semantics for preference handling, necessary and sufficient conditions for programs to be strongly equivalent. These results provide a clear picture of the relationship of these semantics with respect to strong equivalence, which differs considerably from their relationship with respect to answer sets. Finally, based on these results, we present for the first time simplification methods for logic programs with preferences.|Wolfgang Faber,Kathrin Konczak"],["16236|IJCAI|2005|Propositional Abduction is Almost Always Hard|Abduction is a fundamental form of nonmonotonic reasoning that aims at finding explanations for observed manifestations. Applications of this process range from car configuration to medical diagnosis. We study here its computational complexity in the case where the application domain is described by a propositional theory built upon a fixed constraint language and the hypotheses and manifestations are described by sets of literals. We show that depending on the language the problem is either polynomial-time solvable, NP-complete, or P-complete. In particular, we show that under the assumption PNP, only languages that are affine of width  have a polynomial algorithm, and we exhibit very weak conditions for NP-hardness.|Gustav Nordh,Bruno Zanuttini","16132|IJCAI|2005|Integrating Planning and Temporal Reasoning for Domains with Durations and Time Windows|The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the th International Planning Competition showing very good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina","16227|IJCAI|2005|Temporal Context Representation and Reasoning|This paper demonstrates how a model for temporal context reasoning can be implemented. The approach is to detect temporally related events in natural language text and convert the events into an enriched logical representation. Reasoning is provided by a first order logic theorem prover adapted to text. Results show that temporal context reasoning boosts the performance of a Question Answering system.|Dan I. Moldovan,Christine Clark,Sanda M. Harabagiu","16263|IJCAI|2005|Dependency Calculus Reasoning in a General Point Relation Algebra|The point algebra is a fundamental formal calculus for spatial and temporal reasoning. We present a new generalization that meets all requirements to describe dependencies on networks. Applications range from traffic networks to medical diagnostics. We investigate satisfaction problems, tractable subclassses, embeddings into other relation algebras, and the associated interval algebra.|Marco Ragni,Alexander Scivos","16298|IJCAI|2005|Streamlining Local Search for Spatially Balanced Latin Squares|Streamlined constrained reasoning powerfully boosts the performance of backtrack search methods for finding hard combinatorial objects. We use so-called spatially balanced Latin squares to show how streamlining can also be very effective for local search Our approach is much faster and generates considerably larger spatially balanced Latin squares than previously reported approaches (up to order  the previous best results could only generate solutions up to order ). We also provide a detailed characterization of our streamliner and solution topology for small orders. We believe that streamlined local search is a general technique suitable for solving a wide range of hard combinatorial design problems.|Casey Smith,Carla P. Gomes,C√®sar Fern√°ndez","16057|IJCAI|2005|TimeML-Compliant Text Analysis for Temporal Reasoning|Reasoning with time needs more than just a list of temporal expressions. TimeML--an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text--is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. Hard as TimeML-compliant analysis is, the small size of the only currently available annotated corpus makes it even harder. We address this problem with a hybrid TimeML annotator, which uses cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component capable of effectively using large amounts of unannotated data.|Branimir Boguraev,Rie Kubota Ando","16318|IJCAI|2005|Measuring Semantic Similarity by Latent Relational Analysis|This paper introduces Latent Relational Analysis (LRA), a method for measuring semantic similarity. LRA measures similarity in the semantic relations between two pairs of words. When two pairs have a high degree of relational similarity, they are analogous. For example, the pair catmeow is analogous to the pair dogbark. There is evidence from cognitive science that relational similarity is fundamental to many cognitive and linguistic tasks (e.g., analogical reasoning). In the Vector Space Model (VSM) approach to measuring relational similarity, the similarity between two pairs is calculated by the cosine of the angle between the vectors that represent the two pairs. The elements in the vectors are based on the frequencies of manually constructed patterns in a large corpus. LRA extends the VSM approach in three ways () patterns are derived automatically from the corpus, () Singular Value Decomposition is used to smooth the frequency data, and () synonyms are used to reformulate word pairs. This paper describes the LRA algorithm and experimentally compares LRA to VSM on two tasks, answering college-level multiple-choice word analogy questions and classifying semantic relations in noun-modifier expressions. LRA achieves state-of-the-art results, reaching human-level performance on the analogy questions and significantly exceeding VSM performance on both tasks.|Peter D. Turney","16114|IJCAI|2005|Representing Flexible Temporal Behaviors in the Situation Calculus|In this paper we present an approach to representing and managing temporally-flexible behaviors in the Situation Calculus based on a model of time and concurrent situations. We define a new hybrid framework combining temporal constraint reasoning and reasoning about actions. We show that the Constraint Based Interval Planning approach can be imported into the Situation Calculus by defining a temporal and concurrent extension of the basic action theory. Finally, we provide a version of the Golog interpreter suitable for managing flexible plans on multiple timelines.|Alberto Finzi,Fiora Pirri","16226|IJCAI|2005|Applying Local Search to Disjunctive Temporal Problems|We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.|Michael D. Moffitt,Martha E. Pollack","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas St√ºtzle"],["16171|IJCAI|2005|Iterated Belief Revision Revised|The AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide generally accepted criteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulates alone, however, are too permissive They support operators by which all newly acquired information is canceled as soon as an agent learns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the DP postulates, and we show how to solve the problem by an additional postulate of independence. We give a representation theorem for this postulate and prove that it is compatible with AGM and DP.|Yi Jin,Michael Thielscher","16141|IJCAI|2005|Structural Representation and Matching of Articulatory Speech Structures based on the Evolving Transformation System ETS Formalism|A formal structural representation of speech is presented in this paper. The representation is developed within the Evolving Transformation System (ETS) formalism and encapsulates speech processes at the articulatory level. We show how the class structure of several consonantal phonemes of English can be expressed via articulatory gestures. Elements of these classes can be detected in a corresponding structural representation of continuous speech. Our experimental results on the MOCHA articulatory corpus support the hypothesis that the proposed articulatory representation captures sufficient information for the accurate structural identification of phonemic classes.|Alexander Gutkin,David Gay","16288|IJCAI|2005|A Formal Investigation of Mapping Language for Terminological Knowledge|The need to represent mappings between different ontologies has been recognized as a result of the fact that different ontologies may partially overlap, or even represent the same domain from different points of view. Unlike ontology languages, work on languages to represent ontology mappings has not yet reached a state where a common understanding of the basic principles exists. In this paper we propose a formal comparison of existing mapping languages by translating them into distributed first order logic. This allows us to analyze underlying assumptions and differences in the interpretation of ontology mappings.|Luciano Serafini,Heiner Stuckenschmidt,Holger Wache","16263|IJCAI|2005|Dependency Calculus Reasoning in a General Point Relation Algebra|The point algebra is a fundamental formal calculus for spatial and temporal reasoning. We present a new generalization that meets all requirements to describe dependencies on networks. Applications range from traffic networks to medical diagnostics. We investigate satisfaction problems, tractable subclassses, embeddings into other relation algebras, and the associated interval algebra.|Marco Ragni,Alexander Scivos","16261|IJCAI|2005|Using Predictive Representations to Improve Generalization in Reinforcement Learning|The predictive representations hypothesis holds that particularly good generalization will result from representing the state of the world in terms of predictions about possible future experience. This hypothesis has been a central motivation behind recent research in, for example, PSRs and TD networks. In this paper we present the first explicit investigation of this hypothesis. We show in a reinforcement-learning example (a grid-world navigation task) that a predictive representation in tabular form can learn much faster than both the tabular explicit-state representation and a tabular history-based method.|Eddie J. Rafols,Mark B. Ring,Richard S. Sutton,Brian Tanner","16333|IJCAI|2005|A Simple Model to Generate Hard Satisfiable Instances|In this paper, we try to further demonstrate that the models of random CSP instances proposed by Xu and Li,   are of theoretical and practical interest. Indeed, these models, called RB and RD, present several nice features. First, it is quite easy to generate random instances of any arity since no particular structure has to be integrated, or property enforced, in such instances. Then, the existence of an asymptotic phase transition can be guaranteed while applying a limited restriction on domain size and on constraint tightness. In that case, a threshold point can be precisely located and all instances have the guarantee to be hard at the threshold, i.e., to have an exponential tree-resolution complexity. Next, a formal analysis shows that it is possible to generate forced satisfiable instances whose hardness is similar to unforced satisfiable ones. This analysis is supported by some representative results taken from an intensive experimentation that we have carried out, using complete and incomplete search methods.|Ke Xu,Fr√©d√©ric Boussemart,Fred Hemery,Christophe Lecoutre","16305|IJCAI|2005|Inter-Agent Communication A Cost-Reduction Approach Using an Autonomous Mobile Mailbox|In this paper, we consider a mobile mailbox communication scheme to reduce inter-agent communication costs. We employ a mailbox mobility strategy based on the ability of the mailbox to predict variations in inbound message rates and to migrate, if necessary, to a potentially better position in the network.|Armin Stranjak,Igor Cavrak,Mario Zagar","16079|IJCAI|2005|Towards More Intelligent Mobile Search|As the mobile Internet continues to grow there is an increasing need to provide users with effective search facilities. In this paper we argue that the standard Web search approach of providing snippet text alongside each result is not appropriate given the interface limitations of mobile devices. Instead we evaluate an alternative approach involving the use of related queries in place of snippet text for result gisting.|Karen Church,Mark T. Keane,Barry Smyth","16162|IJCAI|2005|Model minimization by linear PSR|Predictive state representation (PSR), proposed by Littman et al.,  Singh et al., , are a general representation for controlled dynamical systems. We present a sufficient condition under which a linear PSR compresses a POMDP representation.|Masoumeh T. Izadi,Doina Precup","16048|IJCAI|2005|Revision of Partially Ordered Information Axiomatization Semantics and Iteration|This paper deals with iterated revision of partially ordered information. The first part of this paper concerns the Katsuno-Mendelzon's postulates we first point out that these postulates are not fully satisfactory since only a class of partially ordered information can be revised. We then propose a suitable definition of faithful assignment, followed by a new set of postulates and a representation theorem. The second part of this paper investigates additional postulates dedicated to iterated revision operators of partially ordered information. Three extensions of well-known iterated belief revision operations for dealing with partially ordered information are briefly presented.|Salem Benferhat,Sylvain Lagrue,Odile Papini"],["16251|IJCAI|2005|Automated Composition of Web Services by Planning at the Knowledge Level|In this paper, we address the problem of the automated composition of web services by planning on their \"knowledge level\" models. We start from descriptions of web services in standard process modeling and execution languages, like BPELWS, and automatically translate them into a planning domain that models the interactions among services at the knowledge level. This allows us to avoid the explosion of the search space due to the usually large and possibly infinite ranges of data values that are exchanged among services, and thus to scale up the applicability of state-of-the-art techniques for the automated composition of web services. We present the theoretical framework, implement it, and provide an experimental evaluation that shows the practical advantage of our approach w.r.t. techniques that are not based on a knowledgelevel representation.|Marco Pistore,Annapaola Marconi,Piergiorgio Bertoli,Paolo Traverso","16213|IJCAI|2005|Active Cost-Sensitive Learning|For many classification tasks a large number of instances available for training are unlabeled and the cost associated with the labeling process varies over the input space. Meanwhile, virtually all these problems require classifiers that minimize a nonuniform loss function associated with the classification decisions (rather than the accuracy or number of errors). For example, to train pattern classification models for a network intrusion detection task, experts need to analyze network events and assign them labels. This can be a very costly procedure if the instances to be labeled are selected at random. In the meantime, the loss associated with mislabeling an intrusion is much higher than the loss associated with the opposite error (i.e., labeling a legal event as being an intrusion). As a result, to address these types of tasks, practitioners need tools that minimize the total cost computed as a sum of the cost of labeling and the loss associated with the decisions. This paper describes an approach for addressing this problem.|Dragos D. Margineantu","16303|IJCAI|2005|Beyond TFIDF Weighting for Text Categorization in the Vector Space Model|KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.|Pascal Soucy,Guy W. Mineau","16165|IJCAI|2005|Path-Planning for Autonomous Training on Robot Manipulators in Space|This paper describes the integration of robot path-planning and spatial task modeling into a software system that teaches the operation of a robot manipulator deployed on International Space Station (ISS). The system addresses the complexity of the manipulator, the limited direct view of the ISS exterior and the unpredictability of lighting conditions in the workspace. Robot path planning is used not for controlling the manipulator, but for automatically checking errors of a student learning to operate the manipulator and for automatically producing illustrations of good and bad motions in training.|Froduald Kabanza,Roger Nkambou,Khaled Belghith","16293|IJCAI|2005|Intimate Learning A Novel Approach for Combining Labelled and Unlabelled Data|This paper introduces a new bootstrapping method closely related to co-training and scoped-learning. The method is tested on a Web information extraction task of learning course names from web pages in which we use very few labelled items as seed data ( web pages) and combine with an unlabelled set ( web pages). The overall performance improved the precisionrecall from .%.% for a baseline EM-based method to .%.% for intimate learning.|Zhongmin Shi,Anoop Sarkar","16050|IJCAI|2005|Over-Subscription Planning with Numeric Goals|By relaxing the hard-goal constraints from classical planning and associating them with reward values, over-subscription planning allows users to concentrate on presenting what they want and leaves the task of deciding the best goals to achieve to the planner. In this paper, we extend the over-subscription planning problem and its limited goal specification to allow numeric goals with continuous utility values and goals with mixed hard and soft constraints. Together they considerably extend the modeling power of goal specification and allow the user to express goal constraints that were not possible before. To handle these new goal constraints, we extend the Sapaps planner's planning graph based techniques to help it choose the best beneficial subset of goals that can include both hard or soft logical and numeric goals. We also provide empirical results in several benchmark domains to demonstrate that our technique helps return quality plans.|J. Benton,Minh Binh Do,Subbarao Kambhampati","16340|IJCAI|2005|Question Classification by Structure Induction|In this article we introduce a new approach (and several implementations) to the task of question classification. The approach extracts structural information using machine learning techniques and the patterns found are used to classify the questions. The approach fits in between the machine learning and handcrafting of regular expressions (as it was done in the past) and combines the best of both classifiers can be generated automatically and the output can be investigated and manually optimised if needed.|Menno van Zaanen,Luiz Augusto Sangoi Pizzato,Diego Moll√°","16238|IJCAI|2005|Capturing and Reusing Case-Based Context for Image Retrieval|Like many other application areas, task-based domains that employ digital imagery are faced with the problem of information overload. Modeling the relationship between images and the tasks being performed is an important step in addressing this problem. We have developed an interactive approach for the capture and reuse of image context information that leverages a measure of a user's intentions with regard to tasks that they address. We analyze aspects of human-computer interaction information that enables us to infer why image contents are important in a particular context and how specific images have been used to address particular domain goals.|Dympna O'Sullivan,Eoin McLoughlin,Michela Bertolotto,David C. Wilson","16100|IJCAI|2005|A Probabilistic Model of Redundancy in Information Extraction|Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness This paper introduces a combinatorial \"balls-andurns\" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are  times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression.|Doug Downey,Oren Etzioni,Stephen Soderland","16085|IJCAI|2005|Learning to Understand Web Site Update Requests|Although Natural Language Processing (NLP) for requests for information has been well-studied, there has been little prior work on understanding requests to update information. In this paper, we propose an intelligent system that can process natural language website update requests semi-automatically. In particular, this system can analyze requests, posted via email, to update the factual content of individual tuples in a database-backed website. Users' messages are processed using a scheme decomposing their requests into a sequence of entity recognition and text classification tasks. Using a corpus generated by human-subject experiments, we experimentally evaluate the performance of this system, as well as its robustness in handling request types not seen in training, or user-specific language styles not seen in training.|William W. Cohen,Einat Minkov,Anthony Tomasic"],["16161|IJCAI|2005|State Abstraction Discovery from Irrelevant State Variables|Abstraction is a powerful form of domain knowledge that allows reinforcement-learning agents to cope with complex environments, but in most cases a human must supply this knowledge. In the absence of such prior knowledge or a given model, we propose an algorithm for the automatic discovery of state abstraction from policies learned in one domain for use in other domains that have similar structure. To this end, we introduce a novel condition for state abstraction in terms of the relevance of state features to optimal behavior, and we exhibit statistical methods that detect this condition robustly. Finally, we show how to apply temporal abstraction to benefit safely from even partial state abstraction in the presence of generalization error.|Nicholas K. Jong,Peter Stone","16069|IJCAI|2005|Fast convergence to satisfying distributions|We investigate an environment where self-interested agents have to find high-quality service resources. Agents have common knowledge about resources which are able to provide these services. The performance of resources is measured by the satisfaction obtained by agents using them. The performance of a resource depends on its intrinsic capability and its current load. We use a satisfying rather than an optimizing framework, where agents are content to receive service quality above a threshold. We introduce a formal framework to characterize the convergence of agents to a state where each agent is satisfied with the performance of the service it is currently using. We analyzed the convergence behavior of such a system and identified a mechanism to speed up convergence.|Teddy Candale,Sandip Sen","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16099|IJCAI|2005|Explaining preferences with argument positions|When deciding what to do agents must choose among alternative actions and different agents may make different choices according to what they wish to achieve in the light of their preferences and values. It cannot be assumed, however, that agents have a conscious understanding of their value preferences independent of the reasoning situations in which they engage. In this paper we consider an extension to a generic framework for reasoning about arguments justifying actions in terms of values in which the preferences amongst values emerge from the reasoning process.|Sylvie Doutre,Trevor J. M. Bench-Capon,Paul E. Dunne","16061|IJCAI|2005|Efficiency and envy-freeness in fair division of indivisible goods logical representation and complexity|We consider the problem of allocating fairly a set of indivisible goods among agents from the point of view of compact representation and computational complexity. We start by assuming that agents have dichotomous preferences expressed by propositional formulae. We express efficiency and envy-freeness in a logical setting, which reveals unexpected connections to nonmonotonic reasoning. Then we identify the complexity of determining whether there exists an efficient and envy-free allocation, for several notions of efficiency, when preferences are represented in a succinct way (as well as restrictions of this problem). We first study the problem under the assumption that preferences are dichotomous, and then in the general case.|Sylvain Bouveret,J√©r√¥me Lang","16039|IJCAI|2005|Achieving Allocatively-Efficient and Strongly Budget-Balanced Mechanisms in the Network Flow Domain for Bounded-Rational Agents|Vickrey-Clarke-Groves (VCG) mechanisms are a framework for finding a solution to a distributed optimization problem in systems of self-interested agents. VCG mechanisms have received wide attention in the AI community because they are efficient and strategy-proof a special case of the Groves family of mechanisms, VCG mechanisms are the only direct-revelation mechanisms that are allocatively efficient and strategy-proof. Unfortunately, they are only weakly budget-balanced. We consider self-interested agents in a network flow domain, and show that in this domain, it is possible to design a mechanism that is both allocatively-efficient and almost completely budget-balanced. This is done by choosing a mechanism that is not strategy-proof but rather strategy-resistant. Instead of using the VCG mechanism, we propose a mechanism in which finding a beneficial manipulation is an NP-complete problem, and the payments from the agents to the mechanism may be minimized as much as desired.|Yoram Bachrach,Jeffrey S. Rosenschein","16258|IJCAI|2005|PsychSim Modeling Theory of Mind with Decision-Theoretic Agents|Agent-based modeling of human social behavior is an increasingly important research area. A key factor in human social interaction is our beliefs about others, a theory of mind. Whether we believe a message depends not only on its content but also on our model of the communicator. How we act depends not only on the immediate effect but also on how we believe others will react. In this paper, we discuss PsychSim, an implemented multiagent-based simulation tool for modeling interactions and influence. While typical approaches to such modeling have used first-order logic, Psych-Sim agents have their own decision-theoretic model of the world, including beliefs about its environment and recursive models of other agents. Using these quantitative models of uncertainty and preferences, we have translated existing psychological theories into a decision-theoretic semantics that allow the agents to reason about degrees of believability in a novel way. We discuss PsychSim's underlying architecture and describe its application to a school violence scenario for illustration.|David V. Pynadath,Stacy Marsella","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White","16090|IJCAI|2005|Two-Sided Bandits and the Dating Market|We study the decision problems facing agents in repeated matching environments with learning, or two-sided bandit problems, and examine the dating market, in which men and women repeatedly go out on dates and learn about each other, as an example. We consider three natural matching mechanisms and empirically examine properties of these mechanisms, focusing on the asymptotic stability of the resulting matchings when the agents use a simple learning rule coupled with an -greedy exploration policy. Matchings tend to be more stable when agents are patient in two different ways -- if they are more likely to explore early or if they are more optimistic. However, the two forms of patience do not interact well in terms of increasing the probability of stable outcomes. We also define a notion of regret for the two-sided problem and study the distribution of regrets under the different matching mechanisms.|Sanmay Das,Emir Kamenica"],["16171|IJCAI|2005|Iterated Belief Revision Revised|The AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide generally accepted criteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulates alone, however, are too permissive They support operators by which all newly acquired information is canceled as soon as an agent learns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the DP postulates, and we show how to solve the problem by an additional postulate of independence. We give a representation theorem for this postulate and prove that it is compatible with AGM and DP.|Yi Jin,Michael Thielscher","16059|IJCAI|2005|Reconstructing an Agents Epistemic State from Observations|We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a \"reverse engineering\" approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that \"best explains\" the observation. Further considerations on this best-explaining model then allow inferences about the agent's epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.|Richard Booth,Alexander Nittka","16180|IJCAI|2005|Reasoning under inconsistency the forgotten connective|In many frameworks for reasoning under inconsistency, it is implicitly assumed that the formulae from the belief base are connected using a weak form of conjunction. When it is consistent, a belief base B  ..., n, where the i are propositional formulae, is logically equivalent to the base   ...  n. However, when it is not consistent, both bases typically lead to different conclusions. This illustrates the fact that the comma used in base B has to be considered as an additional, genuine connective, and not as a simple conjunction. In this work we define and investigate a propositional framework with such a \"comma connective\". We give it a semantics and show how it generalizes several approaches for reasoning from inconsistent beliefs.|S√©bastien Konieczny,J√©r√¥me Lang,Pierre Marquis","16154|IJCAI|2005|Iterated Belief Change A Transition System Approach|We use a transition system approach to reason about the evolution of an agent's beliefs as actions are executed. Some actions cause an agent to perform belief revision and some actions cause an agent to perform belief update, but the interaction between revision and update can be non-elementary. We present a set of basic postulates describing the interaction of revision and update, and we introduce a new belief evolution operator that gives a plausible interpretation to alternating sequences of revisions and updates.|Aaron Hunter,James P. Delgrande","16038|IJCAI|2005|Propagating Logical Combinations of Constraints|Many constraint toolkits provide logical connectives like disjunction, negation and implication. These permit complex constraint expressions to be built from primitive constraints. However, the propagation of such complex constraint expressions is typically limited. We therefore present a simple and light weight method for propagating complex constraint expressions. We provide a precise characterization of when this method enforces generalized arc-consistency. In addition, we demonstrate that with our method many different global constraints can be easily implemented.|Fahiem Bacchus,Toby Walsh","16291|IJCAI|2005|Goal Change|Although there has been much discussion of belief change (e.g., Grdenfors,  Spohn, ), goal change has not received much attention. In this paper, we propose a method for goal change in the framework of Reiter's  theory of action in the situation calculus McCarthy and Hayes,  Levesque et al., , and investigate its properties. We extend the framework developed by Shapiro et al.  and Shapiro and Lesprance , where goals and goal expansion were modelled, but goal contraction was not.|Steven Shapiro,Yves Lesp√©rance,Hector J. Levesque","16240|IJCAI|2005|Inverse Resolution as Belief Change|Belief change is concerned with modelling the way in which a rational reasoner maintains its beliefs as it acquires new information. Of particular interest is the way in which new beliefs are acquired and determined and old beliefs are retained or discarded. A parallel can be drawn to symbolic machine learning approaches where examples to be categorised are presented to the learning system and a theory is subsequently derived, usually over a number of iterations. It is therefore not surprising that the term 'theory revision' is used to describe this process Ourston and Mooney, . Viewing a machine learning system as a rational reasoner allows us to begin seeing these seemingly disparate mechanisms in a similar light. In this paper we are concerned with characterising the well known inverse resolution operations Muggleton,   (and more recently, inverse entailment Muggleton, ) as AGM-style belief change operations. In particular, our account is based on the abductive expansion operation Pagnucco et al.,  Pagnucco,  and characterised by using the notion of epistemic entrenchment Grdenfors and Makinson,  extended for this operation. This work provides a basis for reconciling work in symbolic machine learning and belief revision. Moreover, it allows machine learning techniques to be understood as forms of nonmonotonic reasoning.|Maurice Pagnucco,David Rajaratnam","16188|IJCAI|2005|A Unified Framework of Propositional Knowledge Base Revision and Update Based on State Transition Models|Belief revision and belief update are two of the most basic types of belief change operations. We need to select either revision or update when we accept new information into the current belief, however, such decision making has not been considered. In this paper, we propose a unified framework of revision and update based on state transition models that enable us to do such decision making. This framework provides a hybrid operation of revision and update, called acceptance.|Yasuo Kudo,Tetsuya Murai","16294|IJCAI|2005|First-Order Logical Filtering|Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond immediate intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulae. We sidestep previous discouraging results, and show that our algorithms are exact in many cases of interest. These algorithms accept belief states in full FOL, which allows natural representation with explicit references to unidentified objects, and partially known relationships. Our algorithms keep the encoding compact for important classes of actions, such as STRIPS actions. These results apply to most expressive modeling languages, such as partial databases and belief revision in FOL.|Afsaneh Shirazi,Eyal Amir","16048|IJCAI|2005|Revision of Partially Ordered Information Axiomatization Semantics and Iteration|This paper deals with iterated revision of partially ordered information. The first part of this paper concerns the Katsuno-Mendelzon's postulates we first point out that these postulates are not fully satisfactory since only a class of partially ordered information can be revised. We then propose a suitable definition of faithful assignment, followed by a new set of postulates and a representation theorem. The second part of this paper investigates additional postulates dedicated to iterated revision operators of partially ordered information. Three extensions of well-known iterated belief revision operations for dealing with partially ordered information are briefly presented.|Salem Benferhat,Sylvain Lagrue,Odile Papini"],["16282|IJCAI|2005|Solving Checkers|AI has had notable success in building high-performance game-playing programs to complete against the best human players. However, the availability of fast and plentiful machines with large memories and disks creates the possibility of solving a game. This has been done before for simple or relatively small games. In this paper, we present new ideas and algorithms for solving the game of checkers. Checkers is a popular game of skill with a search space of  possible positions. This paper reports on our first result. One of the most challenging checkers openings has been solved-the White Doctor opening is a draw. Solving roughly  more openings will result in the game-theoretic value of checkers being determined.|Jonathan Schaeffer,Yngvi Bj√∂rnsson,Neil Burch,Akihiro Kishimoto,Martin M√ºller 0003,Robert Lake,Paul Lu,Steve Sutphen","16315|IJCAI|2005|On the Interaction between Inverse Features and Path-functional Dependencies in Description Logics|We investigate how inverse features can be added to a boolean complete description logic with path-functional dependencies in ways that avoid undecidability of the associated logical implication problem. In particular, we present two conditions that ensure the problem remains EXPTIME-complete. The first is syntactic in nature and limits the form that dependencies may have in argument terminologies. The second is a coherence condition on terminologies that is sufficiently weak to allow the transfer of relational and emerging object-oriented normalization techniques.|David Toman,Grant E. Weddell","16137|IJCAI|2005|Shallow Semantics for Relation Extraction|This paper presents a new method for extracting meaningful relations from unstructured natural language sources. The method is based on information made available by shallow semantic parsers. Semantic information was used () to enhance a dependency tree kernel and () to build semantic dependency structures used for enhanced relation extraction for several semantic classifiers. In our experiments the quality of the extracted relations surpassed the results of kernel-based models employing only semantic class information.|Sanda M. Harabagiu,Cosmin Adrian Bejan,Paul Morarescu","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","16256|IJCAI|2005|The Necessity of Syntactic Parsing for Semantic Role Labeling|We provide an experimental study of the role of syntactic parsing in semantic role labeling. Our conclusions demonstrate that syntactic parse information is clearly most relevant in the very first stage - the pruning stage. In addition, the quality of the pruning stage cannot be determined solely based on its recall and precision. Instead it depends on the characteristics of the output candidates that make downstream problems easier or harder. Motivated by this observation, we suggest an effective and simple approach of combining different semantic role labeling systems through joint inference, which significantly improves the performance.|Vasin Punyakanok,Dan Roth,Wen-tau Yih","16126|IJCAI|2005|Generalized Amazons is PSPACE-Complete|Amazons is a perfect information board game with simple rules and large branching factors. Two players alternately move chess queen-like pieces and block squares on a  playing field. The player who makes the last move wins. Amazons endgames usually decompose into independent subgames. Therefore, the game is a natural testbed for combinatorial game theory. It was known that determining the winner of simple generalized Amazons endgames is NP-equivalent. This paper presents two proofs for the PSPACE-completeness of the generalized version of the full game.|Timothy Furtak,Masashi Kiyomi,Takeaki Uno,Michael Buro","16324|IJCAI|2005|Learning Payoff Functions in Infinite Games|We consider a class of games with real-valued strategies and payoff information available only in the form of data from a given sample of strategy profiles. Solving such games with respect to the underlying strategy space requires generalizing from the data to a complete payoff-function representation. We address payoff-function learning as a standard regression problem, with provision for capturing known structure (symmetry) in the multiagent environment. To measure learning performance, we consider the relative utility of prescribed strategies, rather than the accuracy of payoff functions per se. We demonstrate our approach and evaluate its effectiveness on two examples a two-player version of the first-price sealed-bid auction (with known analytical form), and a five-player marketbased scheduling game (with no known solution).|Yevgeniy Vorobeychik,Michael P. Wellman,Satinder P. Singh","16311|IJCAI|2005|Choosing between heuristics and strategies an enhanced model for decision-making|Often an agent that has to solve a problem must choose which heuristic or strategy will help it the most in achieving its objectives. Sometimes the agent wishes to obtain additional units of information on the possible heuristics and strategies in order to choose between them, but it may be costly. As a result, the agent's goal is to acquire enough units of information in order to make a decision while incurring minimal cost. We focus on situations where the agent must decide in advance how many units it would like to obtain. We present an algorithm for choosing between two options, and then formulate three methods for the general case where there are k   options to choose from. We investigate the -option algorithm and the general k-option methods effectiveness in two domains the -SAT domain, and the CT computer game. In both domains we present the experimental performance of our models. Results will show that applying the -option algorithm is beneficial and provides the agent a substantial gain. In addition, applying the k-option method in the domains investigated results in a moderate gain.|Shavit Talman,Rotem Toister,Sarit Kraus","16048|IJCAI|2005|Revision of Partially Ordered Information Axiomatization Semantics and Iteration|This paper deals with iterated revision of partially ordered information. The first part of this paper concerns the Katsuno-Mendelzon's postulates we first point out that these postulates are not fully satisfactory since only a class of partially ordered information can be revised. We then propose a suitable definition of faithful assignment, followed by a new set of postulates and a representation theorem. The second part of this paper investigates additional postulates dedicated to iterated revision operators of partially ordered information. Three extensions of well-known iterated belief revision operations for dealing with partially ordered information are briefly presented.|Salem Benferhat,Sylvain Lagrue,Odile Papini","16294|IJCAI|2005|First-Order Logical Filtering|Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond immediate intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulae. We sidestep previous discouraging results, and show that our algorithms are exact in many cases of interest. These algorithms accept belief states in full FOL, which allows natural representation with explicit references to unidentified objects, and partially known relationships. Our algorithms keep the encoding compact for important classes of actions, such as STRIPS actions. These results apply to most expressive modeling languages, such as partial databases and belief revision in FOL.|Afsaneh Shirazi,Eyal Amir"],["16211|IJCAI|2005|Discovering Classes of Strongly Equivalent Logic Programs|In this paper we apply computer-aided theorem discovery technique to discover theorems about strongly equivalent logic programs under the answer set semantics. Our discovered theorems capture new classes of strongly equivalent logic programs that can lead to new program simplification rules that preserve strong equivalence. Specifically, with the help of computers, we discovered exact conditions that capture the strong equivalence between a rule and the empty set, between two rules, between two rules and one of the two rules, between two rules and another rule, and between three rules and two of the three rules.|Fangzhen Lin,Yin Chen","16235|IJCAI|2005|Possibilistic Stable Models|In this work, we define a new framework in order to improve the knowledge representation power of Answer Set Programming paradigm. Our proposal is to use notions from possibility theory to extend the stable model semantics by taking into account a certainty level, expressed in terms of necessity measure, on each rule of a normal logic program. First of all, we introduce possibilistic definite logic programs and show how to compute the conclusions of such programs both in syntactic and semantic ways. The syntactic handling is done by help of a fix-point operator, the semantic part relies on a possibility distribution on all sets of atoms and we show that the two approaches are equivalent. In a second part, we define what is a possibilistic stable model for a normal logic program, with default negation. Again, we define a possibility distribution allowing to determine the stable models.|Pascal Nicolas,Laurent Garcia,Igor St√©phan","16281|IJCAI|2005|Generative Modeling with Failure in PRISM|PRISM is a logic-based Turing-complete symbolic-statistical modeling language with a built-in parameter learning routine. In this paper,we enhance the modeling power of PRISM by allowing general PRISM programs to fail in the generation process of observable events. Introducing failure extends the class of definable distributions but needs a generalization of the semantics of PRISM programs. We propose a three valued probabilistic semantics and show how failure enables us to pursue constraint-based modeling of complex statistical phenomena.|Taisuke Sato,Yoshitaka Kameya,Neng-Fa Zhou","16290|IJCAI|2005|Coping with exceptions in multiclass ILP problems using possibilistic logic|The handling of exceptions in multiclass problems is a tricky issue in inductive logic programming (ILP). In this paper we propose a new formalization of the ILP problem which accounts for default reasoning, and is encoded with first-order possibilistic logic. We show that this formalization allows us to handle rules with exceptions, and to prevent an example to be classified in more than one class. The possibilistic logic view of ILP problem, can be easily handled at the algorithmic level as an optimization problem.|Mathieu Serrurier,Henri Prade","16103|IJCAI|2005|A Uniform Integration of Higher-Order Reasoning and External Evaluations in Answer-Set Programming|We introduce HEX programs, which are nonmonotonic logic programs admitting higher-order atoms as well as external atoms, and we extend the well-known answer-set semantics to this class of programs. Higher-order features are widely acknowledged as useful for performing meta-reasoning, among other tasks. Furthermore, the possibility to exchange knowledge with external sources in a fully declarative framework such as Answer-Set Programming (ASP) is nowadays important, in particular in view of applications in the Semantic Web area. Through external atoms, HEX programs can model some important extensions to ASP, and are a useful KR tool for expressing various applications. Finally, complexity and implementation issues for a preliminary prototype are discussed.|Thomas Eiter,Giovambattista Ianni,Roman Schindlauer,Hans Tompits","16270|IJCAI|2005|Incorporating a folding rule into inductive logic programming|Many inductive logic programming systems have operators reorganizing the program so far inferred, such as the intra-construction operator of CIGOL. At the same time, there is a similar reorganizing operator, called the \"folding rule,\" developed in program transformation. We argue that there are advantages in using an extended folding rule as a reorganizing operator for inductive-inference systems. Such an extended folding rule allows an inductive-inference system not only to recognize already-learned concepts, but also to increase the efficiently of execution of inferred programs.|David A. Rosenblueth","16343|IJCAI|2005|Solving Logic Program Conflict through Strong and Weak Forgettings|We consider how to forget a set of atoms in a logic program. Intuitively, when a set of atoms is forgotten from a logic program, all atoms in the set should be eliminated from this program in some way, and other atoms related to them in the program might also be affected. We define notions of strong and weak forgettings in logic programs to capture such intuition and reveal their close connections to the notion of forgetting in classical propositional theories. Based on these notions, we then propose a framework for conflict solving in logic programs, which is general enough to represent many important conflict solving problems. We also study some essential semantic and computational properties in relation to strong and weak forgettings and conflict solving in our framework.|Yan Zhang,Norman Y. Foo,Kewen Wang","16316|IJCAI|2005|Ordering Heuristics for Description Logic Reasoning|We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.|Dmitry Tsarkov,Ian Horrocks","16160|IJCAI|2005|Equivalence in Abductive Logic|We consider the problem of identifying equivalence of two knowledge bases which are capable of abductive reasoning. Here, a knowledge base is written in either first-order logic or nonmonotonic logic programming. In this work, we will give two definitions of abductive equivalence. The first one, explainable equivalence, requires that two abductive programs have the same explainability for any observation. Another one, explanatory equivalence, guarantees that any observation has exactly the same explanations in each abductive framework. Explanatory equivalence is a stronger notion than explainable equivalence. In first-order abduction, explainable equivalence can be verified by the notion of extensional equivalence in default theories. In nonmonotonic logic programs, explanatory equivalence can be checked by means of the notion of relative strong equivalence. We also show the complexity results for abductive equivalence.|Katsumi Inoue,Chiaki Sakama","16108|IJCAI|2005|Strong Equivalence for Logic Programs with Preferences|Recently, strong equivalence for Answer Set Programming has been studied intensively, and was shown to be beneficial for modular programming and automated optimization. In this paper we define the novel notion of strong equivalence for logic programs with preferences. Based on this definition we give, for several semantics for preference handling, necessary and sufficient conditions for programs to be strongly equivalent. These results provide a clear picture of the relationship of these semantics with respect to strong equivalence, which differs considerably from their relationship with respect to answer sets. Finally, based on these results, we present for the first time simplification methods for logic programs with preferences.|Wolfgang Faber,Kathrin Konczak"],["16245|IJCAI|2005|Sophia A novel approach for Textual Case-based Reasoning|In this paper we present a novel methodology for textual case-based reasoning. This technique is unique in that it automatically discovers case and similarity knowledge, is language independent, is scaleable and facilitates semantic similarity between cases to be carried out inherently without the need for domain knowledge. In addition it provides an insight into the thematical content of the case-base as a whole, which enables users to better structure queries. We present an analysis of the competency of the system by assessing the quality of the similarity knowledge discovered and show how it is ideally suited to case-based retrieval (querying by example).|David W. Patterson,Niall Rooney,Vladimir Dobrynin,Mykola Galushka","16086|IJCAI|2005|Feature Selection Based on the Shapley Value|We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.|Shay Cohen,Eytan Ruppin,Gideon Dror","16237|IJCAI|2005|Trust No One Evaluating Trust-based Filtering for Recommenders|To be successful recommender systems must gain the trust of users. To do this they must demonstrate their ability to make reliable predictions. We argue that collaborative filtering recommendation algorithms can benefit from explicit models of trust to inform their predictions. We present one such model of trust along with a cost-benefit analysis that focuses on the classical trade-off that exists between recommendation coverage and prediction accuracy.|John O'Donovan,Barry Smyth","16046|IJCAI|2005|A language for functional interpretation of model based simulation|Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.|Jonathan Bell,Neal Snooke,Chris Price","16339|IJCAI|2005|Automation Intelligence for the Smart Environment|Scaling AI algorithms to large problems requires that these algorithms work together to harness their respective strengths. We introduce a method of automatically constructing HHMMs using the output of a sequential data-mining algorithm and sequential prediction algorithm. We present the theory of this technique and demonstrate results using the MavHome intelligent environment.|G. Michael Youngblood,Edwin O. Heierman III,Lawrence B. Holder,Diane J. Cook","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","16316|IJCAI|2005|Ordering Heuristics for Description Logic Reasoning|We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.|Dmitry Tsarkov,Ian Horrocks","16044|IJCAI|2005|Proactive Algorithms for Scheduling with Probabilistic Durations|Proactive scheduling seeks to generate high quality solutions despite execution time uncertainty. Building on work in Beck and Wilson, , we conduct an empirical study of a number of algorithms for the job shop scheduling problem with probabilistic durations. The main contributions of this paper are the introduction and empirical analysis of a novel constraint-based search technique that can be applied beyond probabilistic scheduling problems, the introduction and empirical analysis of a number of deterministic filtering algorithms for probabilistic job shop scheduling, and the identification of a number of problem characteristics that contribute to algorithm performance.|J. Christopher Beck,Nic Wilson","16332|IJCAI|2005|Mining Spatial Object Associations for Scientific Data|In this paper, we present efficient algorithms to discover spatial associations among features extracted from scientific datasets. In contrast to previous work in this area, features are modeled as geometric objects rather than points. We define multiple distance metrics that take into account objects' extent. We have developed algorithms to discover two types of spatial association patterns in scientific data. We present experimental results to demonstrate the efficacy of our approach on real datasets drawn from the bioinformatic domain. We also highlight the importance of the discovered patterns by integrating the underlying domain knowledge.|Hui Yang,Srinivasan Parthasarathy,Sameep Mehta","16280|IJCAI|2005|Supervaluation Semantics for an Inland Water Feature Ontology|This paper describes an ontology for inland water features built using formal concept analysis and supervaluation semantics. The first is used to generate a complete lattice of the water domain, whereas supervaluation semantics is used to model the variability of the concepts in terms of threshold parameters. We also present an algorithm for a mechanism of individuation and classification of water features, from snapshots of river networks, according to the proposed ontology.|Paulo Santos,Brandon Bennett,Georgios Sakellariou"]]},"title":{"entropy":0,"topics":"","ranking":""}}