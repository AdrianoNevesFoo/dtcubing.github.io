{"abstract":{"entropy":6.610568375614429,"topics":["genetic algorithms, evolutionary algorithms, algorithms, particle swarm, optimization problem, optimization algorithms, optimization, evolutionary computation, algorithms problem, present algorithms, estimation distribution, genetic programming, algorithms search, evolutionary optimization, swarm optimization, solving problem, particle optimization, particle pso, swarm pso, multi-objective optimization","genetic programming, neural networks, markov decision, markov processes, partially observable, decision processes, knowledge base, building blocks, bayesian networks, spanning tree, consider problem, semantic web, present approach, description logic, widely used, cartesian programming, job shop, cartesian genetic, observable markov, decision making","machine learning, classifier systems, learning, learning systems, learning classifier, reinforcement learning, data mining, support vector, learning problem, data, constraint satisfaction, classifier xcs, time series, addresses problem, present learning, probabilistic model, xcs systems, address problem, learning algorithms, scheduling problem","artificial intelligence, systems, recent years, real world, play role, agents, immune systems, mobile robot, computer game, artificial immune, natural language, become popular, agents environment, multi-agent systems, resource allocation, artificial, computer vision, autonomous agents, becoming increasingly, robot","evolutionary computation, evolutionary algorithms, algorithms based, present algorithms, present evolutionary, present novel, present approach, evolutionary approach, algorithms use, novel algorithms, present based, paper algorithms, evolutionary multiobjective, algorithms applied, evolutionary emo, evolutionary applied, paper novel, novel approach, design algorithms, paper evolutionary","genetic algorithms, evolutionary algorithms, genetic programming, genetic gas, algorithms gas, present algorithms, genetic problem, algorithms problem, well known, paper algorithms, hybrid algorithms, genetic population, algorithms population, present genetic, population size, algorithms search, paper genetic, describe algorithms, algorithms model, performance algorithms","knowledge base, description logic, nonmonotonic logic, horn transaction, case-based reasoning, heuristic planning, planning actions, describe approach, knowledge, reasoning logic, present approach, reasoning based, reasoning, reasoning approach, modal logic, logic approach, approach based, logic, fuzzy logic, first-order logic","genetic programming, building blocks, problem programming, cartesian programming, cartesian genetic, programming approach, describe programming, embedded cartesian, program genetic, hyper-heuristics heuristic, wide range, logic programming, programming program, logic program, present programming, search heuristic, automatic programming, form programming, based programming, cellular automata","address problem, present model, probabilistic model, present approach, model, systems model, present novel, problem detection, scene understanding, situations calculus, problem model, instances problem, present based, present systems, lower bound, moving objects, detection systems, intrusion detection, present, predictive model","data mining, support vector, learning data, data, vector machine, problem given, problem data, machine data, support machine, machine learning, data information, present data, algorithms data, transfer improve, transfer knowledge, feature selection, learning techniques, statistical learning, vector svm, support svm","real world, autonomous agents, resource allocation, autonomous robot, systems need, agents, autonomous systems, systems complex, agents goal, software systems, quality software, task agents, software testing, mobile robot, agents actions, systems create, multi-agent agents, world applications, task allocation, teaching students","recent years, agents coalitions, negotiation agents, self-interested agents, dynamic environment, recent advances, systems developed, recent, agents environment, recent systems, research systems, recent development, recent research, automated systems, web technologies, systems robot, formation coalitions, systems allows, challenge web, robot"],"ranking":[["66621|AAAI|2010|Goal-Driven Autonomy in a Navy Strategy Simulation|This paper introduces a novel optimization algorithm, group search optimization (GSO) algorithm and its implementation method is presented in detail. The GSO is used to investigate the planar and space truss structures with continuous variables and is tested by two truss optimization problems. The optimization results are compared with that of the particle swarm optimization (PSO) algorithm, the particle swarm optimization with passive congregation (PSOPC) and the heuristic particle swarm optimizer (HPSO) algorithm. Results from the two tested cases illustrate the ability of the GSO algorithm to find the optimal results, which are better than that of the PSO and PSOPC, while are at the same level of that of HPSO optimization method. Meanwhile, the results also show that the GSO algorithm maintains a preferable convergence accuracy among these four algorithms.|Matthew Molineaux,Matthew Klenk,David W. Aha","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","58032|GECCO|2007|Applying particle swarm optimization to software testing|Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with  small artificial test objects and  more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.|Andreas Windisch,Stefan Wappler,Joachim Wegener","59071|GECCO|2010|An parallel particle swarm optimization approach for multiobjective optimization problems|This paper proposes a parallel particle swarm optimization (PPSO) to solve the multiobjective optimization problems (MOP). PPSO makes the use of the parallel characteristic of the PSO algorithm to deal with the multiple objectives issue of the MOP. PPSO uses as many swarms as the number of the objectives in the MOP and lets each swarm optimize only one of the objectives. These swarms work in parallel and each swarm can use a standard PSO or any other improved PSO variants to solve a single objective problem. PPSO has advantages on the following two aspects. First, as each swarm focus on optimizing only one objective, PPSO can avoid the difficulty of fitness assignment because the particles can be evaluated like in the single objective optimization problem. Second, as different swarms optimize different objectives, PPSO can maintain the population diversity to make a throughout search along the whole Pareto front to obtain nondominated solutions as many as possible. The performance of PPSO is tested on a set of benchmark problems complicated Pareto sets in CEC. The experimental results compared with those obtained by the state-of-the-art algorithms demonstrate the effectiveness and efficiency of PPSO, showing the good performance of PPSO in solving the MOP with complicated Pareto sets.|Zhi-hui Zhan,Jun Zhang","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","58967|GECCO|2010|Development of efficient particle swarm optimizers by using concepts from evolutionary algorithms|Particle swarm optimization (PSO) has been in practice for more than  years now and has gained wide popularity in various optimization tasks. In the context to single objective optimization, this paper studies two aspects of PSO (i) its ability to approach an 'optimal basin', and (ii) to find the optimum with high precision once it enters the region. of interest. We test standard PSO algorithms and discover their inability in handling both aspects efficiently. To address these issues with PSO, we propose an evolutionary algorithm (EA) which is algorithmically similar to PSO, and then borrow different EA-specific operators to enhance the PSO's performance. Our final proposed PSO contains a parent-centric recombination operator instead of usual particle update rule, but maintains PSO's individualistic trait and has a demonstrated performance comparable to a well-known GA (and outperforms the GA in some occasions). Moreover, the modified PSO algorithm is found to scale up to solve as large as -variable problems. This study emphasizes the need for similar such studies in establishing an equivalence between various geneticevolutionary and other bio-inspired algorithms, a process that may lead us to better understand the scope and usefulness of various operators associated with each algorithm.|Kalyanmoy Deb,Nikhil Padhye","58731|GECCO|2009|Using a distance metric to guide PSO algorithms for many-objective optimization|In this paper we propose to use a distance metric based on user-preferences to efficiently find solutions for many-objective problems. We use a particle swarm optimization (PSO) algorithm as a baseline to demonstrate the usefulness of this distance metric, though the metric can be used in conjunction with any evolutionary multi-objective (EMO) algorithm. Existing user-preference based EMO algorithms rely on the use of dominance comparisons to explore the search-space. Unfortunately, this is ineffective and computationally expensive for many-objective problems. In the proposed distance metric based PSO, particles update their positions and velocities according to their closeness to preferred regions in the objective-space, as specified by the decision maker. The proposed distance metric allows an EMO algorithm's search to be more effective especially for many-objective problems, and to be more focused on the preferred regions, saving substantial computational cost. We demonstrate how to use a distance metric with two user-preference based PSO algorithms, which implement the reference point and light beam search methods. These algorithms are compared to a user-preference based PSO algorithm relying on the conventional dominance comparisons. Experimental results suggest that the distance metric based algorithms are more effective and efficient especially for difficult many-objective problems.|Upali K. Wickramasinghe,Xiaodong Li","58287|GECCO|2008|Runtime analysis of binary PSO|We investigate the runtime of the Binary Particle Swarm Optimization (PSO) algorithm introduced by Kennedy and Eberhart (). The Binary PSO maintains a global best solution and a swarm of particles. Each particle consists of a current position, an own best position and a velocity vector used in a probabilistic process to update the particle's position. We present lower bounds for swarms of polynomial size. To prove upper bounds, we transfer a fitness-level argument well-established for evolutionary algorithms (EAs) to PSO. This method is applied to estimate the expected runtime on the class of unimodal functions. A simple variant of the Binary PSO is considered in more detail. The -PSO only maintains one particle, hence own best and global best solutions coincide. Despite its simplicity, the -PSO is surprisingly efficient. A detailed analysis for the function OneMax shows that the -PSO is competitive to EAs.|Dirk Sudholt,Carsten Witt","58697|GECCO|2009|Estimation of particle swarm distribution algorithms bringing together the strengths of PSO and EDAs|This paper presents a framework of estimation of particle swarm distribution algorithms (EPSDAs). The aim lies in effectively combining particle swarm optimization (PSO) with estimation of distribution algorithms (EDAs) without losing on their unique features. To exhibit its practicability, an extended compact particle swarm optimization (EcPSO) is developed along the lines of the suggested framework. Empirical results have adduced grounds for its effectiveness.|Chang Wook Ahn,Hyun-Tae Kim","58990|GECCO|2010|Biogeography-based optimization with blended migration for constrained optimization problems|Biogeography-based optimization (BBO) is a new evolutionary algorithm based on the science of biogeography. We propose two extensions to BBO. First, we propose blended migration. Second, we modify BBO to solve constrained optimization problems. The constrained BBO algorithm is compared with solutions based on a genetic algorithm (GA) and particle swarm optimization (PSO). Numerical results indicate that BBO generally performs better than GA and PSO in handling constrained single-objective optimization problems.|Haiping Ma,Dan Simon"],["65917|AAAI|2006|Compact Convex Upper Bound Iteration for Approximate POMDP Planning|Partially observable Markov decision processes (POMDPs) are an intuitive and general way to model sequential decision making problems under uncertainty. Unfortunately, even approximate planning in POMDPs is known to be hard, and developing heuristic planners that can deliver reasonable results in practice has proved to be a significant challenge. In this paper, we present a new approach to approximate value-iteration for POMDP planning that is based on quadratic rather than piecewise linear function approximators. Specifically, we approximate the optimal value function by a convex upper bound composed of a fixed number of quadratics, and optimize it at each stage by semidefinite programming. We demonstrate that our approach can achieve competitive approximation quality to current techniques while still maintaining a bounded size representation of the function approximator. Moreover, an upper bound on the optimal value function can be preserved if required. Overall, the technique requires computation time and space that is only linear in the number of iterations (horizon time).|Tao Wang,Pascal Poupart,Michael H. Bowling,Dale Schuurmans","65199|AAAI|2004|Stochastic Local Search for POMDP Controllers|The search for finite-state controllers for partially observable Markov decision processes (POMDPs) is often based on approaches like gradient ascent, attractive because of their relatively low computational cost. In this paper, we illustrate a basic problem with gradient-based methods applied to POMDPs, where the sequential nature of the decision problem is at issue, and propose a new stochastic local search method as an alternative. The heuristics used in our procedure mimic the sequential reasoning inherent in optimal dynamic programming (DP) approaches. We show that our algorithm consistently finds higher quality controllers than gradient ascent, and is competitive with (and, for some problems, superior to) other state-of-the-art controller and DP-based algorithms on large-scale POMDPs.|Darius Braziunas,Craig Boutilier","66217|AAAI|2007|Purely Epistemic Markov Decision Processes|Planning under uncertainty involves two distinct sources of uncertainty uncertainty about the effects of actions and uncertainty about the current state of the world. The most widely developed model that deals with both sources of uncertainty is that of Partially Observable Markov Decision Processes (POMDPs). Simplifying POMDPs by getting rid of the second source of uncertainty leads to the well-known framework of fully observable MDPs. Getting rid of the first source of uncertainty leads to a less widely studied framework, namely, decision processes where actions cannot change the state of the world and are only intended to bring some information about the (static) state of the world. Such \"purely epistemic\" processes are very relevant, since many practical problems (such as diagnosis, database querying, or preference elicitation) fall into this class. However, it is not known whether this specific restriction of POMDP is computationally simpler than POMDPs. In this paper we establish several complexity results for purely epistemic MDPs (EMDPs). We first show that short-horizon policy existence in EMDPs is PSPACE-complete. Then we focus on the specific case of EMDPs with reliable observations and show that in this case, policy existence is \"only\" NP-complete however, we show that this problem cannot be approximated with a bounded performance ratio by a polynomial-time algorithm.|R√©gis Sabbadin,J√©r√¥me Lang,Nasolo Ravoanjanahry","65906|AAAI|2006|Point-based Dynamic Programming for DEC-POMDPs|We introduce point-based dynamic programming (DP) for decentralized partially observable Markov decision processes (DEC-POMDPs), a new discrete DP algorithm for planning strategies for cooperative multi-agent systems. Our approach makes a connection between optimal DP algorithms for partially observable stochastic games, and point-based approximations for single-agent POMDPs. We show for the first time how relevant multi-agent belief states can be computed. Building on this insight, we then show how the linear programming part in current multi-agent DP algorithms can be avoided, and how multi-agent DP can thus be applied to solve larger problems. We derive both an optimal and an approximated version of our algorithm, and we show its efficiency on test examples from the literature.|Daniel Szer,Fran√ßois Charpillet","66459|AAAI|2008|A Variance Analysis for POMDP Policy Evaluation|Partially Observable Markov Decision Processes have been studied widely as a model for decision making under uncertainty, and a number of methods have been developed to find the solutions for such processes. Such studies often involve calculation of the value function of a specific policy, given a model of the transition and observation probabilities, and the reward. These models can be learned using labeled samples of on-policy trajectories. However, when using empirical models, some bias and variance terms are introduced into the value function as a result of imperfect models. In this paper, we propose a method for estimating the bias and variance of the value function in terms of the statistics of the empirical transition and observation model. Such error terms can be used to meaningfully compare the value of different policies. This is an important result for sequential decision-making, since it will allow us to provide more formal guarantees about the quality of the policies we implement. To evaluate the precision of the proposed method, we provide supporting experiments on problems from the field of robotics and medical decision making.|Mahdi Milani Fard,Joelle Pineau,Peng Sun","66064|AAAI|2007|Optimizing Anthrax Outbreak Detection Using Reinforcement Learning|The potentially catastrophic impact of a bioterrorist attack makes developing effective detection methods essential for public health. In the case of anthrax attack, a delay of hours in making a right decision can lead to hundreds of lives lost. Current detection methods trade off reliability of alarms for early detection of outbreaks. The performance of these methods can be improved by modem disease-specific modeling techniques which take into account the potential costs and effects of an attack to provide optimal warnings. We study this optimization problem in the reinforcement learning framework. The key contribution of this paper is to apply Partially Observable Markov Decision Processes (POMDPs) on outbreak detection mechanism for improving alarm function in anthrax outbreak detection. Our approach relies on estimating the future benefit of true alarms and the costs of false alarms and using these quantities to identify an optimal decision. We present empirical evidence illustrating that the performance of detection methods with respect to sensitivity and timeliness is improved significantly by utilizing POMDPs.|Masoumeh T. Izadi,David L. Buckeridge","66277|AAAI|2008|Exploiting Symmetries in POMDPs for Point-Based Algorithms|We extend the model minimization technique for partially observable Markov decision processes (POMDPs) to handle symmetries in the joint space of states, actions, and observations. The POMDP symmetry we define in this paper cannot be handled by the model minimization techniques previously published in the literature. We formulate the problem of finding the symmetries as a graph automorphism (GA) problem, and although not yet known to be tractable, we experimentally show that the sparseness of the graph representing the POMDP allows us to quickly find symmetries. We show how the symmetries in POMDPs can be exploited for speeding up point-based algorithms. We experimentally demonstrate the effectiveness of our approach.|Kee-Eung Kim","65422|AAAI|2005|Efficient Maximization in Solving POMDPs|We present a simple, yet effective improvement to the dynamic programming algorithm for solving partially observable Markov decision processes. The technique targets the vector pruning operation during the maximization step, a key source of complexity in POMDP algorithms. We identify two types of structures in the belief space and exploit them to reduce significantly the number of constraints in the linear programs used for pruning. The benefits of the new technique are evaluated both analytically and experimentally, showing that it can lead to significant performance improvement. The results open up new research opportunities to enhance the performance and scalability of several POMDP algorithms.|Zhengzhu Feng,Shlomo Zilberstein","65617|AAAI|2005|Planning and Execution with Phase Transitions|We consider a special type of continuous-time Markov decision processes (MDPs) that arise when phase-type distributions are used to model the timing of non-Markovian events and actions. We focus, primarily, on the execution of phase-dependent policies. Phases are introduced into a model to represent relevant execution history, but there is no physical manifestation of phases in the real world. We treat phases as partially observable state features and show how a belief distribution over phase configurations can be derived from observable state features through the use of transient analysis for Markov chains. This results in an efficient method for phase tracking during execution that can be combined with the QMDP value method for POMDPs to make action choices. We also discuss, briefly, how the structure of MDPs with phase transitions can be exploited in structured value iteration with symbolic representation of vectors and matrices.|H√•kan L. S. Younes","65240|AAAI|2004|Dynamic Programming for Partially Observable Stochastic Games|We develop an exact dynamic programming algorithm for partially observable stochastic games (POSGs). The algorithm is a synthesis of dynamic programming for partially observable Markov decision processes (POMDPs) and iterated elimination or dominated strategies in normal form games. We prove that when applied to finite-horizon POSGs, the algorithm iteratively eliminates very weakly dominated strategies without first forming a normal form representation of the game. For the special case in which agents share the same payoffs, the algorithm can be used to find an optimal solution. We present preliminary empirical results and discuss ways to further exploit POMDP theory in solving POSGs.|Eric A. Hansen,Daniel S. Bernstein,Shlomo Zilberstein"],["57883|GECCO|2007|XCS for adaptive user-interfaces|We outline our context learning framework that harnesses information from a user's environment to learn user preferences for application actions. Within this framework, we employ XCS in a real world application for personalizing user-interface actions to individual users. Sycophant, our context aware calendaring application and research test-bed, uses XCS to adaptively generate user-preferred alarms for ten users in our study. Our results show that XCS' alarm prediction performance equals or surpasses the performance of One-R and a decision tree algorithm for all the users. XCS' average performance is close to $$ percent on the alarm prediction task for all ten users. These encouraging results further highlight the feasibility of using XCS for predictive data mining tasks and the promise of a classifier systems based approach to personalize user interfaces.|Anil Shankar,Sushil J. Louis,Sergiu Dascalu,Ramona Houmanfar,Linda J. Hayes","58612|GECCO|2009|On the scalability of XCSF|Many successful applications have proven the potential of Learning Classifier Systems and the XCS classifier system in particular in datamining, reinforcement learning, and function approximation tasks. Recent research has shown that XCS is a highly flexible system, which can be adapted to the task at hand by adjusting its condition structures, learning operators, and prediction mechanisms. However, fundamental theory concerning the scalability of XCS dependent on these enhancements and problem difficulty is still rather sparse and mainly restricted to boolean function problems. In this article we developed a learning scalability theory for XCSF---the XCS system applied to real-valued function approximation problems. We determine crucial dependencies on functional properties and on the developed solution representation and derive a theoretical scalability model out of these constraints. The theoretical model is verified with empirical evidence. That is, we show that given a particular problem difficulty and particular representational constraints XCSF scales optimally. In consequence, we discuss the importance of appropriate prediction and condition structures regarding a given problem and show that scalability properties can be improved by polynomial orders, given an appropriate, problem-suitable representation.|Patrick O. Stalph,Martin V. Butz,David E. Goldberg,Xavier Llor√†","57305|GECCO|2005|Extracted global structure makes local building block processing effective in XCS|Michigan-style learning classifier systems (LCSs), such as the accuracy-based XCS system, evolve distributed problem solutions represented by a population of rules. Recently, it was shown that decomposable problems may require effective processing of subsets of problem attributes, which cannot be generally assured with standard crossover operators. A number of competent crossover operators capable of effective identification and processing of arbitrary subsets of variables or string positions were proposed for genetic and evolutionary algorithms. This paper effectively introduces two competent crossover operators to XCS by incorporating techniques from competent genetic algorithms (GAs) the extended compact GA (ECGA) and the Bayesian optimization algorithm (BOA). Instead of applying standard crossover operators, here a probabilistic model of the global population is built and sampled to generate offspring classifiers locally. Various offspring generation methods are introduced and evaluated. Results indicate that the performance of the proposed learning classifier systems XCSECGA and XCSBOA is similar to that of XCS with informed crossover operators that is given all information about problem structure on input and exploits this knowledge using problem-specific crossover operators.|Martin V. Butz,Martin Pelikan,Xavier Llor√†,David E. Goldberg","57092|GECCO|2003|Designing Efficient Exploration with MACS Modules and Function Approximation|MACS (Modular Anticipatory Classifier System) is a new Anticipatory Classifier System. With respect to its predecessors, ACS ACS and YACS, the latent learning process in MACS is able to take advantage of new regularities. Instead of anticipating all attributes of the perceived situations in the same classifier, MACS only anticipates one attfribute per claasifier. In this paper we describe how the model of the environment represented by the classifiers can be used to perform active exploration and how this exploration policy is aggregated with the exploitation policy. The architecture is validated expermentally. Then we draw more general principles from the architectural choices giving rise to MACS. We show that building a model of the environment can be seen as a function approximation problem which can be solved with Anticipatory Classifier Systems such as MACS, but also with accuracy-based systems like XCS or XCSF, organized into a Dyna architecture.|Pierre G√©rard,Olivier Sigaud","58011|GECCO|2007|Introducing fault tolerance to XCS|In this paper, we introduce fault tolerance to XCS and propose a new XCS framework called XCS with Fault Tolerance (XCSFT). As an important branch of learning classifier systems, XCS has been proven capable of evolving maximally accurate, maximally general problem solutions. However, in practice, it oftentimes generates a lot of rules, which lower the readability of the evolved classification model, and thus, people may not be able to get the desired knowledge or useful information out of the model. Inspired by the fault tolerance mechanism proposed in field of data mining, we devise a new XCS framework by integrating the concept and mechanism of fault tolerance into XCS in order to reduce the number of classification rules and therefore to improve the readability of the generated prediction model. A series of $N$-multiplexer experiments, including -bit, -bit, -bit, and -bit multiplexers, are conducted to examine whether XCSFT can accomplish its goal of design. According to the experimental results, XCSFT can offer the same level of prediction accuracy on the test problems as XCS can, while the prediction model evolved by XCSFT consists of significantly fewer classification rules.|Hong-Wei Chen,Ying-Ping Chen","58957|GECCO|2010|How XCS deals with rarities in domains with continuous attributes|Michigan-style learning classifier systems solve problems by evolving distributed subsolutions online. Extracting accurate models for subsolutions which are represented by a low number of examples in the training data set has been identified as a key challenge in LCS, and facetwise analysis has been applied to identify the critical elements for success in unbalanced domains. While models for these elements have been developed for XCS with ternary representation, no study has been performed for XCS with interval-based representation, which is most often used in data mining tasks. This paper therefore takes the original design decomposition and adapts it to the interval-based representation. Theory and experimental evidence indicate that XCS with interval-based representation may fail to approximate concepts scarcely represented in the training data set. To overcome this problem, an online covering operator that introduces new specific genetic material in regions where we suspect that there are rarities is designed. The benefits of the online covering operator are empirically analyzed on a collection of artificial and real-world problems.|Albert Orriols-Puig,Xavier Llor√†,David E. Goldberg","59027|GECCO|2010|Adaption of XCS to multi-learner predatorprey scenarios|Learning classifier systems (LCSs) are rule-based evolutionary reinforcement learning systems. Today, especially variants of Wilson's extended classifier system (XCS) are widely applied for machine learning. Despite their widespread application, LCSs have drawbacks, e. g., in multi-learner scennarios, since the Markov property is not fulfilled. In this paper, LCSs are investigated in an instance of the generic homogeneous and non-communicating predatorprey scenario. A group of predators collaboratively observe a (randomly) moving prey as long as possible, where each predator is equipped with a single, independent XCS. Results show that improvements in learning are achieved by cleverly adapting a multi-step approach to the characteristics of the investigated scenario. Firstly, the environmental reward function is expanded to include sensory information. Secondly, the learners are equipped with a memory to store and analyze the history of local actions and given payoffs.|Clemens Lode,Urban Richter,Hartmut Schmeck","58006|GECCO|2007|Support vector regression for classifier prediction|In this paper we introduce XCSF with support vector predictionthe problem of learning the prediction function is solved as a support vector regression problem and each classifier exploits a Support Vector Machine to compute the prediction. In XCSF with support vector prediction, XCSFsvm, the genetic algorithm adapts classifier conditions, classifier actions, and the SVM kernel parameters.We compare XCSF with support vector prediction to XCSF with linear prediction on the approximation of four test functions.Our results suggest that XCSF with support vector prediction compared to XCSF with linear prediction (i) is able to evolve accurate approximations of more difficult functions, (ii) has better generalization capabilities and (iii) learns faster.|Daniele Loiacono,Andrea Marelli,Pier Luca Lanzi","57553|GECCO|2005|Hyper-heuristics and classifier systems for solving D-regular cutting stock problems|This paper presents a method for combining concepts of Hyper-heuristics and Learning Classifier Systems for solving D Cutting Stock Problems. The idea behind Hyper-heuristics is to discover some combination of straightforward heuristics to solve a wide range of problems. To be worthwhile, such combination should outperform the single heuristics. In this paper, the Hyper-heuristic is formed using a XCS-type Learning Classifier System which learns a solution procedure when solving individual problems. The XCS evolves a behavior model which determines the possible actions (selection and placement heuristics) for given states of the problem. When tested with a collection of different problems, the method finds very competitive results for most of the cases. The testebed is composed of problems used in other similar studies in the literature. Some additional instances of the testbed were randomly generated.|Hugo Terashima-Mar√≠n,E. J. Flores-√?lvarez,Peter Ross","57781|GECCO|2006|An open-set speaker identification system using genetic learning classifier system|This paper presents the design and implementation of an adaptive open-set speaker identification system with genetic learning classifier systems. One of the challenging problems in using learning classifier systems for numerical problems is the knowledge representation. The voice samples are a series of real numbers that must be encoded in a classifier format. We investigate several different methods for representing voice samples for classifier systems and study the efficacy of the methods. We also identify several challenges for learning classifier systems in the speaker identification problem and introduce new methods to improve the learning and classification abilities of the systems. Experimental results show that our system successfully learns  voice features at the accuracies of % to %, which is considered a strong result in the speaker identification community. This research presents the feasibility of using learning classifier systems for the speaker identification problem.|WonKyung Park,Jae C. Oh,Misty K. Blowers,Matt B. Wolf"],["58298|GECCO|2008|Imitation-based evolution of artificial players in modern computer games|Because of the rapid progress of commercial computer games in recent years the development of artificial characters that inhabit the presented game worlds has become a challenging task with very specific requirements. A very important feature of artificial intelligence for games is that, as the objective of computer games is the entertainment of the player, the artificial game agents should not only be competitive but also show intelligent and human-like behaviours. Therefore, this paper proposes the usage of imitation techniques to generate more human-like behaviours in an action game, whereas the imitation is achieved by recording players and by using these recordings as the basis of an evolutionary learning approach.|Steffen Priesterjahn","66072|AAAI|2007|Acquiring Visibly Intelligent Behavior with Example-Guided Neuroevolution|Much of artificial intelligence research is focused on devising optimal solutions for challenging and well-defined but highly constrained problems. However, as we begin creating autonomous agents to operate in the rich environments of modern videogames and computer simulations, it becomes important to devise agent behaviors that display the visible attributes of intelligence, rather than simply performing optimally. Such visibly intelligent behavior is difficult to specify with rules or characterize in terms of quantifiable objective functions, but it is possible to utilize human intuitions to directly guide a learning system toward the desired sorts of behavior. Policy induction from human-generated examples is a promising approach to training such agents. In this paper, such a method is developed and tested using Lamarckian neuroevolution. Artificial neural networks are evolved to control autonomous agents in a strategy game. The evolution is guided by human-generated examples of play, and the system effectively learns the policies that were used by the player to generate the examples. I.e., the agents learn visibly intelligent behavior. In the future, such methods are likely to play a central rule in creating autonomous agents for complex environments, making it possible to generate rich behaviors derived from nothing more formal than the intuitively generated example, of designers, players, or subject-matter experts.|Bobby D. Bryant,Risto Miikkulainen","58421|GECCO|2008|Real-time imitation-based adaptation of gaming behaviour in modern computer games|In the course of the recent complexification and sophistication of commercial computer games, the creation of competitive artificial players that are able to behave intelligently and successfully in the featured highly dynamic and complex virtual worlds has become a considerable challenge. This paper describes an evolutionary real-time adaptation approach to produce competitive artificial players in an action game. The proposed method is inspired by the idea of social learning or cultural evolution. Thus, the agents try to adapt to the level of their opponents by the exchange of information about advantageous behaviours within the population. In addition, the behaviour of the opponents and other players is recorded and used to create more sophisticated and human-like agents.|Steffen Priesterjahn,Alexander Weimer,Markus Eberling","65259|AAAI|2004|An Explainable Artificial Intelligence System for Small-unit Tactical Behavior|As the artificial intelligence (AI) systems in military simulations and computer games become more complex, their actions become increasingly difficult for users to understand. Expert systems for medical diagnosis have addressed this challenge though the addition of explanation generation systems that explain a system's internal processes. This paper describes the AI architecture and associated explanation capability used by Full Spectrum Command, a training system developed for the U.S. Army by commercial game developers and academic researchers.|Michael van Lent,William Fisher,Michael Mancuso","57182|GECCO|2003|Developing an Immunity to Spam|Immune systems protect animals from pathogens, so why not apply a similar model to protect computers Several researchers have investigated the use of an artificial immune system to protect computers from viruses and others have looked at using such a system to detect unauthorized computer intrusions. This paper describes the use of an artificial immune system for another kind of protection protection from unsolicited email, or spam.|Terri Oda,Tony White","65695|AAAI|2006|Traffic Intersections of the Future|Few concepts embody the goals of artificial intelligence as well as fully autonomous robots. Countless films and stories have been made that focus on a future filled with autonomous agents that complete menial tasks or run errands that humans do not want or are too busy to carry out. One such task is driving automobiles. In this paper, we summarize the work we have dune towards a future of fully-autonomous vehicles, specifically coordinating such vehicles safely and efficiently at intersections. We then discuss the implications this work has for other areas of AI, including planning, multiagent learning, and computer vision.|Kurt M. Dresner,Peter Stone","66245|AAAI|2007|Stochastic Filtering in a Probabilistic Action Model|Stochastic filtering is the problem of estimating the state of a dynamic system after time passes and given partial observations. It is fundamental to automatic tracking, planning, and control of real-world stochastic systems such as robots, programs, and autonomous agents. This paper presents a novel sampling-based filtering algorithm. Its expected error is smaller than sequential Monte Carlo sampling techniques given a fixed number of samples, as we prove and show empirically. It does so by sampling deterministic action sequences and then performing exact filtering on those sequences. These results are promising for applications in stochastic planning, natural language processing, and robot control.|Hannaneh Hajishirzi,Eyal Amir","65303|AAAI|2004|Useful Roles of Emotions in Artificial Agents A Case Study from Artificial Life|In this paper, we discuss the role of emotions in AI and possible ways to determine their utility for the design of artificial agents. We propose a research methodology for determining the utility of emotional control and apply it to the study of autonomous agents that compete for resources in an artificial life environment. The results show that the emotional control can improve performance in some circumstances.|Matthias Scheutz","58069|GECCO|2007|SwarmArchitect a swarm framework for collaborative construction|Computer game development has become increasingly popular in the field of autonomous systems. One of the main topics studies the building of various architectures in computer games. A realistic human-like architecture is expected in a thematic computer game, since it strongly motivates the game players in an intuitive way. However, the task of building a human-like architecture is non-trivial since the construction is a real time process without human supervision. In this paper, we present a collective building algorithm inspired by social insects for intelligent construction based on multiple agents. A swarm of virtual agents indirectly design edifications, which resemble basic features in human-like architecture by using a stigmergic mechanism along with branching rules. The main idea of the algorithm is to map sensory information to appropriate building actions.|Yifeng Zeng,Jorge Cordero Hernandez,Dennis Plougman Buus","66175|AAAI|2007|An Integrated Robotic System for Spatial Understanding and Situated Interaction in Indoor Environments|A major challenge in robotics and artificial intelligence lies in creating robots that are to cooperate with people in human-populated environments, e.g. for domestic assistance or elderly care. Such robots need skills that allow them to interact with the world and the humans living and working therein. In this paper we investigate the question of spatial understanding of human-made environments. The functionalities of our system comprise perception of the world, natural language, learning, and reasoning. For this purpose we integrate state-of-the-art components from different disciplines in AI, robotics and cognitive systems into a mobile robot system. The work focuses on the description of the principles we used for the integration, including cross-modal integration, ontology-based mediation, and multiple levels of abstraction of perception. Finally, we present experiments with the integrated \"CoSy Explorer\" system and list some of the major lessons that were learned from its design, implementation, and evaluation.|Hendrik Zender,Patric Jensfelt,√\u201Cscar Mart√≠nez Mozos,Geert-Jan M. Kruijff,Wolfram Burgard"],["58042|GECCO|2007|Novel ways of improving cooperation and performance in ensemble classifiers|There are two common methods of evolving teams of genetic programs. Research suggests Island approaches produce teams of strong individuals that cooperate poorly and Team approaches produce teams of weak individuals that cooperate strongly. Ideally, teams should be composed of strong individuals that cooperate well. In this paper we present a new class of algorithms called Orthogonal Evolution of Teams (OET) that overcomes the weaknesses of current Island and Team approaches by applying evolutionary pressure at both the level of teams and individuals during selection and replacement. We present four novel algorithms in this new class and compare their performance to Island and Team approaches as well as multi-class Adaboost on a number of classification problems.|Russell Thomason,Terence Soule","57510|GECCO|2005|Improving EA-based design space exploration by utilizing symbolic feasibility tests|This paper will propose a novel approach in combining Evolutionary Algorithms with symbolic techniques in order to improve the convergence of the algorithm in the presence of large search spaces containing only few feasible solutions. Such problems can be encountered in many real-world applications. Here, we will use the example of design space exploration of embedded systems to illustrate the benefits of our approach. The main idea is to integrate symbolic techniques into the Evolutionary Algorithm to guide the search towards the feasible region. We will present experimental results showing the advantages of our novel approach.|Thomas Schlichter,Christian Haubelt,J√ºrgen Teich","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","58152|GECCO|2007|Estimation of fitness landscape contours in EAs|Evolutionary algorithms applied in real domain should profit from information about the local fitness function curvature. This paper presents an initial study of an evolutionary strategy with a novel approach for learning the covariance matrix of a Gaussian distribution. The learning method is based one stimation of the fitness landscape contour line between the selected and discarded individuals. The distribution learned this way is then used to generate new population members. The algorithm presented here is the first attempt to construct the Gaussian distribution this way and should beconsidered only a proof of concept nevertheless, the empirical comparison on low-dimensional quadratic functions shows that our approach is viable and with respect to the number of evaluations needed to find a solution of certain quality, it is comparable to the state-of-the-art CMA-ES incase of sphere function and outperforms the CMA-ES in case of elliptical function.|Petr Pos√≠k,Vojtech Franc","57033|GECCO|2003|Automatic Design Synthesis and Optimization of Component-Based Systems by Evolutionary Algorithms|A novel approach for automatic design synthesis and optimization using evolutionary algorithms (EA) is introduced in the paper. The approach applies to component-based systems in general and is demonstrated with a heating, ventilating and air-conditioning (HVAC) systems problem. The whole process of the system design, including the initial stages that usually entail significant human involvement, is treated as a constraint satisfaction problem. The formulation of the optimization process realizes the complex nature of the design problem using different types of variables (real and integer) that represent both the physical and the topological properties of the system the objective is to design a feasible and efficient system. New evolutionary operators tailored to the component-based, spatially distributed system design problem have been developed. The process of design has been fully automated. Interactive supervision of the optimization process by a human-designer is possible using a specialized GUI. An example of automatic design of HVAC system for two-zone buildings is presented.|Plamen P. Angelov,Y. Zhang,Jonathan A. Wright,V. I. Hanby,R. A. Buswell","58613|GECCO|2009|A fuzzy inference system-inspired influence function for the cultural algorithm with evolutionary programming applied to real-valued function optimization|In this paper, we present a Fuzzy Influence Function for the CAEP model (Cultural Algorithms with Evolutionary Programming) proposed by Chung  and extended by Zhu , applied to real-valued function optimization. The proposal makes use of a Fuzzy Inference System 'FIS' to adjust an Influence Factor that represents the intensity of the influence of the Variation operator of the CAEP model. This paper also presents a comparative analysis of the proposed influence function using a set of  of the CEC ' benchmarking functions.|M√°rio Augusto Torres,Rodrigo Magno Silva,Ot√°vio Noura Teixeira,Roberto Lim√£o","57811|GECCO|2006|Estimating the destructiveness of crossover on binary tree representations|In some cases, evolutionary algorithms represent individuals as typical binary trees with n leaves and n- internal nodes. When designing a crossover operator for a particular representation and application, it is desirable to quantify the operator's destructiveness in order to estimate its effectiveness at using building blocks. For the case of binary tree representations, we present a novel approach for empirically estimating the destructiveness of any crossover operator by computing and summarizing the distribution of Robinson-Foulds distances from the parent to the entire neighborhood of possible children. We demonstrate the approach by quantifying the destructiveness of a popular tree-based crossover operator as applied to the problem of phylogenetic inferencing. We discuss the benefits and limitations of the destructiveness metric.|Luke Sheneman,James A. Foster","59088|GECCO|2010|Sustaining behavioral diversity in NEAT|Niching schemes, which sustains population diversity and let an evolutionary population avoid premature convergence, have been extensively studied in the research field of evolutionary algorithms. Neuroevolutionary (NE) algorithms, such as NEAT, have also benefitted from niching. However, the latest research indicates that the use of genotype- or phenotype-similarity-based niching schemes in NE algorithms is not highly effective because these schemes have difficulty sustaining the behavioral diversity in the environment. In this paper, we propose a novel niching scheme that takes into consideration both the phenotypic and behavioral diversity, and then integrate it with NEAT. An experimental analysis revealed that the proposed algorithm outperforms the original NEAT for various problem settings. More interestingly, it performs especially well for problems with a high noise level and large state space. Since these features are common in problems to which NEAT is applied, the proposed algorithm should be effective in practice.|Hirotaka Moriguchi,Shinichi Honiden","58904|GECCO|2010|Indicator-based evolutionary algorithm with hypervolume approximation by achievement scalarizing functions|Pareto dominance-based algorithms have been the main stream in the field of evolutionary multiobjective optimization (EMO) for the last two decades. It is, however, well-known that Pareto-dominance-based algorithms do not always work well on many-objective problems with more than three objectives. Currently alternative frameworks are studied in the EMO community very actively. One promising framework is the use of an indicator function to find a good solution set of a multiobjective problem. EMO algorithms with this framework are called indicator-based evolutionary algorithms (IBEAs) where the hypervolume measure is frequently used as an indicator. IBEAs with the hypervolume measure have strong theoretical support and high search ability. One practical difficult of such an IBEA is that the hypervolume calculation needs long computation time especially when we have many objectives. In this paper, we propose an idea of using a scalarizing function-based hypervolume approximation method in IBEAs. We explain how the proposed idea can be implemented in IBEAs. We also demonstrate through computational experiments that the proposed idea can drastically decrease the computation time of IBEAs without severe performance deterioration.|Hisao Ishibuchi,Noritaka Tsukamoto,Yuji Sakane,Yusuke Nojima","58972|GECCO|2010|Integrating decision space diversity into hypervolume-based multiobjective search|Multiobjective optimization in general aims at learning about the problem at hand. Usually the focus lies on objective space properties such as the front shape and the distribution of optimal solutions. However, structural characteristics in the decision space can also provide valuable insights. In certain applications, it may even be more important to find a structurally diverse set of close-to-optimal solutions than to identify a set of optimal but structurally similar solutions. Accordingly, multiobjective optimizers are required that are capable of considering both the objective space quality of a Pareto-set approximation and its diversity in the decision space. Although NSGA, one of the first multiobjective evolutionary algorithms, explicitly considered decision space diversity, only a few other studies address that issue. It therefore is an open research question how modern multiobjective evolutionary algorithms can be adapted to search for structurally diverse high-quality Pareto-set approximations. To this end we propose an approach to integrate decision space diversity into hypervolume-based multiobjective search. We present a modified hypervolume indicator and integrate it into an evolutionary algorithm. The proof-of-principle results show the potential of the approach and indicate further research directions for structure-oriented multiobjective search.|Tamara Ulrich,Johannes Bader,Eckart Zitzler"],["59077|GECCO|2010|Analysis of the effects of lifetime learning on population fitness using vose model|Vose's dynamical systems model of the simple genetic algorithm (SGA) is an exact model that uses mathematical operations to capture the dynamical behavior of genetic algorithms. The original model was defined for a simple genetic algorithm. This paper suggests how to extend the model and incorporate two kinds of learning, Darwinian and Lamarckian, into the framework of the Vose model. The extension provides a new theoretical framework to examine the effects of lifetime learning on the fitness of a population. We analyze the asymptotic behavior of different hybrid algorithms on an infinite population vector and compare it to the behavior of the classical genetic algorithm on various population sizes. Our experiments show that Lamarckian-like inheritance - direct transfer of lifetime learning results to offsprings - allows quicker genetic adaptation. However, functions exist where the simple genetic algorithms without learning, as well as Lamarckian evolution, converge to the same local optimum, while genetic search based on Darwinian inheritance converges to the global optimum.|Roi Yehoshua,Mireille Avigal,Ron Unger","58345|GECCO|2008|Deriving evaluation metrics for applicability of genetic algorithms to optimization problems|This paper aims to identify the missing links from theory of Genetic Algorithms (GAs) to application of GAs.|Hsinyi Jiang,Carl K. Chang","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","57152|GECCO|2003|Adaptive Elitist-Population Based Genetic Algorithm for Multimodal Function Optimization|This paper introduces a new technique called adaptive elitist-population search method for allowing unimodal function optimization methods to be extended to efficiently locate all optima of multimodal problems. The technique is based on the concept of adaptively adjusting the population size according to the individuals' dissimilarity and the novel elitist genetic operators. Incorporation of the technique in any known evolutionary algorithm leads to a multimodal version of the algorithm. As a case study, genetic algorithms(GAs) have been endowed with the multimodal technique, yielding an adaptive elitist-population based genetic algorithm(AEGA). The AEGA has been shown to be very efficient and effective in finding multiple solutions of the benchmark multimodal optimization problems.|Kwong-Sak Leung,Yong Liang","58953|GECCO|2010|Definition of a crossover based distance for genetic algorithms|Distances that are bound to (or consistent with) genetic operators are measures that quantify the difficulty of reaching and individual (or a population) starting from another individual (or population) and applying the genetic operator iteratively. Defining distance measures bound to genetic operators is a very important task in evolutionary computation. In fact these distances usually make the analysis of some indicators of the the search process, like for instance population diversity or well-known measures of problem hardness such as fitness distance correlation, more accurate. In this paper, we introduce a distance measure bound to one point standard crossover for genetic algorithms. This measure quantifies the minimum number of crossover operations that have to be applied to a population to tranform it into another population. It is based on the definition of a lattice over some particular schemata that represent the individuals in the population and on the construction of a discrete dynamic system that models the dynamics of the genetic algorithm under the sole effect of crossover. Using this distance measure, it is also possible to build a family of distances between individuals.|Luca Manzoni,Leonardo Vanneschi,Giancarlo Mauri","58052|GECCO|2007|Hybrid multiobjective optimization genetic algorithms for graph drawing|In this paper we introduce an application of multiobjective optimization with genetic algorithms to the problem of graph drawing and explore the potential contribution of the genetic algorithms for this particular problem.|Dana Vrajitoru","57756|GECCO|2006|A fast hybrid genetic algorithm for the quadratic assignment problem|Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the \"fast hybrid genetic algorithm\" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm.|Alfonsas Misevicius","57270|GECCO|2005|On the practical genetic algorithms|This paper offers practical design-guidelines for developing efficient genetic algorithms (GAs) to successfully solve real-world problems. As an important design component, a practical population-sizing model is presented and verified.|Chang Wook Ahn,Sanghoun Oh,Rudrapatna S. Ramakrishna","57423|GECCO|2005|ARGEN  AREPO mixing the artificial genetic engineering and artificial evolution of populations to improve the search process|In this paper we analyze the performance of several evolutionary algorithms in the feature and instance selection problem. It is also introduced the ARGEN + AREPO search algorithm which has been tested in the same problem. There is no need to adapt parameters in this genetic algorithm, except the population size. The reported preliminary results show that using this technique in a wrapper model to search data subsets, we can obtain accuracy similar to the obtained with some of the genetic algorithms models here presented, but with less data.|Agust√≠n Le√≥n-Barranco,Sandra E. Barajas,Carlos A. Reyes Garc√≠a"],["65033|AAAI|1987|An Approach to Default Reasoning Based on a First-Order Conditional Logic|This paper presents an approach to default reasoning based on an extension to classical first-order logic. In this approach. first-order logic is augmented with a \"variable conditional\" operator for representing default statements. Truth in the resulting logic is based on a possible worlds semantics the default statement  is true just when  is true in the least exceptional worlds in which a is true. This system provides a basis for representing and reasoning about default statements. Inferences of default properties of individuals rely on two assumptions first that the world being modelled by a set of sentences is as uniform as consistently possible and, second, that sentences that may consistently be assumed to be irrelevant to a default inference are, in fact, irrelevant to the inference. Two formulations of default inferencing are proposed. The first involves extending the set of defaults to include all combinations of irrelevant properties. The second involves assuming that the world being modelled is among the simplest worlds consistent with the defaults and with what is contingently known. In the end. the second approach is argued to be superior to the first.|James P. Delgrande","66161|AAAI|2007|Forgetting Actions in Domain Descriptions|Forgetting irrelevantproblematic actions in a domain description can be useful in solving reasoning problems, such as query answering, planning, conftict resolution, prediction, postdiction, etc.. Motivated by such applications, we study what forgetting is, how forgetting can be done, and for which applications forgetting can be useful and how, in the context of reasoning about actions. We study these questions in the action language C (a formalism based on causal explanations), and relate it to forgetting in classical logic and logic programming.|Esra Erdem,Paolo Ferraris","65774|AAAI|2006|Towards an Axiom System for Default Logic|Recently, Lakemeyer and Levesque proposed a logic of only-knowing which precisely captures three forms of nonmonotonic reasoning Moore's Autoepistemic Logic, Konolige's variant based on moderately grounded expansions, and Reiter's default logic. Defaults have a uniform representation under all three interpretations in the new logic. Moreover, the logic itself is monotonic, that is, nonmonotonic reasoning is cast in terms of validity in the classical sense. While Lakemeyer and Levesque gave a model-theoretic account of their logic, a proof-theoretic characterization remained open. This paper fills that gap for the propositional subset a sound and complete axiom system in the new logic for all three varieties of default reasoning. We also present formal derivations for some examples of default reasoning. Finally we present evidence that it is unlikely that a complete axiom system exists in the first-order case, even when restricted to the simplest forms of default reasoning.|Gerhard Lakemeyer,Hector J. Levesque","66316|AAAI|2008|Optimizations and Extensions for the Horn Transaction Logic Programs|My thesis describes optimization techniques and extensions for the Horn Transaction Logic. The Horn Transaction Logic is an extension of the classical logic programming with state updates and it has a SLD-style evaluation algorithm. This SLD-style algorithm enters into infinite loops when computing answers to many recursive programs when they change the underlying state of the knowledge base. We solve this problem by tabling the calls, states and answers in a searchable structure, so that the same call is not re-executed ad infinitum. With these techniques, we can efficiently compute queries to transaction logic programs, and when the underlying programs have the bounded term-depth property, these techniques are guaranteed to terminate. I also present extensions to Transaction Logic, for instance a definite semantics for the existentially quantified values that occur in facts, queries and updates of facts. The applications of these techniques promise great improvements in the uses of transaction logic state-changing systems, artificial intelligence planning, dynamic constraints on transaction execution, workflow modeling and verification, and systems involving financial transactions.|Paul Fodor","65474|AAAI|2005|Only-Knowing Taking It Beyond Autoepistemic Reasoning|The idea of only-knowing a collection of sentences has been previously shown to have a close connection with autoepistemic logic. Here we propose a more general account of only-knowing that captures not only autoepistemic logic but default logic as well. This allows us not only to study the properties of default logic in terms of an underlying model of belief, but also the relationship among different forms of nonmonotonic reasoning, all within a classical monotonic logic characterized semantically in terms of possible worlds.|Gerhard Lakemeyer,Hector J. Levesque","66365|AAAI|2008|Querying Sequential and Concurrent Horn Transaction Logic Programs Using Tabling Techniques|In this poster we describe the tabling techniques for Sequential and Concurrent Horn Transaction Logic. Horn Transaction Logic is an extension of classical logic programming with state updates and it has a SLD-style evaluation algorithm. This SLD-style algorithm enters into infinite loops when computing answers to many recursive programs when they change the underlying state of the knowledge base. We solve this problem by tabling (caching) the calls, call states and answers (unifications and return states) in a searchable structure for the Sequential Transaction Logic, or building a graph for the query and memoize the \"hot\" vertices (vertices, currently, possible to execute) for the Propositional Concurrent Transaction Logic, so that the same call is not re-executed ad infinum. With these techniques, we can efficiently compute queries to transaction logic programs, and when the underlying programs have the bounded term-depth property (Transaction Datalog) the techniques are guaranteed to terminate. The applications of these techniques promise termination and great improvements in the uses of transaction logic state-changing systems, artificial intelligence planning, dynamic constraints on transaction execution, workflow modeling and verification, and systems involving financial transactions.|Paul Fodor","65170|AAAI|1993|The Paradoxical Success of Fuzzy Logic|Fuzzy logic methods have been used successfully in many real-world applications, but the foundations of fuzzy logic remain under attack. Taken together, these two facts constitute a paradox. A second paradox is that almost all of the successful fuzzy logic applications are embedded controllers, while most of the theoretical papers on fuzzy methods deal with knowledge representation and reasoning. I hope to resolve these paradoxes by identifying which aspects of fuzzy logic render it useful in practice, and which aspects are inessential. My conclusions are based on a mathematical result, on a survey of literature on the use of fuzzy logic in heuristic control and in expert systems, and on practical experience in developing expert systems.|Charles Elkan","66300|AAAI|2008|Nonmonotonic Modes of Inference|In this paper we investigate nonmonotonic 'modes of inference'. Our approach uses modal (conditional) logic to establish a uniform framework in which to study nonmonotonic consequence. We consider a particular mode of inference which employs a majority-based account of default reasoning--one which differs from the more familiar preferential accounts--and show how modal logic supplies a framework which facilitates analysis of, and comparison with more traditional formulations of nonmonotonic consequence.|Victor Jauregui","66519|AAAI|2008|Terminological Reasoning in SHIQ with Ordered Binary Decision Diagrams|We present a new algorithm for reasoning in the description logic SHIQ, which is the most prominent fragment of the Web Ontology Language OWL. The algorithm is based on ordered binary decision diagrams (OBDDs) as a datastructure for storing and operating on large model representations. We thus draw on the success and the proven scalability of OBDD-based systems. To the best of our knowledge, we present the very first agorithm for using OBDDs for reasoning with general Tboxes.|Sebastian Rudolph,Markus Kr√∂tzsch,Pascal Hitzler","66012|AAAI|2007|The Modal Logic SF the Default Logic and the Logic Here-and-There|The modal logic SF provides an account for the default logic of Reiter, and several modal nonmonotonic logics of knowledge and belief. In this paper we focus on a fragment of the logic SF concerned with modal formulas called modal defaults, and on sets of modal defaults -- modal default theories. We present characterizations of SF-expansions of modal default theories, and show that strong and uniform equivalence of modal default theories can be expressed in terms of the logical equivalence in the logic SF. We argue that the logic SF can be viewed as the general default logic of nested defaults. We also study special modal default theories called modal programs, and show that this fragment of the logic SF generalizes the logic here-and-there.|Miroslaw Truszczynski"],["57397|GECCO|2005|Parsing and translation of expressions by genetic programming|We have investigated the potential for using genetic programming to evolve compiler parsing and translation routines for processing arithmetic and logical expressions as they are used in a typical programming language. Parsing and translation are important and complex real-world problems for which evolved solutions must make use of a range of programming constructs. The exercise also tests the ability of genetic programming to evolve extensive and appropriate use of abstract data types - namely, stacks. Experimentation suggests that the evolution of such code is achievable, provided that program function and terminal sets are judiciously chosen.|David Jackson","58905|GECCO|2010|New crossover operators in linear genetic programming for multiclass object classification|Genetic programming (GP) has been successfully applied to solving multiclass classification problems, but the performance of GP classifiers still lags behind that of alternative techniques. This paper investigates an alternative form of GP, Linear GP (LGP), which demonstrates great promise as a classifier as the division of classes is inherent in this technique. By combining biological inspiration with detailed knowledge of program structure two new crossover operators that significantly improve performance are developed. The first is a new crossover operator that mimics biological crossover between alleles, which helps reduce the disruptive effect on building blocks of information. The second is an extension of the first where a heuristic is used to predict offspring fitness guiding search to promising solutions.|Carlton Downey,Mengjie Zhang,Will N. Browne","57960|GECCO|2007|A new crossover technique for Cartesian genetic programming|Genetic Programming was first introduced by Koza using tree representation together with a crossover technique in which random sub-branches of the parents' trees are swapped to create the offspring. Later Miller and Thomson introduced Cartesian Genetic Programming, which uses directed graphs as a representation to replace the tree structures originally introduced by Koza. Cartesian Genetic Programming has been shown to perform better than the traditional Genetic Programming but it does not use crossover to create offspring, it is implemented using mutation only. In this paper a new crossover method in Genetic Programming is introduced. The new technique is based on an adaptation of the Cartesian Genetic Programming representation and is tested on two simple regression problems. It is shown that by implementing the new crossover technique, convergence is faster than that of using mutation only in the Cartesian Genetic Programming method.|Janet Clegg,James Alfred Walker,Julian Francis Miller","58830|GECCO|2009|Evolution development and learning using self-modifying cartesian genetic programming|Self-Modifying Cartesian Genetic Programming (SMCGP) is a form of genetic programming that integrates developmental (self-modifying) features as a genotype-phenotype mapping. This paper asks Is it possible to evolve a learning algorithm using SMCGP|Simon Harding,Julian Francis Miller,Wolfgang Banzhaf","57849|GECCO|2006|Embedded cartesian genetic programming and the lawnmower and hierarchical-if-and-only-if problems|Embedded Cartesian Genetic Programming (ECGP) is an extension of the directed graph based Cartesian Genetic Programming (CGP), which is capable of automatically acquiring, evolving and re-using partial solutions in the form of modules. In this paper, we apply for the first time, CGP and ECGP to the well known Lawnmower problem and to the Hierarchical-if-and-Only-if problem. The latter is normally associated with Genetic Algorithms. Computational effort figures are calculated from the results of both CGP and ECGP and our results compare favourably with other techniques.|James Alfred Walker,Julian Francis Miller","57850|GECCO|2006|A multi-chromosome approach to standard and embedded cartesian genetic programming|Embedded Cartesian Genetic Programming (ECGP) is an extension of Cartesian Genetic Programming (CGP) that can automatically acquire, evolve and re-use partial solutions in the form of modules. In this paper, we introduce for the first time a new multi-chromosome approach to CGP and ECGP that allows difficult problems with multiple outputs to be broken down into many smaller, simpler problems with single outputs, whilst still encoding the entire solution in a single genotype. We also propose a multi-chromosome evolutionary strategy which selects the best chromosomes from the entire population to form the new fittest individual, which may not have been present in the population. The multi-chromosome approach to CGP and ECGP is tested on a number of multiple output digital circuits. Computational Effort figures are calculated for each problem and compared against those for CGP and ECGP. The results indicate that the use of multiple chromosomes in both CGP and ECGP provide a significant performance increase on all problems tested.|James Alfred Walker,Julian Francis Miller,Rachel Cavill","57990|GECCO|2007|Solving real-valued optimisation problems using cartesian genetic programming|Classical Evolutionary Programming (CEP) and Fast Evolutionary Programming (FEP) have been applied to real-valued function optimisation. Both of these techniques directly evolve the real-values that are the arguments of the real-valued function. In this paper we have applied a form of genetic programming called Cartesian Genetic Programming (CGP) to a number of real-valued optimisation benchmark problems. The approach we have taken is to evolve a computer program that controls a writing-head, which moves along and interacts with a finite set of symbols that are interpreted as real numbers, instead of manipulating the real numbers directly. In other studies, CGP has already been shown to benefit from a high degree of neutrality. We hope to exploit this for real-valued function optimisation problems to avoid being trapped on local optima. We have also used an extended form of CGP called Embedded CGP (ECGP) which allows the acquisition, evolution and re-use of modules. The effectiveness of CGP and ECGP are compared and contrasted with CEP and FEP on the benchmark problems. Results show that the new techniques are very effective.|James Alfred Walker,Julian Francis Miller","58509|GECCO|2008|Advanced techniques for the creation and propagation of modules in cartesian genetic programming|The choice of an appropriate hardware representation model is key to successful evolution of digital circuits. One of the most popular models is cartesian genetic programming, which encodes an array of logic gates into a chromosome. While several smaller circuits have been successfully evolved on this model, it lacks scalability. A recent approach towards scalable hardware evolution is based on the automated creation of modules from primitive gates. In this paper, we present two novel approaches for module creation, an age-based and a cone-based technique. Further, we detail a cone-based crossover operator for use with cartesian genetic programming. We evaluate the different techniques and compare them with related work. The results show that age-based module creation is highly effective, while cone-based approaches are only beneficial for regularly structured, multiple output functions such as multipliers.|Paul Kaufmann,Marco Platzner","57561|GECCO|2005|Investigating the performance of module acquisition in cartesian genetic programming|Embedded Cartesian Genetic Programming (ECGP) is a form of the graph based Cartesian Genetic Programming (CGP) in which modules are automatically acquired and evolved. In this paper we compare the efficiencies of the ECGP and CGP techniques on three classes of problem digital adders, digital multipliers and digital comparators. We show that in most cases ECGP shows a substantial improvement in performance over CGP and that the computational speedup is more pronounced on larger problems.|James Alfred Walker,Julian Francis Miller","57437|GECCO|2005|Learning computer programs with the bayesian optimization algorithm|We describe an extension of the Bayesian Optimization Algorithm (BOA), a probabilistic model building genetic algorithm, to the domain of program tree evolution. The new system, BOA programming (BOAP), improves significantly on previous probabilistic model building genetic programming (PMBGP) systems in terms of the articulacy and open-ended flexibility of the models learned, and hence control over the distribution of instances generated. Innovations include a novel tree representation and a generalized program evaluation scheme.|Moshe Looks,Ben Goertzel,Cassio Pennachin"],["66091|AAAI|2007|Detection of Multiple Deformable Objects using PCA-SIFT|In this paper, we address the problem of identifying and localizing multiple instances of highly deformable objects in real-time video data. We present an approach which uses PCA-SIFT (Scale Invariant Feature Transform) in combination with a clustered voting scheme to achieve detection and localization of multiple objects while providing robustness against rapid shape deformation, partial occlusion, and perspective changes. We test our approach in two highly deformable robot domains and evaluate Its performance using ROC (Receiver Operating Characteristic) statistics.|Stefan Zickler,Alexei A. Efros","66347|AAAI|2008|Proactive Intrusion Detection|Machine learning systems are deployed in many adversarial conditions like intrusion detection, where a classifier has to decide whether a sequence of actions come from a legitimate user or not. However, the attacker, being an adversarial agent, could reverse engineer the classifier and successfully masquerade as a legitimate user. In this paper, we propose the notion of a Proactive Intrusion Detection System (IDS) that can counter such attacks by incorporating feedback into the process. A proactive IDS influences the user's actions and observes them in different situations to decide whether the user is an intruder. We present a formal analysis of proactive intrusion detection and extend the adversarial relationship between the IDS and the attacker to present a game theoretic analysis. Finally, we present experimental results on real and synthetic data that confirm the predictions of the analysis.|Benjamin Liebald,Dan Roth,Neelay Shah,Vivek Srikumar","65976|AAAI|2007|Optimal Multi-Agent Scheduling with Constraint Programming|We consider the problem of computing optimal schedules in multi-agent systems. In these problems, actions of one agent can influence the actions of other agents, while the objective is to maximize the total 'quality' of the schedule. More specifically, we focus on multi-agent scheduling problems with time windows, hard and soft precedence relations, and a nonlinear objective function. We show how we can model and efficiently solve these problems with constraint programming technology. Elements of our proposed method include constraint-based reasoning, search strategies, problem decomposition, scheduling algorithms, and a linear programming relaxation. We present experimental results on realistic problem instances to display the different elements of the solution process.|Willem Jan van Hoeve,Carla P. Gomes,Bart Selman,Michele Lombardi","66897|AAAI|2010|Grouping Strokes into Shapes in Hand-Drawn Diagrams|Many video surveillance applications require detecting human reappearances in a scene monitored by a camera or over a network of cameras. This is the human reappearance detection (HRD) problem. Studying this problem is important for analyzing a surveillance scenario at semantic level. In this paper, we propose a novel online learning framework for solving HRD problem. Both generative model and discriminative model are employed in this framework and a voting scheme is presented to fuse the decisions of both models for determining whether a just entered person is one of those who have shown up, i.e. whether a reappearance happens. Both models will be updated based on mistake-driven online learning strategy. Our experimental results show that the adopted online learning framework not only improves the reappearance detection accuracy but also achieves high robustness in various surveillance scenes.|Eric Jeffrey Peterson,Thomas F. Stahovich,Eric Doi,Christine Alvarado","65761|AAAI|2006|Learning Systems of Concepts with an Infinite Relational Model|Relationships between concepts account for a large proportion of semantic knowledge. We present a nonparametric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data.|Charles Kemp,Joshua B. Tenenbaum,Thomas L. Griffiths,Takeshi Yamada,Naonori Ueda","57778|GECCO|2006|Immune anomaly detection enhanced with evolutionary paradigms|The paper presents an approach based on principles of immune systems to the anomaly detection problem. Flexibility and efficiency of the anomaly detection system are achieved by building a model of network behavior based on the self-nonself space paradigm. Covering both self and nonself spaces by hyperrectangular structures is proposed. Structures corresponding to self-space are built using a training set from this space. Hyperrectangular detectors covering nonself space are created using niching genetic algorithm. A coevolutionary algorithm is proposed to enhance this process. Results of experiments show a high quality of intrusion detection, which outperform the quality of recently proposed approach based on hypersphere representation of self-space.|Marek Ostaszewski,Franciszek Seredynski,Pascal Bouvry","58444|GECCO|2008|Finding ground states of Sherrington-Kirkpatrick spin glasses with hierarchical boa and genetic algorithms|This study focuses on the problem of finding ground states of random instances of the Sherrington-Kirkpatrick (SK) spin-glass model with Gaussian couplings. While the ground states of SK spin-glass instances can be obtained with branch and bound, the computational complexity of branch and bound yields instances of not more than approximately  spins. We describe several approaches based on the hierarchical Bayesian optimization algorithm (hBOA) to reliably identify ground states of SK instances intractable with branch and bound, and present a broad range of empirical results on such problem instances. We argue that the proposed methodology holds a big promise for reliably solving large SK spin-glass instances to optimality with practical time complexity. The proposed approaches to identifying global optima reliably can also be applied to other problems and can be used with many other evolutionary algorithms. Performance of hBOA is compared to that of the genetic algorithm with two common crossover operators.|Martin Pelikan,Helmut G. Katzgraber,Sigismund Kobe","65752|AAAI|2006|A Dynamic Mixture Model to Detect Student Motivation and Proficiency|Unmotivated students do not reap the full rewards of using a computer-based intelligent tutoring system. Detection of improper behavior is thus an important component of an online student model. To meet this challenge, we present a dynamic mixture model based on Item Response Theory. This model, which simultaneously estimates a student's proficiency and changing motivation level, was tested with data of high school students using a geometry tutoring system. By accounting for student motivation, the dynamic mixture model can more accurately estimate proficiency and the probability of a correct response. The model's generality is an added benefit, making it applicable to many intelligent tutoring systems as well as other domains.|Jeffrey Johns,Beverly Park Woolf","66632|AAAI|2010|Constraint Programming for Data Mining and Machine Learning|While face detection seems a solved problem under general conditions, most state-of-the-art systems degrade rapidly when faces are partially occluded by other objects. This paper presents a solution to detect partially occluded faces by reasonably modifying the AdaBoost-based face detector. Our basic idea is that the weak classifiers in the AdaBoost-based face detector, each corresponding to a Haar-like feature, are inherently a patch-based model. Therefore, one can divide the whole face region into multiple patches, and map those weak classifiers to the patches. The weak classifiers belonging to each patch are re-formed to be a new classifier to determine if it is a valid face patch - without occlusion. Finally, we combine all of the valid face patches by assigning the patches with different weights to make the final decision whether the input subwindow is a face. The experimental results show that the proposed method is promising for the detection of occluded faces|Luc De Raedt,Tias Guns,Siegfried Nijssen","66702|AAAI|2010|Possible Winners when New Candidates Are Added The Case of Scoring Rules|The article presents methods for D scene geometry recoveryrefinement and pose estimation from motion imagery in two representative scenarios. First, we present a method for pose estimation and scene geometry recovery from extended sequences without prior knowledge of the scheme. Second, we discuss how to recover camera poses when a rough scene model is provided. We show how to extend and refine the scene model using the recovered poses. Finally, we present applications of the above techniques for D imagery manipulation such as enhanced visualization for video and D insertion of synthetic objects in the imagery|Yann Chevaleyre,J√©r√¥me Lang,Nicolas Maudet,J√©r√¥me Monnot"],["57472|GECCO|2005|Extraction of informative genes from microarray data|Identification of those genes that might anticipate the clinical behavior of different types of cancers is challenging due to availability of a smaller number of patient samples compared to huge number of genes, and the noisy nature of microarray data. After selection of some good genes based on signal-to-noise ratio, unsupervised learning like clustering and supervised learning like k-nearest neighbor (kNN) classifier are widely used in cancer researches to correlate the pathological behavior of cancers with the gene expression levels' differences in cancerous and normal tissues. By applying adaptive searches like Probabilistic Model Building Genetic Algorithm (PMBGA), it may be possible to get a smaller size gene subset that would classify patient samples more accurately than the above methods. In this paper, we propose a new PMBGA based method to extract informative genes from microarray data using Support Vector Machine (SVM) as a classifier. We apply our method to three microarray data sets and present the experimental results. Our method with SVM obtains encouraging results on those data sets as compared with the rank based method using kNN as a classifier.|Topon Kumar Paul,Hitoshi Iba","65605|AAAI|2005|Unsupervised and Semi-Supervised Multi-Class Support Vector Machines|We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.|Linli Xu,Dale Schuurmans","66477|AAAI|2008|Constrained Classification on Structured Data|Most standard learning algorithms, such as Logistic Regression (LR) and the Support Vector Machine (SVM), are designed to deal with i.i.d. (independent and identically distributed) data. They therefore do not work effectively for tasks that involve non-i.i.d. data, such as \"region segmentation\". (Eg, the \"tumor vs non-tumor\" labels in a medical image are correlated, in that adjacent pixels typically have the same label.) This has motivated the work in random fields, which has produced classifiers for such non-i.i.d. data that are significantly better than standard i.i.d.-based classifiers. However, these random field methods are often too slow to be trained for the tasks they were designed to solve. This paper presents a novel variant, Pseudo Conditional Random Fields (PCRFs), that is also based on i.i.d. learners, to allow efficient training but also incorporates correlations, like random fields. We demonstrate that this system is as accurate as other random fields variants, but significantly faster to train.|Chi-Hoon Lee,Matthew R. G. Brown,Russell Greiner,Shaojun Wang,Albert Murtha","65753|AAAI|2006|Kernel Methods for Word Sense Disambiguation and Acronym Expansion|The scarcity of manually labeled data for supervised machine learning methods presents a significant limitation on their ability to acquire knowledge. The use of kernels in Support Vector Machines (SVMs) provides an excellent mechanism to introduce prior knowledge into the SVM learners, such as by using unlabeled text or existing ontologies as additional knowledge sources. Our aim is to develop three kernels - one that makes use of knowledge derived from unlabeled text, the second using semantic knowledge from ontologies, and finally a third, additive kernel consisting of the first two kernels - and study their effect on the tasks of word sense disambiguation and automatic expansion of ambiguous acronyms.|Mahesh Joshi,Ted Pedersen,Richard Maclin,Serguei V. S. Pakhomov","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","58006|GECCO|2007|Support vector regression for classifier prediction|In this paper we introduce XCSF with support vector predictionthe problem of learning the prediction function is solved as a support vector regression problem and each classifier exploits a Support Vector Machine to compute the prediction. In XCSF with support vector prediction, XCSFsvm, the genetic algorithm adapts classifier conditions, classifier actions, and the SVM kernel parameters.We compare XCSF with support vector prediction to XCSF with linear prediction on the approximation of four test functions.Our results suggest that XCSF with support vector prediction compared to XCSF with linear prediction (i) is able to evolve accurate approximations of more difficult functions, (ii) has better generalization capabilities and (iii) learns faster.|Daniele Loiacono,Andrea Marelli,Pier Luca Lanzi","65867|AAAI|2006|Closest Pairs Data Selection for Support Vector Machines|This paper presents data selection procedures for support vector machines (SVM). The purpose of data selection is to reduce the dataset by eliminating as many non support vectors (non-SVs) as possible. Based on the fact that support vectors (SVs) are those vectors close to the decision boundary, data selection keeps only the closest pair vectors of opposite classes. The selected dataset will replace the full dataset as the training component for any standard SVM algorithm.|Chaofan Sun","66870|AAAI|2010|Algorithms for Finding Approximate Formations in Games|Practical applications call for efficient model selection criteria for multiclass support vector machine (SVM) classification. To solve this problem, this paper develops two model selection criteria by combining or redefining the radius-margin bound used in binary SVMs. The combination is justified by linking the test error rate of a multiclass SVM with that of a set of binary SVMs. The redefinition, which is relatively heuristic, is inspired by the conceptual relationship between the radius-margin bound and the class separability measure. Hence, the two criteria are developed from the perspective of model selection rather than a generalization of the radius-margin bound for multiclass SVMs. As demonstrated by extensive experimental study, the minimization of these two criteria achieves good model selection on most data sets. Compared with the k-fold cross validation which is often regarded as a benchmark, these two criteria give rise to comparable performance with much less computational overhead, particularly when a large number of model parameters are to be optimized.|Patrick R. Jordan,Michael P. Wellman","57751|GECCO|2006|Evolutionary learning with kernels a generic solution for large margin problems|In this paper we embed evolutionary computation into statistical learning theory. First, we outline the connection between large margin optimization and statistical learning and see why this paradigm is successful for many pattern recognition problems. We then embed evolutionary computation into the most prominent representative of this class of learning methods, namely into Support Vector Machines (SVM). In contrast to former applications of evolutionary algorithms to SVMs we do not only optimize the method or kernel parameters. We rather use both evolution strategies and particle swarm optimization in order to directly solve the posed constrained optimization problem. Transforming the problem into the Wolfe dual reduces the total runtime and allows the usage of kernel functions. Exploiting the knowledge about this optimization problem leads to a hybrid mutation which further decreases convergence time while classification accuracy is preserved. We will show that evolutionary SVMs are at least as accurate as their quadratic programming counterparts on six real-world benchmark data sets. The evolutionary SVM variants frequently outperform their quadratic programming competitors. Additionally, the proposed algorithm is more generic than existing traditional solutions since it will also work for non-positive semidefinite kernel functions and for several, possibly competing, performance criteria.|Ingo Mierswa","58029|GECCO|2007|Hybrid coevolutionary algorithms vs SVM algorithms|As a learning method support vector machine is regarded as one of the best classifiers with a strong mathematical foundation. On the other hand, evolutionary computational technique is characterized as a soft computing learning method with its roots in the theory of evolution. During the past decade, SVM has been commonly used as a classifier for various applications. The evolutionary computation has also attracted a lot of attention in pattern recognition and has shown significant performance improvement on a variety of applications. However, there has been no comparison of the two methods. In this paper, first we propose an improvement of a coevolutionary computational classification algorithm, called Improved Coevolutionary Feature Synthesized EM (I-CFS-EM) algorithm. It is a hybrid of coevolutionary genetic programming and EM algorithm applied on partially labeled data. It requires less labeled data and it makes the test in a lower dimension, which speeds up the testing. Then, we provide a comprehensive comparison between SVM with different kernel functions and I-CFS-EM on several real datasets. This comparison shows that I-CFS-EM outperforms SVM in the sense of both the classification performance and the computational efficiency in the testing phase. We also give an intensive analysis of the pros and cons of both approaches.|Rui Li,Bir Bhanu,Krzysztof Krawiec"],["66446|AAAI|2008|A Demonstration of the RADAR Personal Assistant|Email clients were not designed to serve as a task management tools, but a high volume of task-relevant information in email leads many people to use email clients for this purpose. Such usage aggravates a user's experience of email overload and reduces productivity. Prior research systems have sought to address this problem by experimentally adding task management capabilities to email client software. RADAR (Reflective Agents with Distributed Adaptive Reasoning) takes a different approach in which a software agent acts like a trusted human assistant. Many RADAR components employ machine learning to improve their performance. Human participant studies showed a clear impact of learning on useI peIformance metrics.|Andrew Faulring,Brad A. Myers,Ken Mohnkern,Michael Freed","65048|AAAI|1987|Reactive Reasoning and Planning|In this paper, the reasoning and planning capabilities of an autonomous mobile robot are described. The reasoning system that controls the robot is designed to exhibit the kind of behavior expected of a rational agent, and is endowed with the psychological attitudes of belief, desire, and intention. Because these attitudes are explicitly represented, they can be manipulated and reasoned about, resulting in complex goal-directed and reflective behaviors. Unlike most planning systems, the plans or intentions formed by the robot need only be partly elaborated before it decides to act. This allows the robot to avoid overly strong expectations about the environment, overly constrained plans of action, and other forms of overcommitment common to previous planners. In addition, the robot is continuously reactive and has the ability to change its goals and intentions as situations warrant. The system has been tested with SRI's autonomous robot (Flakey) in a space station scenario involving navigation and the performance of emergency tasks.|Michael P. Georgeff,Amy L. Lansky","58573|GECCO|2009|Environmental robustness in multi-agent teams|Evolution has proven to be an effective method of training heterogeneous multi-agent teams of autonomous agents to explore unknown environments. Autonomous, heterogeneous agents are able to go places where humans are unable to go and perform tasks that would be otherwise dangerous or impossible to complete. However, a serious problem for practical applications of multi-agent teams is how to move from training environments to real-world environments. In particular, if the training environment cannot be made identical to the real-world environment how much will performance suffer In this research we investigate how differences in training and testing environments affect performance. We find that while in general performance degrades from training to testing, for difficult training environments performance improves in the test environment. Further, we find distinct differences between the performance of different training algorithms with Orthogonal Evolution of Teams (OET) producing the best overall performance.|Terence Soule,Robert B. Heckendorn","65566|AAAI|2005|OAR A Formal Framework for Multi-Agent Negotiation|In Multi-Agent systems, agents often need to make decisions about how to interact with each other when negotiating over task allocation. In this paper, we present OAR, a formal framework to address the question of how the agents should interact in an evolving environment in order to achieve their different goals. The traditional categorization of self-interested and cooperative agents is unified by adopting a utility view. We illustrate mathematically that the degree of cooperativeness of an agent and the degree of its selfdirectness are not directly related. We also show how OAR can be used to evaluate different negotiation strategies and to develop distributed mechanisms that optimize the performance dynamically. This research demonstrates that sophisticated probabilistic modeling can be used to understand the behaviors of a system with complex agent interactions.|Jiaying Shen,Ingo Weber,Victor R. Lesser","65912|AAAI|2006|Contract Enactment in Virtual Organizations A Commitment-Based Approach|A virtual organization (VO) is a dynamic collection of entities (individuals, enterprises, and information resources) collaborating on some computational activity. VOs are an emerging means to model, enact, and manage large-scale computations. VOs consist of autonomous, heterogeneous members, often dynamic exhibiting complex behaviors. Thus, VOs are best modeled via multiagent systems. An agent can be an individual such as a person, business partner, or a resource. An agent may also be a VO. A VO is an agent that comprises other agents. Contracts provide a natural arms-length abstraction for modeling interaction among autonomous and heterogeneous agents. The interplay of contracts and VOs is the subject of this paper. The core of this paper is an approach to formalize VOs and contracts based on commitments. Our main contributions are () a formalization of VOs, () a discussion of certain key properties of VOs, and () an identification of a variety of VO structures and an analysis of how they support contract enactment. We evaluate our approach with an analysis of several scenarios involving the handling of exceptions and conflicts in contracts.|Yathiraj B. Udupi,Munindar P. Singh","65374|AAAI|2005|Coordination and Adaptation in Impromptu Teams|Coordinating a team of autonomous agents is one of the major challenges in building effective multiagcnt systems. Many techniques have been devised for this problem. and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques. though. is that the team members are developed together as a whole. In many multi agent scenarios. this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills. models. strategies. and coordination mechanisms. and no external organization is imposed upon them. In particular. we propose two techniques. one adaptive and one predictive. for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.|Michael H. Bowling,Peter McCracken","66245|AAAI|2007|Stochastic Filtering in a Probabilistic Action Model|Stochastic filtering is the problem of estimating the state of a dynamic system after time passes and given partial observations. It is fundamental to automatic tracking, planning, and control of real-world stochastic systems such as robots, programs, and autonomous agents. This paper presents a novel sampling-based filtering algorithm. Its expected error is smaller than sequential Monte Carlo sampling techniques given a fixed number of samples, as we prove and show empirically. It does so by sampling deterministic action sequences and then performing exact filtering on those sequences. These results are promising for applications in stochastic planning, natural language processing, and robot control.|Hannaneh Hajishirzi,Eyal Amir","65277|AAAI|2004|Making Better Recommendations with Online Profiling Agents|In recent years, we have witnessed the success of autonomous agents applying machine learning techniques across a wide range of applications. However, agents applying the same machine learning techniques in online applications have not been so successful. Even agent-based hybrid recommender systems that combine information filtering techniques with collaborative filtering techniques have only been applied with considerable success to simple consumer goods such as movies, books, clothing and food. Complex, adaptive autonomous agent systems that can handle complex goods such as real estate, vacation plans, insurance, mutual funds, and mortgage have yet emerged. To a large extent, the reinforcement learning methods developed to aid agents in learning have been more successfully deployed in offline applications. The inherent limitations in these methods have rendered them somewhat ineffective in online applications. In this paper, we postulate that a small amount of prior knowledge and human-provided input can dramatically speed up online learning. We will demonstrate that our agent HumanE - with its prior knowledge or \"experiences\" about the real estate domain - can effectively assist users in identifying requirements, especially unstated ones, quickly and unobtrusively.|Danny Oh,Chew Lim Tan","65187|AAAI|2004|Intelligent Systems Demonstration The Secure Wireless Agent Testbed SWAT|We will demonstrate the Secure Wireless Agent Testbed (SWAT), a unique facility developed at Drexel University to study integration, networking and information assurance for next-generation wireless mobile agent systems. SWAT is an implemented system that fully integrates ) mobile agents, ) wireless ad hoc multi-hop networks, and ) security. The demonstration will show the functionality of a number of decentralized agent-based applications, including applications for authentication, collaboration, messaging, and remote sensor monitoring. The demonstration will take place on a live mobile ad hoc network consisting of approximately a dozen nodes (PDAs, tablet PCs, and laptops) and hundreds of mobile software agents.|Gustave Anderson,Andrew Burnheimer,Vincent A. Cicirello,David Dorsey,Saturnino Garcia,Moshe Kam,Joseph Kopena,Kris Malfettone,Andrew Mroczkowski,Gaurav Naik,Maxim Peysakhov,William C. Regli,Joshua Shaffer,Evan Sultanik,Kenneth Tsang,Leonardo Urbano,Kyle Usbeck,Jacob Warren","58069|GECCO|2007|SwarmArchitect a swarm framework for collaborative construction|Computer game development has become increasingly popular in the field of autonomous systems. One of the main topics studies the building of various architectures in computer games. A realistic human-like architecture is expected in a thematic computer game, since it strongly motivates the game players in an intuitive way. However, the task of building a human-like architecture is non-trivial since the construction is a real time process without human supervision. In this paper, we present a collective building algorithm inspired by social insects for intelligent construction based on multiple agents. A swarm of virtual agents indirectly design edifications, which resemble basic features in human-like architecture by using a stigmergic mechanism along with branching rules. The main idea of the algorithm is to map sensory information to appropriate building actions.|Yifeng Zeng,Jorge Cordero Hernandez,Dennis Plougman Buus"],["65841|AAAI|2006|A Compact Representation Scheme for Coalitional Games in Open Anonymous Environments|Coalition formation is an important capability of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Recent research has revealed that traditional solution concepts, such as the Shapley value, core, least core, and nucleolus, are vulnerable to various manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names, collusion, and hiding some skills. To address this, a solution concept called the anonymity-proof core, which is robust against such manipulations, was developed. However, the representation size of the outcome function in the anonymity-proof core (and similar concepts) requires space exponential in the number of agentsskills. This paper proposes a compact representation of the outcome function, given that the characteristic function is represented using a recently introduced compact language that explicitly specifies only coalitions that introduce synergy. This compact representation scheme can successfully express the outcome function in the anonymity-proof core. Furthermore, this paper develops a new solution concept, the anonymity-proof nucleolus, that is also expressible in this compact representation. We show that the anonymity-proof nucleolus always exists, is unique, and is in the anonymity-proof core (if the latter is nonempty). and assigns the same value to symmetric skills.|Naoki Ohta,Atsushi Iwasaki,Makoto Yokoo,Kohki Maruono,Vincent Conitzer,Tuomas Sandholm","66590|AAAI|2008|Agent Organized Networks Redux|Individual robots or agents will often need to form coalitions to accomplish shared tasks, e.g., in sensor networks or markets. Furthermore, in most real systems it is infeasible for entities to interact with all peers. The presence of a social network can alleviate this problem by providing a neighborhood system within which entities interact with a reduced number of peers. Previous research has shown that the topology of the underlying social network has a dramatic effect on the quality of coalitions formed and consequently on system performance (Gaston & deslardins a). It has also been shown that it is feasible to develop agents which dynamically alter connections to improve an organization's ability to form coalitions on the network. However those studies have not analysed the network topologies that result from connectivity adaptation strategies. In this paper the resulting network topologies were analysed and it was found that high performance and rapid convergence were attained because scale free networks were being formed. However it was observed that organizational performance is not impacted by limiting the number of links per agent to the total number of skills available within the population. implying that bandwidth was wasted by previous approaches. We used these observations to inform the design of a token based algorithm that attains higher performance using an order of magnitude less messages for both uniform and non-uniform distributions of skills.|Robin Glinton,Katia P. Sycara,Paul Scerri","65566|AAAI|2005|OAR A Formal Framework for Multi-Agent Negotiation|In Multi-Agent systems, agents often need to make decisions about how to interact with each other when negotiating over task allocation. In this paper, we present OAR, a formal framework to address the question of how the agents should interact in an evolving environment in order to achieve their different goals. The traditional categorization of self-interested and cooperative agents is unified by adopting a utility view. We illustrate mathematically that the degree of cooperativeness of an agent and the degree of its selfdirectness are not directly related. We also show how OAR can be used to evaluate different negotiation strategies and to develop distributed mechanisms that optimize the performance dynamically. This research demonstrates that sophisticated probabilistic modeling can be used to understand the behaviors of a system with complex agent interactions.|Jiaying Shen,Ingo Weber,Victor R. Lesser","58382|GECCO|2008|Context-dependent predictions and cognitive arm control with XCSF|While John Holland has always envisioned learning classifier systems (LCSs) as cognitive systems, most work on LCSs has focused on classification, datamining, and function approximation. In this paper, we show that the XCSF classifier system can be very suitably modified to control a robot system with redundant degrees of freedom, such as a robot arm. Inspired by recent research insights that suggest that sensorimotor codes are nearly ubiquitous in the brain and an essential ingredient for cognition in general, the XCSF system is modified to learn classifiers that encode piecewise linear sensorimotor structures, which are conditioned on prediction-relevant contextual input. In the investigated robot arm problem, we show that XCSF partitions the (contextual) posture space of the arm in such a way that accurate hand movements can be predicted given particular motor commands. Furthermore, we show that the inversion of the sensorimotor predictive structures enables accurate goal-directed closed-loop control of arm reaching movements. Besides the robot arm application, we also investigate performance of the modified XCSF system on a set of artificial functions. All results point out that XCSF is a useful tool to evolve problem space partitions that are maximally effective for the encoding of sensorimotor dependencies. A final discussion elaborates on the relation of the taken approach to actual brain structures and cognitive psychology theories of learning and behavior.|Martin V. Butz,Oliver Herbort","66158|AAAI|2007|Interest-Matching Comparisons using CP-nets|The formation of internet-based social networks has revived research on traditional social network models as well as interest-matching, or match-making, systems. In order to automate or augment the process of interest-matching, we describe a method for the comparison of preference orderings represented by CP-nets, which allows one to determine a shared interest level between agents. Empirical results suggest that this distance measure for preference orderings agrees with the intuitive assessment of shared interest levels.|Andrew W. Wicker,Jon Doyle","65374|AAAI|2005|Coordination and Adaptation in Impromptu Teams|Coordinating a team of autonomous agents is one of the major challenges in building effective multiagcnt systems. Many techniques have been devised for this problem. and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques. though. is that the team members are developed together as a whole. In many multi agent scenarios. this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills. models. strategies. and coordination mechanisms. and no external organization is imposed upon them. In particular. we propose two techniques. one adaptive and one predictive. for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.|Michael H. Bowling,Peter McCracken","65277|AAAI|2004|Making Better Recommendations with Online Profiling Agents|In recent years, we have witnessed the success of autonomous agents applying machine learning techniques across a wide range of applications. However, agents applying the same machine learning techniques in online applications have not been so successful. Even agent-based hybrid recommender systems that combine information filtering techniques with collaborative filtering techniques have only been applied with considerable success to simple consumer goods such as movies, books, clothing and food. Complex, adaptive autonomous agent systems that can handle complex goods such as real estate, vacation plans, insurance, mutual funds, and mortgage have yet emerged. To a large extent, the reinforcement learning methods developed to aid agents in learning have been more successfully deployed in offline applications. The inherent limitations in these methods have rendered them somewhat ineffective in online applications. In this paper, we postulate that a small amount of prior knowledge and human-provided input can dramatically speed up online learning. We will demonstrate that our agent HumanE - with its prior knowledge or \"experiences\" about the real estate domain - can effectively assist users in identifying requirements, especially unstated ones, quickly and unobtrusively.|Danny Oh,Chew Lim Tan","65766|AAAI|2006|Lessons on Applying Automated Recommender Systems to Information-Seeking Tasks|Automated recommender systems predict user preferences by applying machine learning techniques to data on products, users, and past user preferences for products. Such systems have become increasingly popular in entertainment and e-commerce domains, but have thus far had little success in information-seeking domains such as identifying published research of interest. We report on several recent publications that show how recommenders can be extended to more effectively address information-seeking tasks by expanding the focus from accurate prediction of user preferences to identifying a useful set of items to recommend in response to the user's specific information need. Specific research demonstrates the value of diversity in recommendation lists, shows how users value lists of recommendations as something different from the sum of the individual recommendations within, and presents an analytic model for customizing a recommender to match user information-seeking needs.|Joseph A. Konstan,Sean M. McNee,Cai-Nicolas Ziegler,Roberto Torres,Nishikant Kapoor,John Riedl","65549|AAAI|2005|Planning for Stream Processing Systems|With the advent of compositional programming models in computer Science, applying planning technologies to automatically build workflows for solving large and complex problems in such a paradigm becomes not only technically appealing but also feasible approach. The application areas that will benefit from automatic composition include, among others, Web services, Grid computing and stream processing systems. Although the classical planning formalism is expressive enough to describe planning problems that arise in a large variety of different applications, it can pose significant limitations on planner performance in compositional applications, in particular, in stream processing systems. In this paper we exlend the classical planning formalism by introducing new language constructs that support the structure of stream processing domains. Exposing this structure to the planner can result in dramatic performance improvements our experiments show exponential planning time reduction in comparison to most recent metric planners.|Anton Riabov,Zhen Liu","65679|AAAI|2006|Nonexistence of Voting Rules That Are Usually Hard to Manipulate|Aggregating the preferences of self-interested agents is a key problem for multiagent systems, and one general method for doing so is to vote over the alternatives (candidates). Unfortunately, the Gibbard-Satterthwaite theorem shows that when there are three or more candidates, all reasonable voting rules are manipulable (in the sense that there exist situations in which a voter would benefit from reporting its preferences insincerely). To circumvent this impossibility result, recent research has investigated whether it is possible to make finding a beneficial manipulation computationally hard. This approach has had some limited success, exhibiting rules under which the problem of finding a beneficial manipulation is NP-hard, P-hard, or even PSPACE-hard. Thus, under these rules, it is unlikely that a computationally efficient algorithm can be constructed that always finds a beneficial manipulation (when it exists). However, this still does not preclude the existence of an efficient algorithm that often finds a successful manipulation (when it exists). There have been attempts to design a rule under which finding a beneficial manipulation is usually hard, but they have failed. To explain this failure, in this paper, we show that it is in fact impossible to design such a rule, if the rule is also required to satisfy another property a large fraction of the manipulable instances are both weakly monotone, and allow the manipulators to make either of exactly two candidates win. We argue why one should expect voting rules to have this property, and show experimentally that common voting rules clearly satisfy it. We also discuss approaches for potentially circumventing this impossibility result.|Vincent Conitzer,Tuomas Sandholm"]]},"title":{"entropy":6.02438972760108,"topics":["and for, the web, the and, semantic web, natural language, reasoning about, constraint satisfaction, for planning, for logic, with constraint, answer set, planning with, with and, planning and, for games, answer programming, and, combinatorial auctions, planning, planning domains","genetic programming, using genetic, neural networks, genetic algorithm, using programming, for networks, genetic for, and genetic, model for, programming for, and programming, search space, using, using and, networks, bayesian networks, using algorithm, model, networks using, evolution strategies","algorithm for, genetic algorithm, the problem, particle swarm, for problem, evolutionary algorithm, for the, for optimization, the, evolutionary for, algorithm the, genetic for, for, algorithm with, algorithm problem, particle optimization, swarm optimization, ant colony, algorithm optimization, solving problem","learning for, reinforcement learning, systems for, learning, classifier systems, artificial immune, for data, support vector, learning and, learning with, systems, from data, systems and, learning classifier, information extraction, for classification, artificial systems, immune systems, using data, vector machine","the web, semantic web, reasoning about, knowledge and, framework for, for reasoning, representation for, for semantic, the semantic, for knowledge, and reasoning, semantic and, for web, representation and, reasoning, the reasoning, web service, and web, the and, reasoning with","and for, the and, for games, constraint satisfaction, for constraint, and, and constraint, with constraint, and its, situation calculus, distributed constraint, general for, integrating and, the games, games, between and, games playing, and search, information and, learning and","search space, and search, search for, for design, and design, using search, model building, genetic search, building blocks, search, for structure, design using, local search, structure and, the search, fault tolerance, simulated annealing, protein prediction, protein structure, genetic structure","for networks, neural networks, networks using, bayesian networks, networks, algorithm networks, and networks, the networks, and neural, neural for, genetic networks, networks with, networks model, social networks, evolution networks, stock markets, sensor networks, for agents, evolving networks, regulatory networks","for optimization, particle swarm, algorithm optimization, solving problem, particle optimization, swarm optimization, evolutionary optimization, optimization, optimization problem, for multi-objective, optimization with, multi-objective evolutionary, multi-objective algorithm, multiobjective optimization, multi-objective optimization, optimization using, and optimization, the optimization, for multiobjective, genetic optimization","ant colony, algorithm for, genetic for, evolutionary computation, selection for, selection algorithm, based algorithm, operator for, the selection, for the, based for, and for, the time, time series, based genetic, adaptive for, techniques for, operator genetic, adaptive algorithm, selection and","learning for, reinforcement learning, learning and, learning, learning with, for detection, learning using, for reinforcement, learning algorithm, learning model, evolutionary learning, the learning, matrix factorization, and detection, for interaction, building blocks, learning from, learning networks, human-robot interaction, detection using","information extraction, common sense, artificial intelligence, large scale, for clustering, for information, combining and, for interactive, for pomdps, and interactive, clustering and, intelligence and, collaborative filtering, for retrieval, mining web, artificial aaai, extraction and, information retrieval, based and, for collaborative"],"ranking":[["65048|AAAI|1987|Reactive Reasoning and Planning|In this paper, the reasoning and planning capabilities of an autonomous mobile robot are described. The reasoning system that controls the robot is designed to exhibit the kind of behavior expected of a rational agent, and is endowed with the psychological attitudes of belief, desire, and intention. Because these attitudes are explicitly represented, they can be manipulated and reasoned about, resulting in complex goal-directed and reflective behaviors. Unlike most planning systems, the plans or intentions formed by the robot need only be partly elaborated before it decides to act. This allows the robot to avoid overly strong expectations about the environment, overly constrained plans of action, and other forms of overcommitment common to previous planners. In addition, the robot is continuously reactive and has the ability to change its goals and intentions as situations warrant. The system has been tested with SRI's autonomous robot (Flakey) in a space station scenario involving navigation and the performance of emergency tasks.|Michael P. Georgeff,Amy L. Lansky","65253|AAAI|2004|Forward-Chaining Planning in Nondeterministic Domains|In this paper, we present a general technique for taking forward-chaining planners for deterministic domains (e.g., HSP, TLPlan, TALplanner, and SHOP) and adapting them to work in nondeterministic domains. Our results suggest that our technique preserves many of the desirable properties of these planners, such as the ability to use heuristic techniques to achieve highly efficient planning. In our experimental studies on two problem domains, the well-known MBP algorithm took exponential time, confirming prior results by others. A nondeterminized version of SHOP took only polynomial time. The polynomial-time figures are confirmed by a complexity analysis, and a similar complexity analysis shows that a nondeterminized version of TLPlan would perform similarly.|Ugur Kuter,Dana S. Nau","65633|AAAI|2006|SEMAPLAN Combining Planning with Semantic Matching to Achieve Web Service Composition|In this paper, we present a novel algorithm to compose Web services in the presence of semantic ambiguity by combining semantic matching and AI planning algorithms. Specifically, we use cues from domain-independent and domain-specific ontologies to compute an overall semantic similarity score between ambiguous terms. This semantic similarity score is used by AI planning algorithms to guide the searching process when composing services. Experimental results indicate that planning with semantic matching produces better results than planning or semantic matching alone. The solution is suitable for semi-automated composition tools or directory browsers.|Rama Akkiraju,Biplav Srivastava,Anca-Andreea Ivan,Richard Goodwin,Tanveer Fathima Syeda-Mahmood","65041|AAAI|1987|An Investigation into Reactive Planning in Complex Domains|A model of purely reactive planning is proposed based on the concept of reactive action packages. A reactive action package, or RAP, can be thought of as an independent entity pursuing some goal in competition with many others at execution time. The RAP processing algorithm addresses the problems of execution monitoring and replanning in uncertain domains with a single, uniform representation and control structure. Use of the RAP model as a basis for adaptive strategic planning is also discussed.|R. James Firby","66193|AAAI|2007|Model-lite Planning for the Web Age Masses The Challenges of Planning with Incomplete and Evolving Domain Models|The automated planning community has traditionally focused on the efficient synthesis of plans given a complete domain theory. In the past several years, this line of work met with significant successes, and the future course of the community seems to be set on efficient planning with even richer models. While this line of research has its applications, there are also many domains and scenarios where the first bottleneck is getting the domain model at any level of completeness. In these scenarios, the modeling burden automatically renders the planning technology unusable. To counter this, I will motivate model-lite planning technology aimed at reducing the domain-modeling burden (possibly at the expense of reduced functionality), and outline the research challenges that need to be addressed to realize it.|Subbarao Kambhampati","65893|AAAI|2006|The Synthy Approach for End to End Web Services Composition Planning with Decoupled Causal and Resource Reasoning|Web services offer a unique opportunity to simplify application integration by defining common, web-based, platform-neutral, standards for publishing service descriptions to a registry, finding and invoking them - not necessarily by the same parties. Viewing software components as web services, the current solutions to web services composition based on business web services (using WSDL, BPEL, SOAP etc.) or semantic web services (using ontologies, goal-directed reasoning etc.) are both piecemeal and insufficient for building practical applications. Inspired by the work in Al planning on decoupling causal (planning) and resource reasoning (scheduling), we introduced the first integrated work in composing web services end to end from specification to deployment by synergistically combining the strengths of the current approaches. The solution is based on a novel two-staged composition approach that addresses the information modeling aspects of web services, provides support for contextual information while composing services, employs efficient decoupling of functional and non-functional requirements, and leads to improved scalability and failure handling. A prototype of the solution has been implemented in the Synthy service composition system and applied to a number of composition scenarios from the telecom domain. The application of planning to web services has also brought new plan and planner usability-driven research issues to the fore for AI.|Biplav Srivastava","66237|AAAI|2007|An Experimental Comparison of Constraint Logic Programming and Answer Set Programming|Answer Set Programming (ASP) and Constraint Logic Programming over finite domains (CLP(FD)) are two declarative progmmming paradigms that have been extensively used to encode applications involving search, optimization, and reasoning (e.g., commonsense reasoning and planning). This paper presents experimental comparisons between the declarative encodings of various computationally hard problems in both frameworks. The objective is to investigate how the solvers in the two domains respond to different problems, highlighting strengths and weaknesses of their implementations, and suggesting criteria for choosing one approach over the other. Ultimately, the work in this paper is expected to lay the foundations for transfer of technology between the two domains, e.g., suggesting ways to use CLP(FD) in the execution of ASP.|Agostino Dovier,Andrea Formisano,Enrico Pontelli","66048|AAAI|2007|A Planning Approach for Message-Oriented Semantic Web Service Composition|In this paper, we consider the problem of composing a set of web services, where the requirements are specified in terms of the input and output messages of the composite workflow. We propose a semantic model of messages using RDF graphs that encode OWL ABox assertions. We also propose a model of web service operations where the input message requirements and output message characteristics are modeled using RDF graph patterns. We formulate the message-oriented semantic web service composition problem and show how it can be translated into a planning problem. There are, however, significant challenges in scalably doing planning in this domain, especially since DL reasoning may be performed to check if an operation can be given a certain input message. We propose a two-phase planning algorithm that incorporates DLP reasoning and evaluate the performance of this planning algorithm.|Zhen Liu,Anand Ranganathan,Anton Riabov","65613|AAAI|2005|Learning Measures of Progress for Planning Domains|We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress (parmar ), which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results.|Sung Wook Yoon,Alan Fern,Robert Givan","66724|AAAI|2010|Transferable Utility Planning Games|An immune chaos genetic algorithm is presented to keep population's diversity, avoid local optimum and improve performance of genetic algorithm. Immune selection is used to adjust antibody's density, and the advantage of individuals is exerted by introducing vaccination. By virtue of the over-spread character of chaos sequence, it is used to generate the pool of antibody to overcome redundancies. At the same time, searching space is enlarged by using sensitivity of chaos initial value. The result of simulation experiments shows that the algorithm has good performance in the aspects of both the convergence speed and the global optimum.|Ronen I. Brafman,Carmel Domshlak,Yagil Engel,Moshe Tennenholtz"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","58865|GECCO|2009|On the evolution of neural networks for pairwise classification using gene expression programming|Neural networks are a common choice for solving classification problems, but require experimental adjustments of the topology, weights and thresholds to be effective. Success has been seen in the development of neural networks with evolutionary algorithms, making the extension of this work to classification problems a logical step. This paper presents the first known use of the Gene Expression Programming-based GEP-NN algorithm to design neural networks for classification purposes. The system uses pairwise decomposition to produce a series of binary classifiers for a given multi-class problem, with the results of the classifier set being combined by majority vote.|Stephen Johns,Marcus V. dos Santos","57769|GECCO|2006|Inference of genetic networks using S-system information criteria for model selection|In this paper we present an evolutionary approach for inferring the structure and dynamics in gene circuits from observed expression kinetics. For representing the regulatory interactions in a genetic network the decoupled S-system formalism has been used. We proposed an Information Criteria based fitness evaluation for model selection instead of the traditional Mean Squared Error (MSE) based fitness evaluation. A hill climbing local search method has been incorporated in our evolutionary algorithm for attaining the skeletal architecture which is most frequently observed in biological networks. Using small and medium-scale artificial networks we verified the implementation. The reconstruction method identified the correct network topology and predicted the kinetic parameters with high accuracy.|Nasimul Noman,Hitoshi Iba","66770|AAAI|2010|The Genetic Algorithm as a General Diffusion Model for Social Networks|Link-based ranking has contributed significantly to the success of Web search. PageRank and HITS are the best known link-based ranking algorithms. These algorithms do not consider an important dimension, the temporal dimension. They favor older pages because these pages have many in-links accumulated over time. Bringing new and quality pages to the users is important because most users want the latest information. Existing remedies to PageRank are mostly heuristic approaches. This paper investigates the temporal aspect of ranking with application to publication search, and proposes a principled method based on the stationary probability distribution of the Markov chain. The proposed techniques are evaluated empirically using a large collection of high energy particle physics publication. The results show that the proposed methods are highly effective.|Mayank Lahiri,Manuel Cebri√°n","65650|AAAI|2006|Acquiring Constraint Networks Using a SAT-based Version Space Algorithm|Constraint programming is a commonly used technology for solving complex combinatorial problems. However, users of this technology need significant expertise in order to model their problems appropriately. We propose a basis for addressing this problem a new SAT-based version space algorithm for acquiring constraint networks from examples of solutions and non-solutions of a target problem. An important advantage of the algorithm is the ease with which domain-specific knowledge can be exploited.|Christian Bessi√®re,Remi Coletta,Fr√©d√©ric Koriche,Barry O'Sullivan","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","58617|GECCO|2009|Overcoming partitioning in large ad hoc networks using genetic algorithms|We deal in this paper with the important problem of partitioning in ad hoc networks. In our approach, we assume that some devices might have other communication interfaces rather than Wi-Fi andor Bluetooth allowing to connect remote devices (e.g., technologies such as GPRS or HSDPA). This would allow us to build hybrid networks for overcoming the network partitioning. Hence, the problem considered in this work is to establish remote links between devices (called bypass links) in order to maximize the QoS of the network by optimizing its properties to make it small world. Additionally, the number of this kind of links in the network should be minimized as well, since we consider that not all the devices have these communication capabilities, or it could be a requirement to minimize the use of the long range network (for example, in the case its use supposes some cost). We face the problem with four different GAs (both parallel and sequential) and compare their behaviors on six different network instances. All the algorithms were tested with a new encoding of the problem, which is demonstrated to provide more accurate results than the previously existing one.|Gr√©goire Danoy,Bernab√© Dorronsoro,Pascal Bouvry","57930|GECCO|2007|Optimal design of ad hoc injection networks by using genetic algorithms|This work aims at optimizing injection networks, which consist in adding a set of long-range links (called bypass links) in mobile multi-hop ad hoc networks so as to improve connectivity and overcome network partitioning. To this end, we rely on small-world network properties, that comprise a high clustering coefficient and a low characteristic path length. We investigate the use of two genetic algorithms (generational and steady-state) to optimize three instances of this topology control problem and present results that show initial evidence of their capacity to solve it.|Gr√©goire Danoy,Enrique Alba,Pascal Bouvry,Matthias R. Brust","58715|GECCO|2009|Pareto front feature selection using genetic programming to explore feature space|In this paper we use genetic programming (GP) for feature selection in binary classification tasks. Mathematical expressions built by GP transform the feature space in a way that the relevance of subsets of features can be measured using a simple relevance function. We make some modifications to the standard GP to make it explore large subsets of features when necessary. This is done by increasing the depth limit at run-time and at the same time trying to avoid bloating and overfitting by some control mechanism. We take a filter (non-wrapper) approach to exploring the search space. Unlike most filter methods that usually deal with single features, we explore subsets of features. The solution of the proposed search is a vector of Pareto-front points. Our experiments show that a linear search over this vector can improve the classification performance of classifiers while decreasing their complexity.|Kourosh Neshatian,Mengjie Zhang"],["58756|GECCO|2009|Cheating for problem solving a genetic algorithm with social interactions|We propose a variation of the standard genetic algorithm that incorporates social interaction between the individuals in the population. Our goal is to understand the evolutionary role of social systems and its possible application as a non-genetic new step in evolutionary algorithms. In biological populations, i.e. animals, even human beings and microorganisms, social interactions often affect the fitness of individuals. It is conceivable that the perturbation of the fitness via social interactions is an evolutionary strategy to avoid trapping into local optimum, thus avoiding a fast convergence of the population. We model the social interactions according to Game Theory. The population is, therefore, composed by cooperator and defector individuals whose interactions produce payoffs according to well known game models (prisoner's dilemma, chicken game, and others). Our results on Knapsack problems show, for some game models, a significant performance improvement as compared to a standard genetic algorithm.|Rafael Lahoz-Beltra,Gabriela Ochoa,Uwe Aickelin","58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Su√°rez,Manuel Valenzuela-Rend√≥n,Hugo Terashima-Mar√≠n,Eduardo Uresti-Charre","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57972|GECCO|2007|Kernel based automatic clustering using modified particle swarm optimization algorithm|This paper introduces a method for clustering complex and linearly non-separable datasets, without any prior knowledge of the number of naturally occurring clusters. The proposed method is based on an improved variant of the Particle Swarm Optimization (PSO) algorithm. In addition, it employs a kernel-induced similarity measure instead of the conventional sum-of-squares distance. Use of the kernel function makes it possible to cluster data that is linearly non-separable in the original input space into homogeneous groups in a transformed high-dimensional feature space. Computer simulations have been undertaken with a test bench of five synthetic and three real life datasets, in order to compare the performance of the proposed method with a few state-of-the-art clustering algorithms. The results reflect the superiority of the proposed algorithm in terms of accuracy, convergence speed and robustness.|Ajith Abraham,Swagatam Das,Amit Konar","58491|GECCO|2008|Convergence behavior of the fully informed particle swarm optimization algorithm|The fully informed particle swarm optimization algorithm (FIPS) is very sensitive to changes in the population topology. The velocity update rule used in FIPS considers all the neighbors of a particle to update its velocity instead of just the best one as it is done in most variants. It has been argued that this rule induces a random behavior of the particle swarm when a fully connected topology is used. This argument could explain the often observed poor performance of the algorithm under that circumstance. In this paper we study experimentally the convergence behavior of the particles in FIPS when using topologies with different levels of connectivity. We show that the particles tend to search a region whose size decreases as the connectivity of the population topology increases. We therefore put forward the idea that spatial convergence, and not a random behavior, is the cause of the poor performance of FIPS with a fully connected topology. The practical implications of this result are explored.|Marco Antonio Montes de Oca,Thomas St√ºtzle","57274|GECCO|2005|Heuristic rules embedded genetic algorithm to solve in-core fuel management optimization problem|Because of the large number of possible combinations for the fuel assembly loading in the core, the design of the loading pattern (LP) is a complex optimization problem. It requires finding an optimal fuel arrangement in order to achieve maximum cycle length while satisfying the safety constraints. The objective of this study is to develop a loading pattern optimization code. Generally in-core fuel management codes are written for specific cores and limited fuel inventory. One of the goals of this study is to develop a loading pattern optimization code, which is applicable for all types of Pressurized Water Reactor (PWR) core structures with unlimited number of fuel assembly types in the inventory. To reach this goal an innovative genetic algorithm is developed with modifying the classical representation of the genotype. To obtain the best result in a shorter time not only the representation is changed but also the algorithm is changed to use in-core fuel management heuristics rules. The improved GA code was tested demonstrating the advantages of the introduced enhancements. The core physics code used in this research is Moby-Dick, which was developed to analyze the VVER reactors by SKODA Inc.|Fatih Alim,Kostadin Ivanov","58759|GECCO|2009|The singly-linked ring topology for the particle swarm optimization algorithm|This paper introduces a new neighborhood structure for Particle Swarm Optimization, called Singly-Linked Ring. The approach proposes a neighborhood whose members share the information at a different rate. The objective is to avoid the premature convergence of the flock and stagnation into local optimal. The approach is applied at a set of global optimization problems commonly used in the literature. The singly-linked structure is compared against the state-of-the-art neighborhoods structures. The proposal is easy to implement, and its results and its convergence performance are better than other structures.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["58941|GECCO|2010|On the problems of using learning classifier systems for fraud detection|Fraud detection problems have some uniquely challenging properties which make them difficult. In this paper, we investigate the fraud detection problem by describing the common properties of electronic fraud and examining how learning classifier systems (LCSs) can be applied to it. Also, we introduce \"random Boolean function\" (RBF) an abstract problem with high level of controllability which can be tuned to exhibit those characteristics individually, and report the results of using XCSR (a continuous variant of LCS) on RBF problem and also on a real-world problem. Results from our experiments demonstrate that XCSR can overcome most of the difficulties inherent to the fraud detection problem and can achieve good performance in case of the real-world problem.|Mohammad Behdad,Tim French,Luigi Barone,Mohammed Bennamoun","57595|GECCO|2006|Coordination number prediction using learning classifier systems performance and interpretability|The prediction of the coordination number (CN) of an amino acid in a protein structure has recently received renewed attention. In a recent paper, Kinjo et al. proposed a real-valued definition of CN and a criterion to map it onto a finite set of classes, in order to predict it using classification approaches. The literature reports several kinds of input information used for CN prediction. The aim of this paper is to assess the performance of a state-of-the-art learning method, Learning Classifier Systems (LCS) on this CN definition, with various degrees of precision, based on several combinations of input attributes. Moreover, we will compare the LCS performance to other well-known learning techniques. Our experiments are also intended to determinethe minimum set of input information needed to achieve good predictive performance, so as to generate competent yet simple and interpretable classification rules. Thus, the generated predictors (rule sets) are analyzed for their interpretability.|Jaume Bacardit,Michael Stout,Natalio Krasnogor,Jonathan D. Hirst,Jacek Blazewicz","65519|AAAI|2005|Data-Driven MCMC for Learning and Inference in Switching Linear Dynamic Systems|Switching Linear Dynamic System (SLDS) models are a popular technique for modeling complex nonlinear dynamic systems. An SLDS has significantly more descriptive power than an HMM, but inference in SLDS models is computationally intractable. This paper describes a novel inference algorithm for SLDS models based on the Data-Driven MCMC paradigm. We describe a new proposal distribution which substantially increases the convergence speed. Comparisons to standard deterministic approximation methods demonstrate the improved accuracy of our new approach. We apply our approach to the problem of learning an SLDS model of the bee dance. Honeybees communicate the location and distance to food sources through a dance that takes place within the hive. We learn SLDS model parameters from tracking data which is automatically extracted from video. We then demonstrate the ability to successfully segment novel bee dances into their constituent parts, effectively decoding the dance of the bees.|Sang Min Oh,James M. Rehg,Tucker R. Balch,Frank Dellaert","57218|GECCO|2003|Towards Learning Classifier Systems for Continuous-Valued Online Environments|Previous work has studied the use of interval representations in XCS to allow its use in continuous-valued environments. Here we compare the speed of learning of continuous-valued versions of ZCS and XCS with a simple model of an online environment.|Christopher Stone,Larry Bull","57733|GECCO|2006|Fast rule matching for learning classifier systems via vector instructions|Over the last ten years XCS has become the standard for Michigan-style learning classifier systems (LCS). Since the initial CS- work conceived by Holland, classifiers (rules) have widely used a ternary condition alphabet ,, for binary input problems. Most of the freely available implementations of this ternary alphabet in XCS rely on character-based encodings---easy to implement, not memory efficient, and expensive to compute. Profiling of freely available XCS implementations shows that most of their execution time is spent determining whether a rule is match or not, posing a serious threat to XCS scalability. In the last decade, multimedia and scientific applications have pushed CPU manufactures to include native support for vector instruction sets. This paper presents how to implement efficient condition encoding and fast rule matching strategies using vector instructions. The paper elaborates on Altivec (PowerPC G, G) and SSE (Intel PXeon and AMD Opteron) instruction sets producing speedups of XCS matching process beyond ninety times. Moreover, such a vectorized matching code will allow to easily scale beyond tens of thousands of conditions in a reasonable time. The proposed fast matching scheme also fits in any other LCS other than XCS.|Xavier Llor√†,Kumara Sastry","58220|GECCO|2007|Initial results from the use of learning classifier systems to control neuronal networks|In this paper we describe the use of a learning classifier system to control the electrical stimulation of cultured neuronal networks. The aim is to manipulate the environment of the cells such that they display elementary learning, i.e., so that they respond to a given input signal in a pre-specified way. Results indicate that this is possible and that the learned stimulation protocols identify seemingly fundamental properties of in vitro neuronal networks.allUse of another learning scheme and simpler stimulation confirms these properties.|Larry Bull,Ivan S. Uroukov","57507|GECCO|2005|Event-driven learning classifier systems for online soccer games|This paper reports on the application of classifier systems to the acquisition of decision-making algorithms for agents in online soccer games. The objective of this research is to support changes in the video-game environment brought on by the Internet and to enable the provision of bug-free programs in a short period of time. To achieve real-time learning during a game, a bucket brigade algorithm is used to reinforce learning by classifiers and a technique for selecting learning targets according to event frequency is adopted. A hybrid system combining an existing strategy algorithm and a classifier system is also employed. In experiments that observed the outcome of , soccer games between this event-driven classifier system and a human-designed algorithm, the proposed system was found to be capable of learning effective decision-making algorithms in real time.|Yuji Sato,Ryutaro Kanno","57748|GECCO|2006|A representational ecology for learning classifier systems|The representation used by a learning algorithm introduces a bias which is more or less well-suited to any given learning problem. It is well known that, across all possible problems, one algorithm is no better than any other. Accordingly, the traditional approach in machine learning is to choose an appropriate representation making use of some domain-specific knowledge, and this representation is then used exclusively during the learning process.To reduce reliance on domain-knowledge and its appropriate use it would be desirable for the learning algorithm to select its own representation for the problem.We investigate this with XCS, a Michigan-style Learning Classifier System.We begin with an analysis of two representations from the literature hyperplanes and hyperspheres. We then apply XCS with either one or the other representation to two Boolean functions, the well-known multiplexer function and a function defined by hyperspheres, and confirm that planes are better suited to the multiplexer and spheres to the sphere-based function.Finally, we allow both representations to compete within XCS, which learns the most appropriate representation for problem thanks to the pressure against overlapping rules which its niche GA supplies. The result is an ecology in which the representations are species.|James A. R. Marshall,Tim Kovacs","58397|GECCO|2008|An analysis of matching in learning classifier systems|We investigate rule matching in learning classifier systems for problems involving binary and real inputs. We consider three rule encodings the widely used character-based encoding, a specificity-based encoding, and a binary encoding used in Alecsys. We compare the performance of the three algorithms both on matching alone and on typical test problems. The results on matching alone show that the population generality influences the performance of the matching algorithms based on string representations in different ways. Character-based encoding becomes slower and slower as generality increases, specificity-based encoding becomes faster and faster as generality increases. The results on typical test problems show that the specificity-based representation can halve the time required for matching but also that binary encoding is about ten times faster on the most difficult problems. Moreover, we extend specificity-based encoding to real-inputs and propose an algorithm that can halve the time require for matching real inputs using an interval-based representation.|Martin V. Butz,Pier Luca Lanzi,Xavier Llor√†,Daniele Loiacono","57601|GECCO|2006|A Bayesian approach to learning classifier systems in uncertain environments|In this paper we propose a Bayesian framework for XCS , called BXCS. Following , we use probability distributions to represent the uncertainty over the classifier estimates of payoff. A novel interpretation of classifier and an extension of the accuracy concept are presented. The probabilistic approach is aimed at increasing XCS learning capabilities and tendency to evolve accurate, maximally general classifiers, especially when uncertainty affects the environment or the reward function. We show that BXCS can approximate optimal solutions in stochastic environments with a high level of uncertainty.|Davide Aliprandi,Alex Mancastroppa,Matteo Matteucci"],["66910|AAAI|2010|A General Framework for Representing and Reasoning with Annotated Semantic Web Data|Analyzed the energy consumption disciplinarian of the nodes in WSN, the node's energy attenuation forecast model (EAFM) can be established. A difference-threshold reporting mechanism (DTRM) is used to report the residual energy of nodes. The energy collection mechanism based on EAFM and DTRM can reduce energy data reporting times significantly, improve the efficient of energy data collection, save the node's energy at the same time. The experiments in the platform of telosb nodes show that the predicable rate is between % and %, and this method can extend the node's life by %  .%.|Umberto Straccia,Nuno Lopes 0002,Gergely Lukacsy,Axel Polleres","66108|AAAI|2007|Making the Difference in Semantic Web Service Composition|Automation of Web service composition is one of the most interesting challenges facing the Semantic Web today. In this paper we propose a mean of performing automated Web service composition by exploiting semantic matchmaking between Web service parameters (i.e., outputs and inputs) to enable their connection and interaction. The key idea is that the matchmaking enables, at run time, finding semantic compatibilities among independently defined Web service descriptions. To this end, our approach extends existing methods in order to explain misconnections between Web services. From this we generate Web service compositions that realize the goal, satisfying and optimizing the semantic connections between Web services. Moreover a process of relaxing the hard constraints is introduced in case the composition process failed. Our system is implemented and interacting with Web services dedicated on a Telecom scenario. The preliminary evaluation results showed high efficiency and effectiveness of the proposed approach.|Freddy L√©cu√©,Alexandre Delteil","65756|AAAI|2006|Using Semantic Web Technologies for Policy Management on the Web|With policy management becoming popular as a means of providing flexible Web security, the number of policy languages being proposed for the Web is constantly increasing. We recognize the importance of policies for securing the Web and believe that the future will only bring more policy languages. We do not, however, believe that users should be forced to conform the description of their policy relationships to a single standard policy language. Instead there should be a way of encompassing different policy languages and supporting heterogeneous policy systems. As a step in this direction, we propose Rein, a policy framework grounded in Semantic Web technologies, which leverages the distributed nature and linkability of the Web to provide Web-based policy management. Rein provides ontologies for describing policy domains in a decentralized manner and provides an engine for reasoning over these descriptions, both of which can be used to develop domain and policy language specific security systems. We describe the Rein policy framework and discuss how a Rein policy management systems can be developed for access control in an online photo sharing application.|Lalana Kagal,Tim Berners-Lee,Dan Connolly,Daniel J. Weitzner","65633|AAAI|2006|SEMAPLAN Combining Planning with Semantic Matching to Achieve Web Service Composition|In this paper, we present a novel algorithm to compose Web services in the presence of semantic ambiguity by combining semantic matching and AI planning algorithms. Specifically, we use cues from domain-independent and domain-specific ontologies to compute an overall semantic similarity score between ambiguous terms. This semantic similarity score is used by AI planning algorithms to guide the searching process when composing services. Experimental results indicate that planning with semantic matching produces better results than planning or semantic matching alone. The solution is suitable for semi-automated composition tools or directory browsers.|Rama Akkiraju,Biplav Srivastava,Anca-Andreea Ivan,Richard Goodwin,Tanveer Fathima Syeda-Mahmood","65625|AAAI|2006|A Platform to Evaluate the Technology for Service Discovery in the Semantic Web|Since the description of the Semantic Web paradigm in , technology has been proposed to allow its deployment and use. However, there is not yet any large and widely deployed set of semantically annotated Web resources available. As a result, it is not possible to evaluate the use of the technology in a real environment, and several assumptions about how the Semantic Web should work are emerging. In order to further investigate these assumptions and the related technology, we propose a simulation and evaluation platform. The platform provides tools to create Semantic Web simulations using different technologies for different purposes, and to evaluate their performance. In this paper we introduce the model of the platform and describe the current implementation. The implementation facilitates the integration of technology for an essential operation on the Semantic Web, namely Semantic Web service discovery. We illustrate the use of the platform in a case study by implementing a Semantic Web where the Jade multi-agent platform provides the framework to describe the agents, and a number of existing Semantic Web technologies are embedded in agent behavior.|C√©cile Aberg,Johan Aberg,Patrick Lambrix,Nahid Shahmehri","66048|AAAI|2007|A Planning Approach for Message-Oriented Semantic Web Service Composition|In this paper, we consider the problem of composing a set of web services, where the requirements are specified in terms of the input and output messages of the composite workflow. We propose a semantic model of messages using RDF graphs that encode OWL ABox assertions. We also propose a model of web service operations where the input message requirements and output message characteristics are modeled using RDF graph patterns. We formulate the message-oriented semantic web service composition problem and show how it can be translated into a planning problem. There are, however, significant challenges in scalably doing planning in this domain, especially since DL reasoning may be performed to check if an operation can be given a certain input message. We propose a two-phase planning algorithm that incorporates DLP reasoning and evaluate the performance of this planning algorithm.|Zhen Liu,Anand Ranganathan,Anton Riabov","66901|AAAI|2010|Framework and Schema for Semantic Web Knowledge Bases|This paper presents a file transfer global dynamic scheduling algorithm that incorporates the two optimizations of multi-hop path splitting and multi-pathing in conjunction with the use of available file replicas, This algorithm makes use of information from past GridFTP transfers to estimate network bandwidths and resource availability. The experimental results show that this algorithm achieve significant performance improvement.|James P. McGlothlin","65845|AAAI|2006|An Investigation into the Feasibility of the Semantic Web|We investigate the challenges that must be addressed for the Semantic Web to become a feasible enterprise. Specifically we focus on the query answering capability of the Semantic Web. We put forward that two key challenges we face are heterogeneity and scalability. We propose a flexible and decentralized framework for addressing the heterogeneity problem and demonstrate that sufficient reasoning is possible over a large dataset by taking advantage of database technologies and making some tradeoff decisions. As a proof of concept, we collect a significant portion of the available Semantic Web data use our framework to resolve some heterogeneity and reason over the data as one big knowledge base. In addition to demonstrating the feasibility of a \"real\" Semantic Web, our experiments have provided us with some interesting insights into how it is evolving and the type of queries that can be answered.|Zhengxiang Pan,Abir Qasem,Jeff Heflin","66162|AAAI|2007|Reasoning about Attribute Authenticity in a Web Environment|The reliable authentication of user attributes is an important prerequisite for the security of web based applications. Digital certificates are widely used for that purpose. However, practical certification scenarios can be very complex. Each certiticate carries a validity period and can be revoked during this period. Furthermore, the verifying user has to trust the issuers of certificates and revocations. This work presents a formal model which covers these aspects and provides a theoretical foundation for the decision about attribute authenticity even in complex scenarios. The model is based on the event calculus, an AI technique from the field of temporal reasoning. It uses Clark's completion to address the frame problem. An example illustrates the application of the model.|Thomas W√∂lfl","65725|AAAI|2006|Bounded Treewidth as a Key to Tractability of Knowledge Representation and Reasoning|Several forms of reasoning in AI - like abduction, closed world reasoning, circumscription, and disjunctive logic programming - are well known to be intractable. In fact, many of the relevant problems are on the second or third level of the polynomial hierarchy. In this paper, we show how the notion of treewidth can be fruitfully applied to this area. In particular, we show that all these problems become tractable (actually, even solvable in linear time), if the treewidth of the involved formulae or programs is bounded by some constant. Clearly, these theoretical tractability results as such do not immediately yield feasible algorithms. However, we have recently established a new method based on monadic datalog which allowed us to design an efficient algorithm for a related problem in the database area. In this work, we exploit the monadic datalog approach to construct new algorithms for logic-based abduction.|Georg Gottlob,Reinhard Pichler,Fang Wei"],["66705|AAAI|2010|Integrating Constraint Satisfaction and Spatial Reasoning|Chip multithreading is exposed to dual challenges of increasing chip complexity and design variations. It is important to develop effective reliability-enhancing schemes to ensure robust computing. In this paper, we propose the immediate write-back and self-recovery schemes to reduce error accumulation effect in multithreaded memory systems. These schemes are built upon the previously proposed dynamic multithreading redundancy technique for improving reliability in multithreaded architectures. The idea of DMR is to exploit self-generated hardware redundancy due to inter-thread variations inherent in multithreaded architectures. Simulation results demonstrate that the proposed solutions improve error-control performance with minimal hardware overheads. The proposed immediate write-back and self-recovery schemes also feature good scalability for future process generations|Unmesh Kurup,Nicholas L. Cassimatis","66764|AAAI|2010|Reasoning about Imperfect Information Games in the Epistemic Situation Calculus|In the past years dynamic voltage and frequency scaling (DVFS) has been an effective technique that allowed microprocessors to match a predefined power budget. However, as process technology shrinks, DVFS becomes less effective (because of the increasing leakage power) and it is getting closer to a point where DVFS won't be useful at all (when static power exceeds dynamic power). In this paper we propose the use of microarchitectural techniques to accurately match a power constraint while maximizing the energy efficiency of the processor. We predict the processor power consumption at a basic block level, using the consumed power translated into tokens to select between different power-saving micro-architectural techniques. These techniques are orthogonal to DVFS so they can be simultaneously applied. We propose a two-level approach where DVFS acts as a coarse-grained technique to lower the average power while microarchitectural techniques remove all the power spikes efficiently. Experimental results show that the use of power-saving microarchitectural techniques in conjunction with DVFS is up to six times more precise, in terms of total energy consumed (area) over the power budget, than using DVFS alone for matching a predefined power budget. Furthermore, in a near future DVFS will become DFS because lowering the supply voltage will be too expensive in terms of leakage power. At that point, the use of power-saving microarchitectural techniques will become even more energy efficient.|Vaishak Belle,Gerhard Lakemeyer","65781|AAAI|2006|Weighted Constraint Satisfaction with Set Variables|Set variables are ubiquitous in modeling (soft) constraint problems, but efforts on practical consistency algorithms for Weighted Constraint Satisfaction Problems (WCSPs) have only been on integer variables. We adapt the classical notion of set bounds consistency for WCSPs, and propose efficient representation schemes for set variables and common unary, binary, and ternary set constraints, as well as cardinality constraints. Instead of reasoning consistency on an entire set variable directly, we propose local consistency check at the set element level, and demonstrate that this apparent \"micro\"-management of consistency does imply set bounds consistency at the variable level. In addition, we prove that our framework captures classical CSPs with set variables, and degenerates to the classical case when the weights in the problem contain only  and T. Last but not least, we verify the feasibility and efficiency of our proposal with a prototype implementation, the efficiency of which is competitive against ILOG Solver on classical problems and orders of magnitude better than WCSP models using - variables to simulate set variables on soft problems.|J. H. M. Lee,C. F. K. Siu","65196|AAAI|2004|Domain Transmutation in Constraint Satisfaction Problems|We study local interchangeability of values in constraint networks based on a new approach where a single value in the domain of a variable can be treated as a combination of \"subvalues\". We present an algorithm for breaking up values and combining identical fragments. Experimental results show that the transformed problems take less time to solve for all solutions and yield more compactly-representable, but equivalent, solution sets. We obtain new theoretical results on context dependent interchangeability and full interchangeability, and suggest some other applications.|James Bowen,Chavalit Likitvivatanavong","65206|AAAI|2004|Collapsibility and Consistency in Quantified Constraint Satisfaction|The concept of consistency has pervaded studies of the constraint satisfiction problem. We introduce two concepts, which are inspired by consistency, for the more general framework of the quantified constraint satisfaction problem (QCSP). We use these concepts to derive, in a uniform fashion, proofs of polynomial-time tractability and corresponding algorithms for certain cases of the QCSP where the types of allowed relations are restricted. We not only unify existing tractability results and algorithms, but also identify new classes of tractable QCSPs.|Hubie Chen","66125|AAAI|2007|Transposition Tables for Constraint Satisfaction|In this paper, a state-based approach for the Constraint Satisfaction Problem (CSP) is proposed. The key novelty is an original use of state memorization during search to prevent the exploration of similar subnetworks. Classical techniques to avoid the resurgence of previously encountered conflicts involve recording conflict sets. This contrasts with our state-based approach which records subnetworks - a snapshot of some selected domains - already explored. This knowledge is later used to either prune inconsistent states or avoid recomputing the solutions of these subnetworks. Interestingly enough, the two approaches present some complementarity different states can be pruned from the same partial instantiation or conflict set, whereas different partial instantiations can lead to the same state that needs to be explored only once. Also, our proposed approach is able to dynamically break some kinds of symmetries (e.g. neighborhood interchangeability). The obtained experimental results demonstrate the promising prospects of state-based search.|Christophe Lecoutre,Lakhdar Sais,S√©bastien Tabary,Vincent Vidal","65506|AAAI|2005|A Constraint Satisfaction Approach to Geospatial Reasoning|The large number of data sources on the Internet can be used to augment and verify the accuracy of geospatial sources, such as gazetteers and annotated satellite imagery. Data sources such as satellite imagery, maps, gazetteers and vector data have been traditionally used in geographic infonnation systems (GIS), but nontraditional geospatial data, such as online phone books and property records are more difficult to relate to imagery. In this paper, we present a novel approach to combining extracted information from imagery, road vector data, and online data sources. We represent the problem of identifying buildings in satellite images as a constraint satisfing problem (CSP) and use constraint programming to solve it. We apply this technique to real-world data sources in EI Segundo, CA and our experimental evaluation shows how this approach can accurately identify buildings when provided with both traditional and nontraditional data sources.|Martin Michalowski,Craig A. Knoblock","66467|AAAI|2008|Dynamic Distributed Constraint Reasoning|What local action can agents take, without the benefit of global knowledge, to produce the best global solution Many dynamic distributed systems can be modeled using techniques from distributed constraint reasoning, however, existing work in the distributed constraint reasoning community does not address the true dynamism inherent in many real-world systems.|Robert N. Lass,Evan Sultanik,William C. Regli","65241|AAAI|2004|Robust Solutions for Constraint Satisfaction and Optimization|Super solutions are solutions in which, if a small number of variables lose their values, we are guaranteed to be able to repair the solution with only a few changes. In this paper, we stress the need to extend the super solution framework along several dimensions to make it more useful practically. We demonstrate the usefulness of those extensions on an example from jobshop scheduling, an optimization problem solved through constraint satisfaction. In such a case there is indeed a trade-off between optimality and robustness, however robustness may be increased without sacrificing optimality.|Emmanuel Hebrard","66469|AAAI|2008|Anytime Local Search for Distributed Constraint Optimization|Most former studies of Distributed Constraint Optimization Problems (DisCOPs) search considered only complete search algorithms, which are practical only for relatively small problems. Distributed local search algorithms can be used for solving DisCOPs. However, because of the differences between the global evaluation of a system's state and the private evaluation of states by agents, agents are unaware of the global best state which is explored by the algorithm. Previous attempts to use local search algorithms for solving DisCOPs reported the state held by the system at the termination of the algorithm, which was not necessarily the best state explored. A general framework for implementing distributed local search algorithms for DisCOPs is proposed. The proposed framework makes use of a BFS-tree in order to accumulate the costs of the system's state in its different steps and to propagate the detection of a new best step when it is found. The resulting framework enhances local search algorithms for DisCOPs with the anytime property. The proposed framework does not require additional network load. Agents are required to hold a small (linear) additional space (beside the requirements of the algorithm in use). The proposed framework preserves privacy at a higher level than complete Dis-COP algorithms which make use ofa pseudo-tree (ADOPT, DPOP).|Roie Zivan"],["66555|AAAI|2008|Protein Structure Prediction on the Face Centered Cubic Lattice by Local Search|Ab initio protein structure prediction is an important problem for which several algorithms have been developed. Algorithms differ by how they represent D protein conformations (on-lattice, off-lattice, coarse-grain or fine-grain model), by the energy model they consider, and whether they are heuristic or exact algorithms. This paper presents a local search algorithm to find the native state for the Hydrophobic-Polar (HP) model on the Face Centered Cubic (FCC) lattice i.e. a self-avoiding walk on the FCC lattice with maximum number of H-H contacts. The algorithm relies on a randomized, structured initialization, a novel fitness function to guide the search, and efficient data structures to obtain self-avoiding walks. Experimental results on benchmark instances show the efficiency and excellent performance of our algorithm, and illustrate the biological pertinence of the FCC lattice.|Manuel Cebri√°n,Iv√°n Dot√∫,Pascal Van Hentenryck,Peter Clote","58457|GECCO|2008|Warping search a new metaheuristic applied to the protein structure prediction|This paper presents a new technique to search the solution of difficult optimization problems. The Warping Search is inspired on the movements of celestial bodies in the universe and their interactions. Based on some concepts of Einstein's General Relativity, the search operators proposed in this approach are inspired on gravitational wave sources such as mass transfer, spin, collapse, explosion and collision and defined based on gravitational fields. The technique has been tested in the Protein Structure Prediction Problem in lattice models that is known to be NP-hard. The presented approach is compared with recent heuristics proposed for the problem and the computational results attest the efficiency of the method.|Richard A. Gon√ßalves,Marco C√©sar Goldbarg,Elizabeth Ferreira Gouvea Goldbarg,Myriam Regattieri Delgado","58316|GECCO|2008|Genetic algorithms with local search optimization for protein structure prediction problem|This paper presents a new Genetic Algorithm for Protein Structure Prediction problem in both D and D hydrophobic-hydrophilic lattice models, introduced in . Our algorithm evolves a new local-search genetic operation (called Pull-Move and well described in ), into the standard GA (,). The experiments show that performing a set of Pull-Moves in addition to standard genetic operations in GA (such as crossover and mutation) leads to significant energy improvements. The paper also introduces the Global Energy as fitness function and explains the advantages of utilizing it rather than the standard Free Energy. The experimental results are even more impressive when using the Global Energy as fitness function in GA.|Igor Berenboym,Mireille Avigal","57096|GECCO|2003|Using Adaptive Operators in Genetic Search|In this paper, we provided an extension of our previous work on adaptive genetic algorithm . Each individual encodes the probability (rate) of its genetic operators. In every generation, each individual is modified by only one operator. This operator is selected according to its encoded rates. The rates are updated according to the performance achieved by the offspring (compared to its parents) and a random learning rate. The proposed approach is augmented with a simple transposition operator and tested on a number of benchmark functions.|Jonatan G√≥mez,Dipankar Dasgupta,Fabio A. Gonz√°lez","57810|GECCO|2006|Search-based determination of refactorings for improving the class structure of object-oriented systems|A software system's structure degrades over time, a phenomenon that is known as software decay or design drift. Since the quality of the structure has major impact on the maintainability of a system, the structure has to be reconditioned from time to time. Even if recent advances in the fields of automated detection of bad smells and refactorings have made life easier for software engineers, this is still a very complex and resource consuming task.Search-based approaches have turned out to be helpful in aiding a software engineer to improve the subsystem structure of a software system. In this paper we show that such techniques are also applicable when reconditioning the class structure of a system. We describe a novel search-based approach that assists a software engineer who has to perform this task by suggesting a list of refactorings. Our approach uses an evolutionary algorithm and simulated refactorings that do not change the system's externally visible behavior. The approach is evaluated using the open-source case study JHotDraw.|Olaf Seng,Johannes Stammel,David Burkhart","57474|GECCO|2005|A hybrid genetic algorithm with pattern search for finding heavy atoms in protein crystals|One approach for determining the molecular structure of proteins is a technique called iso-morphous replacement, in which crystallographers dope protein crystals with heavy atoms, such as mercury or platinum. By comparing measured amplitudes of diffracted x-rays through protein crystals with and without the heavy atoms, the locations of the heavy atoms can be estimated. Once the locations of the heavy atoms are known, the phases of the diffracted x-rays through the protein crystal can be estimated, which in turn enables the structure of the protein to be estimated. Unfortunately, the key step in this process is the estimation of the locations of the heavy atoms, and this is a multi-modal, non-linear inverse problem. We report results of a pilot study that show that a -stage hybrid algorithm, using a stochastic genetic algorithm for stage  followed by a deterministic pattern search algorithm for stage , can successfully locate up to  heavy atoms in computer simulated crystals using noise free data. We conclude that the method may be a viable approach for finding heavy atoms in protein crystals, and suggest ways in which the approach can be scaled up to larger problems.|Joshua L. Payne,Margaret J. Eppstein","57408|GECCO|2005|New topologies for genetic search space|We propose three distance measures for genetic search space. One is a distance measure in the population space that is useful for understanding the working mechanism of genetic algorithms. Another is a distance measure in the solution space for K-grouping problems. This can be used for normalization in crossover. The third is a level distance measure for genetic algorithms, which is useful for measuring problem difficulty with respect to genetic algorithms. We show that the proposed measures are metrics and the measures are efficiently computed.|Yong-Hyuk Kim,Byung Ro Moon","57359|GECCO|2005|Harmony search for structural design|Various algorithms have been developed and applied to structural optimization, in which cross-sectional areas of structure members are assumed to be continuous. In most cases of practical structure designs, however, decision variables (cross-sectional areas) are discrete. This paper proposes a combinatorial optimization model for structural design using a new nature-inspired algorithm, harmony search (HS). HS is also compared to genetic algorithms through a standard truss example. Numerical results reveal that the proposed HS is a powerful search algorithm for combinatorial structure optimization.|Zong Woo Geem,Kang Seok Lee,Chung-Li Tseng","58570|GECCO|2009|Enhancing search space diversity in multi-objective evolutionary drug molecule design using niching|There exist several applications of multi-objective evolutionary algorithms for drug design, however, a common drawback in recent approaches is that the diversity of resulting molecule populations is relatively low. This paper seeks to overcome this problem by introducing niching as a technique to enhance search space diversity. A single population approach with dynamic niche identification is studied in the application domain. In order to apply niching in molecular spaces a metric for measuring the dissimilarity of molecules will be introduced. The approach will be validated in case studies and compared with results of an NSGA-II algorithm without niching in the search space.|Johannes W. Kruisselbrink,Alexander Aleman,Michael T. M. Emmerich,Adriaan P. IJzerman,Andreas Bender,Thomas B√§ck,Eelke van der Horst","57267|GECCO|2005|Search space modulation in genetic algorithms evolving the search space by sinusoidal transformations|An experimental form of Modulation (Reinterpretation) of the Search Space is presented. This modulation is developed as a mathematical method that can be implemented directly into existing evolutionary algorithms without writing special operators, changing the program loop etc. The main mathematical principle behind this method is the dynamic sinusoidal envelope of the search space. This method is presented in order to solve some theoretical and practical issues in evolutionary algorithms like numerical bounded variables, dynamic focalized search, dynamic control of diversity, feasible region analysis etc.|Jos√© Antonio Martin H."],["65178|AAAI|1994|Evolving Neural Networks to Focus Minimax Search|Neural Networks were evolved through genetic algorithms to focus minimax search in the game of Othello. At each level of the search tree, the focus networks decide which moves are promising enough to be explored further. The networks effectively hide problem states from minimax based on the knowledge they have evolved about the limitations of minimax and the evaluation function. Focus networks were encoded in marker-based chromosomes and were evolved against a full-width minimax opponent that used the same evaluation function. The networks were able to guide the search away from poor information, resulting in stronger play while examining fewer states. When evolved with a highly sophisticated evaluation function of the Bill program, the system was able to match Bill''s performance while only searching a subset of the moves.|David E. Moriarty,Risto Miikkulainen","58929|GECCO|2010|Evolving neural networks in compressed weight space|We propose a new indirect encoding scheme for neural networks in which the weight matrices are represented in the frequency domain by sets Fourier coefficients. This scheme exploits spatial regularities in the matrix to reduce the dimensionality of the representation by ignoring high-frequency coefficients, as is done in lossy image compression. We compare the efficiency of searching in this \"compressed\" network space to searching in the space of directly encoded networks, using the CoSyNE neuroevolution algorithm on three benchmark problems pole-balancing, ball throwing and octopus arm control. The results show that this encoding can dramatically reduce the search space dimensionality such that solutions can be found in significantly fewer evaluations|Jan Koutnik,Faustino J. Gomez,J√ºrgen Schmidhuber","66770|AAAI|2010|The Genetic Algorithm as a General Diffusion Model for Social Networks|Link-based ranking has contributed significantly to the success of Web search. PageRank and HITS are the best known link-based ranking algorithms. These algorithms do not consider an important dimension, the temporal dimension. They favor older pages because these pages have many in-links accumulated over time. Bringing new and quality pages to the users is important because most users want the latest information. Existing remedies to PageRank are mostly heuristic approaches. This paper investigates the temporal aspect of ranking with application to publication search, and proposes a principled method based on the stationary probability distribution of the Markov chain. The proposed techniques are evaluated empirically using a large collection of high energy particle physics publication. The results show that the proposed methods are highly effective.|Mayank Lahiri,Manuel Cebri√°n","65226|AAAI|2004|Fibring Neural Networks|Neural-symbolic systems are hybrid systems that integrate symbolic logic and neural networks. The goal of neural-symbolic integration is to benefit from the combination of features of the symbolic and connectionist paradigms of artificial intelligence. This paper introduces a new neural network architecture based on the idea of fibring logical systems. Fibring allows one to combine different logical systems in a principled way. Fibred neural networks may be composed not only of interconnected neurons but also of other networks, forming a recursive architecture. A fibring function then defines how this recursive architecture must behave by defining how the networks in the ensemble relate to each other, typically by allowing the activation of neurons in one network (A) to influence the change of weights in another network (B). Intuitively, this can be seen as training network B at the same time that one runs network A. We show that, in addition to being universal approximators like standard feedforward networks, fibred neural networks can approximate any polynomial function to any desired degree of accuracy, thus being more expressive than standard feedforward networks.|Artur S. d'Avila Garcez,Dov M. Gabbay","58918|GECCO|2010|The baldwin effect in developing neural networks|The Baldwin Effect is a very plausible, but unproven, biological theory concerning the power of learning to accelerate evolution. Simple computational models in the 's gave the first constructive proof of its potential existence, and subsequent work in evolutionary computation has shown the practical, computational, advantages of hybrid evolution-learning systems. However, the basic theory, particularly its second phase (involving genetic assimilation of acquired characteristics) is difficult to reconcile in systems controlled by neural networks, particularly those that arise from their genotypes via a complex developmental process. Our research uses new evidence of the blurred distinction between development and learning in natural neural systems as the basis for an abstract model displaying the Baldwin Effect in artificial neural networks that evolve, develop and learn.|Keith L. Downing","58442|GECCO|2008|Evolving neural networks for fractured domains|Evolution of neural networks, or neuroevolution, bas been successful on many low-level control problems such as pole balancing, vehicle control, and collision warning. However, high-level strategy problems that require the integration of multiple sub-behaviors have remained difficult for neuroevolution to solve. This paper proposes the hypothesis that such problems are difficult because they are fractured the correct action varies discontinuously as the agent moves from state to state. This hypothesis is evaluated on several examples of fractured high-level reinforcement learning domains. Standard neuroevolution methods such as NEAT indeed have difficulty solving them. However, a modification of NEAT that uses radial basis function (RBF) nodes to make precise local mutations to network output is able to do much better. These results provide a better understanding of the different types of reinforcement learning problems and the limitations of current neuroevolution methods. Thus, they lay the groundwork for creating the next generation of neuroevolution algorithms that can learn strategic high-level behavior in fractured domains.|Nate Kohl,Risto Miikkulainen","58761|GECCO|2009|Evolving symmetric and modular neural networks for distributed control|Problems such as the design of distributed controllers are characterized by modularity and symmetry. However, the symmetries useful for solving them are often difficult to determine analytically. This paper presents a nature-inspired approach called Evolution of Network Symmetry and mOdularity (ENSO) to solve such problems. It abstracts properties of generative and developmental systems, and utilizes group theory to represent symmetry and search for it systematically, making it more evolvable than randomly mutating symmetry. This approach is evaluated by evolving controllers for a quadruped robot in physically realistic simulations. On flat ground, the resulting controllers are as effective as those having hand-designed symmetries. However, they are significantly faster when evolved on inclined ground, where the appropriate symmetries are difficult to determine manually. The group-theoretic symmetry mutations of ENSO were also significantly more effective at evolving such controllers than random symmetry mutations. Thus, ENSO is a promising approach for evolving modular and symmetric solutions to distributed control problems, as well as multiagent systems in general.|Vinod K. Valsalam,Risto Miikkulainen","57805|GECCO|2006|Modular thinking evolving modular neural networks for visual guidance of agents|This paper investigates whether replacing non-modular artificial neural network brains of visual agents with modular brains improves their ability to solve difficult tasks, specifically, survive in a changing environment. A set of experiments was conducted and confirmed that agents with modular brains are in fact better. Further analysis of the evolved modules characterised their function and determined their mechanism of operation. The results indicate that the greater survival ability is obtained due to functional specialisation of the evolved modules good agents do well because their modules are more specialised at tasks such as reproduction and consumption. Overall, the more specialised the modules, the fitter the agents.|Ehud Schlessinger,Peter J. Bentley,R. Beau Lotto","57760|GECCO|2006|Coevolution of neural networks using a layered pareto archive|The Layered Pareto Coevolution Archive (LAPCA) was recently proposed as an effective Coevolutionary Memory (CM) which, under certain assumptions, approximates monotonic progress in coevolution. In this paper, a technique is developed that interfaces the LAPCA algorithm with NeuroEvolution of Augmenting Topologies (NEAT), a method to evolve neural networks with demonstrated efficiency in game playing domains. In addition, the behavior of LAPCA is analyzed for the first time in a complex game-playing domain evolving neural network controllers for the game Pong. The technique is shown to keep the total number of evaluations in the order of those required by NEAT, making it applicable to complex domains. Pong players evolved with a LAPCA and with the Hall of Fame (HOF) perform equally well, but the LAPCA is shown to require significantly less space than the HOF. Therefore, combining NEAT and LAPCA is found to be an effective approach to coevolution.|German A. Monroy,Kenneth O. Stanley,Risto Miikkulainen","65014|AAAI|1987|Modular Learning in Neural Networks|In the development of large-scale knowledge networks much recent progress has been inspired by connections to neurobiology. An important component of any \"neural\" network is an accompanying learning algorithm. Such an algorithm, to be biologically plausible, must work for very large numbers of units. Studies of large-scale systems have so far been restricted to systems Without internal units (units With no direct connections to the input or output). Internal units are crucial to such systems as they are the means by which a system can encode high-order regularities (or invariants) that are Implicit in its inputs and outputs. Computer simulations of learning using internal units have been restricted to small-scale systems. This paper describes away of coupling autoassociative learning modules Into hierarchies that should greatly improve the performance of learning algorithms in large-scale systems. The Idea has been tested experimentally with positive results.|Dana H. Ballard"],["58495|GECCO|2008|A robust evolutionary framework for multi-objective optimization|Evolutionary multi-objective optimization (EMO) methodologies, suggested in the beginning of Nineties, focussed on the task of finding a set of well-converged and well-distributed set of solutions using evolutionary optimization principles. Of the EMO methodologies, the elitist non-dominated sorting genetic algorithm or NSGA-II, suggested in , is now probably the most popularly used EMO procedure. NSGA-II follows three independent principles -- domination principle, diversity preservation principle and elite preserving principle -- which make NSGA-II a flexible and robust EMO procedure in the sense of solving various multi-objective optimization problems using a common framework. In this paper, we describe NSGA-II through a functional decomposition following the implementation of these three principles and demonstrate how various multi-objective optimization tasks can be achieved by simply modifying one of the three principles. We argue that such a functionally decomposed and modular implementation of NSGA-II is probably the reason for it's popularity and robustness in solving various types of multi-objective optimization problems.|Kalyanmoy Deb","58008|GECCO|2007|Multi-objective particle swarm optimization on computer grids|In recent years, a number of authors have successfully extended particle swarmoptimization to problem domains with multiple objec-tives. This paper addresses theissue of parallelizing multi-objec-tive particle swarms. We propose and empirically comparetwo parallel versions which differ in the way they divide the swarminto subswarms that can be processed independently on differentprocessors. One of the variants works asynchronouslyand is thus particularly suitable for heterogeneous computer clusters asoccurring e.g. in moderngrid computing platforms.|Sanaz Mostaghim,J√ºrgen Branke,Hartmut Schmeck","57670|GECCO|2006|On the effect of populations in evolutionary multi-objective optimization|Multi-objective evolutionary algorithms (MOEAs) have become increasingly popular as multi-objective problem solving techniques. An important open problem is to understand the role of populations in MOEAs. We present a simple bi-objective problem which emphasizes when populations are needed. Rigorous runtime analysis point out an exponential runtime gap between the population-based algorithm Simple Evolutionary Multi-objective Optimizer (SEMO) and several single individual-based algorithms on this problem. This means that among the algorithms considered, only the population-based MOEA is successful and all other algorithms fail.|Oliver Giel,Per Kristian Lehre","58716|GECCO|2009|Particle swarm optimization based multi-prototype ensembles|This paper proposes and evaluates a Particle Swarm Optimization (PSO) based ensemble classifier. The members of the ensemble are Nearest Prototype Classifiers generated sequentially using PSO and combined by a majority voting mechanism. Two necessary requirements for good performance of an ensemble are accuracy and diversity of error. Accuracy is achieved by PSO minimizing a fitness function representing the error rate as the members are created. The diversity of error is promoted by using a different initialization of PSO each time to create a new member and by adopting decorrelated training where a penalty term is added to the fitness function to penalize particles that make the same errors as previously generated classifiers. Simulation experiments on different classification problems show that the ensemble has better performance than a single classifier and are effective in generating diverse ensemble members.|Ammar W. Mohemmed,Mark Johnston,Mengjie Zhang","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Mu√±oz Zavala,Arturo Hern√°ndez Aguirre,Enrique Ra√∫l Villa Diharce","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57294|GECCO|2005|Fitness inheritance for noisy evolutionary multi-objective optimization|This paper compares the performance of anti-noise methods, particularly probabilistic and re-sampling methods, using NSGA. It then proposes a computationally less expensive approach to counteracting noise using re-sampling and fitness inheritance. Six problems with different difficulties are used to test the methods. The results indicate that the probabilistic approach has better convergence to the Pareto optimal front, but it looses diversity quickly. However, methods based on re-sampling are more robust against noise but they are computationally very expensive to use. The proposed fitness inheritance approach is very competitive to re-sampling methods with much lower computational cost.|Lam Thu Bui,Hussein A. Abbass,Daryl Essam","57112|GECCO|2003|HEMO A Sustainable Multi-objective Evolutionary Optimization Framework|The capability of multi-objective evolutionary algorithms (MOEAs) to handle premature convergence is critically important when applied to real-world problems. Their highly multi-modal and discrete search space often makes the required performance out of reach to current MOEAs. Examining the fundamental cause of premature convergence in evolutionary search has led to proposing of a generic framework, named Hierarchical Fair Competition (HFC), for robust and sustainable evolutionary search. Here an HFC-based Hierarchical Evolutionary Multi-objective Optimization framework (HEMO) is proposed, which is characterized by its simultaneous maintenance of individuals of all degrees of evolution in hierarchically organized repositories, by its continuous inflow of random individuals at the base repository, by its intrinsic hierarchical elitism and hyper-grid-based density estimation. Two experiments demonstrate its search robustness and its capability to provide sustainable evolutionary search for difficult multi-modal problems. HEMO makes it possible to do reliable multi-objective search without risk of premature convergence. The paradigmatic transition of HEMO to handle premature convergence is that instead of trying to escape local optima from converged high fitness populations, it tries to maintain the opportunity for new optima to emerge from the bottom up as enabled by its hierarchical organization of individuals of different fitnesses.|Jianjun Hu,Kisung Seo,Zhun Fan,Ronald C. Rosenberg,Erik D. Goodman","57813|GECCO|2006|Dynamic fitness inheritance proportion for multi-objective particle swarm optimization|In this paper, we propose a dynamic mechanism to vary the probability by which fitness inheritance is applied throughout the run of a multi-objective particle swarm optimizer, in order to obtain a greater reduction in computational cost (than the obtained with a fixed probability), without dramatically affecting the quality of the results. The results obtained show that it is possible to reduce the computational cost by % without affecting the quality of the obtained Pareto front.|Margarita Reyes Sierra,Carlos A. Coello Coello"],["58593|GECCO|2009|Genetic algorithm with adaptive elitism-based immigrants for dynamic optimization problems|We propose a genetic algorithm with adaptive elitism-based immigrants which tunes the balance between elitism-based immigrants and random immigrants by itself. Experimental results show that our genetic algorithm with adaptive elitism-based immigrants performs better than that with the elitism-based immigrants for onemax and produces comparable results for royal road and knapsack problems.|Seung-Kyu Lee,Byung Ro Moon","58660|GECCO|2009|Gene transposon based clonal selection algorithm for clustering|Inspired by the principle of gene transposon proposed by Barbara McClintock, a new immune computing algorithm for clustering multi-class data sets named as Gene Transposition based Clone Selection Algorithm (GTCSA) is proposed in this paper, The proposed algorithm does not require a prior knowledge of the numbers of clustering an improved variant of the clonal selection algorithm has been used to determine the number of clusters as well as to refine the cluster center. a novel operator called antibody transposon is introduced to the framework of clonal selection algorithm which can realize to find the optimal number of cluster automatically. The proposed method has been extensively compared with Variable-string-length Genetic Algorithm(VGA)based clustering techniques over a test suit of several real life data sets and synthetic data sets. The results of experiments indicate the superiority of the GTCSA over VGA on stability and convergence rate, when clustering multi-class data sets.|Ruochen Liu,Zhengchun Sheng,Licheng Jiao","58500|GECCO|2008|Adaptive operator selection with dynamic multi-armed bandits|An important step toward self-tuning Evolutionary Algorithms is to design efficient Adaptive Operator Selection procedures. Such a procedure is made of two main components a credit assignment mechanism, that computes a reward for each operator at hand based on some characteristics of the past offspring and an adaptation rule, that modifies the selection mechanism based on the rewards of the different operators. This paper is concerned with the latter, and proposes a new approach for it based on the well-known Multi-Armed Bandit paradigm. However, because the basic Multi-Armed Bandit methods have been developed for static frameworks, a specific Dynamic Multi-Armed Bandit algorithm is proposed, that hybridizes an optimal Multi-Armed Bandit algorithm with the statistical Page-Hinkley test, which enforces the efficient detection of changes in time series. This original Operator Selection procedure is then compared to the state-of-the-art rules known as Probability Matching and Adaptive Pursuit on several artificial scenarios, after a careful sensitivity analysis of all methods. The Dynamic Multi-Armed Bandit method is found to outperform the other methods on a scenario from the literature, while on another scenario, the basic Multi-Armed Bandit performs best.|Lu√≠s Da Costa,√?lvaro Fialho,Marc Schoenauer,Mich√®le Sebag","58925|GECCO|2010|GGGP-based method for modeling time series operator selection parameter optimization and expert evaluation|This paper describes the theoretical and experimental analysis conducted to define the best values for the various operators and parameters of a grammar-guided genetic programming process for creating isokinetic reference models for top competition athletes. Isokinetics is a medical domain that studies the strength exerted by the patient joints (knee, ankle, etc.). We also present an evaluation of the resulting reference models comparing our results with the reference models output using other methods.|Fernando Alonso,Lo√Øc Mart√≠nez,Agust√≠n Santamar√≠a,Aurora P√©rez-P√©rez,Juan Pedro Valente","57152|GECCO|2003|Adaptive Elitist-Population Based Genetic Algorithm for Multimodal Function Optimization|This paper introduces a new technique called adaptive elitist-population search method for allowing unimodal function optimization methods to be extended to efficiently locate all optima of multimodal problems. The technique is based on the concept of adaptively adjusting the population size according to the individuals' dissimilarity and the novel elitist genetic operators. Incorporation of the technique in any known evolutionary algorithm leads to a multimodal version of the algorithm. As a case study, genetic algorithms(GAs) have been endowed with the multimodal technique, yielding an adaptive elitist-population based genetic algorithm(AEGA). The AEGA has been shown to be very efficient and effective in finding multiple solutions of the benchmark multimodal optimization problems.|Kwong-Sak Leung,Yong Liang","57877|GECCO|2007|An extended mutation concept for the local selection based differential evolution algorithm|A new mutation concept is proposed to generalize local selection based Differential Evolution algorithm to work in general multi-modal problems. Three variations of the proposed method are compared with classic Differential Evolution algorithm using a set of five well known test functions and their variants. The general idea of the new mutation operation is to divide the mutation into two parts the local and global mutation. The global mutation works as a migration operator allowing the algorithm perform global search efficiently, while the local mutation improves the efficiency of local search. The results show that the concept of global mutation is able to generalize the good performance of local selection based Differential Evolution from convex uni-modal functions to general non-convex and multi-modal problems. Among the tested functions, the new method was able to outperform the classic Differential Evolution in all butone. A limited analysis of the effects of control parameters to the performance of the algorithm is also done.|Jani R√∂nkk√∂nen,Jouni Lampinen","59040|GECCO|2010|Toward comparison-based adaptive operator selection|Adaptive Operator Selection (AOS) turns the impacts of the applications of variation operators into Operator Selection through a Credit Assignment mechanism. However, most Credit Assignment schemes make direct use of the fitness gain between parent and offspring. A first issue is that the Operator Selection technique that uses such kind of Credit Assignment is likely to be highly dependent on the a priori unknown bounds of the fitness function. Additionally, these bounds are likely to change along evolution, as fitness gains tend to get smaller as convergence occurs. Furthermore, and maybe more importantly, a fitness-based credit assignment forbid any invariance by monotonous transformation of the fitness, what is a usual source of robustness for comparison-based Evolutionary Algorithms. In this context, this paper proposes two new Credit Assignment mechanisms, one inspired by the Area Under the Curve paradigm, and the other close to the Sum of Ranks. Using fitness improvement as raw reward, and directly coupled to a Multi-Armed Bandit Operator Selection Rule, the resulting AOS obtain very good performances on both the OneMax problem and some artificial scenarios, while demonstrating their robustness with respect to hyper-parameter and fitness transformations. Furthermore, using fitness ranks as raw reward results in a fully comparison-based AOS with reasonable performances.|√?lvaro Fialho,Marc Schoenauer,Mich√®le Sebag","57567|GECCO|2005|A genetic algorithm approach to the selection of near-optimal subsets from large sets|The problem attempted in this paper is to select a sample from a large set where the sample is required to have a particular average property. The problem can be expressed as an optimisation problem where one selects a subset of r objects from a group of n objects and the objective function is the mismatch between the required average property and that of a proposed sample. We test our method on a real-life problem which arises when we model the assets of a life insurance company in order to understand its risk, solvency andor capital requirements.In this paper we describe a genetic algorithm developed to solve the generic selection task. We demonstrate the algorithm successfully solving our test problem.|P. Whiting,P. W. Poon,J. N. Carter","58021|GECCO|2007|GARS an improved genetic algorithm with reserve selection for global optimization|This paper investigates how genetic algorithms (GAs) can be improved to solve large-scale and complex problems more efficiently. First of all, we review premature convergence, one of the challenges confronted with when applying GAs to real-world problems. Next, some of the methods now available to prevent premature convergence and their intrinsic defects are discussed. A qualitative analysis is then done on the cause of premature convergence that is the loss of building blocks hosted in less-fit individuals during the course of evolution. Thus, we propose a new improver - GAs with Reserve Selection (GARS), where a reserved area is set up to save potential building blocks and a selection mechanism based on individual uniqueness is employed to activate the potentials. Finally, case studies are done in a few standard problems well known in the literature, where the experimental results demonstrate the effectiveness and robustness of GARS in suppressing premature convergence, and also an enhancement is found in global optimization capacity.|Yang Chen,Jinglu Hu,Kotaro Hirasawa,Songnian Yu","58996|GECCO|2010|A clonal selection clustering algorithm using pointed symmetry-based distance measure|A clonal selection clustering algorithm using point symmetry-based distance measure (CSCAPS) is proposed in this paper, a point symmetry-based similarity measure is used to evaluate the similarity between two samples in order to cluster data sets with the character of symmetry. Both Kd-trees based nearest neighbor search and k-nearest-neighbor consistency strategy are used to reduce the computation complexity and improve the clustering accuracy. The proposed method has been extensively compared with four well-known clustering algorithms over a test suit of real life data sets and synthetic data sets. The results of experiments indicate the superiority of the CSCAPS on accuracy.|Ruochen Liu,Hejun Ning,Wei Zhang,Licheng Jiao"],["58470|GECCO|2008|Towards efficient online reinforcement learning using neuroevolution|For many complex Reinforcement Learning (RL) problems with large and continuous state spaces, neuroevolution has achieved promising results. This is especially true when there is noise in sensor andor actuator signals. These results have mainly been obtained in offline learning settings, where the training and the evaluation phases of the systems are separated. In contrast, for online RL tasks, the actual performance of a system matters during its learning phase. In these tasks, neuroevolutionary systems are often impaired by their purely exploratory nature, meaning that they usually do not use (i.e. exploit) their knowledge of a single individual's performance to improve performance during learning. In this paper we describe modifications that significantly improve the online performance of the neuroevolutionary method Evolutionary Acquisition of Neural Topologies and discuss the results obtained in the Mountain Car benchmark.|Jan Hendrik Metzen,Frank Kirchner,Mark Edgington,Yohannes Kassahun","58941|GECCO|2010|On the problems of using learning classifier systems for fraud detection|Fraud detection problems have some uniquely challenging properties which make them difficult. In this paper, we investigate the fraud detection problem by describing the common properties of electronic fraud and examining how learning classifier systems (LCSs) can be applied to it. Also, we introduce \"random Boolean function\" (RBF) an abstract problem with high level of controllability which can be tuned to exhibit those characteristics individually, and report the results of using XCSR (a continuous variant of LCS) on RBF problem and also on a real-world problem. Results from our experiments demonstrate that XCSR can overcome most of the difficulties inherent to the fraud detection problem and can achieve good performance in case of the real-world problem.|Mohammad Behdad,Tim French,Luigi Barone,Mohammed Bennamoun","65590|AAAI|2005|Online Resource Allocation Using Decompositional Reinforcement Learning|This paper considers a novel application domain for reinforcement learning that of \"autonomic computing,\" i.e. selfmanaging computing systems. RL is applied to an online resource allocation task in a distributed multi-application computing environment with independent time-varying load in each application. The task is to allocate servers in real time so as to maximize the sum of performance-based expected utility in each application. This task may be treated as a composite MDP, and to exploit the problem structure, a simple localized RL approach is proposed, with better scalability than previous approaches. The RL approach is tested in a realistic prototype data center comprising real servers, real HTTP requests, and realistic time-varying demand. This domain poses a number of major challenges associated with live training in a real system, including the need for rapid training, exploration that avoids excessive penalties, and handling complex, potentially non-Markovian system effects. The early results are encouraging in overnight training, RL performs as well as or slightly better than heavily researched model-based approaches derived from queuing theory.|Gerald Tesauro","65649|AAAI|2006|Perspective Taking An Organizing Principle for Learning in Human-Robot Interaction|The ability to interpret demonstrations from the perspective of the teacher plays a critical role in human learning. Robotic systems that aim to learn effectively from human teachers must similarly be able to engage in perspective taking. We present an integrated architecture wherein the robot's cognitive functionality is organized around the ability to understand the environment from the perspective of a social partner as well as its own. The performance of this architecture on a set of learning tasks is evaluated against human data derived from a novel study examining the importance of perspective taking in human learning. Perspective taking, both in humans and in our architecture, focuses the agent's attention on the subset of the problem space that is important to the teacher. This constrained attention allows the agent to overcome ambiguity and incompleteness that can often be present in human demonstrations and thus learn what the teacher intends to teach.|Matt Berlin,Jesse Gray,Andrea Lockerd Thomaz,Cynthia Breazeal","58754|GECCO|2009|Are evolutionary rule learning algorithms appropriate for malware detection|In this paper, we evaluate the performance of ten well-known evolutionary and non-evolutionary rule learning algorithms. The comparative study is performed on a real-world classification problem of detecting malicious executables. The executable dataset, used in this study, consists of a total of  attributes which are statically extracted from the executables of Microsoft Windows operating system. In our study, we evaluate the performance of rule learning algorithms with respect to four metrics () classification accuracy, () the number of rules in the developed rule set, () the comprehensibility of the generated rules, and () the processing overhead of the rule learning process. The results of our study highlight important shortcomings in evolutionary rule learning classifiers that render them infeasible for deployment in a real-world malware detection system.|M. Zubair Shafiq,S. Momina Tabish,Muddassar Farooq","66730|AAAI|2010|Learning Methods to Generate Good Plans Integrating HTN Learning and Reinforcement Learning|In this paper, we study the upper and the lower bounds on the joint source-channel coding error exponent with decoder side-information. The results in the paper are non-trivial extensions of the Csiszar's classical paper. Unlike the joint source-channel coding result in, it is not obvious whether the lower bound and the upper bound are equivalent even if the channel coding error exponent is known. For a class of channels, including the symmetric channels, we apply a game-theoretic result to establish the existence of a saddle point and hence prove that the lower and upper bounds are the same if the channel coding error exponent is known. More interestingly, we show that encoder side-information does not increase the error exponents in this case.|Chad Hogg,Ugur Kuter,Hector Mu√±oz-Avila","66159|AAAI|2007|A Reinforcement Learning Algorithm with Polynomial Interaction Complexity for Only-Costly-Observable MDPs|An Unobservable MDP (UMDP) is a POMDP in which there are no observations. An Only-Costly-Observable MDP (OCOMDP) is a POMDP which extends an UMDP by allowing a particular costly action which completely observes the state. We introduce UR-MAX, a reinforcement learning algorithm with polynomial interaction complexity for unknown OCOMDPs.|Roy Fox,Moshe Tennenholtz","66064|AAAI|2007|Optimizing Anthrax Outbreak Detection Using Reinforcement Learning|The potentially catastrophic impact of a bioterrorist attack makes developing effective detection methods essential for public health. In the case of anthrax attack, a delay of hours in making a right decision can lead to hundreds of lives lost. Current detection methods trade off reliability of alarms for early detection of outbreaks. The performance of these methods can be improved by modem disease-specific modeling techniques which take into account the potential costs and effects of an attack to provide optimal warnings. We study this optimization problem in the reinforcement learning framework. The key contribution of this paper is to apply Partially Observable Markov Decision Processes (POMDPs) on outbreak detection mechanism for improving alarm function in anthrax outbreak detection. Our approach relies on estimating the future benefit of true alarms and the costs of false alarms and using these quantities to identify an optimal decision. We present empirical evidence illustrating that the performance of detection methods with respect to sensitivity and timeliness is improved significantly by utilizing POMDPs.|Masoumeh T. Izadi,David L. Buckeridge","57186|GECCO|2003|Reinforcement Learning Estimation of Distribution Algorithm|This paper proposes an algorithm for combinatorial optimizations that uses reinforcement learning and estimation of joint probability distribution of promising solutions to generate a new population of solutions. We call it Reinforcement Learning Estimation of Distribution Algorithm (RELEDA). For the estimation of the joint probability distribution we consider each variable as univariate. Then we update the probability of each variable by applying reinforcement learning method. Though we consider variables independent of one another, the proposed method can solve problems of highly correlated variables. To compare the efficiency of our proposed algorithm with other Estimation of Distribution Algorithms (EDAs) we provide the experimental results of the two problems four peaks problem and bipolar function.|Topon Kumar Paul,Hitoshi Iba","65909|AAAI|2006|Reinforcement Learning with Human Teachers Evidence of Feedback and Guidance with Implications for Learning Performance|As robots become a mass consumer product, they will need to learn new skills by interacting with typical human users. Past approaches have adapted reinforcement learning (RL) to accept a human reward signal however, we question the implicit assumption that people shall only want to give the learner feedback on its past actions. We present findings from a human user study showing that people use the reward signal not only to provide feedback about past actions, but also to provide future directed rewards to guide subsequent actions. Given this, we made specific modifications to the simulated RL robot to incorporate guidance. We then analyze and evaluate its learning performance in a second user study, and we report significant improvements on several measures. This work demonstrates the importance of understanding the human-teacherrobot-learner system as a whole in order to design algorithms that support how people want to teach while simultaneously improving the robot's learning performance.|Andrea Lockerd Thomaz,Cynthia Breazeal"],["65281|AAAI|2004|Capturing User Intent for Information Retrieval|We study the problem of employing a cognitive user model for information retrieval in which knowledge about a user is captured and used for improving retrieval performance and user satisfaction. In this proposed research, we improve retrieval performance and user satisfaction for information retrieval by building a user model to capture user intent dynamically through analyzing behavioral information from retrieved relevant documents, and by combining captured user intent with the elements of an information retrieval system. We use decision theoretic principles and bayesian networks for building this model. The novelties of our approach lie with the fine-grained representation of the model, the ability to learn user knowledge incrementally and dynamically, the integration of user intent and system elements for improving retrieval performance and the unified evaluation framework to assess the accuracy of user intent captured and effectiveness of our model.|Hien Nguyen","66620|AAAI|2010|Temporal Information Extraction|Linear optimization queries retrieve the top-K tuples in a sliding window of a data stream that maximizeminimize the linearly weighted sums of certain attribute values. To efficiently answer such queries against a large relation, an onion index was previously proposed to properly organize all the tuples in the relation. However, such an onion index does not work in a streaming environment due to fast tuple arrival rate and limited memory. In this paper, we propose a SAO index to approximately answer arbitrary linear optimization queries against a data stream. It uses a small amount of memory to efficiently keep track of the most \"important\" tuples in a sliding window of a data stream. The index maintenance cost is small because the great majority of the incoming tuples do not cause any changes to the index and are quickly discarded. At any time, for any linear optimization query, we can retrieve from the SAO index the approximate top-K tuples in the sliding window almost instantly. The larger the amount of available memory, the better the quality of the answers is. More importantly, for a given amount of memory, the quality of the answers can be further improved by dynamically allocating a larger portion of the memory to the outer layers of the SAO index. We evaluate the effectiveness of this SAO index through a prototype implementation.|Xiao Ling,Daniel S. Weld","66353|AAAI|2008|Concept-Based Feature Generation and Selection for Information Retrieval|Traditional information retrieval systems use query words to identify relevant documents. In difficult retrieval tasks, however, one needs access to a wealth of background knowledge. We present a method that uses Wikipedia-based feature generation to improve retrieval performance. Intuitively, we expect that using extensive world knowledge is likely to improve recall but may adversely affect precision. High quality feature selection is necessary to maintain high precision, but here we do not have the labeled training data for evaluating features, that we have in supervised learning. We present a new feature selection method that is inspired by pseudorelevance feedback. We use the top-ranked and bottom-ranked documents retrieved by the bag-of-words method as representative sets of relevant and non-relevant documents. The generated features are then evaluated and filtered on the basis of these sets. Experiments on TREC data confirm the superior performance of our method compared to the previous state of the art.|Ofer Egozi,Evgeniy Gabrilovich,Shaul Markovitch","65250|AAAI|2004|Interactive Information Extraction with Constrained Conditional Random Fields|Information Extraction methods can be used to automatically \"fill-in\" database forms from unstructured data such as Web documents or email. State-of-the-art methods have achieved low error rates but invariably make a number of errors. The goal of an interactive information extraction system is to assist the user in filling in database fields while giving the user confidence in the integrity of the data. The user is presented with an interactive interface that allows both the rapid verification of automatic field assignments and the correction of errors. In cases where there are multiple errors, our system takes into account user corrections, and immediately propagates these constraints such that other fields are often corrected automatically. Linear-chain conditional random fields (CRFs) have been shown to perform well for information extraction and other language modelling tasks due to their ability to capture arbitrary, overlapping features of the input in a Markov model. We apply this framework with two extensions a constrained Viterbi decoding which finds the optimal field assignments consistent with the fields explicitly specified or corrected by the user and a mechanism for estimating the confidence of each extracted field, so that low-confidence extractions can be highlighted. Both of these mechanisms are incorporated in a novel user interface for form filling that is intuitive and speeds the entry of data--providing a % reduction in error due to automated corrections.|Trausti T. Kristjansson,Aron Culotta,Paul A. Viola,Andrew McCallum","66902|AAAI|2010|Prioritization of Domain-Specific Web Information Extraction|In distributed systems based on BSM, events and event-condition-action rules are the fundamental metaphors for defining and enforcing the system. Processing entities execute behavior by reacting to and generating new events. It is important that event semantics is explicit. Although a lot of research has concentrated on event semantics, there still exists potential semantic ambiguity which is unacceptable in some circumstances. We propose an event model and incorporate an interaction group identifier into it. We emphasize that the semantics is a key to capture the actual meaning of events in real life, in which the same composite event patterns may imply totally different semantic meanings. Based on this observation, a graph-ESIG (Event and Service Interacting Graph) and ESIC (Event and Service Interacting Chain), which are constructed according to ECA-Rules, are proposed to trace events. ESIG greatly enhanced the expressive power to allow event detection correctly, which matches situations in reality. Finally, we develop a event detection algorithm that uses ESIG and ESIC|Jian Huang,Cong Yu","65216|AAAI|2004|Methods for Domain-Independent Information Extraction from the Web An Experimental Comparison|Our KNOWITALL system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an autonomous, domain-independent, and scalable manner. In its first major run, KNOWITALL extracted over , facts with high precision, but suggested a challenge How can we improve KNOWITALL's recall and extraction rate without sacrificing precision This paper presents three distinct ways to address this challenge and evaluates their performance. Rule Learning learns domain-specific extraction rules. Subclass Extraction automatically identifies sub-classes in order to boost recall. List Extraction locates lists of class instances, learns a \"wrapper\" for each list, and extracts elements of each list. Since each method bootstraps from KNOWITALL's domain-independent methods, no hand-labeled training examples are required. Experiments show the relative coverage of each method and demonstrate their synergy. In concert, our methods gave KNOWITALL a -fold to -fold increase in recall, while maintaining high precision, and discovered , cities missing from the Tipster Gazetteer.|Oren Etzioni,Michael J. Cafarella,Doug Downey,Ana-Maria Popescu,Tal Shaked,Stephen Soderland,Daniel S. Weld,Alexander Yates","66099|AAAI|2007|Joint Inference in Information Extraction|The goal of information extraction is to extract database records from text or semi-structured sources. Traditionally, information extraction proceeds by first segmenting each candidate record separately, and then merging records that refer to the same entities. While computationally efficient, this approach is suboptimal, because it ignores the fact that segmenting one candidate record can help to segment similar ones. For example, resolving a well-segmented field with a less-clear one can disambiguate the latter's boundaries. In this paper we propose a joint approach to information extraction, where segmentation of all records and entity resolution are performed together in a single integrated inference process. While a number of previous authors have taken steps in this direction (eg., Pasula et al. (), Wellner et al. ()), to our knowledge this is the first fully joint approach. In experiments on the CiteSeer and Cora citation matching datasets, joint inference improved accuracy, and our approach outperformed previous ones. Further, by using Markov logic and the existing algorithms for it, our solution consisted mainly of writing the appropriate logical formulas, and required much less engineering than previous ones.|Hoifung Poon,Pedro Domingos","66522|AAAI|2008|Combining Global Relevance Information with Local Contextual Clues for Event-Oriented Information Extraction|Existing IE systems tend to focus on a tight window of context surrounding the desired information to be extracted. This research addresses shortcomings of these systems by introducing a two-phase approach to IE that incorporates global relevance information with local contextual evidence, to effectively extract information from free text.|Siddharth Patwardhan","58769|GECCO|2009|Swarming to rank for information retrieval|This paper presents an approach to automatically optimize the retrieval quality of ranking functions. Taking a Swarm Intelligence perspective, we present a novel method, Swarm-Rank, which is well-founded in a Particle Swarm Optimization framework. SwarmRank learns a ranking function by optimizing the combination of various types of evidences such content and hyperlink features, while directly maximizing Mean Average Precision, a widely used evaluation measure in Information Retrieval. Experimental results on well-established Learning To Rank benchmark datasets show that our approach significantly outperformed standard approaches (i.e., BM) that only use basic statistical information derived from documents collections, and is found to be competitive with Ranking SVM and RankBoost in the task of ranking relevant documents at the very top positions.|Ernesto Diaz-Aviles,Wolfgang Nejdl,Lars Schmidt-Thieme","65488|AAAI|2005|A Learning-Based Term-Weighting Approach for Information Retrieval|One of the core components in information retrieval (IR) is the document-term-weighting scheme. In this paper, we will propose a novel learning-based term-weighting approach to improve the retrieval performance of vector space model in homogeneous collections. We first introduce a simple learning system to weighting the index terms of documents. Then, we deduce a formal computational approach according to some theories of matrix computation and statistical inference. Our experiments on  collections will show that our approach out-performs classic tfidf weighting, about %-%.|Guangcan Liu,Yong Yu,Xing Zhu"]]}}