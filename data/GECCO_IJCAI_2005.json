{"abstract":{"entropy":6.199928151103913,"topics":["particle swarm, present approach, arc consistency, learning classifier, classifier systems, particle pso, particle optimization, swarm pso, present novel, feature selection, resolution process, swarm optimization, algorithms feature, describes systems, classifier xcs, present first, optimization pso, approach evolutionary, approach based, learning systems","constraint satisfaction, learning sequential, constraint problem, consider agents, consider problem, knowledge base, satisfaction problem, belief change, belief revision, problem agents, work planning, markov decision, different ontologies, search web, search satisfaction, search constraint, problem, planning, quantified problem, agents","neural networks, natural language, machine learning, natural generation, local space, language generation, local search, machine data, search space, temporal reasoning, learning example, search technique, model bayesian, data algorithms, model networks, data, probabilistic model, present model, networks, search finding","genetic algorithms, evolutionary algorithms, genetic programming, optimization problem, evolutionary optimization, present algorithms, algorithms optimization, fitness function, algorithms problem, estimation distribution, different fitness, evolutionary computation, genetic gas, differential evolution, evolutionary problem, algorithms search, optimization, algorithms dynamic, evolutionary eas, crossover operator","feature selection, algorithms feature, selection algorithms, selection problem, selection, present selection, present algorithms, present, various, promising, range, improve, estimation, based, called, particular","particle swarm, particle pso, particle optimization, swarm pso, present first, approach first, present novel, swarm optimization, novel approach, evolutionary first, optimization pso, present approach, particle algorithms, scheduling problem, optimization problem, swarm algorithms, hybrid algorithms, novel swarm, novel particle, novel","different ontologies, systems, different, framework, introduce, semantic, complex, allows, logic, need, reason, represent, robot, case, actions","markov decision, decision, formula, investigate, partially, sequence, power, paper, possible, boolean, observable, processes, generalization, involves, heuristic, quantified, problem","search space, local space, model, probabilistic model, model based, space, performance, methods, based, image, proposes, training, generating, interest, available, years, defining, building","search, local search, search technique, environments, analysis, cost, parsing, automatic, communication, formal, example, like, provide","genetic algorithms, genetic programming, algorithms gas, genetic gas, selection algorithms, model genetic, algorithms search, introduce genetic, selection genetic, genetic evolve, genetic used, algorithms evolve, describes genetic, form genetic, genetic based, proposes algorithms, genetic search, algorithms based, work, algorithms programming","evolutionary algorithms, evolutionary optimization, present algorithms, algorithms optimization, algorithms problem, optimization problem, estimation distribution, evolutionary computation, evolutionary problem, algorithms dynamic, distribution algorithms, optimization dynamic, evolutionary eas, estimation algorithms, algorithms eas, present evolutionary, optimization application, present genetic, use algorithms, present optimization"],"ranking":[["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["16190|IJCAI|2005|An MCMC Approach to Solving Hybrid Factored MDPs|Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.|Branislav Kveton,Milos Hauskrecht","16209|IJCAI|2005|Identifying Conflicts in Overconstrained Temporal Problems|We describe a strong connection between maximally satisfiable and minimally unsatisfiable subsets of constraint systems. Using this relationship, we develop a two-phase algorithm, employing powerful constraint satisfaction techniques, for the identification of conflicting sets of constraints in infeasible constraint systems. We apply this technique to overconstrained instances of the Disjunctive Temporal Problem (DTP), an expressive form of temporal constraint satisfaction problems. Using randomly-generated benchmarks, we provide experimental results that demonstrate how the algorithm scales with problem size and constraint density.|Mark H. Liffiton,Michael D. Moffitt,Martha E. Pollack,Karem A. Sakallah","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder","16286|IJCAI|2005|Structural Symmetry Breaking|Symmetry breaking has been shown to be an important method to speed up the search in constraint satisfaction problems that contain symmetry. When breaking symmetry by dominance detection, a computationally efficient symmetry breaking scheme can be achieved if we can solve the dominance detection problem in polynomial time. We study the complexity of dominance detection when value and variable symmetry appear simultaneously in constraint satisfaction problems (CSPs) with single-valued variables and set-CSPs. We devise an efficient dominance detection algorithm for CSPs with single-valued variables that yields symmetry-free search trees and that is based on the abstraction to the actual, intuitive structure of a symmetric CSP.|Meinolf Sellmann,Pascal Van Hentenryck","16299|IJCAI|2005|Value Ordering for Finding All Solutions|In finding all solutions to a constraint satisfaction problem, or proving that there are none, with a search algorithm that backtracks chronologically and forms k-way branches, the order in which the values are assigned is immaterial. However, we show that if the values of a variable are assigned instead via a sequence of binary choice points, and the removal of the value just tried from the domain of the variable is propagated before another value is selected, the value ordering can affect the search effort. We show that this depends on the problem constraints for some types of constraints, we show that the savings in search effort can be significant, given a good value ordering.|Barbara M. Smith,Paula Sturdy"],["16136|IJCAI|2005|Learning Strategies for Open-Domain Natural Language Question Answering|We present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources, questions, and answers. Our approach formulates QA as a problem of first order inference over a suitably expressive, learned representation. This framework draws on prior work in learning action and problem-solving strategies, as well as relational learning methods. We describe the design of a system implementing this model in the framework of natural language question answering for story comprehension. Finally, we compare our approach to three prior systems, and present experimental results demonstrating the efficacy of our model.|Eugene Grois,David C. Wilkins","16057|IJCAI|2005|TimeML-Compliant Text Analysis for Temporal Reasoning|Reasoning with time needs more than just a list of temporal expressions. TimeML--an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text--is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. Hard as TimeML-compliant analysis is, the small size of the only currently available annotated corpus makes it even harder. We address this problem with a hybrid TimeML annotator, which uses cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component capable of effectively using large amounts of unannotated data.|Branimir Boguraev,Rie Kubota Ando","16206|IJCAI|2005|Location-Based Activity Recognition using Relational Markov Networks|In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.|Lin Liao,Dieter Fox,Henry A. Kautz","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","16214|IJCAI|2005|ANDOR Branch-and-Bound for Graphical Models|The paper presents and evaluates the power of a new framework for optimization in graphical models, based on ANDOR search spaces. The virtue of the ANDOR representation of the search space is that its size may be far smaller than that of a traditional OR representation. We develop our work on Constraint Optimization Problems (COP) and introduce a new generation of depth-first Branch-and-Bound algorithms that explore an ANDOR search space and use static and dynamic mini-bucket heuristics to guide the search. We focus on two optimization problems, solvingWeighted CSPs (WCSP) and finding theMost Probable Explanation (MPE) in belief networks. We show that the new ANDOR approach improves considerably over the classic OR space, on a variety of benchmarks including random and real-world problems. We also demonstrate the impact of different lower bounding heuristics on Branch-and-Bound exploring ANDOR spaces.|Radu Marinescu 0002,Rina Dechter","16265|IJCAI|2005|CSP Search with Responsibility Sets and Kernels|We introduce data structures called responsibility set and kernel. We present an algorithm FCRK, which is a modification of FC that maintains these structures and uses them for pruning of the search space. According to our experimental evaluation, FC-RK outperforms FC-CBJ on constraint networks encoding graph k-coloring instances and on non-dense random binary constraint networks.|Igor Razgon,Amnon Meisels","16220|IJCAI|2005|Training without data Knowledge Insertion into RBF Neural Networks|A major problem when developing neural networks or machine diagnostics situations is that no data or very little data is available for training on fault conditions. However, the domain expert often has a good idea of what to expect in terms of input and output parameter values. If the expert can express these relationships in the form of rules, this would provide a resource too valuable to ignore. Fuzzy logic is used to handle the imprecision and vagueness of natural language and provides this additional advantage to a system. This paper investigates the development of a novel knowledge insertion algorithm that explores the benefits of prestructuring RBF neural networks by using prior fuzzy domain knowledge and previous training experiences. Pre-structuring is accomplished by using fuzzy rules gained from a domain expert and using them to modify existing Radial Basis Function (RBF) networks. The benefits and novel achievements of this work enable RBF neural networks to be trained without actual data but to rely on input to output mappings defined through expert knowledge.|Kenneth McGarry,Stefan Wermter","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas Stützle","16304|IJCAI|2005|Evaluating an NLG System using Post-Editing|Computer-generated texts, whether from Natural Language Generation (NLG) or Machine Translation (MT) systems, are often post-edited by humans before being released to users. The frequency and type of post-edits is a measure of how well the system works, and can be used for evaluation. We describe how we have used post-edit data to evaluate SUMTIME-MOUSAM, an NLG system that produces weather forecasts.|Somayajulu Sripada,Ehud Reiter,Lezan Hawizy","16199|IJCAI|2005|A Greedy Approach to Establish Singleton Arc Consistency|In this paper, we propose a new approach to establish Singleton Arc Consistency (SAC) on constraint networks. While the principle of existing SAC algorithms involves performing a breadth-first search up to a depth equal to , the principle of the two algorithms introduced in this paper involves performing several runs of a greedy search (where at each step, arc consistency is maintained). It is then an original illustration of applying inference (i.e. establishing singleton arc consistency) by search. Using a greedy search allows benefiting from the incrementality of arc consistency, learning relevant information from conflicts and, potentially finding solution(s) during the inference process. Further-more, both space and time complexities are quite competitive.|Christophe Lecoutre,Stéphane Cardon"],["57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","57501|GECCO|2005|Real-coded crossover as a role of kernel density estimation|This paper presents a kernel density estimation method by means of real-coded crossovers. Estimation of density algorithms (EDAs) are evolutionary optimization techniques, which determine the sampling strategy by means of a parametric probabilistic density function estimated from the population. Real-coded Genetic Algorithm (RCGA) does not explicitly estimate any probabilistic distribution, however, the probabilistic model of the population is implicitly estimated by crossovers and the sampling strategy is determined by this implicit probabilistic model. Based on this understanding, we propose a novel density estimation algorithm by using crossovers as nonparametric kernels and apply this kernel density estimation to the Gaussian Mixture modeling. We show that the proposed method is superior in the robustness of the computation and in the accuracy of the estimation by the comparison of conventional EM estimation.|Jun Sakuma,Shigenobu Kobayashi","57305|GECCO|2005|Extracted global structure makes local building block processing effective in XCS|Michigan-style learning classifier systems (LCSs), such as the accuracy-based XCS system, evolve distributed problem solutions represented by a population of rules. Recently, it was shown that decomposable problems may require effective processing of subsets of problem attributes, which cannot be generally assured with standard crossover operators. A number of competent crossover operators capable of effective identification and processing of arbitrary subsets of variables or string positions were proposed for genetic and evolutionary algorithms. This paper effectively introduces two competent crossover operators to XCS by incorporating techniques from competent genetic algorithms (GAs) the extended compact GA (ECGA) and the Bayesian optimization algorithm (BOA). Instead of applying standard crossover operators, here a probabilistic model of the global population is built and sampled to generate offspring classifiers locally. Various offspring generation methods are introduced and evaluated. Results indicate that the performance of the proposed learning classifier systems XCSECGA and XCSBOA is similar to that of XCS with informed crossover operators that is given all information about problem structure on input and exploits this knowledge using problem-specific crossover operators.|Martin V. Butz,Martin Pelikan,Xavier Llorà,David E. Goldberg","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","57485|GECCO|2005|Understanding cooperative co-evolutionary dynamics via simple fitness landscapes|Cooperative co-evolution is often used to solve difficult optimization problems by means of problem decomposition. Its performance for such tasks can vary widely from good to disappointing. One of the reasons for this is that attempts to improve co-evolutionary performance using traditional EC analysis techniques often fail to provide the necessary insights into the dynamics of co-evolutionary systems, a key factor affecting performance. In this paper we use two simple fitness landscapes to illustrate the importance of taking a dynamical systems approach to analyzing co-evolutionary algorithms in order to understand them better and to improve their problem solving performance.|Elena Popovici,Kenneth A. De Jong","57429|GECCO|2005|The molecule evoluator an interactive evolutionary algorithm for designing drug molecules|To help chemists design new drugs, we created a tool that uses interactive evolution to design drug molecules, the \"Molecule Evoluator\". In contrast to most other evolutionary de novo design programs, the molecule representation and the set of mutations enable it to both search the chemical space of all drug like molecules extensively and to fine-tune molecular structures to the problem at hand. Additionally, we use interaction with the user as a fitness function, which is new in evolutionary algorithms in drug design. This interactivity allows the Molecule Evoluator to use the domain knowledge of the chemist to estimate the ease of synthesis and the biological activity of the compound. This knowledge can guide the optimization process and thereby improve its results. Chemists of our department using the Molecule Evoluator were able to find six novel and synthesizable druglike core structures, indicating that the Molecule Evoluator can be used as a tool to enhance the chemist's creativity.|Eric-Wubbo Lameijer,Adriaan P. IJzerman,Joost N. Kok","57545|GECCO|2005|Crossover is provably essential for the ising model on trees|Due to experimental evidence it is incontestable that crossover is essential for some fitness functions. However, theoretical results without assumptions are difficult. So-called real royal road functions are known where crossover is proved to be essential, i.e., mutation-based algorithms have an exponential expected runtime while the expected runtime of a genetic algorithm is polynomially bounded. However, these functions are artificial and have been designed in such a way that crossover is essential only at the very end (or at other well-specified points) of the optimization process.Here, a more natural fitness function based on a generalized Ising model is presented where crossover is essential throughout the whole optimization process. Mutation-based algorithms such as (+) EAs with constant population size are proved to have an exponential expected runtime while the expected runtime of a simple genetic algorithm with population size  and fitness sharing is polynomially bounded.|Dirk Sudholt","57461|GECCO|2005|Minimum spanning trees made easier via multi-objective optimization|Many real-world problems are multi-objective optimization problems and evolutionary algorithms are quite successful on such problems. Since the task is to compute or approximate the Pareto front, multi-objective optimization problems are considered as more difficult than single-objective problems. One should not forget that the fitness vector with respect to more than one objective contains more information that in principle can direct the search of evolutionary algorithms. Therefore, it is possible that a single-objective problem can be solved more efficiently via a generalized multi-objective model of the problem. That this is indeed the case is proved by investigating the computation of minimum spanning trees.|Frank Neumann,Ingo Wegener","57296|GECCO|2005|Diversity as a selection pressure in dynamic environments|Evolutionary algorithms (EAs) are widely used to deal with optimization problems in dynamic environments (DE) . When using EAs to solve DE problems, we are usually interested in the algorithm's ability to adapt and recover from the changes. One of the main problems facing an evolutionary method when solving DE problems is the loss of genetic diversity.In this paper, we investigate the use of evolutionary multi-objective optimization methods (EMOs) for single-objective DE problems. For that purpose, we introduce an artificial second objective with the aim to maintain useful diversity in the population. Six different artificial objectives are examined and compared.All the results will be compared against a traditional GA and the random immigrants algorithm. NSGA is employed as the evolutionary multi-objective technique.|Lam Thu Bui,Jürgen Branke,Hussein A. Abbass"],["57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57421|GECCO|2005|Fitness uniform deletion a simple way to preserve diversity|A commonly experienced problem with population based optimisation methods is the gradual decline in population diversity that tends to occur over time. This can slow a system's progress or even halt it completely if the population converges on a local optimum from which it cannot escape. In this paper we present the Fitness Uniform Deletion Scheme (FUDS), a simple but somewhat unconventional approach to this problem. Under FUDS the deletion operation is modified to only delete those individuals which are \"common\" in the sense that there exist many other individuals of similar fitness in the population. This makes it impossible for the population to collapse to a collection of highly related individuals with similar fitness. Our experimental results on a range of optimisation problems confirm this, in particular for deceptive optimisation problems the performance is significantly more robust to variation in the selection intensity.|Shane Legg,Marcus Hutter","57284|GECCO|2005|A model based on ant colony system and rough set theory to feature selection|In this paper we propose a hybrid approach to feature selection based on Ant Colony System algorithm and Rough Set Theory. Rough Set Theory offers the heuristic function to measure the quality of a single subset. We have studied the influence of the setting of the parameters for this problem, in particular for finding reducts. Experimental results show this hybrid approach is a promising method for features selection.|Rafael Bello,Ann Nowé,Yaile Caballero,Yudel Gómez,Peter Vrancx","57362|GECCO|2005|Feature influence for evolutionary learning|This paper presents an approach that deals with the feature selection problem, and includes two main aspects first, the selection is done during the evolutionary learning process, i.e., it is a dynamic approach and second, the selection is local, i.e., the algorithm selects the best features from the best space region to learn at a given time of the exploration process. While the traditional feature selection is based on the attribute relevance, our approach is based on a new concept, called feature influence, which is aware of the dynamics and locality of the concept. The feature influence provides a measure of the attribute relevance at a certain instant of the evolutionary learning process, since it depends on each generation. Experimental results have been obtained by comparing an EA--based supervised learning algorithm to its modified version to include the concept approached. The results show an excellent performance, as the new adapted algorithm achieves the same classification results while using less rules, less conditions in rules and much less generations. The experiments include the statistical significance of the improvement over a set of sixteen datasets from the UCI repository.|Raúl Giráldez,Jesús S. Aguilar-Ruiz","16150|IJCAI|2005|Reasoning with Inconsistent Ontologies|In this paper we present a framework of reasoning with inconsistent ontologies, in which pre-defined selection functions are used to deal with concept relevance. We examine how the notion of \"concept relevance\" can be used for reasoning with inconsistent ontologies. We have implemented a prototype called PION (Processing Inconsistent ONtologies), which is based on a syntactic relevance-based selection function. In this paper, we also report the experiments with PION.|Zhisheng Huang,Frank van Harmelen,Annette ten Teije","57361|GECCO|2005|Takeover time curves in random and small-world structured populations|We present discrete stochastic mathematical models for the growth curves of synchronous and synchronous evolutionary algorithms with populations structured ccording to a random graph. We show that, to good approximation, randomly structured and panmictic populations have the some growth behavior. Furthermore, we show that global selection intensity depends on the update policy. The validity of the models is confirmed by comparison with experimental results of simulations. We also present experimental results on small-world nd scale-free population graph topologies. We show that they lead to qualitatively similar results. However, the different nature of the nodes can be exploited to obtain more varied evolutionary behavior.|Mario Giacobini,Marco Tomassini,Andrea Tettamanzi","16086|IJCAI|2005|Feature Selection Based on the Shapley Value|We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.|Shay Cohen,Eytan Ruppin,Gideon Dror","16303|IJCAI|2005|Beyond TFIDF Weighting for Text Categorization in the Vector Space Model|KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.|Pascal Soucy,Guy W. Mineau","57566|GECCO|2005|Automatic feature selection in neuroevolution|Feature selection is the process of finding the set of inputs to a machine learning algorithm that will yield the best performance. Developing a way to solve this problem automatically would make current machine learning methods much more useful. Previous efforts to automate feature selection rely on expensive meta-learning or are applicable only when labeled training data is available. This paper presents a novel method called FS-NEAT which extends the NEAT neuroevolution method to automatically determine an appropriate set of inputs for the networks it evolves. By learning the network's inputs, topology, and weights simultaneously, FS-NEAT addresses the feature selection problem without relying on meta-learning or labeled data. Initial experiments in an autonomous car racing simulation demonstrate that FS-NEAT can learn better and faster than regular NEAT. In addition, the networks it evolves are smaller and require fewer inputs. Furthermore, FS-NEAT's performance remains robust even as the feature selection task it faces is made increasingly difficult.|Shimon Whiteson,Peter Stone,Kenneth O. Stanley,Risto Miikkulainen,Nate Kohl","57423|GECCO|2005|ARGEN  AREPO mixing the artificial genetic engineering and artificial evolution of populations to improve the search process|In this paper we analyze the performance of several evolutionary algorithms in the feature and instance selection problem. It is also introduced the ARGEN + AREPO search algorithm which has been tested in the same problem. There is no need to adapt parameters in this genetic algorithm, except the population size. The reported preliminary results show that using this technique in a wrapper model to search data subsets, we can obtain accuracy similar to the obtained with some of the genetic algorithms models here presented, but with less data.|Agustín León-Barranco,Sandra E. Barajas,Carlos A. Reyes García"],["57521|GECCO|2005|Breeding swarms a GAPSO hybrid|In this paper we propose a novel hybrid (GAPSO) algorithm, Breeding Swarms, combining the strengths of particle swarm optimization with genetic algorithms. The hybrid algorithm combines the standard velocity and position update rules of PSOs with the ideas of selection, crossover and mutation from GAs. We propose a new crossover operator, Velocity Propelled Averaged Crossover (VPAC), incorporating the PSO velocity vector. The VPAC crossover operator actively disperses the population preventing premature convergence. We compare the hybrid algorithm to both the standard GA and PSO models in evolving solutions to five standard function minimization problems. Results show the algorithm to be highly competitive, often outperforming both the GA and PSO.|Matthew Settles,Terence Soule","57323|GECCO|2005|A modified particle swarm optimization predicted by velocity|In standard particle swarm optimization (PSO), the velocity only provides a position displacement contrast with the longer computational time. To avoid premature convergence, a new modified PSO is proposed in which the velocity considered as a predictor, while the position considered as a corrector. The algorithm gives some balance between global and local search capability, and results the high computational efficiency. The optimization computing of some examples is made to show the new algorithm has better global search capacity and rapid convergence rate.|Zhihua Cui,Jianchao Zeng","57489|GECCO|2005|An effective use of crowding distance in multiobjective particle swarm optimization|In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions.|Carlo R. Raquel,Prospero C. Naval Jr.","57331|GECCO|2005|An efficient evolutionary algorithm applied to the design of two-dimensional IIR filters|This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","57329|GECCO|2005|Improving particle swarm optimization with differentially perturbed velocity|This paper introduces a novel scheme of improving the performance of particle swarm optimization (PSO) by a vector differential operator borrowed from differential evolution (DE). Performance comparisons of the proposed method are provided against (a) the original DE, (b) the canonical PSO, and (c) three recent, high-performance PSO-variants. The new algorithm is shown to be statistically significantly better on a seven-function test suite for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57330|GECCO|2005|Two improved differential evolution schemes for faster global search|Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures solution quality, time to find the solution, frequency of finding the solution, and scalability.|Swagatam Das,Amit Konar,Uday Kumar Chakraborty","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule","57483|GECCO|2005|Exploring extended particle swarms a genetic programming approach|Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.|Riccardo Poli,Cecilia Di Chio,William B. Langdon"],["16070|IJCAI|2005|A Multidimensional Semantic Framework for Adaptive Hypermedia Systems|This paper introduces a multidimensional semantic framework for adaptive systems. Different planes allow us to represent ontologies of user, her actions, context, device, domain, while the intersection between planes allow us to represent the semantic rules for inferring new user features or adaptation strategies. The adoption of ontology-based framework aims at creating a server for user modeling and adaptation strategy.|Francesca Carmagnola,Federica Cena,Cristina Gena,Ilaria Torre","16288|IJCAI|2005|A Formal Investigation of Mapping Language for Terminological Knowledge|The need to represent mappings between different ontologies has been recognized as a result of the fact that different ontologies may partially overlap, or even represent the same domain from different points of view. Unlike ontology languages, work on languages to represent ontology mappings has not yet reached a state where a common understanding of the basic principles exists. In this paper we propose a formal comparison of existing mapping languages by translating them into distributed first order logic. This allows us to analyze underlying assumptions and differences in the interpretation of ontology mappings.|Luciano Serafini,Heiner Stuckenschmidt,Holger Wache","16142|IJCAI|2005|Real-Time Path Planning for Humanoid Robot Navigation|We present a data structure and an algorithm for real-time path planning of a humanoid robot. Due to the many degrees of freedom, the robots shape and available actions are approximated for finding solutions efficiently. The resulting  dimensional configuration space is searched by the A* algorithm finding solutions in tenths of a second on lowperformance, embedded hardware. Experimental results demonstrate our solution for a robot in a world containing obstacles with different heights, stairs and a higher-level platform.|Jens-Steffen Gutmann,Masaki Fukuchi,Masahiro Fujita","16104|IJCAI|2005|On Solution Correspondences in Answer-Set Programming|We introduce a general framework for specifying program correspondence under the answer-set semantics. The framework allows to define different kinds of equivalence notions, including previously defined notions like strong and uniform equivalence, in which programs are extended with rules from a given context, and correspondence is determined by means of a binary relation. In particular, refined equivalence notions based on projected answer sets can be defined within this framework, where not all parts of an answer set are of relevance. We study general characterizations of inclusion and equivalence problems, introducing novel semantical structures. Furthermore, we deal with the issue of determining counterexamples for a given correspondence problem, and we analyze the computational complexity of correspondence checking.|Thomas Eiter,Hans Tompits,Stefan Woltran","16343|IJCAI|2005|Solving Logic Program Conflict through Strong and Weak Forgettings|We consider how to forget a set of atoms in a logic program. Intuitively, when a set of atoms is forgotten from a logic program, all atoms in the set should be eliminated from this program in some way, and other atoms related to them in the program might also be affected. We define notions of strong and weak forgettings in logic programs to capture such intuition and reveal their close connections to the notion of forgetting in classical propositional theories. Based on these notions, we then propose a framework for conflict solving in logic programs, which is general enough to represent many important conflict solving problems. We also study some essential semantic and computational properties in relation to strong and weak forgettings and conflict solving in our framework.|Yan Zhang,Norman Y. Foo,Kewen Wang","16099|IJCAI|2005|Explaining preferences with argument positions|When deciding what to do agents must choose among alternative actions and different agents may make different choices according to what they wish to achieve in the light of their preferences and values. It cannot be assumed, however, that agents have a conscious understanding of their value preferences independent of the reasoning situations in which they engage. In this paper we consider an extension to a generic framework for reasoning about arguments justifying actions in terms of values in which the preferences amongst values emerge from the reasoning process.|Sylvie Doutre,Trevor J. M. Bench-Capon,Paul E. Dunne","16210|IJCAI|2005|Relational Object Maps for Mobile Robots|Mobile robot map building is the task of generating a model of an environment from sensor data. Most existing approaches to mobile robot mapping either build topological representations or generate accurate, metric maps of an environment. In this paper we introduce relational object maps, a novel approach to building metric maps that represent individual objects such as doors or walls. We show how to extend relational Markov networks in order to reason about a hierarchy of objects and the spatial relationships between them. Markov chain Monte Carlo is used for efficient inference and to learn the parameters of the model. We show that the spatial constraints modeled by our mapping technique yield drastic improvements for labeling line segments extracted from laser range-finders.|Benson Limketkai,Lin Liao,Dieter Fox","57396|GECCO|2005|Evolution of Voronoi based fuzzy recurrent controllers|A fuzzy controller is usually designed by formulating the knowledge of a human expert into a set of linguistic variables and fuzzy rules. Among the most successful methods to automate the fuzzy controllers development process are evolutionary algorithms. In this work, we propose the Recurrent Fuzzy Voronoi (RFV) model, a representation for recurrent fuzzy systems. It is an extension of the FV model proposed by Kavka and Schoenauer that extends the application domain to include temporal problems. The FV model is a representation for fuzzy controllers based on Voronoi diagrams that can represent fuzzy systems with synergistic rules, fulfilling the -completeness property and providing a simple way to introduce a priory knowledge. In the proposed representation, the temporal relations are embedded by including internal units that provide feedback by connecting outputs to inputs. These internal units act as memory elements. In the RFV model, the semantic of the internal units can be specified together with the a priori rules. The geometric interpretation of the rules allows the use of geometric variational operators during the evolution. The representation and the algorithms are validated in two problems in the area of system identification and evolutionary robotics.|Carlos Kavka,Patricia Roggero,Marc Schoenauer","16058|IJCAI|2005|Viewing Referring Expression Generation as Search|Almost all natural language generation (NLG) systems are faced with the problem of the generation of referring expressions (GRE) given a symbol corresponding to an intended referent, how do we work out the semantic content of a referring expression that uniquely identifies the entity in question This is now one of the most widely explored problems in NLG over the last  years, a number of algorithms have been proposed for addressing different aspects of this problem, but the different approaches taken make it very difficult to compare and contrast the algorithms provided in any meaningful way. In this paper, we show how viewing the problem of referring expression generation as a search problem allows us to recast existing algorithms in a way that makes their similarities and differences clear.|Bernd Bohnet,Robert Dale","16294|IJCAI|2005|First-Order Logical Filtering|Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond immediate intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulae. We sidestep previous discouraging results, and show that our algorithms are exact in many cases of interest. These algorithms accept belief states in full FOL, which allows natural representation with explicit references to unidentified objects, and partially known relationships. Our algorithms keep the encoding compact for important classes of actions, such as STRIPS actions. These results apply to most expressive modeling languages, such as partial databases and belief revision in FOL.|Afsaneh Shirazi,Eyal Amir"],["16313|IJCAI|2005|Temporal-Difference Networks with History|Temporal-difference (TD) networks are a formalism for expressing and learning grounded world knowledge in a predictive form Sutton and Tanner, . However, not all partially observable Markov decision processes can be efficiently learned with TD networks. In this paper, we extend TD networks by allowing the network-update process (answer network) to depend on the recent history of previous actions and observations rather than only on the most recent action and observation. We show that this extension enables the solution of a larger class of problems than can be solved by the original TD networks or by history-based methods alone. In addition, we apply TD networks to a problem that, while still simple, is significantly larger than has previously been considered. We show that history-extended TD networks can learn much of the common-sense knowledge of an egocentric gridworld domain with a single bit of perception.|Brian Tanner,Richard S. Sutton","16075|IJCAI|2005|A Model for Generating Random Quantified Boolean Formulas|The quantified boolean formula (QBF) problem is a powerful generalization of the boolean satisfiability (SAT) problem where variables can be both universally and existentially quantified. Inspired by the fruitfulness of the established model for generating random SAT instances, we define and study a general model for generating random QBF instances. We exhibit experimental results showing that our model bears certain desirable similarities to the random SAT model, as well as a number of theoretical results concerning our model.|Hubie Chen,Yannet Interian","16147|IJCAI|2005|Solving POMDPs with Continuous or Large Discrete Observation Spaces|We describe methods to solve partially observable Markov decision processes (POMDPs) with continuous or large discrete observation spaces. Realistic problems often have rich observation spaces, posing significant problems for standard POMDP algorithms that require explicit enumeration of the observations. This problem is usually approached by imposing an a priori discretisation on the observation space, which can be sub-optimal for the decision making task. However, since only those observations that would change the policy need to be distinguished, the decision problem itself induces a lossless partitioning of the observation space. This paper demonstrates how to find this partition while computing a policy, and how the resulting discretisation of the observation space reveals the relevant features of the application domain. The algorithms are demonstrated on a toy example and on a realistic assisted living task.|Jesse Hoey,Pascal Poupart","16281|IJCAI|2005|Generative Modeling with Failure in PRISM|PRISM is a logic-based Turing-complete symbolic-statistical modeling language with a built-in parameter learning routine. In this paper,we enhance the modeling power of PRISM by allowing general PRISM programs to fail in the generation process of observable events. Introducing failure extends the class of definable distributions but needs a generalization of the semantics of PRISM programs. We propose a three valued probabilistic semantics and show how failure enables us to pursue constraint-based modeling of complex statistical phenomena.|Taisuke Sato,Yoshitaka Kameya,Neng-Fa Zhou","16034|IJCAI|2005|Learning Partially Observable Deterministic Action Models|We present the first tractable, exact solution for the problem of identifying actions' effects in partially observable STRIPS domains. Our algorithms resemble Version Spaces and Logical Filtering, and they identify all the models that are consistent with observations. They apply in other deterministic domains (e.g., with conditional effects), but are inexact (may return false positives) or inefficient (we could not bound the representation size). Our experiments verify the theoretical guarantees, and show that we learn STRIPS actions efficiently, with time that is significantly better than approaches for HMMs and Reinforcement Learning (which are inexact). Our results are especially surprising because of the inherent intractability of the general deterministic case. These results have been applied to an autonomous agent in a virtual world, facilitating decision making, diagnosis, and exploration.|Eyal Amir","16047|IJCAI|2005|Extracting Certificates from Quantified Boolean Formulas|A certificate of satisfiability for a quantified boolean formula is a compact representation of one of its models which is used to provide solver-independent evidence of satisfiability. In addition, it can be inspected to gather explicit information about the semantics of the formula. Due to the intrinsic nature of quantified formulas, such certificates demand much care to be efficiently extracted, compactly represented, and easily queried. We show how to solve all these problems.|Marco Benedetti","16267|IJCAI|2005|Conditional Planning in the Discrete Belief Space|Probabilistic planning with observability restrictions, as formalized for example as partially observable Markov decision processes (POMDP), has a wide range of applications, but it is computationally extremely difficult. For POMDPs, the most general decision problems about existence of policies satisfying certain properties are undecidable. We consider a computationally easier form of planning that ignores exact probabilities, and give an algorithm for a class of planning problems with partial observability. We show that the basic backup step in the algorithm is NP-complete. Then we proceed to give an algorithm for the backup step, and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.|Jussi Rintanen","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","16056|IJCAI|2005|A Decision-Theoretic Approach to Task Assistance for Persons with Dementia|Cognitive assistive technologies that aid people with dementia (such as Alzheimer's disease) hold the promise to provide such people with an increased level of independence. However, to realize this promise, such systems must account for the specific needs and preferences of individuals. We argue that this form of customization requires a sequential, decision-theoretic model of interaction. We describe both fully and partially observable Markov decision process (POMDP) models of a handwashing task, and show that, despite the potential computational complexity, these can be effectively solved and produce policies that are evaluated as useful by professional caregivers.|Jennifer Boger,Pascal Poupart,Jesse Hoey,Craig Boutilier,Geoff Fernie,Alex Mihailidis","16311|IJCAI|2005|Choosing between heuristics and strategies an enhanced model for decision-making|Often an agent that has to solve a problem must choose which heuristic or strategy will help it the most in achieving its objectives. Sometimes the agent wishes to obtain additional units of information on the possible heuristics and strategies in order to choose between them, but it may be costly. As a result, the agent's goal is to acquire enough units of information in order to make a decision while incurring minimal cost. We focus on situations where the agent must decide in advance how many units it would like to obtain. We present an algorithm for choosing between two options, and then formulate three methods for the general case where there are k   options to choose from. We investigate the -option algorithm and the general k-option methods effectiveness in two domains the -SAT domain, and the CT computer game. In both domains we present the experimental performance of our models. Results will show that applying the -option algorithm is beneficial and provides the agent a substantial gain. In addition, applying the k-option method in the domains investigated results in a moderate gain.|Shavit Talman,Rotem Toister,Sarit Kraus"],["57588|GECCO|2005|Adaptive crossover and mutation in genetic algorithms based on clustering technique|Instead of having fixed px and pm, this paper presents the use of fuzzy logic to adaptively tune px and pm for optimization of power electronic circuits throughout the process. By applying the K-means algorithm, distribution of the population in the search space is clustered in each training generation. Inferences of px and pm are performed by a fuzzy-based system that fuzzifies the relative sizes of the clusters containing the best and worst chromosomes. The proposed adaptation method is applied to optimize a buck regulator that requires satisfying some static and dynamic requirements. The optimized circuit component values, the regulator's performance, and the convergence rate in the training are favorably compared with the GA's using fixed px and p.|Jun Zhang,Henry Shu-Hung Chung,Jinghui Zhong","57282|GECCO|2005|Local and global order  convergence of a surrogate evolutionary algorithm|A Quasi-Monte-Carlo method based on the computation of a surrogate model of the fitness function is proposed, and its convergence at super-linear rate  is proved under rather mild assumptions on the fitness function -- but assuming that the starting point lies within a small neighborhood of a global maximum. A memetic algorithm is then constructed, that performs both a random exploration of the search space and the exploitation of the best-so-far points using the previous surrogate local algorithm, coupled through selection. Under the same mild hypotheses, the global convergence of the memetic algorithm, at the same  rate, is proved.|Anne Auger,Marc Schoenauer,Olivier Teytaud","16167|IJCAI|2005|Predicate-Oriented Isomorphism Elimination in Model Finding|Finding models of logical formulas is a challenging problem. For first-order formulas, a finite model can be found by exhaustive search. For many structured problem instances, there is much isomorphism in the search space. This paper proposes general-purpose techniques for eliminating isomorphic subspaces, which can be helpful when the formulas have many predicates. The techniques are based on inherent symmetries in first-order clauses.|Xiangxue Jia,Jian Zhang 0001","57494|GECCO|2005|EA models and population fixed-points versus mutation rates for functions of unitation|Using a dynamic systems model for the Simple Genetic Algorithm due to Vose, we analyze the fixed point behavior of the model without crossover applied to functions of unitation. Unitation functions are simplified fitness functions that reduce the search space into a smaller number of equivalence classes. This reduction allows easier computation of fixed points. We also create a dynamic systems model from a simple nondecreasing EA like the (+) EA and variants, then analyze this models on unitation classes.|J. Neal Richter,John Paxton,Alden H. Wright","16241|IJCAI|2005|Accurate and Low-cost Location Estimation Using Kernels|We present a novel method for indoor-location estimation using a vector-space model based on signals received from a wireless client. Our aim is to obtain an accurate mapping between the signal space and the physical space without incurring too much human calibration effort. This problem has traditionally been tackled through probabilistic models trained on manually labeled data, which are expensive to obtain. In this paper, we present a novel approach to building a mapping between the signalvector space and the physical location space using kernel canonical correlation analysis (KCCA). Its training requires much less human labor. Moreover, unlike traditional location-estimation systems that treat grid points as independent and discrete target classes during training, we use the physical location as a continuous feedback to build a similarity mapping using KCCA. We test our algorithm in a . wireless LAN environment, and demonstrate the advantage of our method in both accuracy and its ability to utilize a much smaller set of labeled training data than previous methods.|Jeffrey Junfeng Pan,James T. Kwok,Qiang Yang,Yiqiang Chen","57473|GECCO|2005|Evolutionary form-finding of tensegrity structures|Tensegrity structures are stable -dimensional mechanical structures which maintain their form due to an intricate balance of forces between disjoint rigid elements and continuous tensile elements. Tensegrity structures can give rise to lightweight structures with high strength-to-weight ratios and their utility has been appreciated in architecture, engineering and recently robotics. However, the determination of connectivity patterns of the rigid and tensile elements which lead to stable tensegrity is challenging. Available methods are limited to the use of heuristic guidelines, hierarchical design based on known components, or mathematical methods which can explore only a subset of the space. This paper investigates the use of evolutionary algorithms in the form-finding of tensegrity structures. It is shown that an evolutionary algorithm can be used to explore the space of arbitrary tensegrity structures which are difficult to design using other methods, and determine new, non-regular forms. It suggests that evolutionary algorithms can be used as the basis for a general design methodology for tensegrity structures.|Chandana Paul,Hod Lipson,Francisco J. Valero Cuevas","16226|IJCAI|2005|Applying Local Search to Disjunctive Temporal Problems|We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.|Michael D. Moffitt,Martha E. Pollack","57575|GECCO|2005|Probabilistic distribution models for EDA-based GP|This paper proposes a novel technique for a program evolution based on probabilistic models. In the proposed method, two probabilistic distribution models with probabilistic dependencies between variables are used together. We empirically comfirm that our proposed method has higher search performance. Thereafter, we discuss the effectiveness of its distribution models.|Kohsuke Yanai,Hitoshi Iba","57431|GECCO|2005|Combining competent crossover and mutation operators a probabilistic model building approach|This paper presents an approach to combine competent crossover and mutation operators via probabilistic model building. Both operators are based on the probabilistic model building procedure of the extended compact genetic algorithm (eCGA). The model sampling procedure of eCGA, which mimics the behavior of an idealized recombination---where the building blocks (BBs) are exchanged without disruption---is used as the competent crossover operator. On the other hand, a recently proposed BB-wise mutation operator---which uses the BB partition information to perform local search in the BB space---is used as the competent mutation operator. The resulting algorithm, called hybrid extended compact genetic algorithm (heCGA), makes use of the problem decomposition information for () effective recombination of BBs and () effective local search in the BB neighborhood. The proposed approach is tested on different problems that combine the core of three well known problem difficulty dimensions deception, scaling, and noise. The results show that, in the absence of domain knowledge, the hybrid approach is more robust than either single-operator-based approach.|Cláudio F. Lima,Kumara Sastry,David E. Goldberg,Fernando G. Lobo","57444|GECCO|2005|Using evolutionary optimization to improve Markov-based classification with limited training data|Bayesian classification using Markov model analysis of token strings is used in many areas such as computational linguistics, speech recognition, and bioinformatics. Unfortunately, for many problems, the available data sets are too small to accurately estimate the large number of parameters in a Markov model. In our work, we explore the possibility of using string space transformations to reduce the perplexity of the modeling problem and thereby improve model performance. The set of all possible string-to-string transformation functions is very large. By using a genetic algorithm to search for transformation functions that improve the performance of a Markov-based classifier, we are able to construct a classifier system that performs better than the Markov classifier alone. We go on to demonstrate the improved performance on the problem of classifying English and Spanish character strings, where training set size is arbitrarily limited.|Timothy Meekhof,Robert B. Heckendorn"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","16177|IJCAI|2005|Redundancy-free Island Parsing of Word Graphs|Island parsing is a bidirectional parsing strategy mostly used in speech analysis, as well as in applications where robustness is highly relevant andor processing resources are limited. Although there exists an efficient redundancy-free island parsing algorithm for string input, it has not yet been applied to word graph input, an application which is central for speech analysis systems. This paper describes how the established algorithm can be generalized from string input to word graphs, increasing its flexibility by integrating the selection of island seeds into the search process inherent to parsing.|Bernd Kiefer","16298|IJCAI|2005|Streamlining Local Search for Spatially Balanced Latin Squares|Streamlined constrained reasoning powerfully boosts the performance of backtrack search methods for finding hard combinatorial objects. We use so-called spatially balanced Latin squares to show how streamlining can also be very effective for local search Our approach is much faster and generates considerably larger spatially balanced Latin squares than previously reported approaches (up to order  the previous best results could only generate solutions up to order ). We also provide a detailed characterization of our streamliner and solution topology for small orders. We believe that streamlined local search is a general technique suitable for solving a wide range of hard combinatorial design problems.|Casey Smith,Carla P. Gomes,Cèsar Fernández","16124|IJCAI|2005|Limited Discrepancy Beam Search|Beam search reduces the memory consumption of best-first search at the cost of finding longer paths but its memory consumption can still exceed the given memory capacity quickly. We therefore develop BULB (Beam search Using Limited discrepancy Backtracking), a complete memory-bounded search method that is able to solve more problem instances of large search problems than beam search and does so with a reasonable runtime. At the same time, BULB tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory. We demonstrate these properties of BULB experimentally for three standard benchmark domains.|David Furcy,Sven Koenig","16226|IJCAI|2005|Applying Local Search to Disjunctive Temporal Problems|We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.|Michael D. Moffitt,Martha E. Pollack","57556|GECCO|2005|Coordinating multi-rover systems evaluation functions for dynamic and noisy environments|This paper addresses the evolution of control strategies for a collective a set of entities that collectively strives to maximize a global evaluation function that rates the performance of the full system. Directly addressing such problems by having a population of collectives and applying the evolutionary algorithm to that population is appealing, but the search space is prohibitively large in most cases. Instead, we focus on evolving control policies for each member of the collective. The main difficulty with this approach is creating an evaluation function for each member of the collective that is both aligned with the global evaluation function and sensitive to the fitness changes of the member. We show how to construct evaluation functions in dynamic, noisy and communication-limited collective environments. On a rover coordination problem, a control policy evolved using aligned and member-sensitive evaluations outperforms global evaluation methods by up to %. More notably, in the presence of a larger number of rovers or rovers with noisy and communication limited sensors, the improvements due to the proposed method become significantly more pronounced.|Kagan Tumer,Adrian K. Agogino","57267|GECCO|2005|Search space modulation in genetic algorithms evolving the search space by sinusoidal transformations|An experimental form of Modulation (Reinterpretation) of the Search Space is presented. This modulation is developed as a mathematical method that can be implemented directly into existing evolutionary algorithms without writing special operators, changing the program loop etc. The main mathematical principle behind this method is the dynamic sinusoidal envelope of the search space. This method is presented in order to solve some theoretical and practical issues in evolutionary algorithms like numerical bounded variables, dynamic focalized search, dynamic control of diversity, feasible region analysis etc.|José Antonio Martin H.","16044|IJCAI|2005|Proactive Algorithms for Scheduling with Probabilistic Durations|Proactive scheduling seeks to generate high quality solutions despite execution time uncertainty. Building on work in Beck and Wilson, , we conduct an empirical study of a number of algorithms for the job shop scheduling problem with probabilistic durations. The main contributions of this paper are the introduction and empirical analysis of a novel constraint-based search technique that can be applied beyond probabilistic scheduling problems, the introduction and empirical analysis of a number of deterministic filtering algorithms for probabilistic job shop scheduling, and the identification of a number of problem characteristics that contribute to algorithm performance.|J. Christopher Beck,Nic Wilson","57372|GECCO|2005|Improving network applications security a new heuristic to generate stress testing data|Buffer overflows cause serious problems in different categories of software systems. For example, if present in network or security applications, they can be exploited to gain unauthorized grant or access to the system. In embedded systems, such as avionics or automotive systems, they can be the cause of serious accidents.This paper proposes to combine static analysis and program slicing with evolutionary testing, to detect buffer overflow threats. Static analysis identifies vulnerable statements, while slicing and data dependency analysis identify the relationship between these statements and program or function inputs, thus reducing the search space.To guide the search towards discovering buffer overflow in this work we define three multi-objective fitness functions and compare them on two open-source systems. These functions account for terms such as the statement coverage, the coverage of vulnerable statements, the distance form buffer boundaries and the coverage of unconstrained nodes of the control flow graph.|Concettina Del Grosso,Giuliano Antoniol,Massimiliano Di Penta,Philippe Galinier,Ettore Merlo","57438|GECCO|2005|The enhanced evolutionary tabu search and its application to the quadratic assignment problem|We describe the Enhanced Evolutionary Tabu Search (EE-TS) local search technique. The EE-TS metaheuristic technique combines Reactive Tabu Search with evolutionary computing elements proven to work well in multimodal search spaces. An initial set of solutions is generated using a stochastic heuristic operator based on Restricted Candidate List. Reactive Tabu Search is augmented with selection and recombination operators that preserve common traits between solutions while maintaining a diverse set of good solutions. EE-TS performance is applied to the Quadratic Assignment Problem using problem instances from the QAPLIB. The results show that EE-TS compares favorably against other known techniques. In most cases, EE-TS was able to find the known optimal solutions in fewer iterations. We conclude by describing the main benefits and limitations of EE-TS.|John F. McLoughlin III,Walter Cedeño"],["57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57266|GECCO|2005|Goal-oriented preservation of essential genetic information by offspring selection|This contribution proposes an enhanced and generic selection model for Genetic Algorithms (GAs) and Genetic Programming (GP) which is able to preserve the alleles which are part of a high quality solution. Some selected aspects of these enhanced techniques are discussed exemplarily on the basis of standardized benchmark problems.|Michael Affenzeller,Stefan Wagner 0002,Stephan M. Winkler","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57468|GECCO|2005|A hardware pipeline for function optimization using genetic algorithms|Genetic Algorithms (GAs) are very commonly used as function optimizers, basically due to their search capability. A number of different serial and parallel versions of GA exist. In this paper, a pipelined version of the commonly used Genetic Algorithms and a corresponding hardware platform is described. The main idea of achieving pipelined execution of different operations of GA is to use a stochastic selection function which works with the fitness value of the candidate chromosome only. The modified algorithm is termed PLGA (Pipelined Genetic Algorithm). When executed in a CGA (Classical Genetic Algorithm) framework, the stochastic selection gives comparable performances with the roulette-wheel selection. In the pipelined hardware environment, PLGA will be much faster than the CGA. When executed on similar hardware platforms, PLGA may attain a maximum speedup of four over CGA. However, if CGA is executed in a uniprocessor system the speedup is much more. A comparison of PLGA against PGA (Parallel Genetic Algorithms) shows that PLGA may be even more effective than PGAs. A scheme for realizing the hardware pipeline is also presented. Since a general function evaluation unit is essential, a detailed description of one such unit is presented.|Malay Kumar Pakhira,Rajat K. De","57385|GECCO|2005|Open-ended robust design of analog filters using genetic programming|Most existing research on robust design using evolutionary algorithms (EA) follows the paradigm of traditional robust design, in which parameters of a design solution are tuned to improve the robustness of the system. However, the topological structure of a system may set a limit on the possible robustness achievable through parameter tuning. This paper proposes a new robust design paradigm that exploits the open-ended topological synthesis capability of genetic programming to evolve more robust systems. As a case study, a methodology for automated synthesis of dynamic systems, based on genetic programming and bond graph modeling (GPBG), is applied to evolve robust low-pass and high-pass analog filters. Compared with a traditional robust design approach based on a state-of-the-art real-parameter genetic algorithm (GA), it is shown that open-ended topology search by genetic programming with a fitness criterion rewarding robustness can evolve more robust systems with respect to parameter perturbations than what was achieved through parameter tuning alone, for our test problems.|Jianjun Hu,Xiwei Zhong,Erik D. Goodman","57408|GECCO|2005|New topologies for genetic search space|We propose three distance measures for genetic search space. One is a distance measure in the population space that is useful for understanding the working mechanism of genetic algorithms. Another is a distance measure in the solution space for K-grouping problems. This can be used for normalization in crossover. The third is a level distance measure for genetic algorithms, which is useful for measuring problem difficulty with respect to genetic algorithms. We show that the proposed measures are metrics and the measures are efficiently computed.|Yong-Hyuk Kim,Byung Ro Moon","57270|GECCO|2005|On the practical genetic algorithms|This paper offers practical design-guidelines for developing efficient genetic algorithms (GAs) to successfully solve real-world problems. As an important design component, a practical population-sizing model is presented and verified.|Chang Wook Ahn,Sanghoun Oh,Rudrapatna S. Ramakrishna","57423|GECCO|2005|ARGEN  AREPO mixing the artificial genetic engineering and artificial evolution of populations to improve the search process|In this paper we analyze the performance of several evolutionary algorithms in the feature and instance selection problem. It is also introduced the ARGEN + AREPO search algorithm which has been tested in the same problem. There is no need to adapt parameters in this genetic algorithm, except the population size. The reported preliminary results show that using this technique in a wrapper model to search data subsets, we can obtain accuracy similar to the obtained with some of the genetic algorithms models here presented, but with less data.|Agustín León-Barranco,Sandra E. Barajas,Carlos A. Reyes García","57481|GECCO|2005|An investigation into using genetic programming as a means of inducing solutions to novice procedural programming problems|The study presented in this paper forms part of a larger initiative aimed at creating a generic architecture for the development of intelligent programming tutors (IPTs) in an attempt to reduce the costs associated with building IPTs. Thus, instead of requiring the lecturer to provide solution algorithms to the programming problems that students will be tested on by the system, the generic architecture will automatically generate the solutions to these problems. This paper reports on the results of an investigation conducted to test the hypothesis that genetic programming (GP) can be used for this purpose. The paper proposes a genetic programming system for the induction of solutions to arithmetic, character and string manipulation, conditional, iterative, nested iteration, and recursive problems. The paper analyses the results of applying the proposed system to  randomly chosen novice procedural programming problems. Extensions made to the proposed system based on this analysis, namely, the implementation of the iterative structure-based algorithm (ISBA), are discussed.|Nelishia Pillay"],["57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","57501|GECCO|2005|Real-coded crossover as a role of kernel density estimation|This paper presents a kernel density estimation method by means of real-coded crossovers. Estimation of density algorithms (EDAs) are evolutionary optimization techniques, which determine the sampling strategy by means of a parametric probabilistic density function estimated from the population. Real-coded Genetic Algorithm (RCGA) does not explicitly estimate any probabilistic distribution, however, the probabilistic model of the population is implicitly estimated by crossovers and the sampling strategy is determined by this implicit probabilistic model. Based on this understanding, we propose a novel density estimation algorithm by using crossovers as nonparametric kernels and apply this kernel density estimation to the Gaussian Mixture modeling. We show that the proposed method is superior in the robustness of the computation and in the accuracy of the estimation by the comparison of conventional EM estimation.|Jun Sakuma,Shigenobu Kobayashi","57339|GECCO|2005|Not all linear functions are equally difficult for the compact genetic algorithm|Estimation of distribution algorithms (EDAs) try to solve an optimization problem by finding a probability distribution focussed around its optima. For this purpose they conduct a sampling-evaluation-adjustment cycle, where search points are sampled with respect to a probability distribution, which is adjusted according to the evaluation of the sampled points. Although there are many successful experiments suggesting the usefulness of EDAs, there are only few rigorous theoretical results apart from convergence results without time bounds. Here we present first rigorous runtime analyses of a simple EDA, the compact genetic algorithm, for linear pseudo-boolean functions on n variables. We prove a number of results showing that not all linear functions have the same asymptotical runtime.|Stefan Droste","57584|GECCO|2005|MRI magnet design search space analysis EDAs and a real-world problem with significant dependencies|This paper introduces the design of superconductive magnet configurations in Magnetic Resonance Imaging (MRI) systems as a challenging real-world problem for Evolutionary Algorithms (EAs). Analysis of the problem structure is conducted using a general statistical method, which could be easily applied to other problems. The results suggest that the problem is highly multimodal and likely to present a significant challenge for many algorithms. Through a series of preliminary experiments, a continuous Estimation of Distribution Algorithm (EDA) is shown to be able to generate promising designs with a small computational effort. The importance of utilizing problem-specific knowledge and the ability of an algorithm to capture dependencies in solving complex real-world problems is also highlighted.|Bo Yuan,Marcus Gallagher,Stuart Crozier","57456|GECCO|2005|A comparison study between genetic algorithms and bayesian optimize algorithms by novel indices|Genetic Algorithms (GAs) are a search and optimization technique based on the mechanism of evolution. Recently, another sort of population-based optimization method called Estimation of Distribution Algorithms (EDAs) have been proposed to solve the GA's defects. Although several comparison studies between GAs and EDAs have been made, little is known about differences of statistical features between them. In this paper, we propose new statistical indices which are based on the concepts of crossover and mutation, used in GAs, to analyze the behavior of the population based optimization techniques. We also show simple results of comparison studies between GAs and the Bayesian Optimization Algorithm (BOA), a well-known Estimation of Distribution Algorithms (EDAs).|Naoki Mori,Masayuki Takeda,Keinosuke Matsumoto","57537|GECCO|2005|Identifying valid solutions for the inference of regulatory networks|In this paper, we address the problem of finding gene regulatory networks from experimental DNA microarray data. The problem often is multi-modal and therefore appropriate optimization strategies become necessary. We propose to use a clustering based niching evolutionary algorithm to maintain diversity in the optimization population to prevent premature convergence and to raise the probability of finding the global optimum by identifying multiple alternative networks than standard algorithms. With this set of alternatives, the identification of the true solution has then to be addressed in a second post-processing step.|Christian Spieth,Felix Streichert,Nora Speer,Andreas Zell","57461|GECCO|2005|Minimum spanning trees made easier via multi-objective optimization|Many real-world problems are multi-objective optimization problems and evolutionary algorithms are quite successful on such problems. Since the task is to compute or approximate the Pareto front, multi-objective optimization problems are considered as more difficult than single-objective problems. One should not forget that the fitness vector with respect to more than one objective contains more information that in principle can direct the search of evolutionary algorithms. Therefore, it is possible that a single-objective problem can be solved more efficiently via a generalized multi-objective model of the problem. That this is indeed the case is proved by investigating the computation of minimum spanning trees.|Frank Neumann,Ingo Wegener","57410|GECCO|2005|Genetic algorithms using low-discrepancy sequences|The random number generator is one of the important components of evolutionary algorithms (EAs). Therefore, when we try to solve function optimization problems using EAs, we must carefully choose a good pseudo-random number generator. In EAs, the pseudo-random number generator is often used for creating uniformly distributed individuals. As the low-discrepancy sequences allow us to create individuals more uniformly than the random number sequences, we apply the low-discrepancy sequence generator, instead of the pseudo-random number generator, to EAs in this study. The numerical experiments show that the low-discrepancy sequence generator improves the search performances of EAs.|Shuhei Kimura,Koki Matsumura","57296|GECCO|2005|Diversity as a selection pressure in dynamic environments|Evolutionary algorithms (EAs) are widely used to deal with optimization problems in dynamic environments (DE) . When using EAs to solve DE problems, we are usually interested in the algorithm's ability to adapt and recover from the changes. One of the main problems facing an evolutionary method when solving DE problems is the loss of genetic diversity.In this paper, we investigate the use of evolutionary multi-objective optimization methods (EMOs) for single-objective DE problems. For that purpose, we introduce an artificial second objective with the aim to maintain useful diversity in the population. Six different artificial objectives are examined and compared.All the results will be compared against a traditional GA and the random immigrants algorithm. NSGA is employed as the evolutionary multi-objective technique.|Lam Thu Bui,Jürgen Branke,Hussein A. Abbass","57576|GECCO|2005|Population-based incremental learning with memory scheme for changing environments|In recent years there has been a growing interest in studying evolutionary algorithms for dynamic optimization problems due to its importance in real world applications. Several approaches have been developed, such as the memory scheme. This paper investigates the application of the memory scheme for population-based incremental learning (PBIL) algorithms, a class of evolutionary algorithms, for dynamic optimization problems. A PBIL-specific memory scheme is proposed to improve its adaptability in dynamic environments. In this memory scheme the working probability vector is stored together with the best sample it creates in the memory and is used to reactivate old environments when change occurs. Experimental study based on a series of dynamic environments shows the efficiency of the memory scheme for PBILs in dynamic environments. In this paper, the relationship between the memory scheme and the multi-population scheme for PBILs in dynamic environments is also investigated. The experimental results indicate a negative interaction of the multi-population scheme on the memory scheme for PBILs in the dynamic test environments.|Shengxiang Yang"]]},"title":{"entropy":5.859523687812512,"topics":["genetic programming, evolutionary for, particle swarms, algorithm for, for optimization, using genetic, differential evolution, optimization, particle optimization, evolutionary algorithm, estimation distribution, for function, optimization algorithm, swarms optimization, optimization with, evolutionary optimization, evolutionary and, using algorithm, using, and evolution","learning for, models for, constraint satisfaction, representations and, for and, combining and, models and, constraint and, reinforcement learning, models, statistical learning, generation for, image and, and theory, approach for, novel for, structural and, for constraint, for satisfaction, for data","the and, planning for, negative selection, classifier system, between and, feature selection, multi-agent system, and system, planning with, logic programs, estimation and, the between, evaluation and, with and, semantic for, measuring and, for and, reasoning with, the from, and reasoning","genetic algorithm, algorithm the, the problem, algorithm for, for problem, for the, the, genetic for, search for, artificial immune, genetic the, local search, search, distributed pomdps, dynamic environments, algorithm problem, evolutionary the, search and, parallel genetic, immune system","for function, method for, optimization using, differential evolution, and evolution, evolution for, function optimization, using evolution, using evolutionary, multimodal optimization, with evolution, differential optimization, gene using, multimodal function, for multimodal, multiobjective optimization, differential for, function and, evolutionary method, the evolution","genetic programming, using genetic, using algorithm, genetic algorithm, genetic for, with genetic, for using, using programming, using and, for design, and design, and genetic, design using, and programming, using, for programming, design genetic, algorithm design, system using, design","learning for, for statistical, reinforcement learning, for application, statistical learning, learning with, application, with, memory, consistency","representations and, combining and, for and, and, and theory, image and, complexity and, recognition, object, revision, bayesian, symbolic, modeling","negative selection, feature selection, semantic for, for selection, the selection, selection, semantic, ontology, detection, robust, interactive, role, discovery","planning for, with and, reasoning with, planning with, planning and, with, for with, action, temporal, domain, rule, modelling","for networks, analysis for, algorithm networks, analysis networks, evolutionary algorithm, analysis algorithm, for solving, analysis, evolutionary for, networks, algorithm for, solving, time, mobile, activity, mining, large, data, improved, for","search for, the search, search and, local search, search problem, algorithm search, search with, local for, distributed pomdps, search, the space, search space, web search, search application, global, knowledge, identifying, optimization"],"ranking":[["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57452|GECCO|2005|Bayesian optimization models for particle swarms|We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.|Christopher K. Monson,Kevin D. Seppi","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57324|GECCO|2005|A case study of process facility optimization using discrete event simulation and genetic algorithm|Optimization problems such as resource allocation, job-shop scheduling, equipment utilization and process scheduling occur in a broad range of processing industries. This paper presents modeling, simulation and optimization of a port facility such that effective operational management is obtained. A GA base approach has been integrated with the port system model to optimize its operation. A case study of bulk material port handling systems is considered.|Keshav P. Dahal,Stuart Galloway,Graeme M. Burt,Jim R. McDonald,Ian Hopkins","57468|GECCO|2005|A hardware pipeline for function optimization using genetic algorithms|Genetic Algorithms (GAs) are very commonly used as function optimizers, basically due to their search capability. A number of different serial and parallel versions of GA exist. In this paper, a pipelined version of the commonly used Genetic Algorithms and a corresponding hardware platform is described. The main idea of achieving pipelined execution of different operations of GA is to use a stochastic selection function which works with the fitness value of the candidate chromosome only. The modified algorithm is termed PLGA (Pipelined Genetic Algorithm). When executed in a CGA (Classical Genetic Algorithm) framework, the stochastic selection gives comparable performances with the roulette-wheel selection. In the pipelined hardware environment, PLGA will be much faster than the CGA. When executed on similar hardware platforms, PLGA may attain a maximum speedup of four over CGA. However, if CGA is executed in a uniprocessor system the speedup is much more. A comparison of PLGA against PGA (Parallel Genetic Algorithms) shows that PLGA may be even more effective than PGAs. A scheme for realizing the hardware pipeline is also presented. Since a general function evaluation unit is essential, a detailed description of one such unit is presented.|Malay Kumar Pakhira,Rajat K. De","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57309|GECCO|2005|Optimization of passenger car design for the mitigation of pedestrian head injury using a genetic algorithm|The problem of pedestrian injury is a significant one throughout the world. In , there were  pedestrian fatalities in Europe and  in the US. Significant advances have been made by automotive safety researchers and vehicle manufacturers to address this issue with respect to the design of vehicles, but the complex nature of pedestrian accident scenarios has resulted in great difficulty when using traditional statistical methods. Specifically, problems have been encountered when attempting to study the effects of individual parameters of vehicle front-end geometry on pedestrian head injury. This paper attempts to demonstrate the feasibility of applying the field of evolutionary computation to the problem of pedestrian safety by using a simple genetic algorithm to optimize the centre-line geometry of a car's front-end for the reduction of pedestrian head and thoracic injury. The fitness of each design is assessed by creating a multi-body mathematical model of the vehicle front and simulating impacts with models of different sized pedestrians, and ranking according to the combined injury scores.|Emma Carter,Steve Ebdon,Clive Neal-Sturgess","57444|GECCO|2005|Using evolutionary optimization to improve Markov-based classification with limited training data|Bayesian classification using Markov model analysis of token strings is used in many areas such as computational linguistics, speech recognition, and bioinformatics. Unfortunately, for many problems, the available data sets are too small to accurately estimate the large number of parameters in a Markov model. In our work, we explore the possibility of using string space transformations to reduce the perplexity of the modeling problem and thereby improve model performance. The set of all possible string-to-string transformation functions is very large. By using a genetic algorithm to search for transformation functions that improve the performance of a Markov-based classifier, we are able to construct a classifier system that performs better than the Markov classifier alone. We go on to demonstrate the improved performance on the problem of classifying English and Spanish character strings, where training set size is arbitrarily limited.|Timothy Meekhof,Robert B. Heckendorn","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["16093|IJCAI|2005|Learning Forward Models for Robots|Forward models enable a robot to predict the effects of its actions on its own motor system and its environment. This is a vital aspect of intelligent behaviour, as the robot can use predictions to decide the best set of actions to achieve a goal. The ability to learn forward models enables robots to be more adaptable and autonomous this paper describes a system whereby they can be learnt and represented as a Bayesian network. The robot's motor system is controlled and explored using 'motor babbling'. Feedback about its motor system comes from computer vision techniques requiring no prior information to perform tracking. The learnt forward model can be used by the robot to imitate human movement.|Anthony M. Dearden,Yiannis Demiris","16083|IJCAI|2005|A Unified Theory of Structural Tractability for Constraint Satisfaction and Spread Cut Decomposition|In this paper we introduce a generic form of structural decomposition for the constraint satisfaction problem, which we call a guarded decomposition. We show that many existing decomposition methods can be characterized in terms of finding guarded decompositions satisfying certain specified additional conditions. Using the guarded decomposition framework we are also able to define a new form of decomposition, which we call a spread cut. We show that discovery of width k spread-cut decompositions is tractable for each k, and that the spread cut decomposition strongly generalize all existing decompositions except hypertrees. Finally we exhibit a family of hypergraphs Hn, for n  , ,  ..., where the width of the best hypertree decomposition of each Hn is at least n, but the width of the best spreadcut decomposition is at most n.|David A. Cohen,Peter Jeavons,Marc Gyssens","16133|IJCAI|2005|The Complexity of Quantified Constraint Satisfaction Problems under Structural Restrictions|We give a clear picture of the tractabilityintractability frontier for quantified constraint satisfaction problems (QCSPs) under structural restrictions. On the negative side, we prove that checking QCSP satisfiability remains PSPACE-hard for all known structural properties more general than bounded treewidth and for the incomparable hypergraph acyclicity. Moreover, if the domain is not fixed, the problem is PSPACE-hard even for tree-shaped constraint scopes. On the positive side, we identify relevant tractable classes, including QCSPs with prefix  having bounded hypertree width, and QCSPs with a bounded number of guards. The latter are solvable in polynomial time without any bound on domains or quantifier alternations.|Georg Gottlob,Gianluigi Greco,Francesco Scarcello","57360|GECCO|2005|A statistical learning theory approach of bloat|Code bloat, the excessive increase of code size, is an important issue in Genetic Programming (GP). This paper proposes a theoretical analysis of code bloat in the framework of symbolic regression in GP, from the viewpoint of Statistical Learning Theory, a well grounded mathematical toolbox for Machine Learning. Two kinds of bloat must be distinguished in that context, depending whether the target function lies in the search space or not. Then, important mathematical results are proved using classical results from Statistical Learning. Namely, the Vapnik-Chervonenkis dimension of programs is computed, and further results from Statistical Learning allow to prove that a parsimonious fitness ensures Universal Consistency (the solution minimizing the empirical error does converge to the best possible error when the number of examples goes to infinity). However, it is proved that the standard method consisting in choosing a maximal program size depending on the number of examples might still result in programs of infinitely increasing size with their accuracy a more complicated modification of the fitness is proposed that theoretically avoids unnecessary bloat while nevertheless preserving the Universal Consistency.|Sylvain Gelly,Olivier Teytaud,Nicolas Bredeche,Marc Schoenauer","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","16034|IJCAI|2005|Learning Partially Observable Deterministic Action Models|We present the first tractable, exact solution for the problem of identifying actions' effects in partially observable STRIPS domains. Our algorithms resemble Version Spaces and Logical Filtering, and they identify all the models that are consistent with observations. They apply in other deterministic domains (e.g., with conditional effects), but are inexact (may return false positives) or inefficient (we could not bound the representation size). Our experiments verify the theoretical guarantees, and show that we learn STRIPS actions efficiently, with time that is significantly better than approaches for HMMs and Reinforcement Learning (which are inexact). Our results are especially surprising because of the inherent intractability of the general deterministic case. These results have been applied to an autonomous agent in a virtual world, facilitating decision making, diagnosis, and exploration.|Eyal Amir","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16293|IJCAI|2005|Intimate Learning A Novel Approach for Combining Labelled and Unlabelled Data|This paper introduces a new bootstrapping method closely related to co-training and scoped-learning. The method is tested on a Web information extraction task of learning course names from web pages in which we use very few labelled items as seed data ( web pages) and combine with an unlabelled set ( web pages). The overall performance improved the precisionrecall from .%.% for a baseline EM-based method to .%.% for intimate learning.|Zhongmin Shi,Anoop Sarkar","16130|IJCAI|2005|QCSP-Solve A Solver for Quantified Constraint Satisfaction Problems|The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.|Ian P. Gent,Peter Nightingale,Kostas Stergiou","16239|IJCAI|2005|Corrective Explanation for Interactive Constraint Satisfaction|Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.|Barry O'Sullivan,Barry O'Callaghan,Eugene C. Freuder"],["57284|GECCO|2005|A model based on ant colony system and rough set theory to feature selection|In this paper we propose a hybrid approach to feature selection based on Ant Colony System algorithm and Rough Set Theory. Rough Set Theory offers the heuristic function to measure the quality of a single subset. We have studied the influence of the setting of the parameters for this problem, in particular for finding reducts. Experimental results show this hybrid approach is a promising method for features selection.|Rafael Bello,Ann Nowé,Yaile Caballero,Yudel Gómez,Peter Vrancx","16132|IJCAI|2005|Integrating Planning and Temporal Reasoning for Domains with Durations and Time Windows|The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the th International Planning Competition showing very good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina","57300|GECCO|2005|Kernel-based ellipsoidal conditions in the real-valued XCS classifier system|Many learning classifier system (LCS) implementations are restricted to the binary problem realm. Recently, the XCS classifier system was enhanced to be able to handle real-valued inputs among others. In the real-valued enhancement, XCSF applies as a function approximation system that partitions the input space in hyperrectangular subspaces specified in the classifiers. This paper changes the classifier conditions to hyperspheres and hyperellipsoids and investigates the consequent performance impact. It is shown that the modifications yield improved performance in continuous functions. Even in discontinuous functions with parallel boundaries, XCS's performance does not degrade. Thus, for the real-valued problem domain, ellipsoidal condition structures can improve XCS's performance. From a more general perspective, this paper shows that XCS is readily applicable in diverse problem domains. To apply the system even more successfully, suitable kernel-based bases need to be found and used as classifier conditions. XCS distributes the available structures over the problem space evolving more specialized structures in more complex problem subspaces.|Martin V. Butz","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16262|IJCAI|2005|InterActive Feature Selection|We study the effects of feature selection and human feedback on features in active learning settings. Our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features. Consistent with previous findings, we find that feature selection based on the labeled training set has little effect. But our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion (%) of the most relevant features. Furthermore, these experiments show that feature labeling takes much less (about th) time than document labeling. We propose an algorithm that interleaves labeling features and documents which significantly accelerates active learning.|Hema Raghavan,Omid Madani,Rosie Jones","57566|GECCO|2005|Automatic feature selection in neuroevolution|Feature selection is the process of finding the set of inputs to a machine learning algorithm that will yield the best performance. Developing a way to solve this problem automatically would make current machine learning methods much more useful. Previous efforts to automate feature selection rely on expensive meta-learning or are applicable only when labeled training data is available. This paper presents a novel method called FS-NEAT which extends the NEAT neuroevolution method to automatically determine an appropriate set of inputs for the networks it evolves. By learning the network's inputs, topology, and weights simultaneously, FS-NEAT addresses the feature selection problem without relying on meta-learning or labeled data. Initial experiments in an autonomous car racing simulation demonstrate that FS-NEAT can learn better and faster than regular NEAT. In addition, the networks it evolves are smaller and require fewer inputs. Furthermore, FS-NEAT's performance remains robust even as the feature selection task it faces is made increasingly difficult.|Shimon Whiteson,Peter Stone,Kenneth O. Stanley,Risto Miikkulainen,Nate Kohl","57541|GECCO|2005|Is negative selection appropriate for anomaly detection|Negative selection algorithms for hamming and real-valued shape-spaces are reviewed. Problems are identified with the use of these shape-spaces, and the negative selection algorithm in general, when applied to anomaly detection. A straightforward self detector classification principle is proposed and its classification performance is compared to a real-valued negative selection algorithm and to a one-class support vector machine. Earlier work suggests that real-value negative selection requires a single class to learn from. The investigations presented in this paper reveal, however, that when applied to anomaly detection, the real-valued negative selection and self detector classification techniques require positive and negative examples to achieve a high classification accuracy. Whereas, one-class SVMs only require examples from a single class.|Thomas Stibor,Philipp H. Mohr,Jonathan Timmis,Claudia Eckert","57445|GECCO|2005|A first order logic classifier system|Motivated by the intention to increase the expressive power of learning classifier systems, we developed a new Xcs derivative, Fox-cs, where the classifier and observation languages are a subset of first order logic. We found that Fox-cs was viable at tasks in two relational task domains, poker and blocks world, which cannot be represented easily using traditional bit-string classifiers and inputs. We also found that for these tasks, the level of generality obtained by Fox-cs in the portion of population that produces optimal behaviour is consistent with Wilson's generality hypothesis.|Drew Mellor","57435|GECCO|2005|The compact classifier system motivation analysis and first results|This paper presents an initial analysis of how maximally general and accurate rules can be evolved in a Pittsburgh-style classifier system. In order to be able to perform such analysis we introduce a simple bare-bones Pittsburgh classifier systems---the compact classifier system (CCS)---based on estimation of distribution algorithms. Using a common rule encoding scheme of Pittsburgh classifier systems, CCS maintains a dynamic set of probability vectors that compactly describe a rule set. The compact genetic algorithm is used to evolve each of the initially perturbed probability vectors which represents the rules. Results show how CCS is able to evolve in a compact, simple, and elegant manner rule sets composed by maximally general and accurate rules.|Xavier Llorà,Kumara Sastry,David E. Goldberg","16197|IJCAI|2005|From knowledge-based programs to graded belief-based programs part II off-line reasoning|Belief-based programs generalize knowledgebased programs Fagin et al.,  by allowing for incorrect beliefs, unreliable observations, and branching conditions that refer to implicit graded beliefs, such as in \"while my belief about the direction to the railway station is not strong enough do ask someone\". We show how to reason off-line about the possible executions of a belief-based program, which calls for introducing second-order uncertainty in the model.|Noël Laverny,Jérôme Lang"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","57306|GECCO|2005|A hybrid evolutionary algorithm for the p-median problem|A hybrid evolutionary algorithm (EA) for the p-median problem consist of two stages, each of which is a steady-state hybrid EA. These EAs encode selections of medians as subsets of the candidate sites, apply a recombination operator tailored to the problem, and select symbols in chromosomes to mutate based on an explicit collective memory (named virtual loser). They also apply a sequence of two or three local search procedures to each new solution. Tests e.g. on the benchmark problem instances of ORLIB returned results within .% of the best solutions known.|István Borgulya","57499|GECCO|2005|Multiobjective VLSI cell placement using distributed genetic algorithm|Genetic Algorithms have worked fairly well for the VLSI cell placement problem, albeit with significant run times. Two parallel models for GA are presented for VLSI cell placement where the objectives are optimizing power dissipation, timing performance and interconnect wirelength, while layout width is a constraint. A Master-Slave approach is mentioned wherein both fitness calculation and crossover mechanism are distributed among slaves. A Multi-Deme parallel GA is also presented in which each processor works independently on an allocated subpopulation followed by information exchange through migration of chromosomes. A pseudo-diversity approach is taken, wherein similar solutions with the same overall cost values are not permitted in the population at any given time. A series of experiments are performed on ISCAS- benchmarks to show the performance of the Multi-Deme approach.|Sadiq M. Sait,Mohammed Faheemuddin,Mahmood R. Minhas,Syed Sanaullah","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","57474|GECCO|2005|A hybrid genetic algorithm with pattern search for finding heavy atoms in protein crystals|One approach for determining the molecular structure of proteins is a technique called iso-morphous replacement, in which crystallographers dope protein crystals with heavy atoms, such as mercury or platinum. By comparing measured amplitudes of diffracted x-rays through protein crystals with and without the heavy atoms, the locations of the heavy atoms can be estimated. Once the locations of the heavy atoms are known, the phases of the diffracted x-rays through the protein crystal can be estimated, which in turn enables the structure of the protein to be estimated. Unfortunately, the key step in this process is the estimation of the locations of the heavy atoms, and this is a multi-modal, non-linear inverse problem. We report results of a pilot study that show that a -stage hybrid algorithm, using a stochastic genetic algorithm for stage  followed by a deterministic pattern search algorithm for stage , can successfully locate up to  heavy atoms in computer simulated crystals using noise free data. We conclude that the method may be a viable approach for finding heavy atoms in protein crystals, and suggest ways in which the approach can be scaled up to larger problems.|Joshua L. Payne,Margaret J. Eppstein","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","57408|GECCO|2005|New topologies for genetic search space|We propose three distance measures for genetic search space. One is a distance measure in the population space that is useful for understanding the working mechanism of genetic algorithms. Another is a distance measure in the solution space for K-grouping problems. This can be used for normalization in crossover. The third is a level distance measure for genetic algorithms, which is useful for measuring problem difficulty with respect to genetic algorithms. We show that the proposed measures are metrics and the measures are efficiently computed.|Yong-Hyuk Kim,Byung Ro Moon","57574|GECCO|2005|A scalable parallel genetic algorithm for x-ray spectroscopic analysis|We use a parallel multi-objective genetic algorithm to drive a search and reconstruction spectroscopic analysis of plasma gradients in inertial confinement fusion (ICF) implosion cores. In previous work, we had shown that our serial multi-objective Genetic Algorithm was a good method to solve two-criteria X-ray spectroscopy diagnostics problems. However, this serial version was slow and we therefore could not incorporate better physics and more criteria to solve larger problems and handle larger data sets. In this paper, we develop and use a parallel multi-objective genetic algorithm based on a master-slave model to solve three criteria spectroscopic analysis problems. The algorithm works well in reconciling experimental observations with theoretical physics model parameters. In addition, theoretical analysis and experimental results on the parallelized version show good scalability with up to  processors. This reduces the time for running the GA from . hours to . minutes.|Kai Xu,Sushil J. Louis,Roberto C. Mancini","57274|GECCO|2005|Heuristic rules embedded genetic algorithm to solve in-core fuel management optimization problem|Because of the large number of possible combinations for the fuel assembly loading in the core, the design of the loading pattern (LP) is a complex optimization problem. It requires finding an optimal fuel arrangement in order to achieve maximum cycle length while satisfying the safety constraints. The objective of this study is to develop a loading pattern optimization code. Generally in-core fuel management codes are written for specific cores and limited fuel inventory. One of the goals of this study is to develop a loading pattern optimization code, which is applicable for all types of Pressurized Water Reactor (PWR) core structures with unlimited number of fuel assembly types in the inventory. To reach this goal an innovative genetic algorithm is developed with modifying the classical representation of the genotype. To obtain the best result in a shorter time not only the representation is changed but also the algorithm is changed to use in-core fuel management heuristics rules. The improved GA code was tested demonstrating the advantages of the introduced enhancements. The core physics code used in this research is Moby-Dick, which was developed to analyze the VVER reactors by SKODA Inc.|Fatih Alim,Kostadin Ivanov","57438|GECCO|2005|The enhanced evolutionary tabu search and its application to the quadratic assignment problem|We describe the Enhanced Evolutionary Tabu Search (EE-TS) local search technique. The EE-TS metaheuristic technique combines Reactive Tabu Search with evolutionary computing elements proven to work well in multimodal search spaces. An initial set of solutions is generated using a stochastic heuristic operator based on Restricted Candidate List. Reactive Tabu Search is augmented with selection and recombination operators that preserve common traits between solutions while maintaining a diverse set of good solutions. EE-TS performance is applied to the Quadratic Assignment Problem using problem instances from the QAPLIB. The results show that EE-TS compares favorably against other known techniques. In most cases, EE-TS was able to find the known optimal solutions in fewer iterations. We conclude by describing the main benefits and limitations of EE-TS.|John F. McLoughlin III,Walter Cedeño"],["57281|GECCO|2005|Optimization with constraints using a cultured differential evolution approach|In this paper we propose a cultural algorithm, where different knowledge sources modify the variation operator of a differential evolution algorithm. Differential evolution is used as a basis for the population, variation and selection processes. The experiments performed show that the cultured differential evolution is able to reduce the number of fitness function evaluations needed to obtain a good aproximation of the optimum value in constrained real-parameter optimization. Comparisons are provided with respect to three techniques that are representative of the state-of-the-art in the area.|Ricardo Landa Becerra,Carlos A. Coello Coello","57434|GECCO|2005|A differential evolution based incremental training method for RBF networks|The Differential Evolution (DE) is a floating-point encoded evolutionary strategy for global optimization. It has been demonstrated to be an efficient, effective, and robust optimization method, especially for problems containing continuous variables. This paper concerns applying a DE-based algorithm to training Radial Basis Function (RBF) networks with variables including centres, weights, and widths of RBFs. The proposed algorithm consists of three steps the first step is the initial tuning, which focuses on searching for the center, weight, and width of a one-node RBF network, the second step is the local tuning, which optimizes the three variables of the one-node RBF network --- its centre, weight, and width, and the third step is the global tuning, which optimizes all the parameters of the whole network together. The second step and the third step both use the cycling scheme to find the parameters of RBF network. The Mean Square Error from the desired to actual outputs is applied as the objective function to be minimized. Training the networks is demonstrated by approximating a set of functions, using different strategies of DE. A comparison of the net performances with several approaches reported in the literature is given and shows the resulting network performs better in the tested functions. The results show that proposed method improves the compared approximation results.|Junhong Liu,Jouni Lampinen","57463|GECCO|2005|Enhancing differential evolution performance with local search for high dimensional function optimization|In this paper, we proposed Fittest Individual Refinement (FIR), a crossover based local search method for Differential Evolution (DE). The FIR scheme accelerates DE by enhancing its search capability through exploration of the neighborhood of the best solution in successive generations. The proposed memetic version of DE (augmented by FIR) is expected to obtain an acceptable solution with a lower number of evaluations particularly for higher dimensional functions. Using two different implementations DEfirDE and DEfirSPX we showed that proposed FIR increases the convergence velocity of DE for well known benchmark functions as well as improves the robustness of DE against variation of population. Experiments using multimodal landscape generator showed our proposed algorithms consistently outperformed their parent algorithms. A performance comparison with reported results of well known real coded memetic algorithms is also presented.|Nasimul Noman,Hitoshi Iba","57447|GECCO|2005|Promising infeasibility and multiple offspring incorporated to differential evolution for constrained optimization|In this paper, we incorporate a diversity mechanism to the differential evolution algorithm to solve constrained optimization problems without using a penalty function. The aim is twofold () to allow infeasible solutions with a promising value of the objective function to remain in the population and also () to increase the probabilities of an individual to generate a better offspring while promoting collaboration of all the population to generate better solutions. These goals are achieved by allowing each parent to generate more than one offspring. The best offspring is selected using a comparison mechanism based on feasibility and this child is compared against its parent. To maintain diversity, the proposed approach uses a mechanism successfully adopted with other evolutionary algorithms where, based on a parameter Sr a solution (between the best offspring and the current parent) with a better value of the objective function can remain in the population, regardless of its feasibility. The proposed approach is validated using test functions from a well-known benchmark commonly adopted to validate constraint-handling techniques used with evolutionary algorithms. The statistical results obtained by the proposed approach are highly competitive (based on quality, robustness and number of evaluations of the objective function) with respect to other constraint-handling techniques, either based on differential evolution or on other evolutionary algorithms, that are representative of the state-of-the-art in the area. Finally, a small set of experiments were made to detect sensitivity of the approach to its parameters.|Efrén Mezura-Montes,Jesús Velázquez-Reyes,Carlos A. Coello Coello","57462|GECCO|2005|Inference of gene regulatory networks using s-system and differential evolution|In this work we present an improved evolutionary method for inferring S-system model of genetic networks from the time series data of gene expression. We employed Differential Evolution (DE) for optimizing the network parameters to capture the dynamics in gene expression data. In a preliminary investigation we ascertain the suitability of DE for a multimodal and strongly non-linear problem like gene network estimation. An extension of the fitness function for attaining the sparse structure of biological networks has been proposed. For estimating the parameter values more accurately an enhancement of the optimization procedure has been also suggested. The effectiveness of the proposed method was justified performing experiments on a genetic network using different numbers of artificially created time series data.|Nasimul Noman,Hitoshi Iba","57354|GECCO|2005|An artificial immune network for multimodal function optimization on dynamic environments|Multimodal optimization algorithms inspired by the immune system are generally characterized by a dynamic control of the population size and by diversity maintenance along the search. One of the most popular proposals is denoted opt-aiNet (artificial immune network for optimization) and is extended here to deal with time-varying fitness functions. Additional procedures are designed to improve the overall performance and the robustness of the immune-inspired approach, giving rise to a version for dynamic optimization, denoted dopt-aiNet. Firstly, challenging benchmark problems in static multimodal optimization are considered to validate the new proposal. No parameter adjustment is necessary to adapt the algorithm according to the peculiarities of each problem. In the sequence, dynamic environments are considered, and usual evaluation indices are adopted to assess the performance of dopt-aiNet and compare with alternative solution procedures available in the literature.|Fabrício Olivetti de França,Fernando J. Von Zuben,Leandro Nunes de Castro","57468|GECCO|2005|A hardware pipeline for function optimization using genetic algorithms|Genetic Algorithms (GAs) are very commonly used as function optimizers, basically due to their search capability. A number of different serial and parallel versions of GA exist. In this paper, a pipelined version of the commonly used Genetic Algorithms and a corresponding hardware platform is described. The main idea of achieving pipelined execution of different operations of GA is to use a stochastic selection function which works with the fitness value of the candidate chromosome only. The modified algorithm is termed PLGA (Pipelined Genetic Algorithm). When executed in a CGA (Classical Genetic Algorithm) framework, the stochastic selection gives comparable performances with the roulette-wheel selection. In the pipelined hardware environment, PLGA will be much faster than the CGA. When executed on similar hardware platforms, PLGA may attain a maximum speedup of four over CGA. However, if CGA is executed in a uniprocessor system the speedup is much more. A comparison of PLGA against PGA (Parallel Genetic Algorithms) shows that PLGA may be even more effective than PGAs. A scheme for realizing the hardware pipeline is also presented. Since a general function evaluation unit is essential, a detailed description of one such unit is presented.|Malay Kumar Pakhira,Rajat K. De","57276|GECCO|2005|Fitness-based neighbor selection for multimodal function optimization|We propose a selection scheme called Fitness-based Neighbor Selection (FNS) for multimodal optimization. The FNS is aimed for ill-scaled and locally multimodal domain, both found in real-world numerical optimization problem.In FNS, selection is applied to parent-child pair that most likely belong to the same attractor. We determine such pair with statistical comparison of the fitness values sampled from region between the pairs, instead of conventional Euclidean distance. In addition, the ranks of a parent among sampled values are used to determine if the parent is replaceable. These measurements makes the algorithm scale-invariant thus robust in ill-scaled domain.|Shin Ando,Shigenobu Kobayashi","57399|GECCO|2005|Efficient differential evolution using speciation for multimodal function optimization|In this paper differential evolution is extended by using the notion of speciation for solving multimodal optimization problems. The proposed species-based DE (SDE) is able to locate multiple global optima simultaneously through adaptive formation of multiple species (or subpopulations) in an DE population at each iteration step. Each species functions as an DE by itself. Successive local improvements through species formation can eventually transform into global improvements in identifying multiple global optima. In this study the performance of SDE is compared with another recently proposed DE variant CrowdingDE. The computational complexity of SDE, the effect of population size and species radius on SDE are investigated. SDE is found to be more computationally efficient than CrowdingDE over a number of benchmark multimodal test functions.|Xiaodong Li","57277|GECCO|2005|Adaptive isolation model using data clustering for multimodal function optimization|In this paper, we propose a GA model called Adaptive Isolation Model(AIM), for multimodal optimization. It uses a data clustering algorithm to detect clusters in GA population, which identifies the attractors in the fitness landscape. Then, subpopulations which makes-up the clusters are isolated and optimized independently. Meanwhile, the region of the isolated subpopulations in the original landscape are suppressed. The isolation increases comprehensiveness, i.e., the probability of finding weaker attractors, and the overall efficiency of multimodal search. The advantage of the AIM is that it does not require distance between the optima as a presumed parameter, as it is estimated from the variancecovariance matrix of the subpopulation.Further, AIM's behavior and efficiency is equivalent to basic GA in unimodal landscape, in terms of number of evaluation. Therefore, it is applied recursively to all subpopulations until they converge to a suboptima. This makes AIM suitable for locally-multimodal landscapes, which have closely located attractors that are difficult to distinguish in the initial run.The performance of AIM is evaluated in several benchmark problems and compared to iterated hill-climbing methods.|Shin Ando,Jun Sakuma,Shigenobu Kobayashi"],["57269|GECCO|2005|Inexact pattern matching using genetic algorithm|A Genetic Algorithm for graphical pattern matching based on angle matching had been proposed. It has proven quite effective in matching simple patterns. However, the algorithm needs some modifications to enhance its accuracy on pattern matching when there are some differences between two patterns in terms of numbers of nodes, shapes and rotations. This paper presents the modifications, such as the introduction of node exemption, inexact matching between straight lines and curves in the patterns, and consideration of rotational degrees of the patterns. Each angle is also given with a weight to indicate the significant degree of the angle. A multi-objective function is used to reflect the similarity between two patterns. The experiments designed to evaluate the algorithm have shown very promising results. It is highly accurate on patterns matching with dissimilarities in shapes, numbers of nodes and rotational degrees.|Surapong Auwatanamongkol","57314|GECCO|2005|MDGA motif discovery using a genetic algorithm|Computationally identifying transcription factor binding sites in the promoter regions of genes is an important problem in computational biology and has been under intensive research for a decade. To predict the binding site locations efficiently, many algorithms that incorporate either approximate or heuristic techniques have been developed. However, the prediction accuracy is not satisfactory and binding site prediction thus remains a challenging problem. In this paper, we develop an approach that can be used to predict binding site motifs using a genetic algorithm. Based on the generic framework of a genetic algorithm, the approach explores the search space of all possible starting locations of the binding site motifs in different target sequences with a population that undergoes evolution. Individuals in the population compete to participate in the crossovers and mutations occur with a certain probability. Initial experiments demonstrated that our approach could achieve high prediction accuracy in a small amount of computation time. A promising advantage of our approach is the fact that the computation time does not explicitly depend on the length of target sequences and hence may not increase significantly when the target sequences become very long.|Dongsheng Che,Yinglei Song,Khaled Rasheed","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57518|GECCO|2005|Design of air pump system using bond graph and genetic programming method|This paper introduces a redesign method for an air pump system using bond graphs and genetic programming to maximize outflow subject to a constraint specifying maximum power consumption. The redesign process can alter the topological connections among components and can introduce additional components. The air pump system is a mixed-domain system that includes electromagnetic, mechanical and pneumatic elements. Bond graphs are domain independent, allow free composition, and are efficient for classification and analysis of models. Genetic programming is well recognized as a powerful tool for open-ended search. The combination of these two powerful methods, BGGP, was applied for redesign of an air pump system.|Kisung Seo,Erik D. Goodman,Ronald C. Rosenberg","57425|GECCO|2005|A multi-objective genetic algorithm for robust design optimization|Real-world multi-objective engineering design optimization problems often have parameters with uncontrollable variations. The aim of solving such problems is to obtain solutions that in terms of objectives and feasibility are as good as possible and at the same time are least sensitive to the parameter variations. Such solutions are said to be robust optimum solutions. In order to investigate the trade-off between the performance and robustness of optimum solutions, we present a new Robust Multi-Objective Genetic Algorithm (RMOGA) that optimizes two objectives a fitness value and a robustness index. The fitness value serves as a measure of performance of design solutions with respect to multiple objectives and feasibility of the original optimization problem. The robustness index, which is based on a non-gradient based parameter sensitivity estimation approach, is a measure that quantitatively evaluates the robustness of design solutions. RMOGA does not require a presumed probability distribution of uncontrollable parameters and also does not utilize the gradient information of these parameters. Three distance metrics are used to obtain the robustness index and robust solutions. To illustrate its application, RMOGA is applied to two well-studied engineering design problems from the literature.|Mian Li,Shapour Azarm,Vikrant Aute","57428|GECCO|2005|Multiplex PCR primer design for gene family using genetic algorithm|The multiplex PCR experiment is to amplify multiple regions of a DNA sequence at the same time by using different primer pairs. Designing feasible primer pairs for multiplex PCR is a tedious task since there are too many constraints to be satisfied. In this paper, a new method for multiplex PCR primer design strategy using genetic algorithm is proposed. The proposed algorithm is able to find a set of suitable primer pairs more efficient and uses a MAP model to speed up the examination of the specificity constraint that is important for gene family sequences. The dry-dock experiment shows that the proposed algorithm finds several sets of primer pairs of gene family sequences for multiplex PCR that not only obey the design properties, but also have specificity.|Hong-Long Liang,Chungnan Lee,Jain-Shing Wu","57385|GECCO|2005|Open-ended robust design of analog filters using genetic programming|Most existing research on robust design using evolutionary algorithms (EA) follows the paradigm of traditional robust design, in which parameters of a design solution are tuned to improve the robustness of the system. However, the topological structure of a system may set a limit on the possible robustness achievable through parameter tuning. This paper proposes a new robust design paradigm that exploits the open-ended topological synthesis capability of genetic programming to evolve more robust systems. As a case study, a methodology for automated synthesis of dynamic systems, based on genetic programming and bond graph modeling (GPBG), is applied to evolve robust low-pass and high-pass analog filters. Compared with a traditional robust design approach based on a state-of-the-art real-parameter genetic algorithm (GA), it is shown that open-ended topology search by genetic programming with a fitness criterion rewarding robustness can evolve more robust systems with respect to parameter perturbations than what was achieved through parameter tuning alone, for our test problems.|Jianjun Hu,Xiwei Zhong,Erik D. Goodman","57401|GECCO|2005|Determining equations for vegetation induced resistance using genetic programming|Inducing equations based on theory and data is a time-honoured technique in science. This is usually done manually, based on theoretical understanding and previously established equations. In this work, for a particular problem in hydraulics, human induction of equations is compared with the use of genetic programming. It will be shown that even with the use of synthetic data for training, genetic programming was capable of identifying a relationship that was more concise and more accurate than the relationship uncovered by scientists. As such this is a human-competitive result. Furthermore it will be shown that the genetic programming induced expression could be embedded in a line of theoretical work, filling in a few gaps in an already established line of reasoning. The resulting equation is the most accurate and elegant formulation of vegetation induced resistance to date.|Maarten Keijzer,Martin Baptist,Vladan Babovic,Javier Rodriguez Uthurburu","57432|GECCO|2005|Primer design for multiplex PCR using a genetic algorithm|Multiplex Polymerase Chain Reaction (PCR) experiments are used for amplifying several segments of the target DNA simultaneously and thereby to conserve template DNA, reduce the experimental time, and minimize the experimental expense. The success of the experiment is dependent on primer design. However, this can be a dreary task as there are many constrains such as melting temperatures, primer length, GC content and complementarity that need to be optimized to obtain a good PCR product. Motivated by the lack of primer design tools for multiplex PCR genotypic assay, we propose a multiplex PCR primer design tool using a genetic algorithm, which is a stochastic approach based on the concept of biological evolution, biological genetics and genetic operations on chromosomes, to find an optimal selection of primer pairs for multiplex PCR experiments. The presented experimental results indicate that the proposed algorithm is capable of finding a series of primer pairs that obeies the design properties in the same tube.|Feng-Mao Lin,Hsien-Da Huang,Hsi-Yuan Huang,Jorng-Tzong Horng","57309|GECCO|2005|Optimization of passenger car design for the mitigation of pedestrian head injury using a genetic algorithm|The problem of pedestrian injury is a significant one throughout the world. In , there were  pedestrian fatalities in Europe and  in the US. Significant advances have been made by automotive safety researchers and vehicle manufacturers to address this issue with respect to the design of vehicles, but the complex nature of pedestrian accident scenarios has resulted in great difficulty when using traditional statistical methods. Specifically, problems have been encountered when attempting to study the effects of individual parameters of vehicle front-end geometry on pedestrian head injury. This paper attempts to demonstrate the feasibility of applying the field of evolutionary computation to the problem of pedestrian safety by using a simple genetic algorithm to optimize the centre-line geometry of a car's front-end for the reduction of pedestrian head and thoracic injury. The fitness of each design is assessed by creating a multi-body mathematical model of the vehicle front and simulating impacts with models of different sized pedestrians, and ranking according to the combined injury scores.|Emma Carter,Steve Ebdon,Clive Neal-Sturgess"],["16092|IJCAI|2005|View Learning for Statistical Relational Learning With an Application to Mammography|Statistical relational learning (SRL) constructs probabilistic models from relational databases. A key capability of SRL is the learning of arcs (in the Bayes net sense) connecting entries in different rows of a relational table, or in different tables. Nevertheless, SRL approaches currently are constrained to use the existing database schema. For many database applications, users find it profitable to define alternative \"views\" of the database, in effect defining new fields or tables. Such new fields or tables can also be highly useful in learning. We provide SRL with the capability of learning new views.|Jesse Davis,Elizabeth S. Burnside,Inês de Castro Dutra,David Page,Raghu Ramakrishnan,Vítor Santos Costa,Jude W. Shavlik","16035|IJCAI|2005|A Two-Stage Method for Active Learning of Statistical Grammars|Active learning reduces the amount of manually annotated sentences necessary when training state-of-the-art statistical parsers. One popular method, uncertainty sampling, selects sentences for which the parser exhibits low certainty. However, this method does not quantify confidence about the current statistical model itself. In particular, we should be less confident about selection decisions based on low frequency events. We present a novel two-stage method which first targets sentences which cannot be reliably selected using uncertainty sampling, and then applies standard uncertainty sampling to the remaining sentences. An evaluation shows that this method performs better than pure uncertainty sampling, and better than an ensemble method based on bagged ensemble members only.|Markus Becker,Miles Osborne","16252|IJCAI|2005|Learning against opponents with bounded memory|Recently, a number of authors have proposed criteria for evaluating learning algorithms in multiagent systems. While well-justified, each of these has generally given little attention to one of the main challenges of a multi-agent setting the capability of the other agents to adapt and learn as well. We propose extending existing criteria to apply to a class of adaptive opponents with bounded memory. We then show an algorithm that provably achieves an o-best response against this richer class of opponents while simultaneously guaranteeing a minimum payoff against any opponent and performing well in self-play. This new algorithm also demonstrates strong performance in empirical tests against a variety of opponents in a wide range of environments.|Rob Powers,Yoav Shoham","57362|GECCO|2005|Feature influence for evolutionary learning|This paper presents an approach that deals with the feature selection problem, and includes two main aspects first, the selection is done during the evolutionary learning process, i.e., it is a dynamic approach and second, the selection is local, i.e., the algorithm selects the best features from the best space region to learn at a given time of the exploration process. While the traditional feature selection is based on the attribute relevance, our approach is based on a new concept, called feature influence, which is aware of the dynamics and locality of the concept. The feature influence provides a measure of the attribute relevance at a certain instant of the evolutionary learning process, since it depends on each generation. Experimental results have been obtained by comparing an EA--based supervised learning algorithm to its modified version to include the concept approached. The results show an excellent performance, as the new adapted algorithm achieves the same classification results while using less rules, less conditions in rules and much less generations. The experiments include the statistical significance of the improvement over a set of sixteen datasets from the UCI repository.|Raúl Giráldez,Jesús S. Aguilar-Ruiz","57288|GECCO|2005|An abstraction agorithm for genetics-based reinforcement learning|Abstraction is a higher order cognitive ability that facilitates the production of rules that are independent of their associations. Experience from real-world data-mining has shown the need for such higher level rules. The game of Connect  is both multistep and complex, so standard Q-learning and Learning Classifier Systems perform poorly. The introduction of a novel Abstraction algorithm into an LCS is shown to improve performance in the evolution of playing strategies.|William N. L. Browne,Dan Scott","16261|IJCAI|2005|Using Predictive Representations to Improve Generalization in Reinforcement Learning|The predictive representations hypothesis holds that particularly good generalization will result from representing the state of the world in terms of predictions about possible future experience. This hypothesis has been a central motivation behind recent research in, for example, PSRs and TD networks. In this paper we present the first explicit investigation of this hypothesis. We show in a reinforcement-learning example (a grid-world navigation task) that a predictive representation in tabular form can learn much faster than both the tabular explicit-state representation and a tabular history-based method.|Eddie J. Rafols,Mark B. Ring,Richard S. Sutton,Brian Tanner","57360|GECCO|2005|A statistical learning theory approach of bloat|Code bloat, the excessive increase of code size, is an important issue in Genetic Programming (GP). This paper proposes a theoretical analysis of code bloat in the framework of symbolic regression in GP, from the viewpoint of Statistical Learning Theory, a well grounded mathematical toolbox for Machine Learning. Two kinds of bloat must be distinguished in that context, depending whether the target function lies in the search space or not. Then, important mathematical results are proved using classical results from Statistical Learning. Namely, the Vapnik-Chervonenkis dimension of programs is computed, and further results from Statistical Learning allow to prove that a parsimonious fitness ensures Universal Consistency (the solution minimizing the empirical error does converge to the best possible error when the number of examples goes to infinity). However, it is proved that the standard method consisting in choosing a maximal program size depending on the number of examples might still result in programs of infinitely increasing size with their accuracy a more complicated modification of the fitness is proposed that theoretically avoids unnecessary bloat while nevertheless preserving the Universal Consistency.|Sylvain Gelly,Olivier Teytaud,Nicolas Bredeche,Marc Schoenauer","16215|IJCAI|2005|Concurrent Hierarchical Reinforcement Learning|We consider applying hierarchical reinforcement learning techniques to problems in which an agent has several effectors to control simultaneously. We argue that the kind of prior knowledge one typically has about such problems is best expressed using a multithreaded partial program, and present concurrent ALisp, a language for specifying such partial programs. We describe algorithms for learning and acting with concurrent ALisp that can be efficient even when there are exponentially many joint choices at each decision point. Finally, we show results of applying these methods to a complex computer game domain.|Bhaskara Marthi,Stuart J. Russell,David Latham,Carlos Guestrin","16106|IJCAI|2005|Reinforcement Learning in POMDPs Without Resets|We consider the most realistic reinforcement learning setting in which an agent starts in an unknown environment (the POMDP) and must follow one continuous and uninterrupted chain of experience with no access to \"resets\" or \"offline\" simulation. We provide algorithms for general connected POMDPs that obtain near optimal average reward. One algorithm we present has a convergence rate which depends exponentially on a certain horizon time of an optimal policy, but has no dependence on the number of (unobservable) states. The main building block of our algorithms is an implementation of an approximate reset strategy, which we show always exists in every POMDP. An interesting aspect of our algorithms is how they use this strategy when balancing exploration and exploitation.|Eyal Even-Dar,Sham M. Kakade,Yishay Mansour","57576|GECCO|2005|Population-based incremental learning with memory scheme for changing environments|In recent years there has been a growing interest in studying evolutionary algorithms for dynamic optimization problems due to its importance in real world applications. Several approaches have been developed, such as the memory scheme. This paper investigates the application of the memory scheme for population-based incremental learning (PBIL) algorithms, a class of evolutionary algorithms, for dynamic optimization problems. A PBIL-specific memory scheme is proposed to improve its adaptability in dynamic environments. In this memory scheme the working probability vector is stored together with the best sample it creates in the memory and is used to reactivate old environments when change occurs. Experimental study based on a series of dynamic environments shows the efficiency of the memory scheme for PBILs in dynamic environments. In this paper, the relationship between the memory scheme and the multi-population scheme for PBILs in dynamic environments is also investigated. The experimental results indicate a negative interaction of the multi-population scheme on the memory scheme for PBILs in the dynamic test environments.|Shengxiang Yang"],["16159|IJCAI|2005|Combining Structural Descriptions and Image-based Representations for Image Object and Scene Recognition|Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.|Nicolas Do Huu,Williams Paquier,Raja Chatila","16171|IJCAI|2005|Iterated Belief Revision Revised|The AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide generally accepted criteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulates alone, however, are too permissive They support operators by which all newly acquired information is canceled as soon as an agent learns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the DP postulates, and we show how to solve the problem by an additional postulate of independence. We give a representation theorem for this postulate and prove that it is compatible with AGM and DP.|Yi Jin,Michael Thielscher","57388|GECCO|2005|On the complexity of hierarchical problem solving|Competent Genetic Algorithms can efficiently address problems in which the linkage between variables is limited to a small order k. Problems with higher order dependencies can only be addressed efficiently if further problem properties exist that can be exploited. An important class of problems for which this occurs is that of hierarchical problems. Hierarchical problems can contain dependencies between all variables (kn) while being solvable in polynomial time.An open question so far is what precise properties a hierarchical problem must possess in order to be solvable efficiently. We study this question by investigating several features of hierarchical problems and determining their effect on computational complexity, both analytically and empirically. The analyses are based on the Hierarchical Genetic Algorithm (HGA), which is developed as part of this work. The HGA is tested on ranges of hierarchical problems, produced by a generator for hierarchical problems.|Edwin D. de Jong,Richard A. Watson,Dirk Thierens","16281|IJCAI|2005|Generative Modeling with Failure in PRISM|PRISM is a logic-based Turing-complete symbolic-statistical modeling language with a built-in parameter learning routine. In this paper,we enhance the modeling power of PRISM by allowing general PRISM programs to fail in the generation process of observable events. Introducing failure extends the class of definable distributions but needs a generalization of the semantics of PRISM programs. We propose a three valued probabilistic semantics and show how failure enables us to pursue constraint-based modeling of complex statistical phenomena.|Taisuke Sato,Yoshitaka Kameya,Neng-Fa Zhou","57310|GECCO|2005|Symbolic regression in multicollinearity problems|In this paper the potential of GP-generated symbolic regression for alleviating multicollinearity problems in multiple regression is presented with a case study in an industrial setting. The main advantage of this approach is the potential to produce a simple and stable polynomial model in terms of the original variables.|Flor A. Castillo,Carlos M. Villa","16309|IJCAI|2005|The Ontology Revision|An ontology consists of a set of concepts, a set of constraints imposing on instances of concepts, and the subsumption relation. It is assumed that an ontology is a tree under the subsumption relation between concepts. To preserve structural properties of ontologies, the ontology revision is not only contracting ontologies by discarding statements inconsistent with a revising statement, but also extracting statements consistent with the revising statement and adding some other statements. In the ontology revision, the consistency of a revising statement with the theory of the logical closure of the ontology under the closed world assumption is discussed. The basic postulates of the ontology revision are proposed and a concrete ontology revision is given based on the consistence or inconsistence of an ontology and a revising statement.|Yu Sun,Yuefei Sui","16068|IJCAI|2005|The Inferential Complexity of Bayesian and Credal Networks|This paper presents new results on the complexity of graph-theoretical models that represent probabilities (Bayesian networks) and that represent interval and set valued probabilities (credal networks). We define a new class of networks with bounded width, and introduce a new decision problem for Bayesian networks, the maximin a posteriori. We present new links between the Bayesian and credal networks, and present new results both for Bayesian networks (most probable explanation with observations, maximin a posteriori) and for credal networks (bounds on probabilities a posteriori, most probable explanation with and without observations, maximum a posteriori).|Cassio Polpo de Campos,Fabio Gagliardi Cozman","16164|IJCAI|2005|Combining Memory and Landmarks with Predictive State Representations|It has recently been proposed that it is advantageous to have models of dynamical systems be based solely on observable quantities. Predictive state representations (PSRs) are a type of model that uses predictions about future observations to capture the state of a dynamical system. However, PSRs do not use memory of past observations. We propose a model called memory-PSRs that uses both memories of the past, and predictions of the future. We show that the use of memories provides a number of potential advantages. It can reduce the size of the model (in comparison to a PSR model). In addition many dynamical systems have memories that can serve as landmarks that completely determine the current state. The detection and recognition of landmarks is advantageous because they can serve to reset a model that has gotten off-track, as often happens when the model is learned from samples. This paper develops both memory-PSRs and the use and detection of landmarks.|Michael R. James,Britton Wolfe,Satinder P. Singh","16258|IJCAI|2005|PsychSim Modeling Theory of Mind with Decision-Theoretic Agents|Agent-based modeling of human social behavior is an increasingly important research area. A key factor in human social interaction is our beliefs about others, a theory of mind. Whether we believe a message depends not only on its content but also on our model of the communicator. How we act depends not only on the immediate effect but also on how we believe others will react. In this paper, we discuss PsychSim, an implemented multiagent-based simulation tool for modeling interactions and influence. While typical approaches to such modeling have used first-order logic, Psych-Sim agents have their own decision-theoretic model of the world, including beliefs about its environment and recursive models of other agents. Using these quantitative models of uncertainty and preferences, we have translated existing psychological theories into a decision-theoretic semantics that allow the agents to reason about degrees of believability in a novel way. We discuss PsychSim's underlying architecture and describe its application to a school violence scenario for illustration.|David V. Pynadath,Stacy Marsella","16036|IJCAI|2005|Fast and Complete Symbolic Plan Recognition|Recent applications of plan recognition face several open challenges (i) matching observations to the plan library is costly, especially with complex multi-featured observations (ii) computing recognition hypotheses is expensive. We present techniques for addressing these challenges. First, we show a novel application of machine-learning decision-tree to efficiently map multi-featured observations to matching plan steps. Second, we provide efficient lazy-commitment recognition algorithms that avoid enumerating hypotheses with every observation, instead only carrying out bookkeeping incrementally. The algorithms answer queries as to the current state of the agent, as well as its history of selected states. We provide empirical results demonstrating their efficiency and capabilities.|Dorit Avrahami-Zilberbrand,Gal A. Kaminka"],["57532|GECCO|2005|Unbiased tournament selection|Tournament selection is a popular form of selection which is commonly used with genetic algorithms, genetic programming and evolutionary programming. However, tournament selection introduces a sampling bias into the selection process. We review analytic results and present empirical evidence that shows this bias has a significant impact on search performance. We introduce two new forms of unbiased tournament selection that remove or reduce sampling bias in tournament selection.|Artem Sokolov,Darrell Whitley","57304|GECCO|2005|Estimating the detector coverage in a negative selection algorithm|This paper proposes a statistical mechanism to analyze the detector coverage in a negative selection algorithm, namely a quantitative measurement of a detector set's capability to detect nonself data. This novel method has the advantage of statistical confidence in the estimation of the actual coverage. Furthermore, unlike the existing analysis works of negative selection, it doesn't depend on specific detector representation and generation algorithm. Not only can it be implemented as a procedure independent from the steps to generate detectors, the experiments in this paper showed that it can also be tightly integrated into the detector generation algorithm to control the number of detectors.|Zhou Ji,Dipankar Dasgupta","57375|GECCO|2005|Applying both positive and negative selection to supervised learning for anomaly detection|This paper presents a novel approach of applying both positive selection and negative selection to supervised learning for anomaly detection. It first learns the patterns of the normal class via co-evolutionary genetic algorithm, which is inspired from the positive selection, and then generates synthetic samples of the anomaly class, which is based on the negative selection in the immune system. Two algorithms about synthetic generation of the anomaly class are proposed. One deals with data sets containing a few anomalous samples while the other deals with data sets containing no anomalous samples at all. The experimental results on some benchmark data sets from UCI data set repertory show that the detection rate is improved evidently, accompanied by a slight increase in false alarm rate via introducing novel synthetic samples of the anomaly class. The advantages of our method are the increased ability of classifiers in identifying both previously known and innovative anomalies, and the maximal degradation of overfitting phenomenon.|Xiaoshu Hang,Honghua Dai","16086|IJCAI|2005|Feature Selection Based on the Shapley Value|We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.|Shay Cohen,Eytan Ruppin,Gideon Dror","16262|IJCAI|2005|InterActive Feature Selection|We study the effects of feature selection and human feedback on features in active learning settings. Our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features. Consistent with previous findings, we find that feature selection based on the labeled training set has little effect. But our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion (%) of the most relevant features. Furthermore, these experiments show that feature labeling takes much less (about th) time than document labeling. We propose an algorithm that interleaves labeling features and documents which significantly accelerates active learning.|Hema Raghavan,Omid Madani,Rosie Jones","57566|GECCO|2005|Automatic feature selection in neuroevolution|Feature selection is the process of finding the set of inputs to a machine learning algorithm that will yield the best performance. Developing a way to solve this problem automatically would make current machine learning methods much more useful. Previous efforts to automate feature selection rely on expensive meta-learning or are applicable only when labeled training data is available. This paper presents a novel method called FS-NEAT which extends the NEAT neuroevolution method to automatically determine an appropriate set of inputs for the networks it evolves. By learning the network's inputs, topology, and weights simultaneously, FS-NEAT addresses the feature selection problem without relying on meta-learning or labeled data. Initial experiments in an autonomous car racing simulation demonstrate that FS-NEAT can learn better and faster than regular NEAT. In addition, the networks it evolves are smaller and require fewer inputs. Furthermore, FS-NEAT's performance remains robust even as the feature selection task it faces is made increasingly difficult.|Shimon Whiteson,Peter Stone,Kenneth O. Stanley,Risto Miikkulainen,Nate Kohl","57541|GECCO|2005|Is negative selection appropriate for anomaly detection|Negative selection algorithms for hamming and real-valued shape-spaces are reviewed. Problems are identified with the use of these shape-spaces, and the negative selection algorithm in general, when applied to anomaly detection. A straightforward self detector classification principle is proposed and its classification performance is compared to a real-valued negative selection algorithm and to a one-class support vector machine. Earlier work suggests that real-value negative selection requires a single class to learn from. The investigations presented in this paper reveal, however, that when applied to anomaly detection, the real-valued negative selection and self detector classification techniques require positive and negative examples to achieve a high classification accuracy. Whereas, one-class SVMs only require examples from a single class.|Thomas Stibor,Philipp H. Mohr,Jonathan Timmis,Claudia Eckert","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","57367|GECCO|2005|Discriminating and visualizing anomalies using negative selection and self-organizing maps|An immune inspired model that can detect anomalies, even when trained only with normal samples, and can learn from encounters with new anomalies is presented. The model combines a negative selection algorithm and a self-organizing map (SOM) in an immune inspired architecture. The proposed system is able to produce a visual representation of the selfnon-self feature space, thanks to the topological -dimensional map produced by the SOM. Some experiments were performed on classification data the results are presented and discussed.|Fabio A. González,Juan Carlos Galeano,Diego Alexander Rojas,Angélica Veloza-Suan","16135|IJCAI|2005|The COMPSET Algorithm for Subset Selection|Subset selection problems are relevant in many domains. Unfortunately, their combinatorial nature prohibits solving them optimally in most cases. Local search algorithms have been applied to subset selection with varying degrees of success. This work presents COMPSET, a general algorithm for subset selection that invokes an existing local search algorithm from a random subset and its complementary set, exchanging information between the two runs to help identify wrong moves. Preliminary results on complex SAT, Max Clique,  Multidimensional Knapsack and Vertex Cover problems show that COMPSET improves the efficient stochastic hill climbing and tabu search algorithms by up to two orders of magnitudes.|Yaniv Hamo,Shaul Markovitch"],["16322|IJCAI|2005|Disjunctive Temporal Planning with Uncertainty|Driven by planning problems with both disjunctive constraints and contingency, we define the Disjunctive Temporal Problem with Uncertainty (DTPU), an extension of the DTP that includes contingent events. Generalizing existing work on Simple Temporal Problems with Uncertainty, we divide the time-points into controllable and uncontrollable classes, and propose varying notions of controllability to replace the notion of consistency.|Kristen Brent Venable,Neil Yorke-Smith","16132|IJCAI|2005|Integrating Planning and Temporal Reasoning for Domains with Durations and Time Windows|The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the th International Planning Competition showing very good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina","16094|IJCAI|2005|An Architecture for Proof Planning Systems|This paper presents a generic architecture for proof planning systems in terms of an interaction between a customisable proof module and search module. These refer to both global and local information contained in reasoning states.|Louise A. Dennis","16328|IJCAI|2005|Learning Subjective Representations for Planning|Planning involves using a model of an agent's actions to find a sequence of decisions which achieve a desired goal. It is usually assumed that the models are given, and such models often require expert knowledge of the domain. This paper explores subjective representations for planning that are learned directly from agent observations and actions (requiring no initial domain knowledge). A non-linear embedding technique called Action Respecting Embedding is used to construct such a representation. It is then shown how to extract the effects of the agent's actions as operators in this learned representation. Finally, the learned representation and operators are combined with search to find sequences of actions that achieve given goals. The efficacy of this technique is demonstrated in a challenging robot-vision-inspired image domain.|Dana F. Wilkinson,Michael H. Bowling,Ali Ghodsi","16080|IJCAI|2005|Planning with graded fluents and actions|This work can be seen as a first approach to a new planning model that takes into account the possibility to express actions and fluents with nonboolean values. According to this model, a planning problem is defned using both graded (multi-valued) and classical (boolean) fluents. Moreover, actions that can have different application degrees can be defined. In this work a PDDL extension allowing to describe such new problems is proposed and a planning algorithm for such problems is presented.|Marta Cialdea Mayer,Carla Limongelli,Andrea Orlandini,Valentina Poggioni","16202|IJCAI|2005|Planning with Loops|Unlike the case for sequential and conditional planning, much of the work on iterative planning (planning where loops may be needed) leans heavily on theorem-proving. This paper does the following it proposes a different approach where generating plans is decoupled from verifying them describes the implementation of an iterative planner based on the situation calculus presents a few examples illustrating the sorts of plans that can be generated shows some of the strengths and weaknesses of the approach and finally sketches the beginnings of a theory, where validation of plans is done offline.|Hector J. Levesque","16050|IJCAI|2005|Over-Subscription Planning with Numeric Goals|By relaxing the hard-goal constraints from classical planning and associating them with reward values, over-subscription planning allows users to concentrate on presenting what they want and leaves the task of deciding the best goals to achieve to the planner. In this paper, we extend the over-subscription planning problem and its limited goal specification to allow numeric goals with continuous utility values and goals with mixed hard and soft constraints. Together they considerably extend the modeling power of goal specification and allow the user to express goal constraints that were not possible before. To handle these new goal constraints, we extend the Sapaps planner's planning graph based techniques to help it choose the best beneficial subset of goals that can include both hard or soft logical and numeric goals. We also provide empirical results in several benchmark domains to demonstrate that our technique helps return quality plans.|J. Benton,Minh Binh Do,Subbarao Kambhampati","16182|IJCAI|2005|A Framework for Communication Planning on Mobile Devices|In mobile computing, communicative acts are not free. Costs such as power and bandwidth consumption are prominent issues. In addition, resources vary widely across hardware and operating context. Agents in these settings must account for these costs and adapt to available capabilities. This poster presents a planning optimization formalization of this problem, enabling service-based agents to reason about and conduct communication using local and network accessible resources.|Joseph Kopena,William C. Regli","16118|IJCAI|2005|Abstraction-based Action Ordering in Planning|Many planning problems contain collections of symmetric objects, actions and structures which render them difficult to solve efficiently. It has been shown that the detection and exploitation of symmetric structure in planning problems can dramatically reduce the size of the search space and the time taken to find a solution. We present the idea of using an abstraction of the problem domain to reveal symmetric structure and guide the navigation of the search space. We show that this is effective even in domains in which there is little accessible symmetric structure available for pruning. Proactive exploitation represents a flexible and powerful alternative to the symmetry-breaking strategies exploited in earlier work in planning and CSPs. The notion of almost symmetry is defined and results are presented showing that proactive exploitation of almost symmetry can improve the performance of a heuristic forward search planner.|Maria Fox,Derek Long,Julie Porteous","16066|IJCAI|2005|Robust Planning with LRTDP|Stochastic Shortest Path problems (SSPs), a subclass of Markov Decision Problems (MDPs), can be efficiently dealt with using Real-Time Dynamic Programming (RTDP). Yet, MDP models are often uncertain (obtained through statistics or guessing). The usual approach is robust planning searching for the best policy under the worst model. This paper shows how RTDP can be made robust in the common case where transition probabilities are known to lie in a given interval.|Olivier Buffet,Douglas Aberdeen"],["57417|GECCO|2005|Designing resilient networks using a hybrid genetic algorithm approach|As high-speed networks have proliferated across the globe, their topologies have become sparser due to the increased capacity of communication media and cost considerations. Reliability has been a traditional goal within network design optimization of sparse networks. This paper proposes a genetic approach that uses network resilience as a design criterion in order to ensure the integrity of network services in the event of component failures. Network resilience measures have been previously overlooked as a network design objective in an optimization framework because of their computational complexity - requiring estimation by simulation. This paper analyzes the effect of noise in the simulation estimator used to evaluate network resilience on the performance of the proposed optimization approach.|Abdullah Konak,Alice E. Smith","57405|GECCO|2005|Theoretical analysis of a mutation-based evolutionary algorithm for a tracking problem in the lattice|Evolutionary algorithms are often applied for solving optimization problems that are too complex or different from classical problems so that the application of classical methods is difficult. One example are dynamic problems that change with time. An important class of dynamic problems is the class of tracking problems where an algorithm has to find an approximately optimal solution and insure an almost constant quality in spite of the changing problem. For the application of evolutionary algorithms to static optimization problems, the distribution of the optimization time and most often its expected value are most important. Adopting this perspective a simple tracking problem in the lattice is considered and the performance of a mutation-based evolutionary algorithm is evaluated. For the static case, asymptotically tight upper and lower bounds are proven. These results are applied to derive results on the tracking performance for different rates of change.|Thomas Jansen,Ulf Schellbach","16253|IJCAI|2005|ROCCER An Algorithm for Rule Learning Based on ROC Analysis|We introduce a rule selection algorithm called ROCCER, which operates by selecting classification rules from a larger set of rules - for instance found by Apriori - using ROC analysis. Experimental comparison with rule induction algorithms shows that ROCCER tends to produce considerably smaller rule sets with compatible Area Under the ROC Curve (AUC) values. The individual rules that compose the rule set also have higher support and stronger association indexes.|Ronaldo C. Prati,Peter A. Flach","16071|IJCAI|2005|Sensitivity Analysis in Markov Networks|This paper explores the topic of sensitivity analysis in Markov networks, by tackling questions similar to those arising in the context of Bayesian networks the tuning of parameters to satisfy query constraints, and the bounding of query changes when perturbing network parameters. Even though the distribution induced by a Markov network corresponds to ratios of multi-linear functions, whereas the distribution induced by a Bayesian network corresponds to multi-linear functions, the results we obtain for Markov networks are as effective computationally as those obtained for Bayesian networks. This similarity is due to the fact that conditional probabilities have the same functional form in both Bayesian and Markov networks, which turns out to be the more influential factor. The major difference we found, however, is in how changes in parameter values should be quantified, as such parameters are interpreted differently in Bayesian networks and Markov networks.|Hei Chan,Adnan Darwiche","57315|GECCO|2005|Quality-time analysis of multi-objective evolutionary algorithms|A quality-time analysis of multi-objective evolutionary algorithms (MOEAs) based on schema theorem and building blocks hypothesis is developed. A bicriteria OneMax problem, a hypothesis of niche and species, and a definition of dissimilar schemata are introduced for the analysis. In this paper, the convergence time, the first and last hitting time models are constructed for analyzing the performance of MOEAs. Population sizing model is constructed for determining appropriate population sizes. The models are verified using the bicriteria OneMax problem. The theoretical results indicate how the convergence time and population size of a MOEA scale up with the problem size, the dissimilarity of Pareto-optimal solutions, and the number of Pareto-optimal solutions of a multi-objective optimization problem.|Jian-Hung Chen,Shinn-Ying Ho,David E. Goldberg","57369|GECCO|2005|Statistical analysis of heuristics for evolving sorting networks|Designing efficient sorting networks has been a challenging combinatorial optimization problem since the early 's. The application of evolutionary computing to this problem has yielded human-competitive results in recent years. We build on previous work by presenting a genetic algorithm whose parameters and heuristics are tuned on a small instance of the problem, and then scaled up to larger instances. Also presented are positive and negative results regarding the efficacy of several domain-specific heuristics.|Lee K. Graham,Hassan Masum,Franz Oppacher","57565|GECCO|2005|BeeAdHoc an energy efficient routing algorithm for mobile ad hoc networks inspired by bee behavior|In this paper we present BeeAdHoc, a new routing algorithm for energy efficient routing in mobile ad hoc networks. The algorithm is inspired by the foraging principles of honey bees. The algorithm mainly utilizes two types of agents, scouts and foragers, for doing routing in mobile ad hoc networks. BeeAdHoc is a reactive source routing algorithm and it consumes less energy as compared to existing state-of-the-art routing algorithms because it utilizes less control packets to do routing. The results of our extensive simulation experiments show that BeeAdHoc consumes significantly less energy as compared to DSR, AODV, and DSDV, which are state-of-the-art routing algorithms, without making any compromise on traditional performance metrics (packet delivery ratio, delay and throughput).|Horst Wedde,Muddassar Farooq,Thorsten Pannenbaecker,Bjoern Vogel,Christian Mueller,Johannes Meth,Rene Jeruschkat","57574|GECCO|2005|A scalable parallel genetic algorithm for x-ray spectroscopic analysis|We use a parallel multi-objective genetic algorithm to drive a search and reconstruction spectroscopic analysis of plasma gradients in inertial confinement fusion (ICF) implosion cores. In previous work, we had shown that our serial multi-objective Genetic Algorithm was a good method to solve two-criteria X-ray spectroscopy diagnostics problems. However, this serial version was slow and we therefore could not incorporate better physics and more criteria to solve larger problems and handle larger data sets. In this paper, we develop and use a parallel multi-objective genetic algorithm based on a master-slave model to solve three criteria spectroscopic analysis problems. The algorithm works well in reconciling experimental observations with theoretical physics model parameters. In addition, theoretical analysis and experimental results on the parallelized version show good scalability with up to  processors. This reduces the time for running the GA from . hours to . minutes.|Kai Xu,Sushil J. Louis,Roberto C. Mancini","16043|IJCAI|2005|Analysis and Verification of Qualitative Models of Genetic Regulatory Networks A Model-Checking Approach|Methods developed for the qualitative simulation of dynamical systems have turned out to be powerful tools for studying genetic regulatory networks. A bottleneck in the application of these methods is the analysis of the simulation results. In this paper, we propose a combination of qualitative simulation and model-checking techniques to perform this task systematically and efficiently. We apply our approach to the analysis of the complex network controlling the nutritional stress response in the bacterium Escherichia coli.|Grégory Batt,Delphine Ropers,Hidde de Jong,Johannes Geiselmann,Radu Mateescu,Michel Page,Dominique Schneider","57406|GECCO|2005|Compact genetic algorithm for active interval scheduling in hierarchical sensor networks|This paper introduces a novel scheduling problem called the active interval scheduling problem in hierarchical wireless sensor networks for long-term periodical monitoring applications. To improve the report sensitivity of the hierarchical wireless sensor networks, an efficient scheduling algorithm is desired. In this paper, we propose a compact genetic algorithm (CGA) to optimize the solution quality for sensor network maintenance. The experimental result shows that the proposed CGA brings better solutions in acceptable calculation time.|Ming-Hui Jin,Cheng-Yan Kao,Yu-Cheng Huang,D. Frank Hsu,Ren-Guey Lee,Chih-Kung Lee"],["57265|GECCO|2005|Hybrid multiobjective genetic algorithm with a new adaptive local search process|This paper is concerned with a specific brand of evolutionary algorithms Memetic algorithms. A new local search technique with an adaptive neighborhood setting process is introduced and assessed against a set of test functions presenting different challenges. Two performance criteria were assessed the convergence of the achieved results towards the true Pareto fronts and their distribution.|Salem F. Adra,Ian Griffin,Peter J. Fleming","57463|GECCO|2005|Enhancing differential evolution performance with local search for high dimensional function optimization|In this paper, we proposed Fittest Individual Refinement (FIR), a crossover based local search method for Differential Evolution (DE). The FIR scheme accelerates DE by enhancing its search capability through exploration of the neighborhood of the best solution in successive generations. The proposed memetic version of DE (augmented by FIR) is expected to obtain an acceptable solution with a lower number of evaluations particularly for higher dimensional functions. Using two different implementations DEfirDE and DEfirSPX we showed that proposed FIR increases the convergence velocity of DE for well known benchmark functions as well as improves the robustness of DE against variation of population. Experiments using multimodal landscape generator showed our proposed algorithms consistently outperformed their parent algorithms. A performance comparison with reported results of well known real coded memetic algorithms is also presented.|Nasimul Noman,Hitoshi Iba","16298|IJCAI|2005|Streamlining Local Search for Spatially Balanced Latin Squares|Streamlined constrained reasoning powerfully boosts the performance of backtrack search methods for finding hard combinatorial objects. We use so-called spatially balanced Latin squares to show how streamlining can also be very effective for local search Our approach is much faster and generates considerably larger spatially balanced Latin squares than previously reported approaches (up to order  the previous best results could only generate solutions up to order ). We also provide a detailed characterization of our streamliner and solution topology for small orders. We believe that streamlined local search is a general technique suitable for solving a wide range of hard combinatorial design problems.|Casey Smith,Carla P. Gomes,Cèsar Fernández","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","57408|GECCO|2005|New topologies for genetic search space|We propose three distance measures for genetic search space. One is a distance measure in the population space that is useful for understanding the working mechanism of genetic algorithms. Another is a distance measure in the solution space for K-grouping problems. This can be used for normalization in crossover. The third is a level distance measure for genetic algorithms, which is useful for measuring problem difficulty with respect to genetic algorithms. We show that the proposed measures are metrics and the measures are efficiently computed.|Yong-Hyuk Kim,Byung Ro Moon","16226|IJCAI|2005|Applying Local Search to Disjunctive Temporal Problems|We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.|Michael D. Moffitt,Martha E. Pollack","57267|GECCO|2005|Search space modulation in genetic algorithms evolving the search space by sinusoidal transformations|An experimental form of Modulation (Reinterpretation) of the Search Space is presented. This modulation is developed as a mathematical method that can be implemented directly into existing evolutionary algorithms without writing special operators, changing the program loop etc. The main mathematical principle behind this method is the dynamic sinusoidal envelope of the search space. This method is presented in order to solve some theoretical and practical issues in evolutionary algorithms like numerical bounded variables, dynamic focalized search, dynamic control of diversity, feasible region analysis etc.|José Antonio Martin H.","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas Stützle"]]}}