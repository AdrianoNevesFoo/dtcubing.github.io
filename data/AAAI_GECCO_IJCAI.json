{"abstract":{"entropy":6.446813128256971,"topics":["machine learning, markov decision, markov processes, reinforcement learning, learning system, learning, partially observable, decision processes, mobile robot, classifier system, play role, real world, learning classifier, data, agents, data mining, markov mdps, combinatorial auctions, task, multi-agent system","genetic algorithm, algorithm, evolutionary algorithm, genetic programming, solving problem, particle swarm, present algorithm, constraint satisfaction, problem, optimization problem, optimization algorithm, search algorithm, optimization, evolutionary computation, constraint problem, heuristic search, algorithm problem, search, neural networks, present novel","natural language, knowledge base, description logic, logic, knowledge representation, reasoning, knowledge, logic programming, temporal reasoning, belief revision, present framework, situation calculus, qualitative reasoning, knowledge acquisition, nonmonotonic logic, logic program, effects actions, word sense, sense disambiguation, problem knowledge","artificial intelligence, system, describes system, expert system, recent years, describes, present system, knowledge system, theorem proving, model-based diagnosis, system based, describes approach, language system, system model, planning problem, theorem prover, computer program, planning plan, planning, research intelligence","mobile robot, multi-agent system, autonomous agents, agents, agents environment, system agents, resource allocation, problem agents, autonomous robot, sensor networks, addresses problem, consider problem, distributed agents, robot, activity recognition, multi-agent agents, agents need, control robot, agents resource, problem resource","real world, address problem, important problem, multiple agents, applications problem, applications, important applications, important, agents able, important issue, real-world applications, multiple, system important, time series, problem multiple, gene expression, localization mapping, address system, simultaneous localization, intelligent system","heuristic search, optimization problem, solving problem, search algorithm, solve problem, search problem, ant colony, multi-objective optimization, algorithm solving, algorithm problem, multi-objective problem, search, traveling salesman, shortest path, heuristic problem, search methods, solving optimization, algorithm solve, solve optimization, present search","genetic programming, genetic algorithm, neural networks, bayesian networks, improve performance, genetic problem, selection algorithm, genetic, crossover operators, algorithm networks, genetic evolve, bayesian algorithm, genetic crossover, feature selection, networks, algorithm crossover, selection problem, genetic selection, present genetic, selection","qualitative reasoning, reasoning, reasoning problem, effects actions, spatial reasoning, situation calculus, temporal reasoning, preferences voting, reasoning important, case-based reasoning, planning actions, reasoning actions, reasoning system, preferences aggregation, coalitional game, formalism reasoning, spatial temporal, reasoning case, actions, problem actions","knowledge base, knowledge representation, knowledge, knowledge acquisition, model based, problem knowledge, knowledge system, present model, reasoning knowledge, representation, model, knowledge learning, computational complexity, computational model, present knowledge, inductive learning, probabilistic model, knowledge agents, approach based, knowledge based","recent years, planning problem, planning, planning plan, planning domains, approach planning, case-based reasoning, received attention, planning system, present planning, describes planning, recent work, last years, software system, case-based cbr, development system, recent system, work, recent, equality elimination","describes system, describes approach, describes, system described, theorem proving, theorem prover, describes language, natural language, system use, describes use, describes programming, design system, describes program, system based, automatic system, understanding system, describes based, components system, natural system, present approach"],"ranking":[["16886|IJCAI|2009|Inverse Reinforcement Learning in Partially Observable Environments|Inverse reinforcement learning (IRL) is the problem of recovering the underlying reward function from the behaviour of an expert. Most of the existing algorithms for IRL assume that the expert's environment is modeled as a Markov decision process (MDP), although they should be able to handle partially observable settings in order to widen the applicability to more realistic scenarios. In this paper, we present an extension of the classical IRL algorithm by Ng and Russell to partially observable environments. We discuss technical issues and challenges, and present the experimental results on some of the benchmark partially observable domains.|Jaedeug Choi,Kee-Eung Kim","16533|IJCAI|2007|Bayesian Inverse Reinforcement Learning|Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.|Deepak Ramachandran,Eyal Amir","58868|GECCO|2009|Uncertainty handling CMA-ES for reinforcement learning|The covariance matrix adaptation evolution strategy (CMAES) has proven to be a powerful method for reinforcement learning (RL). Recently, the CMA-ES has been augmented with an adaptive uncertainty handling mechanism. Because uncertainty is a typical property of RL problems this new algorithm, termed UH-CMA-ES, is promising for RL. The UH-CMA-ES dynamically adjusts the number of episodes considered in each evaluation of a policy. It controls the signal to noise ratio such that it is just high enough for a sufficiently good ranking of candidate policies, which in turn allows the evolutionary learning to find better solutions. This significantly increases the learning speed as well as the robustness without impairing the quality of the final solutions. We evaluate the UH-CMA-ES on fully and partially observable Markov decision processes with random start states and noisy observations. A canonical natural policy gradient method and random search serve as a baseline for comparison.|Verena Heidrich-Meisner,Christian Igel","65433|AAAI|2005|Extending Continuous Time Bayesian Networks|Continuous-time Bayesian networks (CTBNs) (Nodelman, Shelton, & Koller  ), are an elegant modeling language for structured stochastic processes that evolve over continuous time. The CTBN framework is based on homogeneous Markov processes, and defines two distributions with respect to each local variable in the system, given its parents an exponential distribution over when the variable transitions, and a multinomial over what is the next value. In this paper, we present two extensions to the framework that make it more useful in modeling practical applications. The first extension models arbitrary transition time distributions using Erlang-Coxian approximations, while maintaining tractable learning. We show how the censored data problem arises in learning the distribution, and present a solution based on expectation-maximization initialized by the Kaplan-Meier estimate. The second extension is a general method for reasoning about negative evidence, by introducing updates that assert no observable events occur over an interval of time. Such updates were not defined in the original CTBN framework, and we show that their inclusion can significantly improve the accuracy of filtering and prediction. We illustrate and evaluate these extensions in two real-world domains, email use and GPS traces of a person traveling about a city.|Karthik Gopalratnam,Henry A. Kautz,Daniel S. Weld","58097|GECCO|2007|Mining breast cancer data with XCS|In this paper, we describe the use of a modern learning classifier system to a data mining task. In particular, in collaboration with a medical specialist, we apply XCS to a primary breast cancer data set. Our results indicate more effective knowledge discovery than with C..|Faten Kharbat,Larry Bull,Mohammed Odeh","15471|IJCAI|1999|A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes|An issue that is critical for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP. In stochastic environments with very large or even infinite state spaces, traditional planning and reinforcement learning algorithms are often inapplicable, since their running time typically scales linearly with the state space size. In this paper we present a new algorithm that, given only a generative model (simulator) for an arbitrary MDP, performs near-optimal planning with a running time that has no dependence on the number of states. Although the running time is exponential in the horizon time (which depends only on the discount factor  and the desired degree of approximation to the optimal policy), our results establish for the first time that there are no theoretical barriers to computing near-optimal policies in arbitrarily large, unstructured MDPs. Our algorithm is based on the idea of sparse sampling. We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suffices to compute near-optimal actions from any state of an MDP. Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs KMN.|Michael J. Kearns,Yishay Mansour,Andrew Y. Ng","66064|AAAI|2007|Optimizing Anthrax Outbreak Detection Using Reinforcement Learning|The potentially catastrophic impact of a bioterrorist attack makes developing effective detection methods essential for public health. In the case of anthrax attack, a delay of hours in making a right decision can lead to hundreds of lives lost. Current detection methods trade off reliability of alarms for early detection of outbreaks. The performance of these methods can be improved by modem disease-specific modeling techniques which take into account the potential costs and effects of an attack to provide optimal warnings. We study this optimization problem in the reinforcement learning framework. The key contribution of this paper is to apply Partially Observable Markov Decision Processes (POMDPs) on outbreak detection mechanism for improving alarm function in anthrax outbreak detection. Our approach relies on estimating the future benefit of true alarms and the costs of false alarms and using these quantities to identify an optimal decision. We present empirical evidence illustrating that the performance of detection methods with respect to sensitivity and timeliness is improved significantly by utilizing POMDPs.|Masoumeh T. Izadi,David L. Buckeridge","59027|GECCO|2010|Adaption of XCS to multi-learner predatorprey scenarios|Learning classifier systems (LCSs) are rule-based evolutionary reinforcement learning systems. Today, especially variants of Wilson's extended classifier system (XCS) are widely applied for machine learning. Despite their widespread application, LCSs have drawbacks, e. g., in multi-learner scennarios, since the Markov property is not fulfilled. In this paper, LCSs are investigated in an instance of the generic homogeneous and non-communicating predatorprey scenario. A group of predators collaboratively observe a (randomly) moving prey as long as possible, where each predator is equipped with a single, independent XCS. Results show that improvements in learning are achieved by cleverly adapting a multi-step approach to the characteristics of the investigated scenario. Firstly, the environmental reward function is expanded to include sensory information. Secondly, the learners are equipped with a memory to store and analyze the history of local actions and given payoffs.|Clemens Lode,Urban Richter,Hartmut Schmeck","57803|GECCO|2006|Reward allotment in an event-driven hybrid learning classifier system for online soccer games|This paper describes our study into the concept of using rewards in a classifier system applied to the acquisition of decision-making algorithms for agents in a soccer game. Our aim is to respond to the changing environment of video gaming that has resulted from the growth of the Internet, and to provide bug-free programs in a short time. We have already proposed a bucket brigade algorithm (a reinforcement learning method for classifiers) and a procedure for choosing what to learn depending on the frequency of events with the aim of facilitating real-time learning while a game is in progress. We have also proposed a hybrid system configuration that combines existing algorithm strategies with a classifier system, and we have reported on the effectiveness of this hybrid system. In this paper, we report on the results of performing reinforcement learning with different reward values assigned to reflect differences in the roles performed by forward, midfielder and defense players, and we describe the results obtained when learning is performed with different combinations of success rewards for various type of play such as dribbling and passing. In  matches played against an existing soccer game incorporating an algorithm devised by humans, a better win ratio and better convergence were observed compared with the case where learning was performed with no roles assigned to all of the in-game agents.|Yuji Sato,Yosuke Akatsuka,Takenori Nishizono","15259|IJCAI|1995|Approximating Optimal Policies for Partially Observable Stochastic Domains|The problem of making optimal decisions in uncertain conditions is central to Artificial Intelligence If the state of the world is known at all times, the world can be modeled as a Markov Decision Process (MDP) MDPs have been studied extensively and many methods are known for determining optimal courses of action or policies. The more realistic case where state information is only partially observable Partially Observable Markov Decision Processes (POMDPs) have received much less attention. The best exact algorithms for these problems can be very inefficient in both space and time. We introduce Smooth Partially Observable Value Approximation (SPOVA), a new approximation method that can quickly yield good approximations which can improve over time. This method can be combined with reinforcement learning meth ods a combination that was very effective in our test cases.|Ronald Parr,Stuart J. Russell"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","16250|IJCAI|2005|A Scalable Method for Multiagent Constraint Optimization|We present in this paper a new, complete method for distributed constraint optimization, based on dynamic programming. It is a utility propagation method, inspired by the sum-product algorithm, which is correct only for tree-shaped constraint networks. In this paper, we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. Our algorithm requires a linear number of messages, whose maximal size depends on the induced width along the particular pseudotree chosen. We compare our algorithm with backtracking algorithms, and present experimental results. For some problem types we report orders of magnitude fewer messages, and the ability to deal with arbitrarily large problems. Our algorithm is formulated for optimization problems, but can be easily applied to satisfaction problems as well.|Adrian Petcu,Boi Faltings","57629|GECCO|2006|GRASP - evolution for constraint satisfaction problems|There are several evolutionary approaches for solving random binary Constraint Satisfaction Problems (CSPs). In most of these strategies we find a complex use of information regarding the problem at hand. Here we present a hybrid Evolutionary Algorithm that outperforms previous approaches in terms of effectiveness and compares well in terms ofefficiency. Our algorithm is conceptual and simple, featuring a GRASP-like (GRASP stands for Greedy Randomized Adaptive Search Procedure) mechanism for genotype-to-phenotype mapping, and without considering any specific knowledge of the problem. Therefore, we provide a simple algorithm that harnesses generality while boosting performance.|Manuel Cebrián,Iván Dotú","58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Suárez,Manuel Valenzuela-Rendón,Hugo Terashima-Marín,Eduardo Uresti-Charre","58515|GECCO|2008|Parameter-less evolutionary search|The paper presents the parameter-less implementation of an evolutionary-based search. It does not need any predefined control parameters values, which are usually used for genetic algorithms and similar techniques. Efficiency of the proposed algorithm was evaluated by CEC benchmark functions and a real-world product optimization problem.|Gregor Papa","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57433|GECCO|2005|MeSwarm memetic particle swarm optimization|In this paper, a novel variant of particle swarm optimization (PSO), named memetic particle swarm optimization algorithm (MeSwarm), is proposed for tackling the overshooting problem in the motion behavior of PSO. The overshooting problem is a phenomenon in PSO due to the velocity update mechanism of PSO. While the overshooting problem occurs, particles may be led to wrong or opposite directions against the direction to the global optimum. As a result, MeSwarm integrates the standard PSO with the Solis and Wets local search strategy to avoid the overshooting problem and that is based on the recent probability of success to efficiently generate a new candidate solution around the current particle. Thus, six test functions and a real-world optimization problem, the flexible protein-ligand docking problem are used to validate the performance of MeSwarm. The experimental results indicate that MeSwarm outperforms the standard PSO and several evolutionary algorithms in terms of solution quality.|Bo-Fu Liu,Hung-Ming Chen,Jian-Hung Chen,Shiow-Fen Hwang,Shinn-Ying Ho","13831|IJCAI|1981|A New Method for Solving Constraint Satisfaction Problems|This paper deals with the combinatorial search problem of finding values for a set of variables subject to a set of constraints. This problem is referred to as a constraint satisfaction problem. We present an algorithm for finding all the solutions of a constraint satisfaction problem with worst case time bound (m*kf+) and space bound (n*kf+), where n is the number of variables in the problem, m the number of constraints, k the cardinality of the domain of the variables, and fn an integer depending only on a graph which is associated with the problem. It will be shown that for planar graphs and graphs of fixed genus this f is (n).|Raimund Seidel","58554|GECCO|2008|An evolutionary approach for competency-based curriculum sequencing|The process of creating e-learning contents using reusable learning objects (LOs) can be broken down in two sub-processes LOs finding and LO sequencing. Sequencing is usually performed by instructors, who create courses targeting generic profiles rather than personalized materials. This paper proposes an evolutionary approach to automate this latter problem while, simultaneously, encourages reusability and interoperability by promoting standards employment. A model that enables automated curriculum sequencing is proposed. By means of interoperable competency records and LO metadata, the sequencing problem is turned into a constraint satisfaction problem. Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) agents are designed, built and tested in real and simulated scenarios. Results show both approaches succeed in all test cases, and that they handle reasonably computational complexity inherent to this problem, but PSO approach outperforms GA.|Luis de Marcos,José-Javier Martínez,José Antonio Gutiérrez,Roberto Barchino,José María Gutiérrez","57520|GECCO|2005|Breeding swarms a new approach to recurrent neural network training|This paper shows that a novel hybrid algorithm, Breeding Swarms, performs equal to, or better than, Genetic Algorithms and Particle Swarm Optimizers when training recurrent neural networks. The algorithm was found to be robust and scale well to very large networks, ultimately outperforming Genetic Algorithms and Particle Swarm Optimization in  of  tested networks. This research shows that the Breeding Swarm algorithm is a viable option when choosing an algorithm to train recurrent neural networks.|Matthew Settles,Paul Nathan,Terence Soule"],["14982|IJCAI|1993|Representing Concurrent Actions in Extended Logic Programming|Gelfond and Lifschitz introduce a declarative language A for describing effects of actions and define a translation of theories in this language into extended logic programs(ELP's). The purpose of this paper is to extend the language and the translation to allow reasoning about the effects of concurrent actions. Logic programming formalization of situation calculus with concurrent actions presented in the paper can be of independent interest and may serve as a test bed for the investigation of various transformations and logic programming inference mechanisms.|Chitta Baral,Michael Gelfond","65962|AAAI|2007|ESP A Logic of Only-Knowing Noisy Sensing and Acting|When reasoning about actions and sensors in realistic domains, the ability to cope with uncertainty often plays an essential role. Among the approaches dealing with uncertainty, the one by Bacchus, Halpern and Levesque, which uses the situation calculus, is perhaps the most expressive. However, there are still some open issues. For example, it remains unclear what an agent's knowledge base would actually look like. The formalism also requires second-order logic to represent uncertain beliefs, yet a first-order representation clearly seems preferable. In this paper we show how these issues can be addressed by incorporating noisy sensors and actions into an existing logic of only-knowing.|Alfredo Gabaldon,Gerhard Lakemeyer","14929|IJCAI|1991|Representing Diagnostic Knowledge for Probabilistic Horn Abduction|This paper presents a simple logical framework for abduction, with probabilities associated with hypotheses. The language is an extension to pure Prolog, and it has straight-forward implementations using branch and bound search with either logic-programming technology or ATMS technology. The main focus of this paper is arguing for a form of representational adequacy of this very simple system for diagnostic reasoning. It is shown how it can represent model-based knowledge, with and without faults, and with and without nonintermittency assumptions. It is also shown how this representation can represent any probabilistic knowledge representable in a Bayesian belief network.|David Poole","16618|IJCAI|2007|The Mathematical Morpho-Logical View on Reasoning about Space|Qualitative reasoning about mereotopological relations has been extensively investigated, while more recently geometrical and spatio-temporal reasoning are gaining increasing attention. We propose to consider mathematical morphology operators as the inspiration for a new language and inference mechanism to reason about space. Interestingly, the proposed morpho-logic captures not only traditional mereotopological relations, but also notions of relative size and morphology. The proposed representational framework is a hybrid arrow logic theory for which we define a resolution calculus which is, to the best of our knowledge, the first such calculus for arrow logics.|Marco Aiello,Brammert Ottens","16348|IJCAI|2007|Decidable Reasoning in a Modified Situation Calculus|We consider a modified version of the situation calculus built using a two-variable fragment of the first-order logic extended with counting quantifiers. We mention several additional groups of axioms that can be introduced to capture taxonomic reasoning. We show that the regression operator in this framework can be defined similarly to regression in the Reiter's version of the situation calculus. Using this new regression operator, we show that the projection and executability problems are decidable in the modified version even if an initial knowledge base is incomplete and open. For an incomplete knowledge base and for context-dependent actions, we consider a type of progression that is sound with respect to the classical progression. We show that the new knowledge base resulting after our progression is definable in our modified situation calculus if one allows actions with local effects only. We mention possible applications to formalization of Semantic Web services.|Yilan Gu,Mikhail Soutchanski","14563|IJCAI|1989|The Logic of Time Structures Temporal and Nonmonotonic Features|We Imbed Into a first order logic a representation language that combines a temporal knowledge with time stamps in a hierarchical fashion. Each time structure contains its own chronology of events sufficient information for an encoding of a classical temporal logic. By quantifying over time structures, we encode a modal logic of temporal knowledge. In addition, we show how to achieve the effect of nonmonotonic inference, by simulating preferential entailment within a first order framework.|Mira Balaban,Neil V. Murray","66497|AAAI|2008|Using Answer Set Programming and Lambda Calculus to Characterize Natural Language Sentences with Normatives and Exceptions|One way to solve the knowledge acquisition bottleneck is to have ways to translate natural language sentences and discourses to a formal knowledge representation language, especially ones that are appropriate to express domain knowledge in sciences, such as Biology. While there have been several proposals, including by Montague (), to give model theoretic semantics for natural language and to translate natural language sentences and discourses to classical logic, none of these approaches use knowledge representation languages that can express domain knowledge involving normative statements and exceptions. In this paper we take a first step to illustrate how one can automatically translate natural language sentences about normative statements and exceptions to representations in the knowledge representation language Answer Set Programming (ASP). To do this, we use -calculus representation of words and their composition as dictated by a CCG grammar.|Chitta Baral,Juraj Dzifcak,Tran Cao Son","16160|IJCAI|2005|Equivalence in Abductive Logic|We consider the problem of identifying equivalence of two knowledge bases which are capable of abductive reasoning. Here, a knowledge base is written in either first-order logic or nonmonotonic logic programming. In this work, we will give two definitions of abductive equivalence. The first one, explainable equivalence, requires that two abductive programs have the same explainability for any observation. Another one, explanatory equivalence, guarantees that any observation has exactly the same explanations in each abductive framework. Explanatory equivalence is a stronger notion than explainable equivalence. In first-order abduction, explainable equivalence can be verified by the notion of extensional equivalence in default theories. In nonmonotonic logic programs, explanatory equivalence can be checked by means of the notion of relative strong equivalence. We also show the complexity results for abductive equivalence.|Katsumi Inoue,Chiaki Sakama","15090|IJCAI|1993|A Metalogic Programming Approach to Reasoning about Time in Knowledge Bases|The problem of representing and reasoning about two notions of time that are relevant in the context of knowledge bases is addressed. These are called historical time and belief time respectively. Historical time denotes the time for which information models realityBelief time denotes the time lor which a belief is held (by an agent or a knowledge base). We formalize an appropriate theory of time using logic as a meta-language. We then present a metalogic program derived from this theory through foldunfold transformations. The metalogic program enables the temporal reasoning required for knowledge base applications to be carried out efficiently. The metalogic program is directly implementable as a Prolog program and hence the need for a more complex theorem prover is obviated. The approach is applicable for such knowledge base applications as legislation and legal reasoning and in the context of multi-agent reasoning where an agent reasons about the beliefs of another agent.|Suryanarayana M. Sripada","15479|IJCAI|1999|Query Evaluation and Progression in AOL Knowledge Bases|Recently Lakemeyer and Levesque proposed the logic AOC, which amalgamates both the situation calculus and Levesques logic of only knowing. While very expressive the practical relevance of the formalism is unclear because it heavily relies on second-order logic. In this paper we demonstrate that the picture is not as bleak as it may seem. In particular, we show that for large classes of AOL knowledge bases and queries, including epistemic ones, query evaluation requires first-order reasoning only. We also provide a simple semantic definition of progressing a knowledge base. For a particular class of knowledge bases, adapted from earlier results by Lin and Reiter, we show that progression is first-order representable and easy to compute.|Gerhard Lakemeyer,Hector J. Levesque"],["14516|IJCAI|1987|Deduction-based Region-Use Planning|This paper describes a deductive approach to \"region use\" planning problems. The planning task is viewed as one of devising a complete set of policy rules by iteratively modifying the rules and making their deductive consequences readily available to the planner. The application of this approach to a National Park region zoning problem is also described. Central to the system are the representation of management policy as knowledge based rules and the detection of inconsistencies in the rules. The implementation of the system has three closely coupled components a spatial database, an interactive graphics server and the deduction subsystem. The last of these is briefly described in the paper.|Robin S. Stanton,Hugh G. Mackenzie","14815|IJCAI|1991|Integration of Neural Networks and Expert Systems for Process Fault Diagnosis|The main thrust of this research is the development of an artificial intelligence (AI) system to be used as an operators' aid in the diagnosis of faults in large-scale chemical process plants. The operator advisory system involves the integration of two fundamentally different AI techniques expert systems and neural networks. A diagnostic strategy based on the hierarchical use of neural networks is used as a first level filter to diagnose faults commonly encountered in chemical process plants. Once the faults are localized within the process by the neural networks, the deep knowledge expert system analyzes the results, and either confirms the diagnosis or offers alternative solutions. The model-based expert system contains information of the plant's structure and function within its object-oriented knowledge base. The diagnostic strategy can handle novel or previously unencountered faults, noisy process sensor measurements, and multiple faults. The operator advisory system is demonstrated using a multi-column distillation plant as a case study.|Warren R. Becraft,Peter L. Lee,Robert B. Newell","14673|IJCAI|1989|Adaptation-Based Explanation Extending ScriptFrame Theory to Handle Novel Input|The ability to develop hypotheses to explain new, unexpected experiences is a hallmark of human intelligence. It is also a crucial concern within artificial intelligence, since intelligent computer systems need to construct explanations in order to guide learning, to recover from planning failures, and to make sense of the stories that they read. The principal issue in designing a computer program that builds explanations is how to bring the system's causal knowledge to bear on a problem so that it can efficiently infer an unseen cause of observed events. In this paper we discuss some drawbacks of previous approaches to this problem, and present an alternative. The alternative involves extending scriptframe theory via a system that adapts its stored explanations to new situations. We discuss the types of explanation failures that occur, and how the system employs adaptation strategies to repair those failures. The execution of one of the strategies is demonstrated.|Alex Kass","14633|IJCAI|1989|Decision-Making in an Embedded Reasoning System|The development of reasoning systems that can reason and plan in a continuously changing environment is emerging as an important area of research in Artificial Intelligence. This paper describes some of the features of a Procedural Reasoning System (PRS) that enables it to operate effectively in such environments. The basic system design is first described and it is shown how this architecture supports both goal-directed reasoning and the ability to react rapidly to unanticipated changes in the environment. The decision-making capabilities of the system are then discussed and it is indicated how the system integrates these components in a manner that takes account of the bounds on both resources and knowledge that typify most real-time operations. The system has been applied to handling malfunctions on the space shuttle, threat assessment, and the control of an autonomous robot.|Michael P. Georgeff,François Felix Ingrand","13436|IJCAI|1973|Understanding Without Proofs|The paper describes the analysis part of a running analysis and generation program for natural language. The system is entirely oriented to matching meaningful patterns onto fragmented paragraph length input. Its core Is a choice system based on what I call \"semantic density\". The system is contrasted with () syntax oriented linguistic approaches and () theorem proving approaches to the understanding problem. It is argued by means of examples that the present system is not only more workable, but more intuitively acceptable, at least as an understander for the purpose of translation, than deduction-based systems.|Yorick Wilks","65259|AAAI|2004|An Explainable Artificial Intelligence System for Small-unit Tactical Behavior|As the artificial intelligence (AI) systems in military simulations and computer games become more complex, their actions become increasingly difficult for users to understand. Expert systems for medical diagnosis have addressed this challenge though the addition of explanation generation systems that explain a system's internal processes. This paper describes the AI architecture and associated explanation capability used by Full Spectrum Command, a training system developed for the U.S. Army by commercial game developers and academic researchers.|Michael van Lent,William Fisher,Michael Mancuso","14892|IJCAI|1991|Massively Parallel Artificial Intelligence|Massively Parallel Artificial Intelligence is a new and growing area of AI research, enabled by the emergence of massively parallel machines. It is a new paradigm in AI research. A high degree of parallelism not only affects computing performance, but also triggers drastic change in the approach toward building intelligent systems memory-based reasoning and parallel marker-passing are examples of new and redefined approaches. These new approaches, fostered by massively parallel machines, offer a golden opportunity for AI in challenging the vastness and irregularities of real - world data that are encountered when a system accesses and processes Very Large Data Bases and Knowledge Bases. This article describes the current status of massively parallel artificial intelligence research and positions of each panelist.|Hiroaki Kitano,James A. Hendler,Tetsuya Higuchi,Dan I. Moldovan,David L. Waltz","13280|IJCAI|1969|A Mobile Automaton An Application of Artificial Intelligence Techniques|A research project applying artificial intelligence techniques to the development of integrated robot systems Is described. The experimental facility consists of an SDS- computer and associated programs controlling a wheeled vehicle that carries a TV camera and other sensors. The primary emphasis is on the development of a system of programs for processing sensory data from the vehicle, for storing relevant information about the environment, and for planning the sequence of motor actions necessary to accomplish tasks in the environment. A typical task performed by our present system requires the robot vehicle to rearrange (by pushing) simple objects in its environment A novel feature of our approach is the use of a formal theorem-proving system to plan the execution of high-level functions as a sequence of other, perhaps lower-level, functions. The execution of these, in turn, requires additional planning at lower levels. The main theme of the research is the integration of the necessary planning systems, models of the world, and sensory processing systems into an efficient whole capable of performing a wide range of tasks in a real environment.|Nils J. Nilsson","13406|IJCAI|1973|Robot Planning System Based on Problem Solvers|This paper is concerned with a planning system for a robot with a hand and an eye which can manipulate blocks. Two different kinds of problem solvers are used. One is mainly composed of a theorem prover based on the resolution principle, and the other consists of a theorem prover based on pattern matching. These problem solvers are called GOAL-FINDER and JOB-SCHEDULER corresponding to their functions. GOAL-FINDER decides a goal state that is suitable for an order of an operator. JOB-SCHEDULER produces a job sequence for a robot to perform the goal state given the constraints of the block world.|Tadashi Nagata,Masato Yamazaki,Michiharu Tsukamoto","14284|IJCAI|1985|A Robot Planning Structure Using Production Rules|Robot plan generation is a field which engendered the development of AI languages and rule-based expert systems. Utilization of these latter concepts permits a flexible formalism for robot planning research. We present a robot plan-generation architecture and its application to a real-world mobile robot system. The system undergoes tests through its utilization in the IIILARE robot project (Ciralt, et al., ). Though the article concentrates on planning, execution monitoring and error recovery are discussed. The system includes models of its synergistic environment as well SR of its sensors and effectors (i.e. operators). Its rules embody both planning specific and domair specific knowledge. The system gains generality and adaptiveness through the use of planning variables which provide constraints to the plan generation system. It is implemented in an efficient compiled Production System language (PSL).|Ralph P. Sobek"],["14282|IJCAI|1985|The Use of Multiple Problem Decompositions in Time Constrained Planning Tasks|Problems requiring the synthesis of a collection of plans accomplishing distinct (but possibly related) goals has received increasing attention within Al. Such problems are typically formulated as multi-agent planning problems, emphasizing a problem decomposition wherein individual agents assume responsibility for the generation of individual plans while taking into account the goals and beliefs of other agents in the system. One consequence of such a problem decomposition is a simplified view of resource allocation that assumes avoidance of conflicts to be the sole concern. The validity of this assumption comes into question in time constrained problem domains requiring the allocation of multiple, shared resources. In job shop scheduling, for example, where sequences of manufacturing operations must be determined and scheduled for multiple orders, it is necessary to consider much more than availability to efficiently allocate resources over time. We argue that in such domains, an ability to reason from both resource-based and agent-based perspectives is essential to appropriate consideration of all domain constraints.|Stephen F. Smith,Peng Si Ow","14480|IJCAI|1987|A Probabilistic Framework for Resource-Constrained Multi-Agent Planning|In this paper, we consider the problem of temporally coordinating the resource demands of a set of independent agents. We assume that resources are unreliable, making it necessary to retain imprecision in the execution times assigned to specific agent operations. To this end, a probabilistic model of resource allocation is developed for use in estimating the consequences of execution intervals (representing sets of possible resource allocation decisions). This leads to a probabilistic representation of requests for resource usage for which resource congestion constraints can be defined. We consider two applications of the framework prediction of bottleneck resources and time bound scheduling.|Nicola Muscettola,Stephen F. Smith","16534|IJCAI|2007|An Efficient Protocol for Negotiation over Multiple Indivisible Resources|We study the problem of autonomous agents negotiating the allocation of multiple indivisible resources. It is difficult to reach optimal outcomes in bilateral or multi-lateral negotiations over multiple resources when the agents' preferences for the resources are not common knowledge. Self-interested agents often end up negotiating inefficient agreements in such situations. We present a protocol for negotiation over multiple indivisible resources which can be used by rational agents to reach efficient outcomes. Our proposed protocol enables the negotiating agents to identify efficient solutions using systematic distributed search that visits only a subspace of the whole solution space.|Sabyasachi Saha,Sandip Sen","66075|AAAI|2007|Allocating Goods on a Graph to Eliminate Envy|We introduce a distributed negotiation framework for multi-agent resource allocation where interactions between agents are limited by a graph defining a negotiation topology. A group of agents may only contract a deal if that group is fully connected according to the negotiation topology. An important criterion for assessing the quality of an allocation of resources, in terms of fairness, is envy-freeness an agent is said to envy another agent if it would prefer to swap places with that other agent. We analyse under what circumstances a sequence of deals respecting the negotiation topology may be expected to converge to a state where no agent envies any of the agents it is directly connected to. We also analyse the computational complexity of a related decision problem, namely the problem of checking whether a given negotiation state admits any deal that would both be beneficial to every agent involved and reduce envy in the agent society.|Yann Chevaleyre,Ulrich Endriss,Nicolas Maudet","66362|AAAI|2008|Efficient Metadeliberation Auctions|Imagine a resource allocation scenario in which the interested parties can, at a cost, individually research ways of using the resource to be allocated, potentially increasing the value they would achieve from obtaining it. Each agent has a private model of its research process and obtains a private realization of its improvement in value, if any. From a social perspective it is optimal to coordinate research in a way that strikes the right tradeoff between value and cost, ultimately allocating the resource to one party- thus this is a problem of multi-agent metadeliberation. We provide a reduction of computing the optimal deliberation-allocation policy to computing Gittins indices in multi-anned bandit worlds, and apply a modification of the dynamic-VCG mechanism to yield truthful participation in an ex post equilibrium. Our mechanism achieves equilibrium implementation ofthe optimal policy even when agents have the capacity to deliberate about other agents' valuations, and thus addresses the problem of strategic deliberation.|Ruggiero Cavallo,David C. Parkes","16505|IJCAI|2007|Market Based Resource Allocation with Incomplete Information|Although there are some research efforts toward resource allocation in multi-agent systems (MAS), most of these work assume that each agent has complete information about other agents. This research investigates interactions among selfish, rational, and autonomous agents in resource allocation, each with incomplete information about other entities, and each seeking to maximize its expected utility. This paper presents a proportional resource allocation mechanism and gives a game theoretical analysis of the optimal strategies and the analysis shows the existence of equilibrium in the incomplete information setting. By augmenting the resource allocation mechanism with a deal optimization mechanism, trading agents can be programmed to optimize resource allocation results by updating beliefs and resubmitting bids. Experimental results showed that by having a deal optimization stage, the resource allocation mechanism produced generally optimistic outcomes (close to market equilibrium).|Bo An,Chunyan Miao,Zhiqi Shen","66360|AAAI|2008|Partially Synchronized DEC-MDPs in Dynamic Mechanism Design|In this paper, we combine for the first time the methods of dynamic mechanism design with techniques from decentralized decision making under uncertainty. Consider a multi-agent system with self-interested agents acting in an uncertain environment, each with private actions, states and rewards. There is also a social planner with its own actions, rewards, and states, acting as a coordinator and able to influence the agents via actions (e.g., resource allocations). Agents can only communicate with the center, but may become inaccessible, e.g., when their communication device fails. When accessible to the center, agents can report their local state (and models) and receive recommendations from the center about local policies to follow for the present period and also, should they become inaccessible, until becoming accessible again. Without self-interest, this poses a new problem class which we call partially-synchronized DEC-MDPs, and for which we establish some positive complexity results under reasonable assumptions. Allowing for self-interested agents, we are able to bridge to methods of dynamic mechanism design, aligning incentives so that agents truthfully report local state when accessible and choose to follow the prescribed \"emergency policies\" of the center.|Sven Seuken,Ruggiero Cavallo,David C. Parkes","65374|AAAI|2005|Coordination and Adaptation in Impromptu Teams|Coordinating a team of autonomous agents is one of the major challenges in building effective multiagcnt systems. Many techniques have been devised for this problem. and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques. though. is that the team members are developed together as a whole. In many multi agent scenarios. this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills. models. strategies. and coordination mechanisms. and no external organization is imposed upon them. In particular. we propose two techniques. one adaptive and one predictive. for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.|Michael H. Bowling,Peter McCracken","66211|AAAI|2007|An Ironing-Based Approach to Adaptive Online Mechanism Design in Single-Valued Domains|Online mechanism design considers the problem of sequential decision making in a multi-agent system with self-interested agents. The agent population is dynamic and each agent has private information about its value for a sequence of decisions. We introduce a method (\"ironing\") to transform an algorithm for online stochastic optimization into one that is incentive-compatible. Ironing achieves this by canceling decisions that violate a form of monotonicity. The approach is applied to the CONSENSUS algorithm and experimental results in a resource allocation domain show that not many decisions need to be canceled and that the overhead of ironing is manageable.|David C. Parkes,Quang Duong","15953|IJCAI|2003|Distributed Patient Scheduling in Hospitals|Patient scheduling in hospitals is a highly complex task. Hospitals have a distributed organisational structure being divided into several autonomous wards and ancillary units. Moreover, the treatment process is dynamic (information about the patients' diseases often varies during treatments, causing changes in the treatment process). Current approaches are insufficient because they either focus only on the single ancillary units, and therefore do not consider the entire treatment process of the patients, or they do not account for the distribution and dynamics of the patient scheduling problem. Therefore, we propose an agent based approach in which the patients and hospital resources are modelled as autonomous agents with their own goals, reflecting the decentralised structures in hospitals. In this multi-agent system, the patient agents compete over the scarce hospital resources. Moreover to improve the overall solution, the agents then negotiate with one another. To this end, a market mechanism is described, in which each self interested agent tries to improve its own situation. In particular we focus on how the agents can calculate demand and supply prices based upon their current schedule. Further, an evaluation of first results of the proposed method is given.|Torsten O. Paulussen,Nicholas R. Jennings,Keith S. Decker,Armin Heinzl"],["16948|IJCAI|2009|Interruptible Algorithms for Multi-Problem Solving|In this paper we address the problem of designing an interruptible system in a setting in which n problem instances, all equally important, must be solved. The system involves scheduling executions of contract algorithms (which offer a trade-off between allowable computation time and quality of the solution) in m identical parallel processors. When an interruption occurs, the system must report a solution to each of the n problem instances. The quality of this output is then compared to the best-possible algorithm that has foreknowledge of the interruption time and must, likewise, produce solutions to all n problem instances. This extends the well-studied setting in which only one problem instance is queried at interruption time. We propose a schedule which we prove is optimal for the case of a single processor. For multiple processors, we show that the quality of the schedule is within a small factor from optimal.|Spyros Angelopoulos,Alejandro López-Ortiz","15936|IJCAI|2003|FastSLAM  An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges|In , Montemerlo et al. proposed an algorithm called FastSLAM as an efficient and robust solution to the simultaneous localization and mapping problem. This paper describes a modified version of FastSLAM that overcomes important deficiencies of the original algorithm. We prove convergence of this new algorithm for linear SLAM problems and provide real-world experimental results that illustrate an order of magnitude improvement in accuracy over the original FastSLAM algorithm.|Michael Montemerlo,Sebastian Thrun,Daphne Koller,Ben Wegbreit","66370|AAAI|2008|Learning to Connect Language and Perception|To truly understand language, an intelligent system must be able to connect words, phrases, and sentences to its perception of objects and events in the world. Current natural language processing and computer vision systems make extensive use of machine learning to acquire the probabilistic knowledge needed to comprehend linguistic and visual input. However, to date, there has been relatively little work on learning the relationships between the two modalities. In this talk, I will review some of the existing work on learning to connect language and perception, discuss important directions for future research in this area, and argue that the time is now ripe to make a concerted effort to address this important, integrative AI problem.|Raymond J. Mooney","15038|IJCAI|1993|Vision Based Robot Behavior Tools and Testbeds for Real-World AI Research|Vision is a key function not only for robotics but also for AI more generally. Today realtime visual processing is becoming possible this means that vision based behavior can become more dynamic, opening fertile areas for applications. One aspect of this is real-time visual tracking. We have built a real-time tracking vision system and incorporated it in an integrated robot programming environment. Using this, we have performed experiments in vision based robot behavior and human-robot interaction. In particular, we have developed a robotic system capable of \"learning by seeing\". In general, it is important for the AI community not to lose sight of the problems and progress of robotics. After all, an AI system which acts in real-time in the real-world is no less (and no more) than an intelligent robot.|Hirochika Inoue","15693|IJCAI|2001|Real-Time Auditory and Visual Multiple-Object Tracking for Humanoids|This paper presents a real-time auditory and visual tracking of multiple objects for humanoid under real-world environments. Real-time processing is crucial for sensorimotor tasks in tracking, and multiple-object tracking is crucial for real-world applications. Multiple sound source tracking needs perception of a mixture of sounds and cancellation of motor noises caused by body movements. However its real-time processing has not been reported yet. Real-time tracking is attained by fusing information obtained by sound source localization, multiple face recognition, speaker tracking, focus of attention control, and motor control. Auditory streams with sound source direction are extracted by active audition system with motor noise cancellation capability from KHz sampling sounds. Visual streams with face ID and D-position are extracted by combining skincolor extraction, correlation-based matching, and multiple-scale image generation from a single camera. These auditory and visual streams are associated by comparing the spatial location, and associated streams are used to control focus of attention. Auditory, visual, and association processing are performed asynchronously on different PC's connected by TCPIP network. The resulting system implemented on an upper-torso humanoid can track multiple objects with the delay of  msec, which is forced by visual tracking and network latency.|Kazuhiro Nakadai,Ken-ichi Hidai,Hiroshi Mizoguchi,Hiroshi G. Okuno,Hiroaki Kitano","66273|AAAI|2007|Adaptive Localization in a Dynamic WiFi Environment through Multi-view Learning|Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications, such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most localization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much recalibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort. We illustrate LeMan-CoR's effectiveness in a real . WiFi environment.|Sinno Jialin Pan,James T. Kwok,Qiang Yang,Jeffrey Junfeng Pan","16833|IJCAI|2009|Early Prediction on Time Series A Nearest Neighbor Approach|In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health-informatics. We introduce a novel concept of MPL (Minimum Prediction Length) and develop ECTS (Early Classification on Time Series), an effective -nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable to that of a NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where NN classification is effective.|Zhengzheng Xing,Jian Pei,Philip S. Yu","66398|AAAI|2008|IMT A Mixed-Initiative Data Mapping and Search Toolkit|Interoperability requires the resolution of syntactic and semantic variations among system data models. To address this problem, we developed the Intelligent Mapping Toolkit (IMT), which employs a distributed multi-agent architecture to enable the mixed-initiative mapping of metadata and instances. This architecture includes a novel federation of service-encapsulated matching agents that leverage case-based reasoning methods. We recently used the IMT matching service to develop several domain-specific search applications in addition to the IMT mapping application.|Michael Zang,Adam Gray,Joe Kriege,Kalyan Moy Gupta,David W. Aha","65120|AAAI|1987|BAGGER An EBL System that Extends and Generalizes Explanations|This paper addresses the important issue in explanation-based learning of generalizing number. Most research in explanation-based learning involves relaxing constraints on the variables in an explanation, rather than generalizing the number of inference rules used. However, many concepts require generalizing the structure of the explanation. An explanation-based approach to the problem of generalizing to N is presented. The fully-implemented BAGGER system analyzes explanation structures and detects extendible repeated, inter-dependent applications of rules. When any are found. the explanation is extended so that an arbitrary number of repeated applications of the original rule are supported. The final structure is then generalized and a new rule produced. An important property of the extended rules is that their preconditions are expressed in terms of the initial state - they do not depend on the results of intermediate applications of the original rule. To illustrate the approach. portions of several situation calculus examples from the blocks world are analyzed. The approach presented leads to the acquisition of efficient plans that can be used to clear an object directly supporting an arbitrary number of other objects. build towers of arbitrary height. and unstack towers containing any number of blocks.|Jude W. Shavlik,Gerald DeJong","14042|IJCAI|1983|On the Requirements of Future Expert Systems|Many artificial intelligence applications require the use of expert systems. As expert systems move into new domains, several significant changes can be expected. Among these are an increase in number of rules in the rule base and an increase in the number of data elements contained in working memory. Also, many new applications require that expert systems move into real-time domains. Here, a system must be able to process large quantities of data which are changing rapidly. Many problem-solving situations will be time critical, and the system must take into account the availability and distribution of scarce system resources. For these reasons, the efficiency of a given expert system design and its ability to perform complex memory management tasks will become Increasingly important. This will require modifications in the traditional production system architectures. In this paper, the design requirements of future expert systems are discussed, and HAPS, a recently implemented production system architecture designed to address these issues, is presented.|Ron Sauers,Rick Walsh"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","15911|IJCAI|2003|Solving Constraint Optimization Problems in Anytime Contexts|This paper presents a new hybrid method for solving constraint optimization problems in anytime contexts. Discrete optimization problems are modelled as Valued CSP. Our method (VNSLDS+CP) combines a Variable Neighborhood Search and Limited Discrepancy Search with Constraint Propagation to efficiently guide the search. Experiments on the CELAR benchmarks demonstrate significant improvements over other competing methods. VNSLDS+CP has been successfully applied to solve a real-life anytime resource allocation problem in computer networks.|Samir Loudni,Patrice Boizumault","13410|IJCAI|1973|The Avoidance of Relative Catastrophe Heuristic Competence Genuine Dynamic Weighting and Computational Issues in Heuristic Problem Solving|To solve difficult problems heuristically, requires detailed attention to computational efficiency. This paper describes how a heuristic problem solving system, HPA, attempts to find a near optimal solution to the traveling salesman problem. A critical innovation over previous search algorithms is an explicit dynamic weighting of the heuristic information. The heuristic information is weighted inversely proportional to its depth in the search tree -- in consequence it produces a narrower depth first search than traditional weightings. At the same time, dynamic weighting retains the catastrophe protection of ordinary branch and bound algorithms.|Ira Pohl","58655|GECCO|2009|Evolving an edge selection formula for ant colony optimization|This project utilizes the evolutionary process found in Genetic Programming to evolve an improved decision formula for the Ant System algorithm. Two such improved formulae are discovered, one which uses the typical roulette wheel selection found in all well-known Ant Colony Optimization algorithms, and one which uses a greedy-style selection mechanism. The evolution of each formula is trained using the Ant System algorithm to solve a small Travelling Salesman Problem (TSP) and tested using larger unseen TSP instances.|Andrew Runka","58522|GECCO|2008|A multi-objective ant colony approach for pareto-optimization using dynamic programming|This paper covers a multi-objective Ant Colony Optimization, which is applied to the NP-complete multi-objective shortest path problem in order to approximate Pareto-fronts. The efficient single-objective solvability of the problem is used to improve the results of the ant algorithm significantly. A dynamic program is developed which generates local heuristic values on the edges of the problem graph. These heuristic values are used by the artificial ants.|Sascha Häckel,Marco Fischer,David Zechel,Tobias Teich","59079|GECCO|2010|Consultant-guided search a new metaheuristic for combinatorial optimization problems|In this paper, we present Consultant-Guided Search (CGS), a new metaheuristic for combinatorial optimization problems, based on the direct exchange of information between individuals in a population. CGS is a swarm intelligence technique inspired by the way real people make decisions based on advice received from consultants. We exemplify the application of this metaheuristic to a specific class of problems by introducing the CGS-TSP algorithm, an instantiation of CGS for the Traveling Salesman Problem. To determine if our direct communication approach can compete with stigmergy-based methods, we compare the performance of CGS-TSP with that of Ant Colony Optimization algorithms. Our experimental results show that the solution quality obtained by CGS-TSP is comparable with or better than that obtained by Ant Colony System and MAX-MIN Ant System.|Serban Iordache","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","65414|AAAI|2005|Cost-Algebraic Heuristic Search|Heuristic search is used to efficiently solve the single-node shortest path problem in weighted graphs. In practice, however, one is not only interested in finding a short path, but an optimal path, according to a certain cost notion. We propose an algebraic formalism that captures many cost notions, like typical Quality of Service attributes. We thus generalize A*, the popular heuristic search algorithm. for solving optimal-path problem. The paper provides an answer to a fundamental question for AI search, namely to which general notion of cost, heuristic search algorithms can be applied. We proof correctness of the algorithms and provide experimental results that validate the feasibility of the approach.|Stefan Edelkamp,Shahid Jabbar,Alberto Lluch-Lafuente","57297|GECCO|2005|Solving geometric TSP with ants|This paper presents an ant-based approach for solving the Traveling Salesman Problem (TSP). Novel concepts of this algorithm that distinguish it from the other heuristics are the inclusion of a preprocessing stage and the use of a modified version of an ant-based approach with local optimization in multi stages. Experimental results show that this algorithm outperforms ACS  and is comparable to MMAS  for Euclidean TSP instances. Of the  instances of Euclidean TSP from TSPLIB  that were tested, this algorithm found the optimal solution for  instances. For the remaining instances, this algorithm returned solutions that were within .% of the optimum.|Thang Nguyen Bui,Mufit Colpan","57245|GECCO|2003|Revisiting Elitism in Ant Colony Optimization|Ant Colony Optimization (ACO) has been applied successfully in solving the Traveling Salesman Problem. Marco Dorigo et al. used Ant System (AS) to explore the Symmetric Traveling Salesman Problem and found that the use of a small number of elitist ants can improve algorithm performance. The elitist ants take advantage of global knowledge of the best tour found to date and reinforce this tour with pheromone in order to focus future searches more effectively. This paper discusses an alternative approach where only local information is used to reinforce good tours thereby enhancing the ability of the algorithm for multiprocessor or actual network implementation. In the model proposed, the ants are endowed with a memory of their best tour to date. The ants then reinforce this \"local best tour\" with pheromone during an iteration to mimic the search focusing of the elitist ants. The environment used to simulate this model is described and compared with Ant System.|Tony White,Simon Kaegi,Terri Oda"],["57055|GECCO|2003|An Analysis of a Reordering Operator with Tournament Selection on a GA-Hard Problem|This paper analyzes the performance of a genetic algorithm that utilizes tournament selection, one-point crossover, and a reordering operator. A model is proposed to describe the combined effect of the reordering operator and tournament selection, and the numerical solutions are presented as well. Pairwise, s-ary, and probabilistic tournament selection are all included in the proposed model. It is also demonstrated that the upper bound of the probability to apply the reordering operator, previously derived with proportionate selection, does not affect the performance. Therefore, tournament selection is a necessity when using a reordering operator in a genetic algorithm to handle the conditions studied in the present work.|Ying-Ping Chen,David E. Goldberg","16363|IJCAI|2007|Adaptive Genetic Algorithm with Mutation and Crossover Matrices|A matrix formulation for an adaptive genetic algorithm is developed using mutation matrix and crossover matrix. Selection, mutation, and crossover are all parameter-free in the sense that the problem at a particular stage of evolution will choose the parameters automatically. This time dependent selection process was first developed in MOGA (mutation only genetic algorithm) Szeto and Zhang,  and now is extended to include crossover. The remaining parameters needed are population size and chromosome length. The adaptive behavior is based on locus statistics and fitness ranking of chromosomes. In crossover, two methods are introduced Long Hamming Distance Crossover (LHDC) and Short Hamming Distance Crossover (SHDC). LHDC emphasizes exploration of solution space. SHDC emphasizes exploitation of local search process. The one-dimensional random coupling Ising Spin Glass problem, which is similar to a knapsack problem, is used as a benchmark test for the comparison of various realizations of the adaptive genetic algorithms. Our results show that LHDC is better than SHDC, but both are superior to MOGA, which has been shown to be better than many traditional methods.|Nga Lam Law,Kwok Yip Szeto","57968|GECCO|2007|An analysis of constructive crossover and selection pressure in genetic programming|A common problem in genetic programming search algorithms is destructive crossover in which the offspring of good parents generally has worse performance than the parents. Designing constructive crossover operators and integrating some local search techniques into the breeding process have been suggested as solutions. This paper reports on experiments demonstrating that premature convergence may happen more often when using these techniques in combination with standard parent selection. It shows that modifying the selection pressure in the parent selection process is necessary to obtain a significant performance improvement.|Huayang Xie,Mengjie Zhang,Peter Andreae","59028|GECCO|2010|Breaking ties with secondary fitness in a genetic algorithm for the bin packing problem|In a genetic algorithm with integer fitnesses, ties in selection tournaments result in the selection of parent chromosomes effectively at random. A secondary measure that estimates how likely chromosomes are to be improved by the GA's variation operators can break such ties to the algorithm's advantage. Such a secondary fitness for the Bin Packing Problem is based on the maximum unused capacity in any one bin. In tests on  instances of the Bin Packing Problem, a permutation-coded genetic algorithm performs better when it applies this measure as a tie-breaker in tournament selection and in elitism than when it does not. The results suggest that similar measures should improve the performance of other GAs that apply tournament selection to chromosomes with integer fitnesses|Justin Benjamin,Bryant A. Julstrom","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","58630|GECCO|2009|Using crossover based similarity measure to improve genetic programming generalization ability|Generalization is a very important issue in Machine Learning. In this paper, we present a new idea for improving Genetic Programming generalization ability. The idea is based on a dynamic two-layered selection algorithm and it is tested on a real-life drug discovery regression application. The algorithm begins using root mean squared error as fitness and the usual tournament selection. A list of individuals called repulsors'' is also kept in memory and initialized as empty. As an individual is found to overfit the training set, it is inserted into the list of repulsors. When the list of repulsors is not empty, selection becomes a two-layer algorithm individuals participating to the tournament are not randomly chosen from the population but are themselves selected, using the average dissimilarity to the repulsors as a criterion to be maximized. Two kinds of similaritydissimilarity measures are tested for this aim the well known structural (or edit) distance and the recently defined subtree crossover based similarity measure. Although simple, this idea seems to improve Genetic Programming generalization ability and the presented experimental results show that Genetic Programming generalizes better when subtree crossover based similarity measure is used, at least for the test problems studied in this paper.|Leonardo Vanneschi,Steven Gustafson","57793|GECCO|2006|A survey of mutation techniques in genetic programming|The importance of mutation varies across evolutionary computation domains including genetic programming, evolution strategies, and genetic algorithms. In the genetic programming community, researchers' view of mutation's effectiveness spans the range from an ineffective or marginal operator, to a neutral operator, to a highly effective operator that evolves solutions more effectively than genetic programming with crossover alone. Mutation implementation and associated parameters are often under reported in genetic programming research and typically lack context that justifies the technique and parameter selection. In part, reporting variance stems from the adaptation of mutation developed by the genetic algorithm community, and the creation of new mutation techniques in genetic programming. This survey describes the controversial operator in genetic programming applications, mutation selection operators, mutation techniques and offers an organization of mutation characteristics. We suggest methodologies to improve reporting of mutation parameters and related individual selection methods.|Alan Piszcz,Terence Soule","57087|GECCO|2003|Enhancing the Performance of GP Using an Ancestry-Based Mate Selection Scheme|The performance of genetic programming relies mostly on population-contained variation. If the population diversity is low then there will be a greater chance of the algorithm being unable to find the global optimum. We present a new method of approximating the genetic similarity between two individuals using ancestry information. We define a new diversity-preserving selection scheme, based on standard tournament selection, which encourages genetically dissimilar individuals to undergo genetic operation. The new method is illustrated by assessing its performance in a well-known problem domain algebraic symbolic regression.|Rodney Fry,Andrew M. Tyrrell","57154|GECCO|2003|Daily Stock Prediction Using Neuro-genetic Hybrids|We propose a neuro-genetic daily stock prediction model. Traditional indicators of stock prediction are utilized to produce useful input features of neural networks. The genetic algorithm optimizes the neural networks under a D encoding and crossover. To reduce the time in processing mass data, a parallel genetic algorithm was used on a Linux cluster system. It showed notable improvement on the average over the buy-and-hold strategy. We also observed that some companies were more predictable than others.|Yung-Keun Kwon,Byung Ro Moon","58670|GECCO|2009|Three interconnected parameters for genetic algorithms|When an optimization problem is encoded using genetic algorithms, one must address issues of population size, crossover and mutation operators and probabilities, stopping criteria, selection operator and pressure, and fitness function to be used in order to solve the problem. This paper tests a relationship between () crossover probability, () mutation probability, and () selection pressure using two problems. This relationship is based on the schema theorem proposed by Holland and reflects the fact that the choice of parameters and operators for genetic algorithms needs to be problem specific.|Pedro A. Diaz-Gomez,Dean F. Hougen"],["16132|IJCAI|2005|Integrating Planning and Temporal Reasoning for Domains with Durations and Time Windows|The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the th International Planning Competition showing very good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina","15536|IJCAI|1999|Temporal Planning with Mutual Exclusion Reasoning|Many planning domains require a richer notion of time in which actions can overlap and have different durations. The key to fast performance in classical planners (e.g., Graphplan, IPP, and Blackbox) has been the use of a disjunctive representation with powerful mutual exclusion reasoning. This paper presents TGP, a new algorithm for temporal planning. TGP operates by incrementally expanding a compact planning graph representation that handles actions of differing duration. The key to TGP performance is tight mutual exclusion reasoning which is based on an expressive language for bounding mutexes and includes mutexes between actions and propositions. Our experiments demonstrate that mutual exclusion reasoning remains valuable in a rich temporal setting.|David E. Smith,Daniel S. Weld","15348|IJCAI|1997|Reasoning with Incomplete Initial Information and Nondeterminism in Situation Calculus|Situation Calculus is arguably the most widely studied and used formalism for reasoning about action and change. The main reason for its popularity is the ability to reason about different action sequences as explicit objects. In particular, planning can be formulated as an existence problem. This paper shows how these properties break down when incomplete information about the initial state and nondeterministic action effects are introduced, basically due to the fact that this incompleteness is not adequately manifested on the object level. A version of Situation Calculus is presented which adequately models the alternative ways the world can develop relative to a choice of actions.|Lars Karlsson","16623|IJCAI|2007|Property Persistence in the Situation Calculus|We develop an algorithm for reducing universally quantified situation calculus queries to a form more amenable to automated reasoning. Universal quantification in the situation calculus requires a second-order induction axiom, making automated reasoning difficult for such queries. We show how to reduce queries about property persistence, a common family of universally-quantified query, to an equivalent form that does not quantify over situations. The algorithm for doing so utilizes only first-order reasoning. We give several examples of important reasoning tasks that are facilitated by our approach, including checking for goal impossibility and reasoning about knowledge with partial observability of actions.|Ryan F. Kelly,Adrian R. Pearce","16114|IJCAI|2005|Representing Flexible Temporal Behaviors in the Situation Calculus|In this paper we present an approach to representing and managing temporally-flexible behaviors in the Situation Calculus based on a model of time and concurrent situations. We define a new hybrid framework combining temporal constraint reasoning and reasoning about actions. We show that the Constraint Based Interval Planning approach can be imported into the Situation Calculus by defining a temporal and concurrent extension of the basic action theory. Finally, we provide a version of the Golog interpreter suitable for managing flexible plans on multiple timelines.|Alberto Finzi,Fiora Pirri","13878|IJCAI|1983|Planning Using a Temporal World Model|Current problem solving systems are constrained in their applicability by inadequate world models. We suggest a world model based on a temporal logic. This approach allows the problem solver to gather constraints on the ordering of actions without having to commit to an ordering when a conflict is detected. As such, it generalizes the work on nonlinear planning by Sacerdoti and Tate. In addition, it allows more general descriptions of actions that may occur simultaneously or overlap, and appears promising in supporting reasoning about external events and actions caused by other agents.|James F. Allen,Johannes A. G. M. Koomen","16099|IJCAI|2005|Explaining preferences with argument positions|When deciding what to do agents must choose among alternative actions and different agents may make different choices according to what they wish to achieve in the light of their preferences and values. It cannot be assumed, however, that agents have a conscious understanding of their value preferences independent of the reasoning situations in which they engage. In this paper we consider an extension to a generic framework for reasoning about arguments justifying actions in terms of values in which the preferences amongst values emerge from the reasoning process.|Sylvie Doutre,Trevor J. M. Bench-Capon,Paul E. Dunne","66005|AAAI|2007|Beyond Individualism Modeling Team Playing Behavior in Robot Soccer through Case-Based Reasoning|We propose a Case-Based Reasoning approach for action selection in the robot soccer domain presented in the th European Conference on Case-Based Reasoning (). Based on the current state of a game, the robots retrieve the most similar past situation and then the team reproduces the sequence of actions performed in that occasion. In this domain we have to deal with all the difficulties that a real environment involves.|Raquel Ros,Manuela M. Veloso,Ramon López de Mántaras,Carles Sierra,Josep Lluís Arcos","65024|AAAI|1987|MU A Development Environment for Prospective Reasoning Systems|We describe a style of problem solving, prospective reasoning, and a development environment, MU, for building prospective reasoning systems. Prospective reasoning is a form of planning in which knowledge of the state of the world and the effects of actions is incomplete. We illustrate one implementation of prospective reasoning in MU with examples from medical diagnosis.|Paul R. Cohen,Michael Greenberg,Jefferson DeLisio","14454|IJCAI|1987|Formal Theories of Action Preliminary Report|We apply circumscription to formalizing reasoning about the effects of actions in the framework of the situation calculus. The axiomatic description of causal connections between actions and changes allows us to solve the qualification problem and the frame problem using only simple forms of circumscription. The method is applied to the Hanks--McDermott shooting problem and to a blocks world in which blocks can be moved and painted.|Vladimir Lifschitz"],["15019|IJCAI|1993|Specification and Generation of Custom-Tailored Knowledge-Acquisition Tools|Domain-oriented knowledge-acquisition tools provide efficient support for the design of knowledge-based systems. However, the cost of developing such tools is high, especially when their restricted scope is taken into account. Developers can use metalevel tools to generate domain-oriented knowledge-acquisition tools that are custom tailored for a small group of experts, with considerably less effort than is required for manual tool development. An epistemic obstacle to creating such metatools is the specification model for target knowledge-acquisition tools. The metatool DOTS is based on an abstract-architecture approach to the specification and generation of knowledge-acquisition tools. DOTS is domain and method independent, because it is based on an architectural model of the target knowledge-acquisition tool.|Henrik Eriksson","14014|IJCAI|1983|Towards Knowledge Acquisition From Natural Language Documents - Automatic Model Construction From Hardware Manual|In this paper, we explore automatic model construction by analyzing natural language documents. The extracted model will be utilized by a CAD system. A system called hmU, in the course of development, is designed to allow knowledge on very complex hardware module like LSI or VLSI to be incorporated into its knowledge base. The acquired knowledge will be utilized for helping human designer understand the component from various levels of abstraction. The focus of this paper is attentioned more to issues on knowledge representation and model inference than that on natural language analysis. Hierarchical model is employed. In particular, cause-effect representation is used to make it clear how actions of each module and events are related to each other. A brief description is given to illustrate our approach.|Toyoaki Nishida,Akira Kosaka,Shuji Doshita","14300|IJCAI|1985|A Model-Theoretic Analysis of Monotonic Knowledge|We present a semantic model for knowledge with the following properties () Knowledge is necessarily correct, () agents are logically omniscient, i.e., they know all the consequences of their knowledge, and () agents are positively introspective, i.e., they are aware of their knowledge, but not negatively introspective, i.e., they may not be aware of their ignorance. We argue that this is the appropriate model for implicit knowledge. We investigate the properties of the model, and use it to formalize the notion of circumscribed knowledge.|Moshe Y. Vardi","66753|AAAI|2010|Dynamic Auction A Tractable Auction Procedure|The G-net model for G-type knowledge representation is introduced. It is capable of modeling both static semantic knowledge and dynamic control knowledge, combining them into a loosely coupled, mixed-type knowledge hierarchy. Four reasoning algorithms for the G-net model are proposed inheritance reasoning and recognition reasoning for semantic knowledge, event-driven reasoning for dynamic knowledge, and control table reasoning for coordination and control in a mixed-type knowledge hierarchy. Based on the knowledge-table representation, the G-net model expresses the constraints and relationships among knowledge objects explicitly so that reasoning algorithms can be implemented efficiently. Applications to information systems prototyping are discussed|Dongmo Zhang,Laurent Perrussel","15623|IJCAI|2001|Visual Analogy in Problem Solving|Computational models of analogical problem solving have traditionally described source and target domains in terms of their causal structure. But psychological research shows that visual reasoning plays a part for many kinds of analogies. This paper describes a model that transfers a solution from a source analog to a new target problem using only visual knowledge represented symbolically. The knowledge representation is based on a language of primitive visual elements and transformations. We found that visual knowledge is sufficient for transfer, but that causal knowledge is needed to determine if the transferred solution is appropriate.|Jim Davies,Ashok K. Goel","16802|IJCAI|2007|Representations for Action Selection Learning from Real-Time Observation of Task Experts|The association of perception and action is key to learning by observation in general, and to program-level task imitation in particular. The question is how to structure this information such that learning is tractable for resource-bounded agents. By introducing a combination of symbolic representation with Bayesian reasoning, we demonstrate both theoretical and empirical improvements to a general-purpose imitation system originally based on a model of infant social learning. We also show how prior task knowledge and selective attention can be rigorously incorporated via loss matrices and Automatic Relevance Determination respectively.|Mark A. Wood,Joanna Bryson","16166|IJCAI|2005|Reflection Patterns for Interactive Knowledge Capture|Current knowledge acquisition tools have limited understanding of how users enter knowledge and how acquired knowledge is used, and provide limited assistance in organizing various knowledge authoring tasks. In this paper, we present a novel extension to existing knowledge acquisition tools where the system ) captures the episodes of knowledge acquisition and knowledge use through a set of declarative reflection patterns ) performs assessment on how to improve the future knowledge acquisition and knowledge use based on captured episodes, and ) provides assistance to the users by combining the assessment results.|Jihie Kim","15584|IJCAI|2001|The SG Family Extensions of Simple Conceptual Graphs|We introduce the SG family of graph-based knowledge representation and reasoning models, basically extensions of the simple conceptual graphs model. Objects of these models are colored simple graphs and are used to represent facts, rules and constraints. Reasonings are based on graphtheoretic mechanisms, mainly graph homomorphism. Models of this family are defined by the kind of objects composing a knowledge base. In this paper, we focus on the formal definitions of these models, including their operational semantics and relationships with FOL, and we study their decidability properties and computational complexity.|Jean-François Baget,Marie-Laure Mugnier","14226|IJCAI|1985|LEAP A Learning Apprentice for VLSl Design|It is by now well-recognised that a major impediment to developing know ledge-based systems is the knowledge acquisition bottleneck the task of building up a complete enough and correct enough knowledge base to provide high-level performance. This paper proposes a new class of knowledge-based systems designed to address this knowledge-acquisition bottleneck by incorporating a learning component to acquire new knowledge through experience. In particular, we define Learning Apprentice Systems as the class of interactive knowledge-based consultants that directly assimilate new knowledge by observing and analyzing the problem solving steps contributed by their users through their normal use of the system. This paper describes a specific Learning Apprentice System, called LEAP, which is presently being developed in the domain of VLSI design We also discuss design issues for Learning Apprentice Systems more generally, as well as restrictions on the generality of our current approach.|Tom M. Mitchell,Sridhar Mahadevan,Louis I. Steinberg","15662|IJCAI|2001|A-System Problem Solving through Abduction|This paper presents a new system, called the A- System, performing abductive reasoning within the framework of Abductive Logic Programming. It is based on a hybrid computational model that implements the abductive search in terms of two tightly coupled processes a reduction process of the highlevel logical representation to a lower-level constraint store and a lower-level constraint solving process. A set of initial \"proof of principle\" experiments demonstrate the versatility of the approach stemming from its declarative representation of problems and the good underlying computational behaviour of the system. The approach offers a general methodology of declarative problem solving in AI where an incremental and modular refinement of the high-level representation with extra domain knowledge can improve and scale the computational performance of the framework.|Antonis C. Kakas,Bert Van Nuffelen,Marc Denecker"],["66380|AAAI|2008|On-line Planning and Scheduling An Application to Controlling Modular Printers|This paper summarizes recent work reported at ICAPS on applying artificial intelligence techniques to the control of production printing equipment. Like many other real-world applications, such as mobile robotics, this complex domain requires real-time autonomous decision-making and robust continual operation. To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning. At the heart of our system is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling. For example, our planning-graph-based planning heuristic takes resource contention into account when estimating makespan remaining. We suggest that this general architecture may prove useful as more intelligent systems operate in continual, on-line settings. Our system has enabled a new product architecture for our industrial partner and has been used to drive several commercial prototypes. When compared with state-of-the-art off-line planners, our system is hundreds of times faster and often finds better plans.|Minh Binh Do,Wheeler Ruml,Rong Zhou","16820|IJCAI|2009|Plan Recognition as Planning|In this work we aim to narrow the gap between plan recognition and planning by exploiting the power and generality of recent planning algorithms for recognizing the set G* of goals G that explain a sequence of observations given a domain theory. After providing a crisp definition of this set, we show by means of a suitable problem transformation that a goal G belongs to G* if there is an action sequence  that is an optimal plan for both the goal G and the goal G extended with extra goals representing the observations. Exploiting this result, we show how the set G* can be computed exactly and approximately by minor modifications of existing optimal and suboptimal planning algorithms, and existing polynomial heuristics. Experiments over several domains show that the suboptimal planning algorithms and the polynomial heuristics provide good approximations of the optimal goal set G* while scaling up as well as state-of-the-art planning algorithms and heuristics.|Miquel Ramírez,Hector Geffner","16744|IJCAI|2007|Case-Based Techniques Used for Dialogue Understanding and Planning in a Human-Robot Dialogue System|We describe an approach to the use of case-based techniques for natural language understanding and for action planning in a system for dialogue between a human and a robot, which in our case is a UAV (unmanned aerial vehicle). A single case base and case-based reasoning engine is used both for understanding and for planning actions by the UAV. This approach has been developed through the work on an experimental dialogue system, called CEDERIC. Dialogue experiments where a number of users have solved tasks by dialogue with this system showed very adequate success rates, while at the same time they indicated a few weak points in the system that could then easily be corrected.|Karolina Eliasson","16132|IJCAI|2005|Integrating Planning and Temporal Reasoning for Domains with Durations and Time Windows|The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the th International Planning Competition showing very good performance in many benchmark problems.|Alfonso Gerevini,Alessandro Saetti,Ivan Serina","14516|IJCAI|1987|Deduction-based Region-Use Planning|This paper describes a deductive approach to \"region use\" planning problems. The planning task is viewed as one of devising a complete set of policy rules by iteratively modifying the rules and making their deductive consequences readily available to the planner. The application of this approach to a National Park region zoning problem is also described. Central to the system are the representation of management policy as knowledge based rules and the detection of inconsistencies in the rules. The implementation of the system has three closely coupled components a spatial database, an interactive graphics server and the deduction subsystem. The last of these is briefly described in the paper.|Robin S. Stanton,Hugh G. Mackenzie","65659|AAAI|2006|Factored Planning How When and When Not|Automated domain factoring, and planning methods that utilize them, have long been of interest to planning researchers. Recent work in this area yielded new theoretical insight and algorithms, but left many questions open How to decompose a domain into factors How to work with these factors And whether and when decomposition-based methods are useful This paper provides theoretical analysis that answers many of these questions it proposes a novel approach to factored planning proves its theoretical superiority over previous methods provides insight into how to factor domains and uses its novel complexity results to analyze when factored planning is likely to perform well, and when not. It also establishes the key role played by the domain's causal graph in the complexity analysis of planning algorithms.|Ronen I. Brafman,Carmel Domshlak","15707|IJCAI|2001|Planning as Model Checking for Extended Goals in Non-deterministic Domains|Recent research has addressed the problem of planning in non-deterministic domains. Classical planning has also been extended to the case of goals that can express temporal properties. However, the combination of these two aspects is not trivial. In non-deterministic domains, goals should take into account the fact that a plan may result in many possible different executions and that some requirements can be enforced on all the possible executions, while others may be enforced only on some executions. In this paper we address this problem. We define a planning algorithm that generates automatically plans for extended goals in nondeterministic domains. We also provide preliminary experimental results based on an implementation of the planning algorithm that uses symbolic model checking techniques.|Marco Pistore,Paolo Traverso","57622|GECCO|2006|A novel approach to optimize clone refactoring activity|Software evolution and software quality are ever changing phenomena. As software evolves, evolution impacts software quality. On the other hand, software quality needs may drive software evolution strategies.This paper presents an approach to schedule quality improvement under constraints and priority. The general problem of scheduling quality improvement has been instantiated into the concrete problem of planning duplicated code removal in a geographical information system developed in C throughout the last  years. Priority and constraints arise from development team and from the adopted development process. The developer team long term goal is to get rid of duplicated code, improve software structure, decrease coupling, and improve cohesion.We present our problem formulation, the adopted approach, including a model of clone removal effort and preliminary results obtained on a real world application.|Salah Bouktif,Giuliano Antoniol,Ettore Merlo,Markus Neteler","15318|IJCAI|1997|Par-KAP a Knowledge Acquisition Tool for Building Practical Planning Systems|Recently, attention has been focused on providing Knowledge Acquisition (KA) support for building practical planning systems. Such support is needed to guide a knowledge engineer in selecting planning methods, as well as for building and validating the planning knowledge-base for a given practical domain. Following current practice in knowledge acquisition, developing KA tools for planning requires that a number of planning knowledge components are made explicit. This includes explicating (i) a planning domain ontology, (ii) a library of problem-solving methods (PSMs) used in planning, and (iii) a set of domain requirements that are used to select a suitable PSM. In this paper, we summarize the planning knowledge components which we have identified in previous work, and, based on these, present an implementation (Par-KAP) that can exploit these models to aid knowledge engineers in constructing practical planning systems.|Leliane Nunes de Barros,James A. Hendler,V. Richard Benjamins","16485|IJCAI|2007|Factored Planning Using Decomposition Trees|Improving AI planning algorithms relies on the ability to exploit the structure of the problem at hand. A promising direction is that of factored planning, where the domain is partitioned into subdomains with as little interaction as possible. Recent work in this field has led to an detailed theoretical analysis of such approaches and to a couple of high-level planning algorithms, but with no practical implementations or with limited experimentations. This paper presents dTreePlan, a new generic factored planning algorithm which uses a decomposition tree to efficiently partition the domain. We discuss some of its aspects, progressively describing a specific implementation before presenting experimental results. This prototype algorithm is a promising contribution--with major possible improvements--and helps enrich the picture of factored planning approaches.|Elena Kelareva,Olivier Buffet,Jinbo Huang,Sylvie Thiébaux"],["13873|IJCAI|1983|TERMINATOR|The Markgraf Karl Refutation Procedure (MKR-Procedure) is an automated theorem prover for sorted logic, based on an extended clause graph calculus, currently under development at the University of Karlsruhe. This paper describes the TERMINATOR module, a component of the MKR-Procedure, which is essentially a very fast algorithm for the search for unit refutations. The TERMINATOR is used as a fast pre-theorem prover as well as an integral component of the system, and is called for different tasks during the search for a proof.|Grigoris Antoniou,Hans Jürgen Ohlbach","13365|IJCAI|1973|A Gobal View of Automatic Programming|This paper presents a framework for characterizing automatic programming systems In terms of how a task Is communicated to the system, the method and time at which the system acquires the knowledge to perform the task, and the characteristics of the resulting program to perform that task. It describes one approach In which both tasks and knowledge about the task domain are stated in natural language In the terms of that domain. All knowledge of computer science necessary to Implement the task Is Internalized Inside the system.|Robert Balzer","13369|IJCAI|1973|A Man-Machine Theorem-Proving System|This paper describes a man-machine theorem proving system at the University of Texas (Austin) which has been used to prove a few theorems in general topology. The theorem (or subgoal) being proved is presented on the scope in its natural form so that the user can easily comprehend it and, by a series of interactive commands, can help with the proof when he desires. A feature called DETAIL is employed which allows the human to interact only when needed and only to the extent necessary for the proof. The program is built around a modified form of IMPLY, a natural-deduction-like theorem proving technique which has been described earlier. A few examples of proofs are given.|W. W. Bledsoe,Peter Bruell","14516|IJCAI|1987|Deduction-based Region-Use Planning|This paper describes a deductive approach to \"region use\" planning problems. The planning task is viewed as one of devising a complete set of policy rules by iteratively modifying the rules and making their deductive consequences readily available to the planner. The application of this approach to a National Park region zoning problem is also described. Central to the system are the representation of management policy as knowledge based rules and the detection of inconsistencies in the rules. The implementation of the system has three closely coupled components a spatial database, an interactive graphics server and the deduction subsystem. The last of these is briefly described in the paper.|Robin S. Stanton,Hugh G. Mackenzie","14747|IJCAI|1989|Outline of a Naive Semantics for Reasoning with Qualitative Linguistic Information|This paper describes the mathematical basis for a computer language which can be used for representing natural human reasoning with imprecise linguistic information. The approach to doing this employs a collection of abstraction mechanisms which are based on the concept of a linguistic variable first introduced by Zadeh . The present semantics differs from that of Zadeh, however, in that (i) it does not require the use of fuzzy sets for the interpretation of linguistic terms, and (ii) the meanings of logical inferences are given as algorithms which act directly on linguistic terms themselves, rather than on their underlying interpretations. Two distinct types of deduction algorithm are proposed. The overall objective is to devise a reasoning system having sufficient generality that it can conveniently employ these plus others in a unified frame.|Daniel G. Schwartz","14404|IJCAI|1987|Understanding System Specifications Written in Natural Language|This paper describes research in understanding system specifications written in natural language. This research involves the implementation of a natural language interface, PHRANSPAN, for specifying the abstract behavior of digital systems in restricted English text. A neutral formal representation for the behavior is described using the USC Design Data Structure. A small set of concepts that characterize digital system behavior are presented using this representation. An intermediate representation loosely based on Conceptual Dependency is presented. Its use with a semantic-based parser to translate from English to the formal representation is illustrated by examples.|John J. Granacki Jr.,Alice C. Parker,Yigal Arens","13991|IJCAI|1983|Transportability and Generality in a Natural-Language Interface System|This paper describes the design of a transportable natural language (NL) interface to databases and the constraints that transportability places on each component of such a system. By a transportable NL system, we mean an NL processing system that is constructed so that a domain expert (rather than an AI or linguistics expert) can move the system to a new application domain. After discussing the general problems presented by transportability, this paper describes TEAM (an acronym for Transportable English database Access Medium), a demonstratable prototype of such a system. The discussion of TEAM shows how domain-independent and domain-dependent information can be separated in the different components of a NL interface system, and presents one method of obtaining domain-specific information from a domain expert.|Paul A. Martin,Douglas E. Appelt,Fernando C. N. Pereira","13436|IJCAI|1973|Understanding Without Proofs|The paper describes the analysis part of a running analysis and generation program for natural language. The system is entirely oriented to matching meaningful patterns onto fragmented paragraph length input. Its core Is a choice system based on what I call \"semantic density\". The system is contrasted with () syntax oriented linguistic approaches and () theorem proving approaches to the understanding problem. It is argued by means of examples that the present system is not only more workable, but more intuitively acceptable, at least as an understander for the purpose of translation, than deduction-based systems.|Yorick Wilks","66224|AAAI|2007|PLOW A Collaborative Task Learning Agent|To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies deep natural language understanding, knowledge representation and reasoning, dialogue systems, planningagent-based systems and machine learning. A formal evaluation shows the approach has great promise.|James F. Allen,Nathanael Chambers,George Ferguson,Lucian Galescu,Hyuckchul Jung,Mary D. Swift,William Taysom","14140|IJCAI|1985|SAPHIR  RESEDA A New Approach to Intelligent Data Base Access|This paper describes a transportable natural language interface to databases, augmented with a knowledge base and inference techniques. The inference mechanism, based on a classical expert system's type of approach, allows, when needed, to automatically convert an Input query into another one which is \"semantically close\". According to RESEDAS theory, \"semantically close\" means that the answer to the transformed query Implies what could have been the answer to the original question. The presented system Integrates natural language processing, expert system and knowledge representation technology to provide a cooperative database access.|Bernard Euzenat,Bernard Normier,Antoine Ogonowski,Gian Piero Zarri"]]},"title":{"entropy":5.984107308217213,"topics":["for system, learning for, neural networks, reinforcement learning, learning, the system, system, for networks, artificial intelligence, expert system, mobile robot, learning and, for agents, for robot, learning with, and system, bayesian networks, for planning, planning with, the learning","natural language, and, for and, reasoning about, the and, for logic, reasoning, logic programming, for language, and logic, logic, and reasoning, description logic, framework for, semantic for, for reasoning, model for, logic programs, knowledge base, and its","genetic algorithm, genetic programming, particle swarm, genetic for, algorithm for, evolutionary algorithm, using genetic, using, using algorithm, for optimization, evolutionary for, swarm optimization, particle optimization, estimation distribution, and genetic, programming for, using programming, algorithm optimization, for using, genetic with","the problem, for the, algorithm for, for problem, the, solving problem, the algorithm, the and, algorithm problem, constraint satisfaction, and problem, search for, local search, search, heuristic search, and search, ant colony, optimization problem, method for, the search","for planning, planning with, planning and, and control, for control, planning, for task, distributed for, planning domains, robot control, distributed system, control, and task, for autonomous, learning through, learning control, autonomous agents, control with, planning using, the control","neural networks, for networks, for recognition, networks, bayesian networks, and recognition, the networks, and networks, networks with, social networks, neural for, pattern recognition, plans recognition, recognition, activity recognition, the recognition, networks using, for object, object recognition, tool for","model for, model and, model, and inference, the model, temporal and, value iteration, with preferences, inference for, computational and, theory and, and preferences, iteration for, and approximation, monte carlo, for and, belief propagation, probabilistic model, theory for, integration and","for knowledge, knowledge base, knowledge representation, knowledge and, representation and, representation for, theorem proving, the knowledge, decision processes, knowledge, markov processes, markov decision, the role, probabilistic for, knowledge system, data base, knowledge acquisition, the representation, first order, question answering","for data, for classification, using data, support vector, for design, evolutionary for, and design, vector machine, for machine, from data, data, and data, semi-supervised learning, evolutionary testing, data mining, gene expression, classification using, genetic data, support machine, classification with","genetic algorithm, genetic programming, genetic for, using genetic, programming for, using algorithm, and genetic, using programming, genetic with, and programming, for using, using, using and, the genetic, with programming, genetic networks, the using, networks using, algorithm for, dynamic programming","constraint satisfaction, for constraint, with constraint, and constraint, ant colony, constraint problem, constraint, the constraint, satisfaction problem, optimal for, optimization problem, for problem, for scheduling, for optimization, constraint optimization, answer set, algorithm scheduling, bound for, the application, arc consistency","algorithm for, solving problem, method for, new for, for problem, for solving, for and, for, genetic algorithm, new the, algorithm problem, method the, and algorithm, genetic for, for the, algorithm with, comparison and, new algorithm, scheme for, algorithm solving"],"ranking":[["13999|IJCAI|1983|Integrating Multiple Knowledge Representations and Learning Capabilities in an Expert System The ADVISE System|The ADVISE system is an integrated set of tools for the development of and experimentation with expert systems in various specific application domains. It functions as a multi-purpose inference system that employs three knowledge representations a rule-base, a conceptual network and a relational data base. In addition, it includes learning capabilities by incorporating the inductive learning programs GEM (for learning from examples) and CLUSTER (for constructing classifications). Three expert systems have been developed using ADVISE PLANTds (version )--for diagnosing soybean diseases, PLANTcd--for predicting cutworm damage to corn, and BABY--a consultant for the neo-natal intensive care unit.|Ryszard S. Michalski,Arthur B. Baskin","65380|AAAI|2005|A Learning and Reasoning System for Intelligence Analysis|This paper presents a personal cognitive assistant, called Disciple-LTA, that can acquire expertise in intelligence analysis directly from intelligence analysts, can train new analysts, and can help analysts find solutions to complex problems through mixed-initiative reasoning, making possible the synergistic integration of a human's experience and creativity with an automated agent's knowledge and speed, and facilitating the collaboration with complementary experts and their agents.|Mihai Boicu,Gheorghe Tecuci,Cindy Ayers,Dorin Marcu,Cristina Boicu,Marcel Barbulescu,Bogdan Stanescu,William Wagner,Vu Le,Denitsa Apostolova,Adrian Ciubotariu","14398|IJCAI|1987|CHARADE A Rule System Learning System|Designed for an operational prospect, the CHARADE system automatically learns consistent rule systems from a description language, a set of axioms reflecting the language semantics and a set of examples. The technique advocated below is based on a \"generate and test\" mechanism where the description space is explored from the more general to the more specific descriptions. Rules and properties to be obtained are translated into exploration procedure constraints thanks to formalization of the learning set with two Boolean lattices.The underlying theoretical framework allows to both justify the heuristics conventionnaly used similarity based-learning and to introduce global properties to be satisfied by a rule system during its construction.|Jean-Gabriel Ganascia","15496|IJCAI|1999|Incremental Learning in a Fuzzy Intelligent System|This paper presents an incremental learning algorithm within the framework of a fuzzy intelligent system. The incremental learning algorithm is based on priority values attached to fuzzy rules. The priority value of a fuzzy rule is generated based on the fuzzy belief values of the fuzzy rule derived from the training data. The fuzzy incremental algorithm has three important properties. It can detect and recover from incorrect knowledge once new knowledge is available it will not lose the useful knowledge generated from the old data while it attempts to learn from new data and it provides a mechanism allowing to emphasize on knowledge learnt from the new data. The incremental fuzzy learning algorithm has been implemented in a fuzzy intelligent system for automotive engineering diagnosis. Its performance is presented in the paper.|Yi Lu Murphey,Tie Qi Chen","13458|IJCAI|1975|A Speech Understanding System With Learning Capability|A speech understanding system with learning capabilities is presented. Its relevant aspecis are a) The spoken senience is represented concisely by a description that can be used to reconstruct the sentence and to verify whether its meaning was not degraded by the coding. b) Syllables or broader coarticulation segments are the smallest units. c) The evaluation of an hypothesis is based on the probability that a syllable. a word or the sentence can generate the spectrogram of the spoken message and that a syntactic structure can generate its witch contour. d) Coarticulation effects are described in terms of pattern grammers, generating all the possible formant irajectories for a given utterence. e) Spectral and prosodic features can be learned by inference of stochastic finite-state-automats. f) More formant choices are allowed for a single syllable segment and an algorithm is proved for assigning to each choice a probability.|Renato de Mori,Silvano Rivoira,Angelo Serra","65027|AAAI|1987|Learning to Control a Dynamic Physical System|This paper presents an approach to learning to control a dynamic physical system. The approach has been implemented in a program named CART, and applied to a simple physical system studied previously by several researchers. Experiments illustrate that a control method is learned in about  trials, an improvement over previous learning programs.|Margaret E. Connell,Paul E. Utgoff","15060|IJCAI|1993|An Analytic Learning System for Specializing Heuristics|This paper describes how meta-level theories are used for analytic learning in MULTI-TAC. MULTI-TAC operationalizes generic heuristics for constraint-satisfaction problems, in order to create programs that are tailored to specific problems. For each of its generic heuristics, MULTI-TAC has a meta-theory specifically designed for operationalising that heuristic. We present examples of the specialisation process and discuss how the theories influence the tractability of the learning process. We also describe an empirical study showing that the specialised programs produced by MULTITAC compare favorably to hand-coded programs.|Steven Minton","14065|IJCAI|1983|Motives and Emotions in a General Learning System|The relationship between motives, emotions and learning in the design of intelligent systems has received relatively little consideration to date. Clarification of the relationship involves tackling fundamental questions such as the survival value or adaptive function of motives and emotions in intelligent systems, the nature of motivational and emotional processes which are features of 'innate' endowment, the learning of additional motives and emotions as a result of environmental interaction, and the results of the influence of motives and emotions on learning processes and, conversely, the effect of learning processes on the nature of motives and emotions.|J. G. (Iain) Wallace","14835|IJCAI|1991|Integration-Kid A Learning Companion System|This paper describes a learning companion system called Integration-Kid in the domain of learning indefinite integration. A learning companion system is an intelligent tutoring system of a new breed. Apart from the teacher, a learning companion models after an additional agent, called the learning companion. The learning companion acts as a companion for the human student in learning. Thus the companion performs the learning task at about the same level as the student and both the student and the companion exchange ideas while being presented the same material by the computer teacher. The computer companion might make mistakes, just like a human student.|Tak-Wai Chan","65014|AAAI|1987|Modular Learning in Neural Networks|In the development of large-scale knowledge networks much recent progress has been inspired by connections to neurobiology. An important component of any \"neural\" network is an accompanying learning algorithm. Such an algorithm, to be biologically plausible, must work for very large numbers of units. Studies of large-scale systems have so far been restricted to systems Without internal units (units With no direct connections to the input or output). Internal units are crucial to such systems as they are the means by which a system can encode high-order regularities (or invariants) that are Implicit in its inputs and outputs. Computer simulations of learning using internal units have been restricted to small-scale systems. This paper describes away of coupling autoassociative learning modules Into hierarchies that should greatly improve the performance of learning algorithms in large-scale systems. The Idea has been tested experimentally with positive results.|Dana H. Ballard"],["13947|IJCAI|1983|Logic Modelling of Cognitive Reasoning|Logic modelling is presented as an approach for exploring cognitive reasoning. The notion of mental construction and execution of propositional models is introduced. A model is constructed through inclusions and exclusions of assertions and assumptions about the task. A constructed model is executed in a logical control structure. Formal rules of inference are argued to be an essential feature of this architecture. A few examples are given for purpose of illustration.|Göran Hagert,\u2026ke Hansson","15791|IJCAI|2003|A Logic For Causal Reasoning|We introduce a logical formalism of irreflexive casual production relations that possesses both a standard monotonic semantics, and a natural nonmonotonic semantics. The formalism is shown to provide a complete characterization for the casual reasoning behind casual theories from McCain and Turner, . It is shown also that any causal relation is reducible to its Horn sub-relation with respect to the nonmonotonic semantics. We describe also a general correspondence between casual relations and abductive systems, which shows, in effect, that casual relations allow to express abductive reasoning. The results of the study seem to suggest causal production relations as a viable general framework for nonmonotonic reasoning.|Alexander Bochman","13934|IJCAI|1983|A Description and Reasoning of Plant Controllers in Temporal Logic|This paper describes the methodology to deal with the behavior of a dynamical system such as plant controllers in the framework of Temporal Logic. Many important concepts of the dynamical system like stability or observability are represented in this framework. As a reasoning method, we present an w -graph approach which enables us to represent the dynamical behavior of a given system, and an automatic synthesis of control rules can be reduced to a simple decision procedure on the w -graph. Moreover, the typical reasoning about the time-dependent system such as a causal argument or a qualitative simulation can be also treated on the w -graph in the same way.|Akira Fusaoka,Hirohisa Seki,Kazuko Takahashi","15653|IJCAI|2001|Ontology Reasoning in the SHOQD Description Logic|Ontologies are set to play a key rle in the \"Semantic Web\" by providing a source of shared and precisely defined terms that can be used in descriptions of web resources. Reasoning over such descriptions will be essential if web resources are to be more accessible to automated processes. SHOQ(D) is an expressive description logic equipped with named individuals and concrete datatypes which has almost exactly the same expressive power as the latest web ontology languages (e.g., OIL and DAML). We present sound and complete reasoning services for this logic.|Ian Horrocks,Ulrike Sattler","16316|IJCAI|2005|Ordering Heuristics for Description Logic Reasoning|We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.|Dmitry Tsarkov,Ian Horrocks","16866|IJCAI|2009|A Logic for Reasoning about Counterfactual Emotions|The aim of this work is to propose a logical framework for the specification of cognitive emotions that are based on counterfactual reasoning about agents' choices. An example of this kind of emotions is regret. In order to meet this objective, we exploit the well-known STIT logic Belnap et al.,  Horty, . STIT logic has been proposed in the domain of formal philosophy in the nineties and, more recently, it has been imported into the field of theoretical computer science where its formal relationships with other logics for multi-agent systems such as ATL and Coalition Logic (CL) have been studied. STIT is a very suitable formalism to reason about choices and capabilities of agents and groups of agents. Unfortunately, the version of STIT with agents and groups has been recently proved to be undecidable. In this work we study a decidable fragment of STIT with agents and groups which is sufficiently expressive for our purpose of formalizing counterfactual emotions.|Emiliano Lorini,François Schwarzentruber","15013|IJCAI|1993|On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning and Logic Programming|The purpose of this paper is to study the fundamental mechanism humans use in argumentation and its role in different major approaches to commonsense reasoning in AI and logic programming. We present three novel results We develop a theory for argumentation in which the acceptability of arguments is precisely defined. We show that logic programming and nonmonotonic reasoning in AI are different forms of argumentation. We show that argumentation can be viewed as a special form of logic programming with negation as failure. This result introduces a general method for generating metainterpreters for argumentation systems.|Phan Minh Dung","15759|IJCAI|2001|EPDL A Logic for Causal Reasoning|This paper presents an extended system EPDL of propositional dynamic logic by allowing a proposition as a modality for representing and specifying direct and indirect effects of actions in a unified logical structure. A set of causal logics based on the framework are proposed to model causal propagations through logical relevancy and iterated effects of causation. It is shown that these logics capture the basic properties of causal reasoning.|Dongmo Zhang,Norman Y. Foo","16539|IJCAI|2007|Epistemic Reasoning in Logic Programs|Although epistemic logic programming has an enhanced capacity to handle complex incomplete information reasoning and represent agents' epistemic behaviours, it embeds a significantly higher computational complexity than non-disjunctive and disjunctive answer set programming. In this paper, we investigate some important properties of epistemic logic programs. In particular, we show that Lee and Lifschitz's result on loop formulas for disjunctive logic programs can be extended to a special class of epistemic logic programs. We also study the polysize model property for epistemic logic programs. Based on these discoveries, we identify two non-trivial classes of epistemic logic programs whose consistency checking complexity is reduced from PSPACE-complete to NP-complete and P -complete respectively. We observe that many important applications on epistemic representation fall into these two classes of epistemic logic programs.|Yan Zhang","66699|AAAI|2010|Ontological Reasoning with F-logic Lite and its Extensions|This paper presents a novel architecture for collaborative multi-agent functional modeling in design on the semantic Web. The proposed architecture is composed of two visiting levels, i.e., local level and global level. The local level is an ontology-based functional modeling framework, which uses Web ontology language (OWL) to build a domain-specific local functional design ontology repository. Using this local ontology repository, the requests coming from the functional design agent can be parsed and performed effectively. The global level is a distributed multi-agent collaborative virtual environment, in which, OWL is used as a content language within the standard FIPA agent communication language (FIPA ACL) messages for describing ontologies, enabling diverse functional design ontologies between different agents to be communicated freely. The proposed architecture facilitates the exchange between diverse knowledge representation schemes in different functional modeling environments, and supports computer supported cooperative work (CSCW) between multiple functional design agents|Andrea Calì,Georg Gottlob,Michael Kifer,Thomas Lukasiewicz,Andreas Pieris"],["58639|GECCO|2009|Optimization of the trading rule in foreign exchange using genetic algorithm|The generation of profitable trading rules for Foreign Exchange (FX) investments is a difficult but popular problem. The use of Machine Learning in this problem allows us to obtain objective results by using information of the past market behavior. In this paper, we propose a Genetic Algorithm (GA) system to automatically generate trading rules based on Technical Indexes. Unlike related researches in the area, our work focuses on calculating the most appropriate trade timing, instead of predicting the trading prices.|Akinori Hirabayashi,Claus de Castro Aranha,Hitoshi Iba","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57585|GECCO|2005|Constrained optimization via particle evolutionary swarm optimization algorithm PESO|We introduce the PESO (Particle Evolutionary Swarm Optimization) algorithm for solving single objective constrained optimization problems. PESO algorithm proposes two new perturbation operators \"c-perturbation\" and \"m-perturbation\". The goal of these operators is to fight premature convergence and poor diversity issues observed in Particle Swarm Optimization (PSO) implementations. Constraint handling is based on simple feasibility rules. PESO is compared with respect to a highly competitive technique representative of the state-of-the-art in the area using a well-known benchmark for evolutionary constrained optimization. PESO matches most results and outperforms other PSO algorithms.|Angel Eduardo Muñoz Zavala,Arturo Hernández Aguirre,Enrique Raúl Villa Diharce","57789|GECCO|2006|Optimising cancer chemotherapy using an estimation of distribution algorithm and genetic algorithms|This paper presents a methodology for using heuristic search methods to optimise cancer chemotherapy. Specifically, two evolutionary algorithms - Population Based Incremental Learning (PBIL), which is an Estimation of Distribution Algorithm (EDA), and Genetic Algorithms (GAs) have been applied to the problem of finding effective chemotherapeutic treatments. To our knowledge, EDAs have been applied to fewer real world problems compared to GAs, and the aim of the present paper is to expand the application domain of this technique.We compare and analyse the performance of both algorithms and draw a conclusion as to which approach to cancer chemotherapy optimisation is more efficient and helpful in the decision-making activity led by the oncologists.|Andrei Petrovski,Siddhartha Shakya,John A. W. McCall","57972|GECCO|2007|Kernel based automatic clustering using modified particle swarm optimization algorithm|This paper introduces a method for clustering complex and linearly non-separable datasets, without any prior knowledge of the number of naturally occurring clusters. The proposed method is based on an improved variant of the Particle Swarm Optimization (PSO) algorithm. In addition, it employs a kernel-induced similarity measure instead of the conventional sum-of-squares distance. Use of the kernel function makes it possible to cluster data that is linearly non-separable in the original input space into homogeneous groups in a transformed high-dimensional feature space. Computer simulations have been undertaken with a test bench of five synthetic and three real life datasets, in order to compare the performance of the proposed method with a few state-of-the-art clustering algorithms. The results reflect the superiority of the proposed algorithm in terms of accuracy, convergence speed and robustness.|Ajith Abraham,Swagatam Das,Amit Konar","59100|GECCO|2010|Optimization of the hlder image descriptor using a genetic algorithm|Local image features can provide the basis for robust and invariant recognition of objects and scenes. Therefore, compact and distinctive representations of local shape and appearance has become invaluable in modern computer vision. In this work, we study a local descriptor based on the Hlder exponent, a measure of signal regularity. The proposal is to find an optimal number of dimensions for the descriptor using a genetic algorithm (GA). To guide the GA search, fitness is computed based on the performance of the descriptor when applied to standard region matching problems. This criterion is quantified using the F-Measure, derived from recall and precision analysis. Results show that it is possible to reduce the size of the canonical Hlder descriptor without degrading the quality of its performance. In fact, the best descriptor found through the GA search is nearly % smaller and achieves similar performance on standard tests.|Leonardo Trujillo,Pierrick Legrand,Gustavo Olague,Cynthia B. Pérez","57139|GECCO|2003|Circuit Bipartitioning Using Genetic Algorithm|In this paper, we propose a hybrid genetic algorithm for partitioning a VLSI circuit graph into two disjoint graphs of minimum cut size. The algorithm includes a local optimization heuristic which is a modification of Fiduccia-Matheses algorithm. Using well-known benchmarks (including ACMSIGDA benchmarks), the combination of genetic algorithm and the local heuristic outperformed hMetis , a representative circuit partitioning algorithm.|Jong-Pil Kim,Byung Ro Moon","58433|GECCO|2008|Combining cartesian genetic programming with an estimation of distribution algorithm|This paper describes initial testing of a novel idea to combine a CGP with an EDA. In recent work a new improved crossover technique was successfully applied to a CGP. To implement the new method meant changing the traditional CGP representation. The new representation developed in that work lends itself very nicely to some probability distribution being implemented. The work in this paper has investigated this idea of incoporating estimated probability distributions into the new CGP method with crossover.|Janet Clegg","58464|GECCO|2008|Construction of portfolio optimization system using genetic network programming with control nodes|Many evolutionary computation methods applied to the financial field have been reported. A new evolutionary method named \"Genetic Network Programming\" (GNP) has been developed and applied to the stock market recently. In this paper a portfolio optimization system based on Genetic Network Programming with control nodes is presented, which makes use of the information from Technical Indices and Candlestick Chart. The proposed optimization system, consisting of technical analysis rules, are trained to generate trading advice. The experimental results on the Japanese stock market show that the proposed optimization system using GNP with control nodes outperforms other traditional models and Buy&Hold method in terms of both accuracy and efficiency, and its effectiveness has been confirmed.|Yan Chen,Shingo Mabu,Kaoru Shimada,Kotaro Hirasawa","57271|GECCO|2005|Genetic algorithm optimization of superresolution parameters|Superresolution is the process of producing a high resolution image from a collection of low resolution images. This process has potential application in a wide spectrum of fields in which navigation, surveillance, and observation are important, yet in which target images have limited resolution. There have been numerous methods proposed and developed to implement superresolution, each with its own advantages and limitations. However, there is no standard method or software for superresolution. In this paper a genetic algorithm solution for determining the registration and point spread function (PSF) parameters for superresolution is proposed and implemented, and a superresolved image is generated using genetic algorithm optimization of an existing superresolution method.|Barry Ahrens"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","57683|GECCO|2006|Search--based approaches to the component selection and prioritization problem|This poster paper addresses the problem of choosing sets of software components to combine in component--based software engineering. It formulates both ranking and selection problems as feature subset selection problems to which search based software engineering can be applied. We will consider selection and ranking of elements from a set of software components from the component base of a large telecommunications organisation.|Mark Harman,Alexandros Skaliotis,Kathleen Steinhöfel,Paul Baker","58959|GECCO|2010|Efficient stochastic local search algorithm for solving the shortest common supersequence problem|The Shortest Common Supersequence (SCS) problem is a well-known hard combinatorial optimization problem that formalizes many real world problems. Recently, an application of the iterative optimization method called Prototype Optimization with Evolved Improvement Steps (POEMS) to the SCS problem has been proposed. The POEMS seeks the best variation of the current solution in each iteration. The variations, considered as structured hypermutations, are evolved by means of an evolutionary algorithm. This approach has been shown to work very well on synthetic as well as real biological data. However, the approach exhibited rather low scalability which is caused by very time demanding evaluation function. This paper proposes a new time efficient evaluation procedure and a new moving-window strategy for constructing and refining the supersequence. These two enhancements significantly improve an efficiency of the approach. Series of experiments with the modified POEMS method have been carried out. Results presented in this paper show that the method is competitive with current state-of-the-art algorithms for solving the SCS problem. Moreover, there is a potential for further improvement as discussed in the conclusions.|Jirí Kubalík","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","58316|GECCO|2008|Genetic algorithms with local search optimization for protein structure prediction problem|This paper presents a new Genetic Algorithm for Protein Structure Prediction problem in both D and D hydrophobic-hydrophilic lattice models, introduced in . Our algorithm evolves a new local-search genetic operation (called Pull-Move and well described in ), into the standard GA (,). The experiments show that performing a set of Pull-Moves in addition to standard genetic operations in GA (such as crossover and mutation) leads to significant energy improvements. The paper also introduces the Global Energy as fitness function and explains the advantages of utilizing it rather than the standard Free Energy. The experimental results are even more impressive when using the Global Energy as fitness function in GA.|Igor Berenboym,Mireille Avigal","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","57233|GECCO|2003|Exploration of a Two Sided Rendezvous Search Problem Using Genetic Algorithms|The problem of searching for a walker that wants to be found, when the walker moves toward the helicopter when it can hear it, is an example of a two sided search problem which is intrinsically difficult to solve. Thomas et al  considered the effectiveness of three standard NATO search paths  for this type of problem. In this paper a genetic algorithm is used to show that more effective search paths exist. In addition it is shown that genetic algorithms can be effective in finding a near optimal path of length  when searching a  cell area, that is a search space of ....|T. Q. S. Truong,A. Stacey","59006|GECCO|2010|Solving OCST problems with problem-specific guided local search|This paper considers the Euclidean variant of the optimal communication spanning tree (OCST) problem. Previous work analyzed features of high-quality solutions and found that edges in optimal solutions have low weight and point towards the center of a tree. Consequently, integrating this problem-specific knowledge into a metaheuristic increases its performance. In this paper, we present an approach to dynamically change the objective function to guide the search process into promising areas. Our approach is based on guided local search. The resulting problem-specific guided local search method considering weight and orientation of edges outperforms standard variants considering only edge weights as well as state-of-the-art evolutionary algorithms using edge-sets for larger problems.|Wolfgang Steitz,Franz Rothlauf","13695|IJCAI|1981|Tuning of Search of the Problem Space for Geometry Proofs|In planning a proof, a student searches through a space of inferences leading forward from the givens of the problem and backward from the to-be-proven statement. One dimension of growth of expertise is that students become more tuned in the search of this problem space. This can be shown to result from the application of various learning operators to production embodiments of the inference rules. Rules are evaluated after the solution of a problem according to whether they led to or led away from the solution. Rules that contributed to a solution are strengthened and an attempt is made to formulate general versions of these rules that will apply in other situations. Rules that led away from the solution are weakened and a discrimination process is evoked to try to add features to the rules that will try to restrict them to the correct circumstances of application. Composition is a learning process that collapses successful sequences of rule operations into single macro-rule productions. There is also a process that converts the backward reasoning rules formed by composition into forward reasoning rules. The effect of these learning processes is to put into production conditions tests for problem features that are heunstically predictive of the rule's success.|John R. Anderson","14053|IJCAI|1983|Flexible Learning of Problem Solving Heuristics Through Adaptive Search|Noting that the methods employed by existing learning systems are often bound to the intended task domain and have little applicability outside that domain, this paper considers an alternative learning system design that offers greater flexibility without sacrificing performance. An operational prototype, constructed around a powerful adaptive search technique, is presented and applied to the problem of acquiring problem solving heuristics through experience. Some performance results obtained with the system in a poker betting domain are reported and compared with those of a previously investigated learning system in the same domain. It is seen that comparable levels of performance are achieved by the two systems, despite the latter's dependence on a considerable amount of domain specific knowledge for effective operation.|Stephen F. Smith"],["66536|AAAI|2008|Beyond Classical Planning Procedural Control Knowledge and Preferences in State-of-the-Art Planners|Real-world planning problems can require search over thousands of actions and may yield a multitude of plans of differing quality. To solve such real-world planning problems, we need to exploit domain control knowledge that will prune the search space to a manageable size. And to ensure that the plans we generate are of high quality, we need to guide search towards generating plans in accordance with user preferences. Unfortunately, most state-of-the-art planners cannot exploit control knowledge, and most of those that can exploit user preferences require those preferences to only talk about the final state. Here, we report on a body of work that extends classical planning to incorporate procedural control knowledge and rich, temporally extended user preferences into the specification of the planning problem. Then to address the ensuing nonclassical planning problem, we propose a broadly-applicable compilation technique that enables a diversity of state-of-the-art planners to generate such plans without additional machinery. While our work is firmly rooted in AI planning it has broad applicability to a variety of computer science problems relating to dynamical systems.|Jorge A. Baier,Christian Fritz,Meghyn Bienvenu,Sheila A. McIlraith","17055|IJCAI|2009|A Distributed Control Loop for Autonomous Recovery in a Multi-Agent Plan|This paper considers the execution of a Multi-Agent Plan in a partially observable environment, and faces the problem of recovering from action failures. The paper formalizes a local plan repair strategy, where each agent in the system is responsible for controlling (monitoring and diagnosing) the actions it executes, and for autonomously repairing its own plan when an action failure is detected. The paper describes also how to mitigate the impact of an action failure on the plans of other agents when the local recovery strategy fails.|Roberto Micalizio","66521|AAAI|2008|Adaptive Control for Autonomous Underwater Vehicles|We describe a novel integration of Planning with Probabilistic State Estimation and Execution. The resulting system is a unified representational and computational framework based on declarative models and constraint-based temporal plans. The work is motivated by the need to explore the oceans more cost-effectively through the use of Autonomous Underwater Vehicles (AUV), requiring them to be goal-directed, perceptive, adaptive and robust in the context of dynamic and uncertain conditions. The novelty of our approach is in integrating deliberation and reaction over different temporal and functional scopes within a single model, and in breaking new ground in oceanography by allowing for precise sampling within a feature of interest using an autonomous robot. The system is general-purpose and adaptable to other ocean going and terrestrial platforms.|Conor McGann,Frederic Py,Kanna Rajan,John Ryan,Richard Henthorn","65453|AAAI|2005|A Discourse Planning Approach to Cinematic Camera Control for Narratives in Virtual Environments|As the complexity of narrative-based virtual environments grows, the need for effective communication of information to the users of these systems increase. Effective camera control for narrative-oriented virtual worlds involves decision making at three different levels choosing cinematic geometric composition, choosing the best camera parameters for conveying affective information, and choosing camera shots and transitions to maintain thetorical coherence. We propose a camera planning system that mirrors the film production pipeline we describe our formalization of film idioms used to communicate affective information. Our representation of idioms captures their hierarchical nature, represents the causal motivation for selection of shots, and provides a way for the system designer to specify the ranking of candidate shot sequences.|Arnav Jhala,R. Michael Young","14172|IJCAI|1985|A Framework for Distributed Sensing and Control|Logical Sensor Specification (LSS) has been introduced as a convenient means for specifying multi-sensor systems and their implementations. In this paper, we demonstrate how control issues can be handled in the content of LSS. In particular, the Logical Sensor Specification is extended to include a control mechanism which permits control information to () flow from more centralized processing to more peripheral processes, and () be generated locally in the logical sensor by means of a micro-expert system specific to the interface represented by the given logical sensor Examples are given including a proposed scheme for controlling the UtahMIT dextrous hand.|Tom Henderson,Chuck Hansen,Bir Bhanu","16855|IJCAI|2009|Learning Hierarchical Task Networks for Nondeterministic Planning Domains|This paper describes how to learn Hierarchical Task Networks (HTNs) in nondeterministic planning domains, where actions may have multiple possible outcomes. We discuss several desired properties that guarantee that the resulting HTNs will correctly handle the nondeterminism in the domain. We developed a new learning algorithm, called HTN-MAKERND, that exploits these properties. We implemented HTN-MAKERND in the recently-proposed HTN-MAKER system, a goal-regression based HTN learning approach. In our theoretical study, we show that HTN-MAKERND soundly produces HTN planning knowledge in low-order polynomial times, despite the nondeterminism. In our experiments with two nondeterministic planning domains, ND-SHOP, a well-known HTN planning algorithm for nondeterministic domains, significantly outperformed (in some cases, by about  orders of magnitude) the well-known planner MBP using the learned HTNs.|Chad Hogg,Ugur Kuter,Héctor Muñoz-Avila","15848|IJCAI|2003|Compiling Control Knowledge into Preconditions for Planning in the Situation Calculus|A promising technique used in some planning systems to improve their performance is the use of domain dependent search control knowledge. We present a procedure for compiling search control knowledge, expressed declaratively in a logic, into the preconditions of the plan actions (operators). We do this within the framework of the situation calculus by introducing a transformation of non-Markovian action theories into classical Markovian situation calculus theories.|Alfredo Gabaldon","13923|IJCAI|1983|A Distributed Control System for the CMU Rover|This paper describes a distributed software control structure developed for the CMU Rover, an advanced mobile robot equipped with a variety of sensors. Expert modules are used to control the operation of the sensors and actuators, interpret sensory and feedback data, build an internal model of the robot's environment, devise strategies to accomplish proposed tasks and execute these strategies. Each expert module is composed of a master process and a slave process, where the master process controls the scheduling and working of the slave process. Communication among expert modules occurs asynchronously over a blackboard structure. Information specific to the execution of a given task is provided through a control plan. The system is distributed over a network of processors. Real-time operating system kernels local to each processor and an interprocess message communication mechanism ensure transparency of the underlying network structure. The various parts of the system are presented in this paper and future work to be performed is mentioned.|Alberto Elfes,Sarosh Talukdar","14926|IJCAI|1991|Planning Robot Control Parameter Values with Qualitative Reasoning|A qualitative reasoning planner for determining robot control parameters to drive manipulation actions has been developed, integrated into a telerobot system, and demonstrated for a match striking task. The planner consists of a qualitative reasoner and a numerical execution history which interact to jointly direct and narrow the search for reliable numerical control parameter values. The planner algorithm, implementation, and an execution example are described. The relationship to previous qualitative reasoning work is also discussed.|Stephen F. Peters,Shigeoki Hirai,Toru Omata,Tomomasa Sato","65473|AAAI|2005|Using Domain-Configurable Search Control for Probabilistic Planning|We describe how to improve the performance of MDP planning algorithms by modifying them to use the search-control mechanisms of planners such as TLPlan, SHOP, and TALplanner. In our experiments, modified versions of RTDP, LRTDP, and Value Iteration were exponentially faster than the original algorithms. On the largest problems the original algorithms could solve, the modified ones were about , times faster. On another set. of problems whose state spaces were more than , times larger than the original algorithms could solve, the modified algorithms took only about  second.|Ugur Kuter,Dana S. Nau"],["14827|IJCAI|1991|HyperBF Networks for Real Object Recognition|Even if represented in a way which is invariant to illumination conditions, a D object gives rise to an infinite number of D views, depending on its pose. It has been recently shown () that it is possible to synthesize a module that can recognize a specific D object from any viewpoint, by using a new technique of learning from examples, which are, in this case, a small set of D views of the object. In this paper we extend the technique, a) to deal with real objects (isolated paper clips) that suffer from noise and occlusions and b) to exploit negative examples during the learning phase. We also compare different versions of the multi-layer networks corresponding to our technique among themselves and with a standard Nearest Neighbor classifier. The simplest version, which is a Radial Basis Functions network, performs less well than a Nearest Neighbor classifier. The more powerful versions, trained with positive and negative examples, perform significantly better. Our results, which may have interesting implications for computer vision despite the relative simplicity of the task studied, are especially interesting for understanding the process of object recognition in biological vision.|Roberto Brunelli,Tomaso Poggio","14088|IJCAI|1985|Object Recognition Using Vision and Touch|A system is described that integrates vision and tactile sensing in a robotics environment to perform object recognition tasks. It uses multiple sensor systems (active touch and passive stereo vision) to compute three dimensional primitives that can be matched against a model data base of complex curved surface objects containing holes and cavities. The low level sensing elements provide local surface and feature matches which are constrained by relational criteria embedded in the models. Once a model has been invoked, a verification procedure establishes confidence measures for a correct recognition. The three dimen* sional nature of the sensed data makes the matching process more robust as does the system's ability to sense visually occluded areas with touch. The model is hierarchic in nature and allows matching at different levels to provide support or inhibition for recognition.|Peter K. Allen,Ruzena Bajcsy","65226|AAAI|2004|Fibring Neural Networks|Neural-symbolic systems are hybrid systems that integrate symbolic logic and neural networks. The goal of neural-symbolic integration is to benefit from the combination of features of the symbolic and connectionist paradigms of artificial intelligence. This paper introduces a new neural network architecture based on the idea of fibring logical systems. Fibring allows one to combine different logical systems in a principled way. Fibred neural networks may be composed not only of interconnected neurons but also of other networks, forming a recursive architecture. A fibring function then defines how this recursive architecture must behave by defining how the networks in the ensemble relate to each other, typically by allowing the activation of neurons in one network (A) to influence the change of weights in another network (B). Intuitively, this can be seen as training network B at the same time that one runs network A. We show that, in addition to being universal approximators like standard feedforward networks, fibred neural networks can approximate any polynomial function to any desired degree of accuracy, thus being more expressive than standard feedforward networks.|Artur S. d'Avila Garcez,Dov M. Gabbay","58918|GECCO|2010|The baldwin effect in developing neural networks|The Baldwin Effect is a very plausible, but unproven, biological theory concerning the power of learning to accelerate evolution. Simple computational models in the 's gave the first constructive proof of its potential existence, and subsequent work in evolutionary computation has shown the practical, computational, advantages of hybrid evolution-learning systems. However, the basic theory, particularly its second phase (involving genetic assimilation of acquired characteristics) is difficult to reconcile in systems controlled by neural networks, particularly those that arise from their genotypes via a complex developmental process. Our research uses new evidence of the blurred distinction between development and learning in natural neural systems as the basis for an abstract model displaying the Baldwin Effect in artificial neural networks that evolve, develop and learn.|Keith L. Downing","16206|IJCAI|2005|Location-Based Activity Recognition using Relational Markov Networks|In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.|Lin Liao,Dieter Fox,Henry A. Kautz","57159|GECCO|2003|Learning Features for Object Recognition|Features represent the characteristics of objects and selecting or synthesizing effective composite features are the key factors to the performance of object recognition. In this paper, we propose a co-evolutionary genetic programming (CGP) approach to learn composite features for object recognition. The motivation for using CGP is to overcome the limitations of human experts who consider only a small number of conventional combinations of primitive features during synthesis. On the other hand, CGP can try a very large number of unconventional combinations and these unconventional combinations may yield exceptionally good results in some cases. Our experimental results with real synthetic aperture radar (SAR) images show that CGP can learn good composite features. We show results to distinguish objects from clutter and to distinguish objects that belong to several classes.|Yingqiang Lin,Bir Bhanu","58442|GECCO|2008|Evolving neural networks for fractured domains|Evolution of neural networks, or neuroevolution, bas been successful on many low-level control problems such as pole balancing, vehicle control, and collision warning. However, high-level strategy problems that require the integration of multiple sub-behaviors have remained difficult for neuroevolution to solve. This paper proposes the hypothesis that such problems are difficult because they are fractured the correct action varies discontinuously as the agent moves from state to state. This hypothesis is evaluated on several examples of fractured high-level reinforcement learning domains. Standard neuroevolution methods such as NEAT indeed have difficulty solving them. However, a modification of NEAT that uses radial basis function (RBF) nodes to make precise local mutations to network output is able to do much better. These results provide a better understanding of the different types of reinforcement learning problems and the limitations of current neuroevolution methods. Thus, they lay the groundwork for creating the next generation of neuroevolution algorithms that can learn strategic high-level behavior in fractured domains.|Nate Kohl,Risto Miikkulainen","13285|IJCAI|1969|Gestalt Pattern Recognition with Arrays of Predetermined Neural Functions|A predetermined neural-like function which makes a ternary logical comparison to its neighbors in an array of similar functions exhibits the ability to categorize two-dimensional geometric patterns by the distinctiveness of their shape directly. This property filter is but one of a family of similar predetermined neural-like functions which exhibit Gestalt recognition characteristics. Actual constructions of individual units and digital simulation of arrays of these units have empirically supported the theoretical foundation of this work. The findings at this time are preliminary and are described here to inform the reader about the nature and scope of the work and the direction in which further work will proceed. The author feels that the demonstration of a neural-like array with Gestalt-like properties for recognizing patterns represents a step in demonstrating that the Gestalt capability of the human being may be mechanistic in nature and can eventually be implemented by artificial means. The utility of this pattern recognition system is obvious for two-dimensional projections. The economics of such a device as compared to other methods of recognition look favourable. Thus, this work not only indicates the theoretical possibility of Gestalt-like functions, but is expected to result in useful applications.|William D. Rowe","15374|IJCAI|1997|Law Discovery using Neural Networks|This paper proposes a new connectionist approach to numeric law discovery i.e., neural networks (law-candidates) are trained by using a newly invented second-order learning algor ithm based on a quasi-Newton method, called BPQ, and the Minimum Description Length criterion selects the most suitable from lawcandidates. The main advantage of our method over previous work of symbolic or connectionist approach is that it can efficiently discover numeric laws whose power values are not restricted to integers. Experiments showed that the proposed method works well in discovering such laws even from data containing irrelevant variables or a small amount of noise.|Kazumi Saito,Ryohei Nakano","65014|AAAI|1987|Modular Learning in Neural Networks|In the development of large-scale knowledge networks much recent progress has been inspired by connections to neurobiology. An important component of any \"neural\" network is an accompanying learning algorithm. Such an algorithm, to be biologically plausible, must work for very large numbers of units. Studies of large-scale systems have so far been restricted to systems Without internal units (units With no direct connections to the input or output). Internal units are crucial to such systems as they are the means by which a system can encode high-order regularities (or invariants) that are Implicit in its inputs and outputs. Computer simulations of learning using internal units have been restricted to small-scale systems. This paper describes away of coupling autoassociative learning modules Into hierarchies that should greatly improve the performance of learning algorithms in large-scale systems. The Idea has been tested experimentally with positive results.|Dana H. Ballard"],["13970|IJCAI|1983|A Computational Model for Causal and Diagnostic Reasoning in Inference Systems|This paper introduces a representation of evidential relationships which permits updating of belief in two simultaneous modes causal (i. e. top-down) and diagnostic (i.e. bottom-up). It extends the hierarchical tree representation by allowing multiple causes to a given manifestation. We develop an updating scheme that obeys the axioms of probability, is computationally efficient, and is compatible with experts reasoning. The belief parameters of each variable are defined and updated by those of its neighbors in such a way that the impact of each new evidence propagates and settles through the network in a single pass.|Jin H. Kim,Judea Pearl","15305|IJCAI|1995|Iterated Theory Base Change A Computational Model|The AGM paradigm is a formal approach to ideal and rational information change From a practical perspective it suffers from two shortcomings, the first involves difficulties with respect to the finite representation of information, and the second involves the lack of support for the iteration of change operators. In this paper we show that these practical problems can be solved in theoretically satisfying ways wholely with in the AGM paradigm. We introduce a partial entrenchment ranking which serves as a canonical representation for a theory base and a well-ranked episterruc entrenchment, and we provide a computational model for adjusting partial entrenchment rankings when they receive new information using a procedure based on the principle of minimal change. The connection between the standard AGM theory change operators and the theory base change operators developed herein suggest that the proposed computational model for iterated theory base change exhibits desirable behaviour.|Mary-Anne Williams","65443|AAAI|2005|Axiom Schemata as Metalevel Axioms Model Theory|Logicians frequently use axiom schemata to encode (potentially infinite) sets of sentences with particular syntactic form. In this paper we examine a first-order language in which it is possible to write expressions that both describe sentences and assert the truth of the sentences so described. The effect of adding such expressions to a knowledge base is the same as directly including the set of described sentences.|Timothy L. Hinrichs,Michael R. Genesereth","16793|IJCAI|2007|Automated Benchmark Model Generators for Model-Based Diagnostic Inference|The task of model-based diagnosis is NP-complete, but it is not known whether it is computationally difficult for the \"average\" real-world system. There has been no systematic study of the complexity of diagnosing real-world problems, and few good benchmarks exist to test this. Real-world-graphs, a mathematical framework that has been proposed as a model for complex systems, have empirically been shown to capture several topological properties of real-world systems. We describe the adequacy with which a real-world-graph can characterise the complexity of model-based diagnostic inference on real-world systems. We empirically compare the inference complexity of diagnosing models automatically generated using the real-world-graph framework with comparable models from well-known ISCAS circuit benchmarks. We identify parameters necessary for the real-world-graph framework to generate benchmark diagnosis circuit models with realistic properties.|Gregory M. Provan,Jun Wang","14152|IJCAI|1985|Using Model Theory to Specify AI Programs|This paper proposes a method for adapting the traditional devices of model theory to the task of specifying the inputoutput behavior of artificial intelligence reasoning programs when viewed as inference engines. The method is illustrated by specifying two programs, one a toy example and the other a program for retrieving information from a declarative knowledge base. Close examination shows that many intuitions about the properties of a retriever can be stated rigorously in terms of inference and that the model-theoretic specification can then be used to prove that the retriever has these properties.|Alan M. Frisch","65381|AAAI|2005|An Inference Model for Semantic Entailment in Natural Language|Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.|Rodrigo de Salvo Braz,Roxana Girju,Vasin Punyakanok,Dan Roth,Mark Sammons","65785|AAAI|2006|Performing Incremental Bayesian Inference by Dynamic Model Counting|The ability to update the structure of a Bayesian network when new data becomes available is crucial for building adaptive systems. Recent work by Sang, Beame, and Kautz (AAAI ) demonstrates that the well-known Davis-Putnam procedure combined with a dynamic decomposition and caching technique is an effective method for exact inference in Bayesian networks with high density and width. In this paper, we define dynamic model counting and extend the dynamic decomposition and caching technique to multiple runs on a series of problems with similar structure. This allows us to perform Bayesian inference incrementally as the structure of the network changes. Experimental results show that our approach yields significant improvements over the previous model counting approaches on multiple challenging Bayesian network instances.|Wei Li 0002,Peter van Beek,Pascal Poupart","13845|IJCAI|1981|The Framework for a Model of Psychoanalytic Inference|Although theoretical prepositions in the field of psychoanalysis ultimately rest on the empirical base of claims by individual psychoanalysts about their institutive understanding of the utterances of individual analysands, there is as yet no significant scientific theory that accounts either for the analyst's ability to understand or for how he does so. Our claim is that these institutions can be represented by a two-stage model whose first step consists of classificatory processes and whose second step is essentially that of inductive inferences. We shall present our case by discussing three levels of structure to be found in the discourse of a patient in psychoanalysis the surface TEXT, the classification of this text in Linguistic MAPS and Personal Event FRAMES derived from the maps.|Virginia Teller,Hartvig Dahl","13419|IJCAI|1973|A Model of the Common-Sense Theory of Intention and Personal Causation|Certain general properties of man's ability to interpret the actions of other persons are discussed. Some distinguishing features of this common-sense theory include the nature of the modal operators of Can and Try, the asymmetry of implication, and the capacity to embed models within models. The structure of a proposed model of this naive theory of personal causation is presented. This model arrives at a specific interpretation of another's actions by showing that these actions represent a possible path to a particular goal that is consistent with the axioms of the belief system's theory of human motivation and personality organization.|Charles F. Schmidt,John D'Addamio","65558|AAAI|2005|Performing Bayesian Inference by Weighted Model Counting|Over the past decade general satisfiability testing algorithms have proven to be surprisingly effective at solving a wide variety of constraint satisfaction problem, such as planning and scheduling (Kautz and Selman ). Solving such NP-complete tasks by \"compilation to SAT\" has turned out to be an approach that is of both practical and theoretical interest. Recently, (Sang et al. ) have shown that state of the art SAT algorithms can be efficiently extended to the harder task of counting the number of models (satisfying assignments) of a formula, by employing a technique called component caching. This paper begins to investigate the question of whether \"compilation to model-counting\" could be a practical technique for solving real-world P-complete problems, in particular Bayesian inference. We describe an efficient translation from Bayesian networks to weighted model counting, extend the best model-counting algorithms to weighted model counting, develop an efficient method for computing all marginals in a single counting pass, and evaluate the approach on computationally challenging reasoning problems.|Tian Sang,Paul Beame,Henry A. Kautz"],["13912|IJCAI|1983|The Mercator Representation of Spatial Knowledge|The MERCATOR program constructs a cognitive map from a sequence of scene descriptions. A new representation of two-dimensional geography was developed for this program. Objects are represented by sets of polygons their boundaries, by sets of directed edges. The relative positions of objects are determined by connecting edges. A truth-conditional semantics for this representation is presented, its strengths and weaknesses are evaluated, and it is compared to other AI representations of shape and position.|Ernest Davis","14408|IJCAI|1987|Constraints in a Hybrid Knowledge Representation System|In our research group, the hybrid knowledge representation system Babylon has been developed providing formalisms for rules, prolog and frames. Beyond it, we implemented Consat, a system for constraint satisfaction. Since applications of Babylon for process diagnosis, planning etc. required constraints. we integrated Consat into the Babylon environment. The paper describes the integration of Consat into Babylon, regarding two aspects. First, constraints should be available as another Babylon formalism by using the functional interface of Consat. On the other hand, it is important to have constraints implicitly controlling other Babylon formalisms, for instance, in order to keep the system's database consistent. While with respect to the first point, the paper describes work already finished, the second form of integration is work in progress.|Hans W. Guesgen,Ulrich Junker,Angi Voß","14247|IJCAI|1985|A Decidable First-Order Logic for Knowledge Representation|Even though logic has played an important role in knowledge representation (KR) research, there has been little effort expended on devising decidable logics for KR. Most modifications to logic suggested for KR are either extensions to first-order logic (e.g., to handle non-monotonicity) or ad hoc changes in its inference mechanism. This paper presents a variant of first-order relevance logic that has a decidable algorithm for determining tautological entailment. Although this logic is considerably weaker than standard first-order logic, it can be used effectively in a KR system when semantically correct answers to queries are required within a finite amount of time.|Peter F. Patel-Schneider","13964|IJCAI|1983|Representation of Temporal Knowledge|The paper describes a system of notions (a T-model) developed for representing temporal information on the semantics-pragmatics level in a natural language understanding system. The choice of the notions to be considered has been relied upon a necessity of special facilities for describing situations with various degrees of detailing according to an inexact character of temporal information in natural language texts. Time is modelled as a straight directed line, and four main objects point, interval, quantity and chain together with four groups of notions associated with them are included into the model. A structure of the T-model and its base notions are briefly outlined in the first section of the paper. The representation of temporal information by means of T-model objects is then considered by examples.|E. Yu Kandrashina","65439|AAAI|2005|A Relational Representation for Procedural Task Knowledge|This paper proposes a methodology for learning joint probability estimates regarding the effect of sensorimotor features on the predicated quality of desired behavior. These relationships can then be used to choose actions that will most likely produce success. relational dependency networks are used to learn statistical models of procedural task knowledge. An example task expert for picking up objects is learned through actual experience with a humanoid robot. We believe that this approach is widely applicable and has great potential to allow a robot to autonomously determine which features in the world are salient and should be used to recommend policy for action.|Stephen Hart,Roderic A. Grupen,David Jensen","14216|IJCAI|1985|Motor Knowledge Representation|The motor control problem is considered in the framework of knowledge representation. In the AIRobotic world, a formal model for Motor knowledge should fill a gap between task planning and low level robot languages such model should be able to \"virtualize\" the robot and the interaction with the environment so that the planner could produce (and rely on) high level abstract actions, characterized by high autonomy and skill. The paper discusses some general aspects about actions, actors, and scenes, and describes the NEM language, which is able to represent and animate humanoids in a scene and is meant to provide a software laboratory for experimenting with action schemas.|Giuseppe Marino,Pietro Morasso,Renato Zaccaria","14250|IJCAI|1985|Self-Knowledge and Self-Representation|In this paper I introduce a contrast between homomorphic and nonhomomorphic ascriptions of informational content to representations. In the former case there is a mapping from the parts of the representation onto the constituents of the content. In the latter case, there is not some of the constituents of the content are settled by background factors. I contrast this distinction with that between context dependent and context independent ascriptions of content. I note that in cases where the ascriber of content shares the background with the agent, one is inclined to ascribe homomorphic content of a sort that does not have a fixed truth-value to a representation. This leads to the notion of relative information. Some uses for relative information are noted. Finally, the distinctions developed are used to distinguish three types of self-knowledge and account for their relations.|John Perry","13698|IJCAI|1981|An Interval-Based Representation of Temporal Knowledge|This paper describes a method for maintaining the relationships between temporal intervals in a hierarchical manner using constraint propagation techniques. The representation includes a notion of the present moment (i.e., \"now\"), and allows one to represent intervals that may extend indefinitely into the pastfuture. This research was supported in part by the National Science Foundation under Grant Number IST--, and in part by the Office of Naval Research under Grant Number N--O.|James F. Allen","15862|IJCAI|2003|Corpus-Based Knowledge Representation|A corpus-based knowledge representation system consists of a large collection of disparate knowledge fragments or schemas, and a rich set of statistics computed over the corpus. We argue that by collecting such a corpus and computing the appropriate statistics, corpus-based representation offers an alternative to traditional knowledge representation for a broad class of applications. The key advantage of corpus-based representation is that we avoid the laborious process of building a (often brittle) knowledge base. We describe the basic building blocks of a corpus-based representation system and a set of applications for which such a paradigm is appropriate, including one application where the approach is already showing promising results.|Alon Y. Halevy,Jayant Madhavan","14283|IJCAI|1985|Representation and Use of Explicit Justifications for Knowledge Base Refinements|We discuss the representation and use of justification structures as an aid to knowledge base refinement We show how justifications can be used by a system to generate explanations - for its own use-of potential causes of observed failures. We discuss specific information that is usefully included in these justifications to allow the system to isolate potential faulty supporting beliefs for its rules and to effect repairs. This research is part of a larger effort to develop a Learning Apprentice System (LAS) that partially automates initial construction of a knowledge base from first-principle domain knowledge as well as knowledge base refinement during routine use. A simple implementation has been constructed that demonstrates the feasibility of building such a system.|Reid G. Smith,Howard A. Winston,Tom M. Mitchell,Bruce G. Buchanan"],["16405|IJCAI|2007|Detection of Cognitive States from fMRI Data Using Machine Learning Techniques|Over the past decade functional Magnetic Resonance Imaging (fMRI) has emerged as a powerful technique to locate activity of human brain while engaged in a particular task or cognitive state. We consider the inverse problem of detecting the cognitive state of a human subject based on the fMRI data. We have explored classification techniques such as Gaussian Naive Bayes, k-Nearest Neighbour and Support Vector Machines. In order to reduce the very high dimensional fMRI data, we have used three feature selection strategies. Discriminating features and activity based features were used to select features for the problem of identifying the instantaneous cognitive state given a single fMRI scan and correlation based features were used when fMRI data from a single time interval was given. A case study of visuo-motor sequence learning is presented. The set of cognitive states we are interested in detecting are whether the subject has learnt a sequence, and if the subject is paying attention only towards the position or towards both the color and position of the visual stimuli. We have successfully used correlation based features to detect position-color related cognitive states with % accuracy and the cognitive states related to learning with .% accuracy.|Vishwajeet Singh,Krishna P. Miyapuram,Raju S. Bapi","16967|IJCAI|2009|Semi-Supervised Classification on Evolutionary Data|In this paper, we consider semi-supervised classification on evolutionary data, where the distribution of the data and the underlying concept that we aim to learn change over time due to short-term noises and long-term drifting, making a single aggregated classifier inapplicable for long-term classification. The drift is smooth if we take a localized view over the time dimension, which enables us to impose temporal smoothness assumption for the learning algorithm. We first discuss how to carry out such assumption using temporal regularizers defined in a structural way with respect to the Hilbert space, and then derive the online algorithm that efficiently finds the closed-form solution to the classification functions. Experimental results on real-world evolutionary mailing list data demonstrate that our algorithm outperforms classical semi-supervised learning algorithms in both algorithmic stability and classification accuracy.|Yangqing Jia,Shuicheng Yan,Changshui Zhang","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","58034|GECCO|2007|Clustering gene expression data via mining ensembles of classification rules evolved using moses|A novel approach, model-based clustering, is described foridentifying complex interactions between genes or gene-categories based on static gene expression data. The approach deals with categorical data, which consists of a set of gene expressionprofiles belonging to one category, and a set belonging to anothercategory. An evolutionary algorithm (Meta-Optimizing Semantic Evolutionary Search, or MOSES) is used to learn an ensemble of classification models distinguishing the two categories, based on inputs that are features corresponding to gene expression values. Each feature is associated with a model-based vector, which encodes quantitative information regarding the utilization of the feature across the ensembles of models. Two different ways of constructing these vectors are explored. These model-based vectors are then clustered using a variant of hierarchical clustering called Omniclust. The result is a set of model-based clusters, in which features are gathered together if they are often considered together by classification models -- which may be because they're co-expressed, or may be for subtler reasons involving multi-gene interactions. The method is illustrated by applying it to two datasets regarding human gene expression, one drawn from brain cells and pertinent to the neurogenetics of aging, and the other drawn from blood cells and relating to differentiating between types of lymphoma. We find that, compared to traditional expression-based clustering, the new method often yields clusters that have higher mathematical quality (in the sense of homogeneity and separation) and also yield novel and meaningful insights into the underlying biological processes.|Moshe Looks,Ben Goertzel,Lúcio de Souza Coelho,Mauricio Mudado,Cassio Pennachin","57053|GECCO|2003|Data Classification Using Genetic Parallel Programming|A novel Linear Genetic Programming (LGP) paradigm called Genetic Parallel Programming (GPP) has been proposed to evolve parallel programs based on a Multi-ALU Processor. It is found that GPP can evolve parallel programs for Data Classification problems. In this paper, five binary-class UCI Machine Learning Repository databases are used to test the effectiveness of the proposed GPP-classifier. The main advantages of employing GPP for data classification are ) speeding up evolutionary process by parallel hardware fitness evaluation and ) discovering parallel algorithms automatically. Experimental results show that the GPP-classifier evolves simple classification programs with good generalization performance. The accuracies of these evolved classifiers are comparable to other existing classification algorithms.|Sin Man Cheang,Kin-Hong Lee,Kwong-Sak Leung","57032|GECCO|2003|Artificial Immune System for Classification of Gene Expression Data|DNA microarray experiments generate thousands of gene expression measurement simultaneously. Analyzing the difference of gene expression in cell and tissue samples is useful in diagnosis of disease. This paper presents an Artificial Immune System for classifying microarray-monitored data. The system evolutionarily selects important features and optimizes their weights to derive classification rules. This system was applied to two datasets of cancerous cells and tissues. The primary result found few classification rules which correctly classified all the test samples and gave some interesting implications for feature selection.|Shin Ando,Hitoshi Iba","65390|AAAI|2005|Learning Support Vector Machines from Distributed Data Sources|In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.|Cornelia Caragea,Doina Caragea,Vasant Honavar","57934|GECCO|2007|Evolutionary selection of minimum number of features for classification of gene expression data using genetic algorithms|Selecting the most relevant factors from genetic profiles that can optimally characterize cellular states is of crucial importance in identifying complex disease genes and biomarkers for disease diagnosis and assessing drug efficiency. In this paper, we present an approach using a genetic algorithm for a feature subset selection problem that can be used in selecting the near optimum set of genes for classification of cancer data. In substantial improvement over existing methods, we classified cancer data with high accuracy with less features.|Alper Küçükural,Reyyan Yeniterzi,Süveyda Yeniterzi,Osman Ugur Sezerman","16376|IJCAI|2007|Semi-Supervised Learning for Multi-Component Data Classification|This paper presents a method for designing a semisupervised classifier for multi-component data such as web pages consisting of text and link information. The proposed method is based on a hybrid of generative and discriminative approaches to take advantage of both approaches. With our hybrid approach, for each component, we consider an individual generative model trained on labeled samples and a model introduced to reduce the effect of the bias that results when there are few labeled samples. Then, we construct a hybrid classifier by combining all the models based on the maximum entropy principle. In our experimental results using three test collections such as web pages and technical papers, we confirmed that our hybrid approach was effective in improving the generalization performance of multi-component data classification.|Akinori Fujino,Naonori Ueda,Kazumi Saito","66632|AAAI|2010|Constraint Programming for Data Mining and Machine Learning|While face detection seems a solved problem under general conditions, most state-of-the-art systems degrade rapidly when faces are partially occluded by other objects. This paper presents a solution to detect partially occluded faces by reasonably modifying the AdaBoost-based face detector. Our basic idea is that the weak classifiers in the AdaBoost-based face detector, each corresponding to a Haar-like feature, are inherently a patch-based model. Therefore, one can divide the whole face region into multiple patches, and map those weak classifiers to the patches. The weak classifiers belonging to each patch are re-formed to be a new classifier to determine if it is a valid face patch - without occlusion. Finally, we combine all of the valid face patches by assigning the patches with different weights to make the final decision whether the input subwindow is a face. The experimental results show that the proposed method is promising for the detection of occluded faces|Luc De Raedt,Tias Guns,Siegfried Nijssen"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","58970|GECCO|2010|The estimation of hlderian regularity using genetic programming|This paper presents a Genetic Programming (GP) approach to synthesize estimators for the pointwise Hlder exponent in D signals. It is known that irregularities and singularities are the most salient and informative parts of a signal. Hence, explicitly measuring these variations can be important in various domains of signal processing. The pointwise Hlder exponent provides a characterization of these types of features. However, current methods for estimation cannot be considered to be optimal in any sense. Therefore, the goal of this work is to automatically synthesize operators that provide an estimation for the Hlderian regularity in a D signal. This goal is posed as an optimization problem in which we attempt to minimize the error between a prescribed regularity and the estimated regularity given by an image operator. The search for optimal estimators is then carried out using a GP algorithm. Experiments confirm that the GP-operators produce a good estimation of the Hlder exponent in images of multifractional Brownian motions. In fact, the evolved estimators significantly outperform a traditional method by as much as one order of magnitude. These results provide further empirical evidence that GP can solve difficult problems of applied mathematics.|Leonardo Trujillo,Pierrick Legrand,Jacques Lévy Véhel","57020|GECCO|2002|Hyperspectral Image Analysis Using Genetic Programming|Genetic programming is used to evolve mineral identification functions for hyperspectral images. The input image set comprises  images from different wavelengths ranging from nm (visible blue) to nm (invisible shortwave in the infrared), taken over Cuprite, Nevada, with the AVIRIS hyperspectral sensor. A composite mineral image indicating the overall reflectance percentage of three minerals (alunite, kaolnite, buddingtonite) is used as a reference or ''solution'' image. The training set is manually selected from this composite image, and results are cross-validated with the remaining image data not used for training. The task of the GP system is to evolve mineral identifiers, where each identifier is trained to identify one of the three mineral specimens. A number of different GP experiments were undertaken, which parameterized features such as thresholded mineral reflectance intensity and target GP language. The results are promising, especially for minerals with higher reflectance thresholds, which indicate more intense concentrations.|Brian J. Ross,Anthony G. Gualtieri,Frank Fueten,Paul Budkewitsch","15740|IJCAI|2001|Neural Logic Network Learning using Genetic Programming|Neural Logic Network or Neulonet is a hybrid of neural network expert systems. Its strength lies in its ability to learn and to represent human logic in decision making using component net rules. The technique originally employed in neulonet learning is backpropagation. However, the resulting weight adjustments will lead to a loss in the logic of the net rules. A new technique is now developed that allows the neulonet to learn by composing net rules using genetic programming. This paper presents experimental results to demonstrate this new and exciting capability in capturing human decision logic from examples. Comparisons will also be made between the use of net rules, and the use of standard boolean logic of negation, disjunction and conjunction in evolutionary computation.|Chew Lim Tan,Henry Wai Kit Chia","57703|GECCO|2006|On evolving buffer overflow attacks using genetic programming|In this work, we employed genetic programming to evolve a \"white hat\" attacker that is to say, we evolve variants of an attack with the objective of providing better detectors. Assuming a generic buffer overflow exploit, we evolve variants of the generic attack, with the objective of evading detection by signature-based methods. To do so, we pay particular attention to the formulation of an appropriate fitness function and partnering instruction set. Moreover, by making use of the intron behavior inherent in the genetic programming paradigm, we are able to explicitly obfuscate the true intent of the code. All the resulting attacks defeat the widely used 'Snort' Intrusion Detection System.|Hilmi Günes Kayacik,Malcolm I. Heywood,A. Nur Zincir-Heywood","58114|GECCO|2007|Coevolution of intelligent agents using cartesian genetic programming|A coevolutionary competitive learning environment for two antagonistic agents is presented. The agents are controlled by a new kind of computational network based on a compartmentalised model of neurons. We have taken the view that the genetic basis of neurons is an important  and neglected aspect of previous approaches. Accordingly, we have defined a collection of chromosomes representing various aspects of the neuron soma, dendrites and axon branches, and synaptic connections. Chromosomes are represented and evolved using a form of genetic programming known as Cartesian Genetic Programming. The network formed by running the chromosomal programs has a highly dynamic morphology in which neurons grow, and die, and neurite branches together with synaptic connections form and change in response to environmental interactions. The idea of this paper is to demonstrate the importance of the genetic transfer of learned experience and life time learning. The learning is a consequence of the complex dynamics produced as a result of interaction (coevolution) between two intelligent agents. Our results show that both agents exhibit interesting learning capabilities.|Gul Muhammad Khan,Julian Francis Miller,David M. Halliday","57450|GECCO|2005|Evolution of a human-competitive quantum fourier transform algorithm using genetic programming|In this paper, we show how genetic programming (GP) can be used to evolve system-size-independent quantum algorithms, and present a human-competitive Quantum Fourier Transform (QFT) algorithm evolved by GP.|Paul Massey,John A. Clark,Susan Stepney","57053|GECCO|2003|Data Classification Using Genetic Parallel Programming|A novel Linear Genetic Programming (LGP) paradigm called Genetic Parallel Programming (GPP) has been proposed to evolve parallel programs based on a Multi-ALU Processor. It is found that GPP can evolve parallel programs for Data Classification problems. In this paper, five binary-class UCI Machine Learning Repository databases are used to test the effectiveness of the proposed GPP-classifier. The main advantages of employing GPP for data classification are ) speeding up evolutionary process by parallel hardware fitness evaluation and ) discovering parallel algorithms automatically. Experimental results show that the GPP-classifier evolves simple classification programs with good generalization performance. The accuracies of these evolved classifiers are comparable to other existing classification algorithms.|Sin Man Cheang,Kin-Hong Lee,Kwong-Sak Leung","57052|GECCO|2003|Improving Evolvability of Genetic Parallel Programming Using Dynamic Sample Weighting|This paper investigates the sample weighting effect on Genetic Parallel Programming (GPP) that evolves parallel programs to solve the training samples captured directly from a real-world system. The distribution of these samples can be extremely biased. Standard GPP assigns equal weights to all samples. It slows down evolution because crowded regions of samples dominate the fitness evaluation and cause premature convergence. This paper compares the performance of four sample weighting (SW) methods, namely, Equal SW (ESW), Class-equal SW (CSW), Static SW (SSW) and Dynamic SW (DSW) on five training sets. Experimental results show that DSW is superior in performance on tested problems.|Sin Man Cheang,Kin-Hong Lee,Kwong-Sak Leung","58332|GECCO|2008|Fault tolerant control using Cartesian genetic programming|The paper focuses on the evolution of algorithms for control of a machine in the presence of sensor faults, using Cartesian Genetic Programming. The key challenges in creating training sets and a fitness function that encourage a general solution are discussed. The evolved algorithms are analysed and discussed. It was found that highly novel, mathematically elegant and hitherto unknown solutions were found.|Yoshikazu Hirayama,Tim Clarke,Julian Francis Miller"],["65781|AAAI|2006|Weighted Constraint Satisfaction with Set Variables|Set variables are ubiquitous in modeling (soft) constraint problems, but efforts on practical consistency algorithms for Weighted Constraint Satisfaction Problems (WCSPs) have only been on integer variables. We adapt the classical notion of set bounds consistency for WCSPs, and propose efficient representation schemes for set variables and common unary, binary, and ternary set constraints, as well as cardinality constraints. Instead of reasoning consistency on an entire set variable directly, we propose local consistency check at the set element level, and demonstrate that this apparent \"micro\"-management of consistency does imply set bounds consistency at the variable level. In addition, we prove that our framework captures classical CSPs with set variables, and degenerates to the classical case when the weights in the problem contain only  and T. Last but not least, we verify the feasibility and efficiency of our proposal with a prototype implementation, the efficiency of which is competitive against ILOG Solver on classical problems and orders of magnitude better than WCSP models using - variables to simulate set variables on soft problems.|J. H. M. Lee,C. F. K. Siu","65542|AAAI|2005|Constraint-Based Preferential Optimization|We first show that the optimal and undominated outcomes of an unconstrained (and possibly cyclic) CP-net are the solutions of a set of hard constraints. We then propose a new algorithm for finding the optimal outcomes of a constrained CP-net which makes use of hard constraint solving. Unlike previous algorithms, this new algorithm works even with cyclic CP-nets. In addition. the algorithm is not tied to CP-nets, but can work with any preference formalism which produces a preorder over the outcomes. We also propose an approximation method which weakens the preference ordering induced by the CP-net, returning a larger set of outcomes, but provides a significant computational advantage. Finally, we describe a weighted constraint approach that allows to find good solutions even when optimals do not exist.|Steven David Prestwich,Francesca Rossi,Kristen Brent Venable,Toby Walsh","16689|IJCAI|2007|On Modeling Multiagent Task Scheduling as a Distributed Constraint Optimization Problem|This paper investigates how to represent and solve multiagent task scheduling as a Distributed Constraint Optimization Problem (DCOP). Recently multiagent researchers have adopted the CTMS language as a standard for multiagent task scheduling. We contribute an automated mapping that transforms CTMS into a DCOP. Further, we propose a set of representational compromises for CTMS that allow existing distributed algorithms for DCOP to be immediately brought to bear on CTMS problems. Next, we demonstrate a key advantage of a constraint based representation is the ability to leverage the representation to do efficient solving. We contribute a set of pre-processing algorithms that leverage existing constraint propagation techniques to do variable domain pruning on the DCOP. We show that these algorithms can result in % reduction in state space size for a given set of CTMS problems. Finally, we demonstrate up to a % increase in the ability to optimally solve CTMS problems in a reasonable amount of time and in a distributed manner as a result of applying our mapping and domain pruning algorithms.|Evan Sultanik,Pragnesh Jay Modi,William C. Regli","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16978|IJCAI|2009|Set Branching in Constraint Optimization|Branch and bound is an effective technique for solving constraint optimization problems (COP's). However, its search space expands very rapidly as the domain sizes of the problem variables grow. In this paper, we present an algorithm that clusters the values of a variable's domain into sets. Branch and bound can then branch on these sets of values rather than on individual values, thereby reducing the branching factor of its search space. The aim of our clustering algorithm is to construct a collection of sets such that branching on these sets will still allow effective bounding. In conjunction with the reduced branching factor, the size of the explored search space is thus significantly reduced. We test our method and show empirically that it can yield significant performance gains over existing state-of-the-art techniques.|Matthew Kitching,Fahiem Bacchus","65206|AAAI|2004|Collapsibility and Consistency in Quantified Constraint Satisfaction|The concept of consistency has pervaded studies of the constraint satisfiction problem. We introduce two concepts, which are inspired by consistency, for the more general framework of the quantified constraint satisfaction problem (QCSP). We use these concepts to derive, in a uniform fashion, proofs of polynomial-time tractability and corresponding algorithms for certain cases of the QCSP where the types of allowed relations are restricted. We not only unify existing tractability results and algorithms, but also identify new classes of tractable QCSPs.|Hubie Chen","65853|AAAI|2006|ODPOP An Algorithm for OpenDistributed Constraint Optimization|We propose ODPOP, a new distributed algorithm for open multiagent combinatorial optimization that feature unbounded domains (Faltings & Macho-Gonzalez ). The ODPOP algorithm explores the same search space as the dynamic programming algorithm DPOP (Petcu & Faltings b) or ADOPT (Modi et at. ). but does so in an incremental, best-first fashion suitable for open problems. ODPOP has several advantages over DPOP. First, it uses messages whose size only grows linearly with the treewidth of the problem. Second, by letting agents explore values in a best-first order, it avoids incurring always the worst case complexity as DPOP, and on average it saves a significant amount of computation and information exchange. To show the merits of our approach, we report on experiments with practically sized distributed meeting scheduling problems on a multiagent system.|Adrian Petcu,Boi Faltings","65819|AAAI|2006|Temporal Preference Optimization as Weighted Constraint Satisfaction|We present a new efficient algorithm for obtaining utilitarian optimal solutions to Disjunctive Temporal Problems with Preferences (DTPPs). The previous state-of-the-art system achieves temporal preference optimization using a SAT formulation, with its creators attributing its performance to advances in SAT solving techniques. We depart from the SAT encoding and instead introduce the Valued DTP (VDTP). In contrast to the traditional semiring-based formalism that annotates legal tuples of a constraint with preferences, our framework instead assigns elementary costs to the constraints themselves. After proving that the VDTP can express the same set of utilitarian optimal solutions as the DTPP with piecewise-constant preference functions, we develop a method for achieving weighted constraint satisfaction within a meta-CSP search space that has traditionally been used to solve DTPs without preferences. This allows us to directly incorporate several powerful techniques developed in previous decision-based DTP literature. Finally, we present empirical results demonstrating that an implementation of our approach consistently outperforms the SAT-based solver by orders of magnitude.|Michael D. Moffitt,Martha E. Pollack","65241|AAAI|2004|Robust Solutions for Constraint Satisfaction and Optimization|Super solutions are solutions in which, if a small number of variables lose their values, we are guaranteed to be able to repair the solution with only a few changes. In this paper, we stress the need to extend the super solution framework along several dimensions to make it more useful practically. We demonstrate the usefulness of those extensions on an example from jobshop scheduling, an optimization problem solved through constraint satisfaction. In such a case there is indeed a trade-off between optimality and robustness, however robustness may be increased without sacrificing optimality.|Emmanuel Hebrard","66003|AAAI|2007|A Distributed Constraint Optimization Solution to the PP Video Streaming Problem|The future success of application layer video multicast depends on the availability of video stream distribution methods that can scale in the number of stream senders and receivers. Previous work on the problem of application layer video streaming has not effectively addressed scalability in the number of receivers and senders. Therefore, new solutions that are amenable to analysis and can achieve scalable PP video streaming are needed. In this work we propose the use of automated negotiation algorithms to construct video streaming trees at the application layer. We show that automated negotiation can effectively solve the problem of distributing a video stream to a large number of receivers.|Theodore Elhourani,Nathan Denny,Michael M. Marefat"],["57864|GECCO|2006|A GA-ACO-local search hybrid algorithm for solving quadratic assignment problem|In recent decades, many meta-heuristics, including genetic algorithm (GA), ant colony optimization (ACO) and various local search (LS) procedures have been developed for solving a variety of NP-hard combinatorial optimization problems. Depending on the complexity of the optimization problem, a meta-heuristic method that may have proven to be successful in the past might not work as well. Hence it is becoming a common practice to hybridize meta-heuristics and local heuristics with the aim of improving the overall performance. In this paper, we propose a novel adaptive GA-ACO-LS hybrid algorithm for solving quadratic assignment problem (QAP). Empirical study on a diverse set of QAP benchmark problems shows that the proposed adaptive GA-ACO-LS converges to good solutions efficiently. The results obtained were compared to the recent state-of-the-art algorithm for QAP, and our algorithm showed obvious improvement.|Yiliang Xu,Meng-Hiot Lim,Yew-Soon Ong,Jing Tang","58756|GECCO|2009|Cheating for problem solving a genetic algorithm with social interactions|We propose a variation of the standard genetic algorithm that incorporates social interaction between the individuals in the population. Our goal is to understand the evolutionary role of social systems and its possible application as a non-genetic new step in evolutionary algorithms. In biological populations, i.e. animals, even human beings and microorganisms, social interactions often affect the fitness of individuals. It is conceivable that the perturbation of the fitness via social interactions is an evolutionary strategy to avoid trapping into local optimum, thus avoiding a fast convergence of the population. We model the social interactions according to Game Theory. The population is, therefore, composed by cooperator and defector individuals whose interactions produce payoffs according to well known game models (prisoner's dilemma, chicken game, and others). Our results on Knapsack problems show, for some game models, a significant performance improvement as compared to a standard genetic algorithm.|Rafael Lahoz-Beltra,Gabriela Ochoa,Uwe Aickelin","58959|GECCO|2010|Efficient stochastic local search algorithm for solving the shortest common supersequence problem|The Shortest Common Supersequence (SCS) problem is a well-known hard combinatorial optimization problem that formalizes many real world problems. Recently, an application of the iterative optimization method called Prototype Optimization with Evolved Improvement Steps (POEMS) to the SCS problem has been proposed. The POEMS seeks the best variation of the current solution in each iteration. The variations, considered as structured hypermutations, are evolved by means of an evolutionary algorithm. This approach has been shown to work very well on synthetic as well as real biological data. However, the approach exhibited rather low scalability which is caused by very time demanding evaluation function. This paper proposes a new time efficient evaluation procedure and a new moving-window strategy for constructing and refining the supersequence. These two enhancements significantly improve an efficiency of the approach. Series of experiments with the modified POEMS method have been carried out. Results presented in this paper show that the method is competitive with current state-of-the-art algorithms for solving the SCS problem. Moreover, there is a potential for further improvement as discussed in the conclusions.|Jirí Kubalík","57057|GECCO|2003|A Hybrid Genetic Algorithm for the Hexagonal Tortoise Problem|We propose a hybrid genetic algorithm for the hexagonal tortoise problem. We combined the genetic algorithm with an efficient local heuristic and aging mechanism. Another search heuristic which focuses on the space around existing solutions is also incorporated into the genetic algorithm. With the proposed algorithm, we could find the optimal solutions of up to a fairly large problem.|Heemahn Choe,Sung-Soon Choi,Byung Ro Moon","58747|GECCO|2009|New heuristic and hybrid genetic algorithm for solving the bounded diameter minimum spanning tree problem|In this paper, we propose a new heuristic, called Center-Based Recursive Clustering - CBRC, for solving the bounded diameter minimum spanning tree (BDMST) problem. Our proposed hybrid genetic algorithm  is also extended to include the new heuristic and a multi-parent crossover operator. We test the new heuristic and genetic algorithm on two sets of benchmark problem instances for the Euclidean and Non-Euclidean cases. Experimental results show the effectiveness of the proposed heuristic and genetic algorithm.|Huynh Thi Thanh Binh,Robert I. McKay,Nguyen Xuan Hoai,Nguyen Duc Nghia","57612|GECCO|2006|A new hybrid evolutionary algorithm for the huge -cardinality tree problem|In recent years it has been shown that an intelligent combination of metaheuristics with other optimization techniques can significantly improve over the application of a pure metaheuristic. In this paper, we combine the evolutionary computation paradigm with dynamic programming for the application to the NP-hard k-cardinality tree problem. Given an undirected graph G with node and edge weights, this problem consists of finding a tree in G with exactly k edges such that the sum of the weights is minimal. The genetic operators of our algorithm are based on an existing dynamic programming algorithm from the literature for finding optimal subtrees in a given tree. The simulation results show that our algorithm is able to improve the best known results for benchmark problems from the literature in  cases.|Christian Blum","57116|GECCO|2003|Designing A Hybrid Genetic Algorithm for the Linear Ordering Problem|The Linear Ordering Problem(LOP), which is a well-known NP-hard problem, has numerous applications in various fields. Using this problem as an example, we illustrate a general procedure of designing a hybrid genetic algorithm, which includes the selection of crossovermutation operators, accelerating the local search module and tuning the parameters. Experimental results show that our hybrid genetic algorithm outperforms all other existing exact and heuristic algorithms for this problem.|Gaofeng Huang,Andrew Lim","57687|GECCO|2006|A genetic algorithm for the longest common subsequence problem|A genetic algorithm for the longest common subsequence problem encodes candidate sequences as binary strings that indicate subsequences of the shortest or first string. Its fitness function penalizes sequences not found in all the strings. In tests on  sets of three strings, a dynamic programming algorithm returns optimum solutions quickly on smaller instances and increasingly slowly on larger instances. Repeated trials of the GA always identify optimum subsequences, and it runs in reasonable times even on the largest instances.|Brenda Hinkemeyer,Bryant A. Julstrom","59051|GECCO|2010|The K-bit-swap a new genetic algorithm operator|Genetic algorithms (GA) mostly commonly use three main operators selection, crossover and mutation, although many others have been proposed in the literature. This article introduces a new operator, k-bit-swap, which swaps bits between two strings without preserving the location of those bits, changing their order of bits in the string. It can be considered as a form of crossover. We investigate the effects of this operator and demonstrate that its use improves the speed and performance on several well-known problems.|Aram Ter-Sarkisov,Stephen R. Marsland,Barbara R. Holland","57037|GECCO|2003|A Hybrid Genetic Algorithm for the Capacitated Vehicle Routing Problem|Recently proved successful for variants of the vehicle routing problem (VRP) involving time windows, genetic algorithms have not yet shown to compete or challenge current best search techniques in solving the classical capacitated VRP. In this paper, a hybrid genetic algorithm to address the capacitated vehicle routing problem is proposed. The basic scheme consists in concurrently evolving two populations of solutions to minimize total traveled distance using genetic operators combining variations of key concepts inspired from routing techniques and search strategies used for a time-variant of the problem to further provide search guidance while balancing intensification and diversification. Results from a computational experiment over common benchmark problems report the proposed approach to be very competitive with the best-known methods.|Jean Berger,Mohamed Barkaoui"]]}}