{"abstract":{"entropy":5.9581025687745175,"topics":["logic programs, markov decision, present approach, introduce framework, logic, approach, framework, programming, recently, analysis, paper, partially, introduce, parsing, complete, first, general, processes, allows, statistical","constraint satisfaction, arc consistency, satisfaction problem, present novel, constraint problem, local space, present algorithms, search satisfaction, work planning, planning, search constraint, search algorithms, algorithms, problem planning, planning constraint, constraint algorithms, present, networks, complexity, heuristic","natural language, learning, learning sequential, describes system, natural generation, machine learning, machine data, language generation, present learning, learning models, models based, based, problem learning, approach learning, learning data, system based, describes, text, information, describes learning","search web, consider problem, consider agents, optimization problem, different ontologies, belief change, belief revision, problem, problem agents, agents, search finding, quantified problem, knowledge agents, belief, reasoning, constraint problem, search problem, formula, problem knowledge, finding","system, describes, objects, introduce, semantic, approach","markov decision, approach, knowledge, partially, first, complete, observable, identifying, problem","arc consistency, present algorithms, present novel, present, complexity","algorithms, heuristic, used, operators","learning sequential, learning, classification, selection, setting, features, called, effects, algorithms, large, modeling, study, introduce","machine learning, describes system, machine data, learning data, describes, data, text, given, applied, svm, reasoning, simple, research","different ontologies, finding, need, estimation, models, order, represent","problem agents, consider agents, consider problem, problem knowledge, knowledge agents, agents, investigate, knowledge, actions, use, domain"],"ranking":[["16235|IJCAI|2005|Possibilistic Stable Models|In this work, we define a new framework in order to improve the knowledge representation power of Answer Set Programming paradigm. Our proposal is to use notions from possibility theory to extend the stable model semantics by taking into account a certainty level, expressed in terms of necessity measure, on each rule of a normal logic program. First of all, we introduce possibilistic definite logic programs and show how to compute the conclusions of such programs both in syntactic and semantic ways. The syntactic handling is done by help of a fix-point operator, the semantic part relies on a possibility distribution on all sets of atoms and we show that the two approaches are equivalent. In a second part, we define what is a possibilistic stable model for a normal logic program, with default negation. Again, we define a possibility distribution allowing to determine the stable models.|Pascal Nicolas,Laurent Garcia,Igor St√©phan","16281|IJCAI|2005|Generative Modeling with Failure in PRISM|PRISM is a logic-based Turing-complete symbolic-statistical modeling language with a built-in parameter learning routine. In this paper,we enhance the modeling power of PRISM by allowing general PRISM programs to fail in the generation process of observable events. Introducing failure extends the class of definable distributions but needs a generalization of the semantics of PRISM programs. We propose a three valued probabilistic semantics and show how failure enables us to pursue constraint-based modeling of complex statistical phenomena.|Taisuke Sato,Yoshitaka Kameya,Neng-Fa Zhou","16103|IJCAI|2005|A Uniform Integration of Higher-Order Reasoning and External Evaluations in Answer-Set Programming|We introduce HEX programs, which are nonmonotonic logic programs admitting higher-order atoms as well as external atoms, and we extend the well-known answer-set semantics to this class of programs. Higher-order features are widely acknowledged as useful for performing meta-reasoning, among other tasks. Furthermore, the possibility to exchange knowledge with external sources in a fully declarative framework such as Answer-Set Programming (ASP) is nowadays important, in particular in view of applications in the Semantic Web area. Through external atoms, HEX programs can model some important extensions to ASP, and are a useful KR tool for expressing various applications. Finally, complexity and implementation issues for a preliminary prototype are discussed.|Thomas Eiter,Giovambattista Ianni,Roman Schindlauer,Hans Tompits","16190|IJCAI|2005|An MCMC Approach to Solving Hybrid Factored MDPs|Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.|Branislav Kveton,Milos Hauskrecht","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","16267|IJCAI|2005|Conditional Planning in the Discrete Belief Space|Probabilistic planning with observability restrictions, as formalized for example as partially observable Markov decision processes (POMDP), has a wide range of applications, but it is computationally extremely difficult. For POMDPs, the most general decision problems about existence of policies satisfying certain properties are undecidable. We consider a computationally easier form of planning that ignores exact probabilities, and give an algorithm for a class of planning problems with partial observability. We show that the basic backup step in the algorithm is NP-complete. Then we proceed to give an algorithm for the backup step, and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.|Jussi Rintanen","16104|IJCAI|2005|On Solution Correspondences in Answer-Set Programming|We introduce a general framework for specifying program correspondence under the answer-set semantics. The framework allows to define different kinds of equivalence notions, including previously defined notions like strong and uniform equivalence, in which programs are extended with rules from a given context, and correspondence is determined by means of a binary relation. In particular, refined equivalence notions based on projected answer sets can be defined within this framework, where not all parts of an answer set are of relevance. We study general characterizations of inclusion and equivalence problems, introducing novel semantical structures. Furthermore, we deal with the issue of determining counterexamples for a given correspondence problem, and we analyze the computational complexity of correspondence checking.|Thomas Eiter,Hans Tompits,Stefan Woltran","16160|IJCAI|2005|Equivalence in Abductive Logic|We consider the problem of identifying equivalence of two knowledge bases which are capable of abductive reasoning. Here, a knowledge base is written in either first-order logic or nonmonotonic logic programming. In this work, we will give two definitions of abductive equivalence. The first one, explainable equivalence, requires that two abductive programs have the same explainability for any observation. Another one, explanatory equivalence, guarantees that any observation has exactly the same explanations in each abductive framework. Explanatory equivalence is a stronger notion than explainable equivalence. In first-order abduction, explainable equivalence can be verified by the notion of extensional equivalence in default theories. In nonmonotonic logic programs, explanatory equivalence can be checked by means of the notion of relative strong equivalence. We also show the complexity results for abductive equivalence.|Katsumi Inoue,Chiaki Sakama","16108|IJCAI|2005|Strong Equivalence for Logic Programs with Preferences|Recently, strong equivalence for Answer Set Programming has been studied intensively, and was shown to be beneficial for modular programming and automated optimization. In this paper we define the novel notion of strong equivalence for logic programs with preferences. Based on this definition we give, for several semantics for preference handling, necessary and sufficient conditions for programs to be strongly equivalent. These results provide a clear picture of the relationship of these semantics with respect to strong equivalence, which differs considerably from their relationship with respect to answer sets. Finally, based on these results, we present for the first time simplification methods for logic programs with preferences.|Wolfgang Faber,Kathrin Konczak","16294|IJCAI|2005|First-Order Logical Filtering|Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond immediate intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulae. We sidestep previous discouraging results, and show that our algorithms are exact in many cases of interest. These algorithms accept belief states in full FOL, which allows natural representation with explicit references to unidentified objects, and partially known relationships. Our algorithms keep the encoding compact for important classes of actions, such as STRIPS actions. These results apply to most expressive modeling languages, such as partial databases and belief revision in FOL.|Afsaneh Shirazi,Eyal Amir"],["16250|IJCAI|2005|A Scalable Method for Multiagent Constraint Optimization|We present in this paper a new, complete method for distributed constraint optimization, based on dynamic programming. It is a utility propagation method, inspired by the sum-product algorithm, which is correct only for tree-shaped constraint networks. In this paper, we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. Our algorithm requires a linear number of messages, whose maximal size depends on the induced width along the particular pseudotree chosen. We compare our algorithm with backtracking algorithms, and present experimental results. For some problem types we report orders of magnitude fewer messages, and the ability to deal with arbitrarily large problems. Our algorithm is formulated for optimization problems, but can be easily applied to satisfaction problems as well.|Adrian Petcu,Boi Faltings","16230|IJCAI|2005|Networked Distributed POMDPs A Synergy of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16223|IJCAI|2005|Reducing Checks and Revisions in Coarse-grained MAC Algorithms|Arc consistency algorithms are widely used to prune the search space of Constraint Satisfaction Problems (CSPs). Coarse-grained arc consistency algorithms like AC-, AC-d and AC- are efficient when it comes to transforming a CSP to its arc-consistent equivalent. These algorithms repeatedly carry out revisions. Revisions require support checks for identifying and deleting all unsupported values from the domain of a variable. In revisions for difficult problems most values have some support. Indeed, most revisions are ineffective, i.e. they cannot delete any value and consume a lot of checks and time. We propose two solutions to overcome these problems. First we introduce the notion of a Support Condition (SC) which guarantees that a value has some support. SCs reduce support checks while maintaining arc consistency during search. Second we introduce the notion of a Revision Condition (RC) which guarantees that all values have support. A RC avoids a candidate revision and queue maintenance overhead. For random problems, SCs reduce the checks required by MAC- (MAC-) up to % (%). RCs avoid at least % of the total revisions. Combining the two results in reducing % of the solution time.|Deepak Mehta,Marc R. C. van Dongen","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16044|IJCAI|2005|Proactive Algorithms for Scheduling with Probabilistic Durations|Proactive scheduling seeks to generate high quality solutions despite execution time uncertainty. Building on work in Beck and Wilson, , we conduct an empirical study of a number of algorithms for the job shop scheduling problem with probabilistic durations. The main contributions of this paper are the introduction and empirical analysis of a novel constraint-based search technique that can be applied beyond probabilistic scheduling problems, the introduction and empirical analysis of a number of deterministic filtering algorithms for probabilistic job shop scheduling, and the identification of a number of problem characteristics that contribute to algorithm performance.|J. Christopher Beck,Nic Wilson","16286|IJCAI|2005|Structural Symmetry Breaking|Symmetry breaking has been shown to be an important method to speed up the search in constraint satisfaction problems that contain symmetry. When breaking symmetry by dominance detection, a computationally efficient symmetry breaking scheme can be achieved if we can solve the dominance detection problem in polynomial time. We study the complexity of dominance detection when value and variable symmetry appear simultaneously in constraint satisfaction problems (CSPs) with single-valued variables and set-CSPs. We devise an efficient dominance detection algorithm for CSPs with single-valued variables that yields symmetry-free search trees and that is based on the abstraction to the actual, intuitive structure of a symmetric CSP.|Meinolf Sellmann,Pascal Van Hentenryck","16118|IJCAI|2005|Abstraction-based Action Ordering in Planning|Many planning problems contain collections of symmetric objects, actions and structures which render them difficult to solve efficiently. It has been shown that the detection and exploitation of symmetric structure in planning problems can dramatically reduce the size of the search space and the time taken to find a solution. We present the idea of using an abstraction of the problem domain to reveal symmetric structure and guide the navigation of the search space. We show that this is effective even in domains in which there is little accessible symmetric structure available for pruning. Proactive exploitation represents a flexible and powerful alternative to the symmetry-breaking strategies exploited in earlier work in planning and CSPs. The notion of almost symmetry is defined and results are presented showing that proactive exploitation of almost symmetry can improve the performance of a heuristic forward search planner.|Maria Fox,Derek Long,Julie Porteous","16199|IJCAI|2005|A Greedy Approach to Establish Singleton Arc Consistency|In this paper, we propose a new approach to establish Singleton Arc Consistency (SAC) on constraint networks. While the principle of existing SAC algorithms involves performing a breadth-first search up to a depth equal to , the principle of the two algorithms introduced in this paper involves performing several runs of a greedy search (where at each step, arc consistency is maintained). It is then an original illustration of applying inference (i.e. establishing singleton arc consistency) by search. Using a greedy search allows benefiting from the incrementality of arc consistency, learning relevant information from conflicts and, potentially finding solution(s) during the inference process. Further-more, both space and time complexities are quite competitive.|Christophe Lecoutre,St√©phane Cardon"],["16169|IJCAI|2005|Learning with Labeled Sessions|Traditional supervised learning deals with labeled instances. In many applications such as physiological data modeling and speaker identification, however, training examples are often labeled objects and each of the labeled objects consists of multiple unlabeled instances. When classifying a new object, its class is determined by the majority of its instance classes. As a consequence of this decision rule, one challenge to learning with labeled objects (or sessions) is to determine during training which subset of the instances inside an object should belong to the class of the object. We call this type of learning 'session-based learning' to distinguish it from the traditional supervised learning. In this paper, we introduce session-based learning problems, give a formal description of session-based learning in the context of related work, and propose an approach that is particularly designed for session-based learning. Empirical studies with UCI datasets and real-world data show that the proposed approach is effective for session-based learning.|Rong Jin,Huan Liu","16122|IJCAI|2005|Feature Generation for Text Categorization Using World Knowledge|We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.|Evgeniy Gabrilovich,Shaul Markovitch","16301|IJCAI|2005|SVM-based Obstacles Recognition for Road Vehicle Applications|This paper describes an obstacle Recognition System based on SVM and vision. The basic components of the detected objects are first located in the image and then combined with a SVM-based classifier. A distributed learning approach is proposed in order to better deal with objects variability, illumination conditions, partial occlusions and rotations. A large database containing thousands of object examples extracted from real road images has been created for learning purposes. We present and discuss the results achieved up to date.|Miguel √?ngel Sotelo,Jes√∫s Nuevo,David Fern√°ndez,I. Parra,Luis Miguel Bergasa,Manuel Oca√±a,Ram√≥n Flores","16136|IJCAI|2005|Learning Strategies for Open-Domain Natural Language Question Answering|We present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources, questions, and answers. Our approach formulates QA as a problem of first order inference over a suitably expressive, learned representation. This framework draws on prior work in learning action and problem-solving strategies, as well as relational learning methods. We describe the design of a system implementing this model in the framework of natural language question answering for story comprehension. Finally, we compare our approach to three prior systems, and present experimental results demonstrating the efficacy of our model.|Eugene Grois,David C. Wilkins","16057|IJCAI|2005|TimeML-Compliant Text Analysis for Temporal Reasoning|Reasoning with time needs more than just a list of temporal expressions. TimeML--an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text--is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. Hard as TimeML-compliant analysis is, the small size of the only currently available annotated corpus makes it even harder. We address this problem with a hybrid TimeML annotator, which uses cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component capable of effectively using large amounts of unannotated data.|Branimir Boguraev,Rie Kubota Ando","16233|IJCAI|2005|A Machine Learning Approach to Identification and Resolution of One-Anaphora|We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.|Hwee Tou Ng,Yu Zhou,Robert Dale,Mary Gardiner","16170|IJCAI|2005|A Novel Approach to Model Generation for Heterogeneous Data Classification|Ensemble methods such as bagging and boosting have been successfully applied to classification problems. Two important issues associated with an ensemble approach are how to generate models to construct an ensemble, and how to combine them for classification. In this paper, we focus on the problem of model generation for heterogeneous data classification. If we could partition heterogeneous data into a number of homogeneous partitions, we will likely generate reliable and accurate classification models over the homogeneous partitions. We examine different ways of forming homogeneous subsets and propose a novel method that allows a data point to be assigned multiple times in order to generate homogeneous partitions for ensemble learning. We present the details of the new algorithm and empirical studies over the UCI benchmark datasets and datasets of image classification, and show that the proposed approach is effective for heterogeneous data classification.|Rong Jin,Huan Liu","16081|IJCAI|2005|Unsupervised Learning of Semantic Relations between Concepts of a Molecular Biology Ontology|In this paper we present an unsupervised model for learning arbitrary relations between concepts of a molecular biology ontology for the purpose of supporting text mining and manual ontology building. Relations between named-entities are learned from the GENIA corpus by means of several standard natural language processing techniques. An in-depth analysis of the output of the system shows that the model is accurate and has good potentials for text mining and ontology building applications.|Massimiliano Ciaramita,Aldo Gangemi,Esther Ratsch,Jasmin Saric,Isabel Rojas","16308|IJCAI|2005|Clinical-Reasoning Skill Acquisition through Intelligent Group Tutoring|This paper describes COMET, a collaborative intelligent tutoring system for medical problembased learning. COMET uses Bayesian networks to model individual student knowledge and activity, as well as that of the group. Generic domainindependent tutoring algorithms use the models to generate tutoring hints. We present an overview of the system and then the results of two evaluation studies. The validity of the modeling approach is evaluated in the areas of head injury, stroke and heart attack. Receiver operating characteristic (ROC) curve analysis indicates that, the models are accurate in predicting individual student actions. Comparison of learning outcomes shows that student clinical reasoning gains from our system are significantly higher than those obtained from human tutored sessions (Mann-Whitney, p  .).|Siriwan Suebnukarn,Peter Haddawy","16240|IJCAI|2005|Inverse Resolution as Belief Change|Belief change is concerned with modelling the way in which a rational reasoner maintains its beliefs as it acquires new information. Of particular interest is the way in which new beliefs are acquired and determined and old beliefs are retained or discarded. A parallel can be drawn to symbolic machine learning approaches where examples to be categorised are presented to the learning system and a theory is subsequently derived, usually over a number of iterations. It is therefore not surprising that the term 'theory revision' is used to describe this process Ourston and Mooney, . Viewing a machine learning system as a rational reasoner allows us to begin seeing these seemingly disparate mechanisms in a similar light. In this paper we are concerned with characterising the well known inverse resolution operations Muggleton,   (and more recently, inverse entailment Muggleton, ) as AGM-style belief change operations. In particular, our account is based on the abductive expansion operation Pagnucco et al.,  Pagnucco,  and characterised by using the notion of epistemic entrenchment Grdenfors and Makinson,  extended for this operation. This work provides a basis for reconciling work in symbolic machine learning and belief revision. Moreover, it allows machine learning techniques to be understood as forms of nonmonotonic reasoning.|Maurice Pagnucco,David Rajaratnam"],["16171|IJCAI|2005|Iterated Belief Revision Revised|The AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide generally accepted criteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulates alone, however, are too permissive They support operators by which all newly acquired information is canceled as soon as an agent learns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the DP postulates, and we show how to solve the problem by an additional postulate of independence. We give a representation theorem for this postulate and prove that it is compatible with AGM and DP.|Yi Jin,Michael Thielscher","16098|IJCAI|2005|Stationary Deterministic Policies for Constrained MDPs with Multiple Rewards Costs and Discount Factors|We consider the problem of policy optimization for a resource-limited agent with multiple time-dependent objectives, represented as an MDP with multiple discount factors in the objective function and constraints. We show that limiting search to stationary deterministic policies, coupled with a novel problem reduction to mixed integer programming, yields an algorithm for finding such policies that is computationally feasible, where no such algorithm has heretofore been identified. In the simpler case where the constrained MDP has a single discount factor, our technique provides a new way for finding an optimal deterministic policy, where previous methods could only find randomized policies. We analyze the properties of our approach and describe implementation results.|Dmitri A. Dolgov,Edmund H. Durfee","16059|IJCAI|2005|Reconstructing an Agents Epistemic State from Observations|We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a \"reverse engineering\" approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that \"best explains\" the observation. Further considerations on this best-explaining model then allow inferences about the agent's epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.|Richard Booth,Alexander Nittka","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16061|IJCAI|2005|Efficiency and envy-freeness in fair division of indivisible goods logical representation and complexity|We consider the problem of allocating fairly a set of indivisible goods among agents from the point of view of compact representation and computational complexity. We start by assuming that agents have dichotomous preferences expressed by propositional formulae. We express efficiency and envy-freeness in a logical setting, which reveals unexpected connections to nonmonotonic reasoning. Then we identify the complexity of determining whether there exists an efficient and envy-free allocation, for several notions of efficiency, when preferences are represented in a succinct way (as well as restrictions of this problem). We first study the problem under the assumption that preferences are dichotomous, and then in the general case.|Sylvain Bouveret,J√©r√¥me Lang","16039|IJCAI|2005|Achieving Allocatively-Efficient and Strongly Budget-Balanced Mechanisms in the Network Flow Domain for Bounded-Rational Agents|Vickrey-Clarke-Groves (VCG) mechanisms are a framework for finding a solution to a distributed optimization problem in systems of self-interested agents. VCG mechanisms have received wide attention in the AI community because they are efficient and strategy-proof a special case of the Groves family of mechanisms, VCG mechanisms are the only direct-revelation mechanisms that are allocatively efficient and strategy-proof. Unfortunately, they are only weakly budget-balanced. We consider self-interested agents in a network flow domain, and show that in this domain, it is possible to design a mechanism that is both allocatively-efficient and almost completely budget-balanced. This is done by choosing a mechanism that is not strategy-proof but rather strategy-resistant. Instead of using the VCG mechanism, we propose a mechanism in which finding a beneficial manipulation is an NP-complete problem, and the payments from the agents to the mechanism may be minimized as much as desired.|Yoram Bachrach,Jeffrey S. Rosenschein","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas St√ºtzle","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White","16090|IJCAI|2005|Two-Sided Bandits and the Dating Market|We study the decision problems facing agents in repeated matching environments with learning, or two-sided bandit problems, and examine the dating market, in which men and women repeatedly go out on dates and learn about each other, as an example. We consider three natural matching mechanisms and empirically examine properties of these mechanisms, focusing on the asymptotic stability of the resulting matchings when the agents use a simple learning rule coupled with an -greedy exploration policy. Matchings tend to be more stable when agents are patient in two different ways -- if they are more likely to explore early or if they are more optimistic. However, the two forms of patience do not interact well in terms of increasing the probability of stable outcomes. We also define a notion of regret for the two-sided problem and study the distribution of regrets under the different matching mechanisms.|Sanmay Das,Emir Kamenica"],["16169|IJCAI|2005|Learning with Labeled Sessions|Traditional supervised learning deals with labeled instances. In many applications such as physiological data modeling and speaker identification, however, training examples are often labeled objects and each of the labeled objects consists of multiple unlabeled instances. When classifying a new object, its class is determined by the majority of its instance classes. As a consequence of this decision rule, one challenge to learning with labeled objects (or sessions) is to determine during training which subset of the instances inside an object should belong to the class of the object. We call this type of learning 'session-based learning' to distinguish it from the traditional supervised learning. In this paper, we introduce session-based learning problems, give a formal description of session-based learning in the context of related work, and propose an approach that is particularly designed for session-based learning. Empirical studies with UCI datasets and real-world data show that the proposed approach is effective for session-based learning.|Rong Jin,Huan Liu","16301|IJCAI|2005|SVM-based Obstacles Recognition for Road Vehicle Applications|This paper describes an obstacle Recognition System based on SVM and vision. The basic components of the detected objects are first located in the image and then combined with a SVM-based classifier. A distributed learning approach is proposed in order to better deal with objects variability, illumination conditions, partial occlusions and rotations. A large database containing thousands of object examples extracted from real road images has been created for learning purposes. We present and discuss the results achieved up to date.|Miguel √?ngel Sotelo,Jes√∫s Nuevo,David Fern√°ndez,I. Parra,Luis Miguel Bergasa,Manuel Oca√±a,Ram√≥n Flores","16234|IJCAI|2005|Robust Ontology Acquisition from Machine-Readable Dictionaries|In this paper, we outline the development of a system that automatically constructs ontologies by extracting knowledge from dictionary definition sentences using Robust Minimal Recursion Semantics (RMRS), a semantic formalism that permits underspecification. We show that by combining deep and shallow parsing resources through the common formalism of RMRS, we can extract ontological relations in greater quality and quantity. Our approach also has the advantages of requiring a very small amount of rules and being easily adaptable to any language with RMRS resources.|Eric Nichols,Francis Bond,Dan Flickinger","16154|IJCAI|2005|Iterated Belief Change A Transition System Approach|We use a transition system approach to reason about the evolution of an agent's beliefs as actions are executed. Some actions cause an agent to perform belief revision and some actions cause an agent to perform belief update, but the interaction between revision and update can be non-elementary. We present a set of basic postulates describing the interaction of revision and update, and we introduce a new belief evolution operator that gives a plausible interpretation to alternating sequences of revisions and updates.|Aaron Hunter,James P. Delgrande","16225|IJCAI|2005|BLOG Probabilistic Models with Unknown Objects|This paper introduces and illustrates BLOG, a formal language for defining probability models over worlds with unknown objects and identity uncertainty. BLOG unifies and extends several existing approaches. Subject to certain acyclicity constraints, every BLOG model specifies a unique probability distribution over first-order model structures that can contain varying and unbounded numbers of objects. Furthermore, complete inference algorithms exist for a large fragment of the language. We also introduce a probabilistic form of Skolemization for handling evidence.|Brian Milch,Bhaskara Marthi,Stuart J. Russell,David Sontag,Daniel L. Ong,Andrey Kolobov","16318|IJCAI|2005|Measuring Semantic Similarity by Latent Relational Analysis|This paper introduces Latent Relational Analysis (LRA), a method for measuring semantic similarity. LRA measures similarity in the semantic relations between two pairs of words. When two pairs have a high degree of relational similarity, they are analogous. For example, the pair catmeow is analogous to the pair dogbark. There is evidence from cognitive science that relational similarity is fundamental to many cognitive and linguistic tasks (e.g., analogical reasoning). In the Vector Space Model (VSM) approach to measuring relational similarity, the similarity between two pairs is calculated by the cosine of the angle between the vectors that represent the two pairs. The elements in the vectors are based on the frequencies of manually constructed patterns in a large corpus. LRA extends the VSM approach in three ways () patterns are derived automatically from the corpus, () Singular Value Decomposition is used to smooth the frequency data, and () synonyms are used to reformulate word pairs. This paper describes the LRA algorithm and experimentally compares LRA to VSM on two tasks, answering college-level multiple-choice word analogy questions and classifying semantic relations in noun-modifier expressions. LRA achieves state-of-the-art results, reaching human-level performance on the analogy questions and significantly exceeding VSM performance on both tasks.|Peter D. Turney","16168|IJCAI|2005|Semantic Argument Classification Exploiting Argument Interdependence|This paper describes our research on automatic semantic argument classification, using the PropBank data Kingsbury et al., . Previous research employed features that were based either on a full parse or shallow parse of a sentence. These features were mostly based on an individual semantic argument and the relation between the predicate and a semantic argument, but they did not capture the interdependence among all arguments of a predicate. In this paper, we propose the use of the neighboring semantic arguments of a predicate as additional features in determining the class of the current semantic argument. Our experimental results show significant improvement in the accuracy of semantic argument classification after exploiting argument interdependence. Argument classification accuracy on the standard Section  test set improves to .%, representing a relative error reduction of %.|Zheng Ping Jiang,Jia Li,Hwee Tou Ng","16330|IJCAI|2005|Decision Diagrams for the Computation of Semiring Valuations|This paper describes a new approach to computation in a semiring-based system, which includes semiring-based CSPs (in particular weighted CSPs, fuzzy CSPs and standard CSPs) as well as Bayesian networks. The approach to computation is based on what we call semiring-labelled decision diagrams (SLDDs). These can be generated in a similar way to a standard search tree (decision tree) for solving a CSP, but some nodes are merged, creating a more compact representation for certain classes of CSPs, the number of nodes in the resulting network will be a tiny fraction of the number of nodes in the corresponding search tree. A method is given for generating an SLDD that represents e.g., a particular instance of a semiring-based CSP it is shown how this can be used to perform various computations of interest, such as solving a semiring-based CSP, finding optimal solutions, determining the possible values of each variable and counting solutions of a CSP.|Nic Wilson","16210|IJCAI|2005|Relational Object Maps for Mobile Robots|Mobile robot map building is the task of generating a model of an environment from sensor data. Most existing approaches to mobile robot mapping either build topological representations or generate accurate, metric maps of an environment. In this paper we introduce relational object maps, a novel approach to building metric maps that represent individual objects such as doors or walls. We show how to extend relational Markov networks in order to reason about a hierarchy of objects and the spatial relationships between them. Markov chain Monte Carlo is used for efficient inference and to learn the parameters of the model. We show that the spatial constraints modeled by our mapping technique yield drastic improvements for labeling line segments extracted from laser range-finders.|Benson Limketkai,Lin Liao,Dieter Fox","16308|IJCAI|2005|Clinical-Reasoning Skill Acquisition through Intelligent Group Tutoring|This paper describes COMET, a collaborative intelligent tutoring system for medical problembased learning. COMET uses Bayesian networks to model individual student knowledge and activity, as well as that of the group. Generic domainindependent tutoring algorithms use the models to generate tutoring hints. We present an overview of the system and then the results of two evaluation studies. The validity of the modeling approach is evaluated in the areas of head injury, stroke and heart attack. Receiver operating characteristic (ROC) curve analysis indicates that, the models are accurate in predicting individual student actions. Comparison of learning outcomes shows that student clinical reasoning gains from our system are significantly higher than those obtained from human tutored sessions (Mann-Whitney, p  .).|Siriwan Suebnukarn,Peter Haddawy"],["16313|IJCAI|2005|Temporal-Difference Networks with History|Temporal-difference (TD) networks are a formalism for expressing and learning grounded world knowledge in a predictive form Sutton and Tanner, . However, not all partially observable Markov decision processes can be efficiently learned with TD networks. In this paper, we extend TD networks by allowing the network-update process (answer network) to depend on the recent history of previous actions and observations rather than only on the most recent action and observation. We show that this extension enables the solution of a larger class of problems than can be solved by the original TD networks or by history-based methods alone. In addition, we apply TD networks to a problem that, while still simple, is significantly larger than has previously been considered. We show that history-extended TD networks can learn much of the common-sense knowledge of an egocentric gridworld domain with a single bit of perception.|Brian Tanner,Richard S. Sutton","16147|IJCAI|2005|Solving POMDPs with Continuous or Large Discrete Observation Spaces|We describe methods to solve partially observable Markov decision processes (POMDPs) with continuous or large discrete observation spaces. Realistic problems often have rich observation spaces, posing significant problems for standard POMDP algorithms that require explicit enumeration of the observations. This problem is usually approached by imposing an a priori discretisation on the observation space, which can be sub-optimal for the decision making task. However, since only those observations that would change the policy need to be distinguished, the decision problem itself induces a lossless partitioning of the observation space. This paper demonstrates how to find this partition while computing a policy, and how the resulting discretisation of the observation space reveals the relevant features of the application domain. The algorithms are demonstrated on a toy example and on a realistic assisted living task.|Jesse Hoey,Pascal Poupart","16233|IJCAI|2005|A Machine Learning Approach to Identification and Resolution of One-Anaphora|We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.|Hwee Tou Ng,Yu Zhou,Robert Dale,Mary Gardiner","16116|IJCAI|2005|Minimizing a Makespan Under Uncertainty|This paper reconsiders the most basic scheduling problem, that of minimizing the makespan of a partially ordered set of activities, in the context of incomplete knowledge. After positioning this paper in the scope of temporal networks under uncertainty, we provide a complete solution to the problem of finding floats of activities, and of locating surely critical ones, as they are often isolated. The minimal float problem is NP-hard while the maximal float problem is polynomial. New complexity results and efficient algorithms are provided for the interval-valued makespan minimization problem.|J√©r√¥me Fortin,Pawel Zielinski,Didier Dubois,H√©l√®ne Fargier","16034|IJCAI|2005|Learning Partially Observable Deterministic Action Models|We present the first tractable, exact solution for the problem of identifying actions' effects in partially observable STRIPS domains. Our algorithms resemble Version Spaces and Logical Filtering, and they identify all the models that are consistent with observations. They apply in other deterministic domains (e.g., with conditional effects), but are inexact (may return false positives) or inefficient (we could not bound the representation size). Our experiments verify the theoretical guarantees, and show that we learn STRIPS actions efficiently, with time that is significantly better than approaches for HMMs and Reinforcement Learning (which are inexact). Our results are especially surprising because of the inherent intractability of the general deterministic case. These results have been applied to an autonomous agent in a virtual world, facilitating decision making, diagnosis, and exploration.|Eyal Amir","16267|IJCAI|2005|Conditional Planning in the Discrete Belief Space|Probabilistic planning with observability restrictions, as formalized for example as partially observable Markov decision processes (POMDP), has a wide range of applications, but it is computationally extremely difficult. For POMDPs, the most general decision problems about existence of policies satisfying certain properties are undecidable. We consider a computationally easier form of planning that ignores exact probabilities, and give an algorithm for a class of planning problems with partial observability. We show that the basic backup step in the algorithm is NP-complete. Then we proceed to give an algorithm for the backup step, and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.|Jussi Rintanen","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","16155|IJCAI|2005|A Tableaux Decision Procedure for SHOIQ|This paper presents a tableaux decision procedure for SHOIQ, the DL underlying OWL DL. To the best of our knowledge, this is the first goal-directed decision procedure for SHOIQ.|Ian Horrocks,Ulrike Sattler","16056|IJCAI|2005|A Decision-Theoretic Approach to Task Assistance for Persons with Dementia|Cognitive assistive technologies that aid people with dementia (such as Alzheimer's disease) hold the promise to provide such people with an increased level of independence. However, to realize this promise, such systems must account for the specific needs and preferences of individuals. We argue that this form of customization requires a sequential, decision-theoretic model of interaction. We describe both fully and partially observable Markov decision process (POMDP) models of a handwashing task, and show that, despite the potential computational complexity, these can be effectively solved and produce policies that are evaluated as useful by professional caregivers.|Jennifer Boger,Pascal Poupart,Jesse Hoey,Craig Boutilier,Geoff Fernie,Alex Mihailidis","16186|IJCAI|2005|Optimal Nonmyopic Value of Information in Graphical Models - Efficient Algorithms and Theoretical Limits|Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of graphical models containing Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan. For both problems, we present algorithms for the filtering case, where only observations made in the past are taken into account, and the smoothing case, where all observations are utilized. Furthermore we prove a surprising result In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytrees. We prove that the value of information problem is NPPP-hard even for discrete polytrees. It also follows from our results that even computing conditional entropies, which are widely used to measure value of information, is a P-complete problem on polytrees. Finally, we demonstrate the effectiveness of our approach on several real-world datasets.|Andreas Krause,Carlos Guestrin"],["16272|IJCAI|2005|Bounded Search and Symbolic Inference for Constraint Optimization|Constraint optimization underlies many problems in AI. We present a novel algorithm for finite domain constraint optimization that generalizes branch-and-bound search by reasoning about sets of assignments rather than individual assignments. Because in many practical cases, sets of assignments can be represented implicitly and compactly using symbolic techniques such as decision diagrams, the set-based algorithm can compute bounds faster than explicitly searching over individual assignments, while memory explosion can be avoided by limiting the size of the sets. Varying the size of the sets yields a family of algorithms that includes known search and inference algorithms as special cases. Furthermore, experiments on random problems indicate that the approach can lead to significant performance improvements.|Martin Sachenbacher,Brian C. Williams","16052|IJCAI|2005|Optimal and Suboptimal Singleton Arc Consistency Algorithms|Singleton arc consistency (SAC) enhances the pruning capability of arc consistency by ensuring that the network cannot become arc inconsistent after the assignment of a value to a variable. Algorithms have already been proposed to enforce SAC, but they are far from optimal time complexity. We give a lower bound to the time complexity of enforcing SAC, and we propose an algorithm that achieves this complexity, thus being optimal. However, it can be costly in space on large problems. We then propose another SAC algorithm that trades time optimality for a better space complexity. Nevertheless, this last algorithm has a better worst-case time complexity than previously published SAC algorithms. An experimental study shows the good performance of the new algorithms.|Christian Bessi√®re,Romuald Debruyne","16053|IJCAI|2005|The Range and Roots Constraints Specifying Counting and Occurrence Problems|We propose a simple declarative language for specifying a wide range of counting and occurrence constraints. This specification language is executable since it immediately provides a polynomial propagation algorithm. To illustrate the capabilities of this language, we specify a dozen global constraints taken from the literature. We observe one of three outcomes we achieve generalized arc-consistency we do not achieve generalized arc-consistency, but achieving generalized arc-consistency is NP-hard we do not achieve generalized arc-consistency, but specialized propagation algorithms can do so in polynomial time. Experiments demonstrate that this specification language is both efficient and effective in practice.|Christian Bessi√®re,Emmanuel Hebrard,Brahim Hnich,Zeynep Kiziltan,Toby Walsh","16189|IJCAI|2005|Correspondence-guided Synchronous Parsing of Parallel Corpora|We present an efficient dynamic programming algorithm for synchronous parsing of sentence pairs from a parallel corpus with a given word alignment. Unless there is a large proportion of words without a correspondence in the other language, the worstcase complexity is significantly reduced over standard synchronous parsing. The theoretical complexity results are corroborated by a quantitative experimental evaluation.|Jonas Kuhn","16038|IJCAI|2005|Propagating Logical Combinations of Constraints|Many constraint toolkits provide logical connectives like disjunction, negation and implication. These permit complex constraint expressions to be built from primitive constraints. However, the propagation of such complex constraint expressions is typically limited. We therefore present a simple and light weight method for propagating complex constraint expressions. We provide a precise characterization of when this method enforces generalized arc-consistency. In addition, we demonstrate that with our method many different global constraints can be easily implemented.|Fahiem Bacchus,Toby Walsh","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","16223|IJCAI|2005|Reducing Checks and Revisions in Coarse-grained MAC Algorithms|Arc consistency algorithms are widely used to prune the search space of Constraint Satisfaction Problems (CSPs). Coarse-grained arc consistency algorithms like AC-, AC-d and AC- are efficient when it comes to transforming a CSP to its arc-consistent equivalent. These algorithms repeatedly carry out revisions. Revisions require support checks for identifying and deleting all unsupported values from the domain of a variable. In revisions for difficult problems most values have some support. Indeed, most revisions are ineffective, i.e. they cannot delete any value and consume a lot of checks and time. We propose two solutions to overcome these problems. First we introduce the notion of a Support Condition (SC) which guarantees that a value has some support. SCs reduce support checks while maintaining arc consistency during search. Second we introduce the notion of a Revision Condition (RC) which guarantees that all values have support. A RC avoids a candidate revision and queue maintenance overhead. For random problems, SCs reduce the checks required by MAC- (MAC-) up to % (%). RCs avoid at least % of the total revisions. Combining the two results in reducing % of the solution time.|Deepak Mehta,Marc R. C. van Dongen","16339|IJCAI|2005|Automation Intelligence for the Smart Environment|Scaling AI algorithms to large problems requires that these algorithms work together to harness their respective strengths. We introduce a method of automatically constructing HHMMs using the output of a sequential data-mining algorithm and sequential prediction algorithm. We present the theory of this technique and demonstrate results using the MavHome intelligent environment.|G. Michael Youngblood,Edwin O. Heierman III,Lawrence B. Holder,Diane J. Cook","16199|IJCAI|2005|A Greedy Approach to Establish Singleton Arc Consistency|In this paper, we propose a new approach to establish Singleton Arc Consistency (SAC) on constraint networks. While the principle of existing SAC algorithms involves performing a breadth-first search up to a depth equal to , the principle of the two algorithms introduced in this paper involves performing several runs of a greedy search (where at each step, arc consistency is maintained). It is then an original illustration of applying inference (i.e. establishing singleton arc consistency) by search. Using a greedy search allows benefiting from the incrementality of arc consistency, learning relevant information from conflicts and, potentially finding solution(s) during the inference process. Further-more, both space and time complexities are quite competitive.|Christophe Lecoutre,St√©phane Cardon","16036|IJCAI|2005|Fast and Complete Symbolic Plan Recognition|Recent applications of plan recognition face several open challenges (i) matching observations to the plan library is costly, especially with complex multi-featured observations (ii) computing recognition hypotheses is expensive. We present techniques for addressing these challenges. First, we show a novel application of machine-learning decision-tree to efficiently map multi-featured observations to matching plan steps. Second, we provide efficient lazy-commitment recognition algorithms that avoid enumerating hypotheses with every observation, instead only carrying out bookkeeping incrementally. The algorithms answer queries as to the current state of the agent, as well as its history of selected states. We provide empirical results demonstrating their efficiency and capabilities.|Dorit Avrahami-Zilberbrand,Gal A. Kaminka"],["16064|IJCAI|2005|Mixed-Initiative Activity Planning for Mars Rovers|One of the ground tools used to operate the Mars Exploration Rovers is a mixed-initiative planning system called MAPGEN. The role of the system is to assist operators building daily plans for each of the rovers, maximizing science return, while maintaining rover safety and abiding by science and engineering constraints. In this paper, we describe the MAPGEN system, focusing on the mixed-initiative planning aspect. We note important challenges, both in terms of human interaction and in terms of automated reasoning requirements. We then describe the approaches taken in MAPGEN, focusing on the novel methods developed by our team.|John L. Bresina,Ari K. J√≥nsson,Paul H. Morris,Kanna Rajan","16247|IJCAI|2005|Phase Transitions within Grammatical Inference|It is now well-known that the feasibility of inductive learning is ruled by statistical properties linking the empirical risk minimization principle and the \"capacity\" of the hypothesis space. The discovery, a few years ago, of a phase transition phenomenon in inductive logic programming proves that other fundamental characteristics of the learning problems may similarly affect the very possibility of learning under very general conditions. Our work examines the case of grammatical inference. We show that while there is no phase transition when considering the whole hypothesis space, there is a much more severe \"gap\" phenomenon affecting the effective search space of standard grammatical induction algorithms for deterministic finite automata (DFA). Focusing on the search heuristics of the RPNI and RED-BLUE algorithms, we show that they overcome this problem to some extent, but that they are subject to overgeneralization. The paper last suggests some directions for new generalization operators, suited to this Phase Transition phenomenon.|Nicolas Pernot,Antoine Cornu√©jols,Mich√®le Sebag","16328|IJCAI|2005|Learning Subjective Representations for Planning|Planning involves using a model of an agent's actions to find a sequence of decisions which achieve a desired goal. It is usually assumed that the models are given, and such models often require expert knowledge of the domain. This paper explores subjective representations for planning that are learned directly from agent observations and actions (requiring no initial domain knowledge). A non-linear embedding technique called Action Respecting Embedding is used to construct such a representation. It is then shown how to extract the effects of the agent's actions as operators in this learned representation. Finally, the learned representation and operators are combined with search to find sequences of actions that achieve given goals. The efficacy of this technique is demonstrated in a challenging robot-vision-inspired image domain.|Dana F. Wilkinson,Michael H. Bowling,Ali Ghodsi","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","16109|IJCAI|2005|Heuristics for Hard ASP Programs|We define a new heuristic hDS for ASP, and implement it in the (disjunctive) ASP system DLV. The new heuristic improves the evaluation of PP - hard ASP programs while maintaining the benign behaviour of the well-assessed heuristic of DLV on NP problems. We experiment with the new heuristic on QBFs. hDS significantly outperforms the heuristic of DLV on hard QBF problems. We compare also the DLV system (with the new heuristic hDS) to three prominent QBF solvers. The results of the comparison, performed on instances used in the last QBF competition, indicate that ASP systems can be faster than QBF systems on PP-hard problems.|Wolfgang Faber,Nicola Leone,Francesco Ricca","16319|IJCAI|2005|Theory of Alignment Generators and Applications to Statistical Machine Translation|Viterbi Alignment and Decoding are two fundamental search problems in Statistical Machine Translation. Both the problems are known to be NP-hard and therefore, it is unlikely that there exists an optimal polynomial time algorithm for either of these search problems. In this paper we characterize exponentially large subspaces in the solution space of Viterbi Alignment and Decoding. Each of these subspaces admits polynomial time optimal search algorithms. We propose a local search heuristic using a neighbourhood relation on these subspaces. Experimental results show that our algorithms produce better solutions taking substantially less time than the previously known algorithms for these problems.|Raghavendra Udupa,Hemanta Kumar Maji","16145|IJCAI|2005|LRTAk|LRTA* is a real-time heuristic search algorithm widely used. In each iteration it updates the heuristic estimate of the current state. Here we present LRTA*(k), a new LRTA*-based algorithm that is able to update the heuristic estimates of up to k states, not necessarily distinct. Based on bounded propagation, this updating strategy maintains heuristic admissibility, so the new algorithm keeps the good theoretical properties of LRTA*. Experimentally, we show that LRTA*(k) produces better solutions in the first trial and converges faster when compared with other state-of-the-art algorithms on benchmarks for real-time search.|Carlos Hern√°ndez,Pedro Meseguer","16273|IJCAI|2005|Hypertree-decomposition via Branch-decomposition|Hypertree-decomposition is the most general approach in the literature for identifying tractable computation problems encoded as hypergraphs. We show how the heuristic branch-decomposition approach for ordinary graphs of Cook and Seymour,  can be used for the heuristic construction of hypertree-decompositions.|Marko Samer","16186|IJCAI|2005|Optimal Nonmyopic Value of Information in Graphical Models - Efficient Algorithms and Theoretical Limits|Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of graphical models containing Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan. For both problems, we present algorithms for the filtering case, where only observations made in the past are taken into account, and the smoothing case, where all observations are utilized. Furthermore we prove a surprising result In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytrees. We prove that the value of information problem is NPPP-hard even for discrete polytrees. It also follows from our results that even computing conditional entropies, which are widely used to measure value of information, is a P-complete problem on polytrees. Finally, we demonstrate the effectiveness of our approach on several real-world datasets.|Andreas Krause,Carlos Guestrin"],["16169|IJCAI|2005|Learning with Labeled Sessions|Traditional supervised learning deals with labeled instances. In many applications such as physiological data modeling and speaker identification, however, training examples are often labeled objects and each of the labeled objects consists of multiple unlabeled instances. When classifying a new object, its class is determined by the majority of its instance classes. As a consequence of this decision rule, one challenge to learning with labeled objects (or sessions) is to determine during training which subset of the instances inside an object should belong to the class of the object. We call this type of learning 'session-based learning' to distinguish it from the traditional supervised learning. In this paper, we introduce session-based learning problems, give a formal description of session-based learning in the context of related work, and propose an approach that is particularly designed for session-based learning. Empirical studies with UCI datasets and real-world data show that the proposed approach is effective for session-based learning.|Rong Jin,Huan Liu","16253|IJCAI|2005|ROCCER An Algorithm for Rule Learning Based on ROC Analysis|We introduce a rule selection algorithm called ROCCER, which operates by selecting classification rules from a larger set of rules - for instance found by Apriori - using ROC analysis. Experimental comparison with rule induction algorithms shows that ROCCER tends to produce considerably smaller rule sets with compatible Area Under the ROC Curve (AUC) values. The individual rules that compose the rule set also have higher support and stronger association indexes.|Ronaldo C. Prati,Peter A. Flach","16086|IJCAI|2005|Feature Selection Based on the Shapley Value|We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.|Shay Cohen,Eytan Ruppin,Gideon Dror","16082|IJCAI|2005|Stacked Sequential Learning|We describe a new sequential learning scheme called \"stacked sequential learning\". Stacked sequential learning is a meta-learning algorithm, in which an arbitrary base learner is augmented so as to make it aware of the labels of nearby examples. We evaluate the method on several \"sequential partitioning problems\", which are characterized by long runs of identical labels. We demonstrate that on these problems, sequential stacking consistently improves the performance of nonsequential base learners that sequential stacking often improves performance of learners (such as CRFs) that are designed specifically for sequential tasks and that a sequentially stacked maximum-entropy learner generally outperforms CRFs.|William W. Cohen,Vitor Rocha de Carvalho","16303|IJCAI|2005|Beyond TFIDF Weighting for Text Categorization in the Vector Space Model|KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.|Pascal Soucy,Guy W. Mineau","16262|IJCAI|2005|InterActive Feature Selection|We study the effects of feature selection and human feedback on features in active learning settings. Our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features. Consistent with previous findings, we find that feature selection based on the labeled training set has little effect. But our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion (%) of the most relevant features. Furthermore, these experiments show that feature labeling takes much less (about th) time than document labeling. We propose an algorithm that interleaves labeling features and documents which significantly accelerates active learning.|Hema Raghavan,Omid Madani,Rosie Jones","16041|IJCAI|2005|Sequential-Simultaneous Information Elicitation in Multi-Agent Systems|We introduce a general setting for information elicitation in multi-agent systems, where agents may be approached both sequentially and simultaneously in order to compute a function that depends on their private secrets. We consider oblivious mechanisms for sequential-simultaneous information elicitation. In such mechanisms the ordering of agents to be approached is fixed in advance. Surprisingly, we show that these mechanisms, which are easy to represent and implement are sufficient for very general settings, such as for the classical uniform model, where agents' secret bits are uniformly distributed, and for the computation of the majority function and other classical threshold functions. Moreover, we provide efficient algorithms for the verification of the existence of the desired elicitation mechanisms, and for synthesizing such mechanisms.|Gal Bahar,Moshe Tennenholtz","16339|IJCAI|2005|Automation Intelligence for the Smart Environment|Scaling AI algorithms to large problems requires that these algorithms work together to harness their respective strengths. We introduce a method of automatically constructing HHMMs using the output of a sequential data-mining algorithm and sequential prediction algorithm. We present the theory of this technique and demonstrate results using the MavHome intelligent environment.|G. Michael Youngblood,Edwin O. Heierman III,Lawrence B. Holder,Diane J. Cook","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","16340|IJCAI|2005|Question Classification by Structure Induction|In this article we introduce a new approach (and several implementations) to the task of question classification. The approach extracts structural information using machine learning techniques and the patterns found are used to classify the questions. The approach fits in between the machine learning and handcrafting of regular expressions (as it was done in the past) and combines the best of both classifiers can be generated automatically and the output can be investigated and manually optimised if needed.|Menno van Zaanen,Luiz Augusto Sangoi Pizzato,Diego Moll√°"],["16301|IJCAI|2005|SVM-based Obstacles Recognition for Road Vehicle Applications|This paper describes an obstacle Recognition System based on SVM and vision. The basic components of the detected objects are first located in the image and then combined with a SVM-based classifier. A distributed learning approach is proposed in order to better deal with objects variability, illumination conditions, partial occlusions and rotations. A large database containing thousands of object examples extracted from real road images has been created for learning purposes. We present and discuss the results achieved up to date.|Miguel √?ngel Sotelo,Jes√∫s Nuevo,David Fern√°ndez,I. Parra,Luis Miguel Bergasa,Manuel Oca√±a,Ram√≥n Flores","16334|IJCAI|2005|Automatic Semantic Role Labeling for Chinese Verbs|Recent years have seen a revived interest in semantic parsing by applying statistical and machine-learning methods to semantically annotated corpora such as the FrameNet and the Proposition Bank. So far much of the research has been focused on English due to the lack of semantically annotated resources in other languages. In this paper, we report first results on semantic role labeling using a pre-release version of the Chinese Proposition Bank. Since the Chinese Proposition Bank is superimposed on top of the Chinese Tree-bank, i.e., the semantic role labels are assigned to constituents in a treebank parse tree, we start by reporting results on experiments using the handcrafted parses in the treebank. This will give us a measure of the extent to which the semantic role labels can be bootstrapped from the syntactic annotation in the treebank. We will then report experiments using a fully automatic Chinese parser that integrates word segmentation, POS-tagging and parsing. This will gauge how successful semantic role labeling can be done for Chinese in realistic situations. We show that our results using hand-crafted parses are slightly higher than the results reported for the state-of-the-art semantic role labeling systems for English using the Penn English Proposition Bank data, even though the Chinese Proposition Bank is smaller in size. When an automatic parser is used, however, the accuracy of our system is much lower than the English state-of-the-art. This reveals an interesting cross-linguistic difference between the two languages, which we attempt to explain. We also describe a method to induce verb classes from the Proposition Bank \"frame files\" that can be used to improve semantic role labeling.|Nianwen Xue,Martha Stone Palmer","16029|IJCAI|2005|Exploiting Informative Priors for Bayesian Classification and Regression Trees|A general method for defining informative priors on statistical models is presented and applied specifically to the space of classification and regression trees. A Bayesian approach to learning such models from data is taken, with the Metropolis-Hastings algorithm being used to approximately sample from the posterior. By only using proposal distributions closely tied to the prior, acceptance probabilities are easily computable via marginal likelihood ratios, whatever the prior used. Our approach is empirically tested by varying (i) the data, (ii) the prior and (iii) the proposal distribution. A comparison with related work is given.|Nicos Angelopoulos,James Cussens","16057|IJCAI|2005|TimeML-Compliant Text Analysis for Temporal Reasoning|Reasoning with time needs more than just a list of temporal expressions. TimeML--an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text--is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. Hard as TimeML-compliant analysis is, the small size of the only currently available annotated corpus makes it even harder. We address this problem with a hybrid TimeML annotator, which uses cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component capable of effectively using large amounts of unannotated data.|Branimir Boguraev,Rie Kubota Ando","16140|IJCAI|2005|Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale|A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.|Shen-Shyang Ho,Harry Wechsler","16346|IJCAI|2005|Semi-Supervised Regression with Co-Training|In many practical machine learning and data mining applications, unlabeled training examples are readily available but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. Previous research mainly focuses on semi-supervised classification. In this paper, a co-training style semi-supervised regression algorithm, i.e. COREG, is proposed. This algorithm uses two k-nearest neighbor regressors with different distance metrics, each of which labels the unlabeled data for the other regressor where the labeling confidence is estimated through consulting the influence of the labeling of unlabeled examples on the labeled ones. Experiments show that COREG can effectively exploit unlabeled data to improve regression estimates.|Zhi-Hua Zhou,Ming Li","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","16138|IJCAI|2005|fMRI Analysis via One-class Machine Learning Techniques|We show how one-class compression Neural Networks and one-class SVM can be applied to fMRI data to learn the classification of brain activity associated with a specific motor activity. For comparison purposes, we use two labeled data and see what degree of classification ability is lost compared with the usual two-class SVM.|David R. Hardoon,Larry M. Manevitz","16095|IJCAI|2005|Inferring Image Templates from Classification Decisions|Assuming human image classification decisions are based on estimating the degree of match between a small number of stored internal templates and certain regions of the input images, we present an algorithm which infers observers classification templates from their classification decisions on a set of test images. The problem is formulated as learning prototypes from labeled data under an adjustable, prototype-specific elliptical metric. The matrix of the elliptical metric indicates the pixels that the template responds to. The model was applied to human psychophysical data collected in a simple image classification experiment.|Arnab Dhua,Florin Cutzu"],["16143|IJCAI|2005|Sentence Extraction for Legal Text Summarisation|We describe a system for generating extractive summaries of texts in the legal domain, focusing on the relevance classifier, which determines which sentences are abstract-worthy. We experiment with nave Bayes and maximum entropy estimation toolkits and explore methods for selecting abstract-worthy sentences in rank order. Evaluation using standard accuracy measures and using correlation confirm the utility of our approach, but suggest different optimal configurations.|Ben Hachey,Claire Grover","16288|IJCAI|2005|A Formal Investigation of Mapping Language for Terminological Knowledge|The need to represent mappings between different ontologies has been recognized as a result of the fact that different ontologies may partially overlap, or even represent the same domain from different points of view. Unlike ontology languages, work on languages to represent ontology mappings has not yet reached a state where a common understanding of the basic principles exists. In this paper we propose a formal comparison of existing mapping languages by translating them into distributed first order logic. This allows us to analyze underlying assumptions and differences in the interpretation of ontology mappings.|Luciano Serafini,Heiner Stuckenschmidt,Holger Wache","16070|IJCAI|2005|A Multidimensional Semantic Framework for Adaptive Hypermedia Systems|This paper introduces a multidimensional semantic framework for adaptive systems. Different planes allow us to represent ontologies of user, her actions, context, device, domain, while the intersection between planes allow us to represent the semantic rules for inferring new user features or adaptation strategies. The adoption of ontology-based framework aims at creating a server for user modeling and adaptation strategy.|Francesca Carmagnola,Federica Cena,Cristina Gena,Ilaria Torre","16231|IJCAI|2005|Generalization Error of Linear Neural Networks in an Empirical Bayes Approach|It is well known that in unidentifiable models, the Bayes estimation has the advantage of generalization performance to the maximum likelihood estimation. However, accurate approximation of the posterior distribution requires huge computational costs. In this paper, we consider an empirical Bayes approach where a part of the parameters are regarded as hyperparameters, which we call a subspace Bayes approach, and theoretically analyze the generalization error of three-layer linear neural networks. We show that a subspace Bayes approach is asymptotically equivalent to a positivepart James-Stein type shrinkage estimation, and behaves similarly to the Bayes estimation in typical cases.|Shinichi Nakajima,Sumio Watanabe","16167|IJCAI|2005|Predicate-Oriented Isomorphism Elimination in Model Finding|Finding models of logical formulas is a challenging problem. For first-order formulas, a finite model can be found by exhaustive search. For many structured problem instances, there is much isomorphism in the search space. This paper proposes general-purpose techniques for eliminating isomorphic subspaces, which can be helpful when the formulas have many predicates. The techniques are based on inherent symmetries in first-order clauses.|Xiangxue Jia,Jian Zhang 0001","16170|IJCAI|2005|A Novel Approach to Model Generation for Heterogeneous Data Classification|Ensemble methods such as bagging and boosting have been successfully applied to classification problems. Two important issues associated with an ensemble approach are how to generate models to construct an ensemble, and how to combine them for classification. In this paper, we focus on the problem of model generation for heterogeneous data classification. If we could partition heterogeneous data into a number of homogeneous partitions, we will likely generate reliable and accurate classification models over the homogeneous partitions. We examine different ways of forming homogeneous subsets and propose a novel method that allows a data point to be assigned multiple times in order to generate homogeneous partitions for ensemble learning. We present the details of the new algorithm and empirical studies over the UCI benchmark datasets and datasets of image classification, and show that the proposed approach is effective for heterogeneous data classification.|Rong Jin,Huan Liu","16214|IJCAI|2005|ANDOR Branch-and-Bound for Graphical Models|The paper presents and evaluates the power of a new framework for optimization in graphical models, based on ANDOR search spaces. The virtue of the ANDOR representation of the search space is that its size may be far smaller than that of a traditional OR representation. We develop our work on Constraint Optimization Problems (COP) and introduce a new generation of depth-first Branch-and-Bound algorithms that explore an ANDOR search space and use static and dynamic mini-bucket heuristics to guide the search. We focus on two optimization problems, solvingWeighted CSPs (WCSP) and finding theMost Probable Explanation (MPE) in belief networks. We show that the new ANDOR approach improves considerably over the classic OR space, on a variety of benchmarks including random and real-world problems. We also demonstrate the impact of different lower bounding heuristics on Branch-and-Bound exploring ANDOR spaces.|Radu Marinescu 0002,Rina Dechter","16248|IJCAI|2005|Algebraic Markov Decision Processes|In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.|Patrice Perny,Olivier Spanjaard,Paul Weng","16054|IJCAI|2005|Computational ontologies of parthood componenthood and containment|Parthood, componenthood, and containment relations are commonly assumed in biomedical ontologies and terminology systems, but are not usually clearly distinguished from another. This paper contributes towards a unified theory of parthood, componenthood, and containment relations. Our goal in this is to clarify distinctions between these relations as well as principles governing their interrelations. We first develop a theory of these relations in first order predicate logic and then discuss how description logics can be used to capture some important aspects of the first order theory.|Thomas Bittner,Maureen Donnelly","16072|IJCAI|2005|Word Sense Disambiguation with Distribution Estimation|A word sense disambiguation (WSD) system trained on one domain and applied to a different domain will show a decrease in performance. One major reason is the different sense distributions between different domains. This paper presents novel application of two distribution estimation algorithms to provide estimates of the sense distribution of the new domain data set. Even though our training examples are automatically gathered from parallel corpora, the sense distributions estimated are good enough to achieve a relative improvement of % when incorporated into our WSD system.|Yee Seng Chan,Hwee Tou Ng"],["16161|IJCAI|2005|State Abstraction Discovery from Irrelevant State Variables|Abstraction is a powerful form of domain knowledge that allows reinforcement-learning agents to cope with complex environments, but in most cases a human must supply this knowledge. In the absence of such prior knowledge or a given model, we propose an algorithm for the automatic discovery of state abstraction from policies learned in one domain for use in other domains that have similar structure. To this end, we introduce a novel condition for state abstraction in terms of the relevance of state features to optimal behavior, and we exhibit statistical methods that detect this condition robustly. Finally, we show how to apply temporal abstraction to benefit safely from even partial state abstraction in the presence of generalization error.|Nicholas K. Jong,Peter Stone","16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","16069|IJCAI|2005|Fast convergence to satisfying distributions|We investigate an environment where self-interested agents have to find high-quality service resources. Agents have common knowledge about resources which are able to provide these services. The performance of resources is measured by the satisfaction obtained by agents using them. The performance of a resource depends on its intrinsic capability and its current load. We use a satisfying rather than an optimizing framework, where agents are content to receive service quality above a threshold. We introduce a formal framework to characterize the convergence of agents to a state where each agent is satisfied with the performance of the service it is currently using. We analyzed the convergence behavior of such a system and identified a mechanism to speed up convergence.|Teddy Candale,Sandip Sen","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16061|IJCAI|2005|Efficiency and envy-freeness in fair division of indivisible goods logical representation and complexity|We consider the problem of allocating fairly a set of indivisible goods among agents from the point of view of compact representation and computational complexity. We start by assuming that agents have dichotomous preferences expressed by propositional formulae. We express efficiency and envy-freeness in a logical setting, which reveals unexpected connections to nonmonotonic reasoning. Then we identify the complexity of determining whether there exists an efficient and envy-free allocation, for several notions of efficiency, when preferences are represented in a succinct way (as well as restrictions of this problem). We first study the problem under the assumption that preferences are dichotomous, and then in the general case.|Sylvain Bouveret,J√©r√¥me Lang","16099|IJCAI|2005|Explaining preferences with argument positions|When deciding what to do agents must choose among alternative actions and different agents may make different choices according to what they wish to achieve in the light of their preferences and values. It cannot be assumed, however, that agents have a conscious understanding of their value preferences independent of the reasoning situations in which they engage. In this paper we consider an extension to a generic framework for reasoning about arguments justifying actions in terms of values in which the preferences amongst values emerge from the reasoning process.|Sylvie Doutre,Trevor J. M. Bench-Capon,Paul E. Dunne","16039|IJCAI|2005|Achieving Allocatively-Efficient and Strongly Budget-Balanced Mechanisms in the Network Flow Domain for Bounded-Rational Agents|Vickrey-Clarke-Groves (VCG) mechanisms are a framework for finding a solution to a distributed optimization problem in systems of self-interested agents. VCG mechanisms have received wide attention in the AI community because they are efficient and strategy-proof a special case of the Groves family of mechanisms, VCG mechanisms are the only direct-revelation mechanisms that are allocatively efficient and strategy-proof. Unfortunately, they are only weakly budget-balanced. We consider self-interested agents in a network flow domain, and show that in this domain, it is possible to design a mechanism that is both allocatively-efficient and almost completely budget-balanced. This is done by choosing a mechanism that is not strategy-proof but rather strategy-resistant. Instead of using the VCG mechanism, we propose a mechanism in which finding a beneficial manipulation is an NP-complete problem, and the payments from the agents to the mechanism may be minimized as much as desired.|Yoram Bachrach,Jeffrey S. Rosenschein","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White","16090|IJCAI|2005|Two-Sided Bandits and the Dating Market|We study the decision problems facing agents in repeated matching environments with learning, or two-sided bandit problems, and examine the dating market, in which men and women repeatedly go out on dates and learn about each other, as an example. We consider three natural matching mechanisms and empirically examine properties of these mechanisms, focusing on the asymptotic stability of the resulting matchings when the agents use a simple learning rule coupled with an -greedy exploration policy. Matchings tend to be more stable when agents are patient in two different ways -- if they are more likely to explore early or if they are more optimistic. However, the two forms of patience do not interact well in terms of increasing the probability of stable outcomes. We also define a notion of regret for the two-sided problem and study the distribution of regrets under the different matching mechanisms.|Sanmay Das,Emir Kamenica"]]},"title":{"entropy":5.544460295321244,"topics":["local search, search for, with, algorithms for, local for, the problems, method for, and problems, for problems, search problems, algorithms and, search, for with, with application, for application, application, search and, problems, probabilistic, with and","distributed pomdps, for the, the, semantic for, heuristics for, for text, the and, knowledge for, semantic, networks, feature, ontology, selection, from, role, relational, knowledge, relation, optimization, between","representations and, reasoning with, for and, and, combining and, image and, reasoning, and recognition, complexity and, for reasoning, and reasoning, the and, logic, programs, description, domain, with and, ordering, solution, classification","constraint satisfaction, learning for, model for, learning, for planning, model, for robot, for satisfaction, model based, language for, for systems, systems, and model, based for, using, learning and, information, learning model, based, for using","search for, search, efficient, application, and","probabilistic, agents, inference, consistency, and","networks, semantic, relation, ontology","distributed pomdps, feature, constraint, selection, optimization, analysis, for","web, data, structure, action","for, classification, image, object","learning for, learning, web, mobile, machine","for planning, for robot, based for, for using, using, based"],"ranking":[["16277|IJCAI|2005|Efficient belief-state AND-OR search with application to Kriegspiel|The paper reports on new algorithms for solving partially observable games. Whereas existing algorithms apply AND-OR search to a tree of blackbox belief states, our \"incremental\" versions treat uncertainty as a new search dimension, examining the physical states within a belief state to construct solution trees incrementally. On a newly created database of checkmate problems for Kriegspiel (a partially observable form of chess), incrementalization yields speedups of two or more orders of magnitude on hard instances.|Stuart J. Russell,Jason Wolfe","16120|IJCAI|2005|Bin-Completion Algorithms for Multicontainer Packing and Covering Problems|Bin-completion, a bin-oriented branch-and-bound approach, was recently shown to be promising for the bin packing problem. We propose several improvements to bin-completion that significantly improves search efficiency. We also show the generality of bin-completion for packing and covering problems involving multiple containers, and present bin-completion algorithms for the multiple knapsack, bin covering, and min-cost covering (liquid loading) problems that significantly outperform the previous state of the art. However, we show that for the bin packing problem, bin-completion is not competitive with the state of the art solver.|Alex S. Fukunaga,Richard E. Korf","16298|IJCAI|2005|Streamlining Local Search for Spatially Balanced Latin Squares|Streamlined constrained reasoning powerfully boosts the performance of backtrack search methods for finding hard combinatorial objects. We use so-called spatially balanced Latin squares to show how streamlining can also be very effective for local search Our approach is much faster and generates considerably larger spatially balanced Latin squares than previously reported approaches (up to order  the previous best results could only generate solutions up to order ). We also provide a detailed characterization of our streamliner and solution topology for small orders. We believe that streamlined local search is a general technique suitable for solving a wide range of hard combinatorial design problems.|Casey Smith,Carla P. Gomes,C√®sar Fern√°ndez","16345|IJCAI|2005|A Novel Local Search Algorithm for the Traveling Salesman Problem that Exploits Backbones|We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.|Weixiong Zhang,Moshe Looks","16229|IJCAI|2005|Combination of Local Search Strategies for Rotating Workforce Scheduling Problem|Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.|Nysret Musliu","16153|IJCAI|2005|Optimal Refutations for Constraint Satisfaction Problems|Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.|Tudor Hulubei,Barry O'Sullivan","16226|IJCAI|2005|Applying Local Search to Disjunctive Temporal Problems|We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.|Michael D. Moffitt,Martha E. Pollack","16191|IJCAI|2005|Complete MCS-Based Search Application to Resource Constrained Project Scheduling|This paper describes a simple complete search for cumulative scheduling based on the detection and resolution of minimal critical sets (MCS). The heuristic for selecting MCSs relies on an estimation of the related reduction of the search space. An extension of the search procedure using self-adapting shaving is proposed. The approach was implemented on top of classical constraint propagation algorithms and tested on resource constrained project scheduling problems (RCPSP). We were able to close more than % of the previously open problems of the PSPLIB Kolisch and Sprecher,  and improve more than % of the best known lower bounds on those heavily studied problems. Other new results on open-shop and cumulative job-shop scheduling are reported.|Philippe Laborie","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas St√ºtzle"],["16122|IJCAI|2005|Feature Generation for Text Categorization Using World Knowledge|We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.|Evgeniy Gabrilovich,Shaul Markovitch","16230|IJCAI|2005|Networked Distributed POMDPs A Synergy of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","16334|IJCAI|2005|Automatic Semantic Role Labeling for Chinese Verbs|Recent years have seen a revived interest in semantic parsing by applying statistical and machine-learning methods to semantically annotated corpora such as the FrameNet and the Proposition Bank. So far much of the research has been focused on English due to the lack of semantically annotated resources in other languages. In this paper, we report first results on semantic role labeling using a pre-release version of the Chinese Proposition Bank. Since the Chinese Proposition Bank is superimposed on top of the Chinese Tree-bank, i.e., the semantic role labels are assigned to constituents in a treebank parse tree, we start by reporting results on experiments using the handcrafted parses in the treebank. This will give us a measure of the extent to which the semantic role labels can be bootstrapped from the syntactic annotation in the treebank. We will then report experiments using a fully automatic Chinese parser that integrates word segmentation, POS-tagging and parsing. This will gauge how successful semantic role labeling can be done for Chinese in realistic situations. We show that our results using hand-crafted parses are slightly higher than the results reported for the state-of-the-art semantic role labeling systems for English using the Penn English Proposition Bank data, even though the Chinese Proposition Bank is smaller in size. When an automatic parser is used, however, the accuracy of our system is much lower than the English state-of-the-art. This reveals an interesting cross-linguistic difference between the two languages, which we attempt to explain. We also describe a method to induce verb classes from the Proposition Bank \"frame files\" that can be used to improve semantic role labeling.|Nianwen Xue,Martha Stone Palmer","16148|IJCAI|2005|DPLL with a Trace From SAT to Knowledge Compilation|We show that the trace of an exhaustive DPLL search can be viewed as a compilation of the propositional theory. With different constraints imposed or lifted on the DPLL algorithm, this compilation will belong to the language of d-DNNF, FBDD, and OBDD, respectively. These languages are decreasingly succinct, yet increasingly tractable, supporting such polynomial-time queries as model counting and equivalence testing. Our contribution is thus twofold. First, we provide a uniform framework, supported by empirical evaluations, for compiling knowledge into various languages of interest. Second, we show that given a particular variant of DPLL, by identifying the language membership of its traces, one gains a fundamental understanding of the intrinsic complexity and computational power of the search algorithm itself. As interesting examples, we unveil the \"hidden power\" of several recent model counters, point to one of their potential limitations, and identify a key limitation of DPLL-based procedures in general.|Jinbo Huang,Adnan Darwiche","16224|IJCAI|2005|Semantic annotation of unstructured and ungrammatical text|There are vast amounts of free text on the internet that are neither grammatical nor formally structured, such as item descriptions on Ebay or internet classifieds like Craig's list. These sources of data, called \"posts,\" are full of useful information for agents scouring the Semantic Web, but they lack the semantic annotation to make them searchable. Annotating these posts is difficult since the text generally exhibits little formal grammar and the structure of the posts varies. However, by leveraging collections of known entities and their common attributes, called \"reference sets,\" we can annotate these posts despite their lack of grammar and structure. To use this reference data, we align a post to a member of the reference set, and then exploit this matched member during information extraction. We compare this extraction approach to more traditional information extraction methods that rely on structural and grammatical characteristics, and we show that our approach outperforms traditional methods on this type of data.|Matthew Michelson,Craig A. Knoblock","16318|IJCAI|2005|Measuring Semantic Similarity by Latent Relational Analysis|This paper introduces Latent Relational Analysis (LRA), a method for measuring semantic similarity. LRA measures similarity in the semantic relations between two pairs of words. When two pairs have a high degree of relational similarity, they are analogous. For example, the pair catmeow is analogous to the pair dogbark. There is evidence from cognitive science that relational similarity is fundamental to many cognitive and linguistic tasks (e.g., analogical reasoning). In the Vector Space Model (VSM) approach to measuring relational similarity, the similarity between two pairs is calculated by the cosine of the angle between the vectors that represent the two pairs. The elements in the vectors are based on the frequencies of manually constructed patterns in a large corpus. LRA extends the VSM approach in three ways () patterns are derived automatically from the corpus, () Singular Value Decomposition is used to smooth the frequency data, and () synonyms are used to reformulate word pairs. This paper describes the LRA algorithm and experimentally compares LRA to VSM on two tasks, answering college-level multiple-choice word analogy questions and classifying semantic relations in noun-modifier expressions. LRA achieves state-of-the-art results, reaching human-level performance on the analogy questions and significantly exceeding VSM performance on both tasks.|Peter D. Turney","16081|IJCAI|2005|Unsupervised Learning of Semantic Relations between Concepts of a Molecular Biology Ontology|In this paper we present an unsupervised model for learning arbitrary relations between concepts of a molecular biology ontology for the purpose of supporting text mining and manual ontology building. Relations between named-entities are learned from the GENIA corpus by means of several standard natural language processing techniques. An in-depth analysis of the output of the system shows that the model is accurate and has good potentials for text mining and ontology building applications.|Massimiliano Ciaramita,Aldo Gangemi,Esther Ratsch,Jasmin Saric,Isabel Rojas","16256|IJCAI|2005|The Necessity of Syntactic Parsing for Semantic Role Labeling|We provide an experimental study of the role of syntactic parsing in semantic role labeling. Our conclusions demonstrate that syntactic parse information is clearly most relevant in the very first stage - the pruning stage. In addition, the quality of the pruning stage cannot be determined solely based on its recall and precision. Instead it depends on the characteristics of the output candidates that make downstream problems easier or harder. Motivated by this observation, we suggest an effective and simple approach of combining different semantic role labeling systems through joint inference, which significantly improves the performance.|Vasin Punyakanok,Dan Roth,Wen-tau Yih","16244|IJCAI|2005|Building the Semantic Web Tower from RDF Straw|A same-syntax extension of RDF to first-order logic results in a collapse of the model theory due to logical paradoxes resulting from diagonalization. RDF is thus the wrong material for building the Semantic Web tower.|Peter F. Patel-Schneider","16128|IJCAI|2005|Inferring Useful Heuristics from the Dynamics of Iterative Relational Classifiers|In this paper we consider dynamical properties of simple iterative relational classifiers. We conjecture that for a class of algorithms that use label-propagation the iterative procedure can lead to nontrivial dynamics in the number of newly classified instances. The underlaying reason for this nontriviality is that in relational networks true class labels are likely to propagate faster than false ones. We suggest that this phenomenon, which we call two-tiered dynamics for binary classifiers, can be used for establishing a self-consistent classification threshold and a criterion for stopping iteration. We demonstrate this effect for two unrelated binary classification problems using a variation of a iterative relational neighbor classifier. We also study analytically the dynamical properties of the suggested classifier, and compare its results to the numerical experiments on synthetic data.|Aram Galstyan,Paul R. Cohen"],["16159|IJCAI|2005|Combining Structural Descriptions and Image-based Representations for Image Object and Scene Recognition|Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.|Nicolas Do Huu,Williams Paquier,Raja Chatila","16180|IJCAI|2005|Reasoning under inconsistency the forgotten connective|In many frameworks for reasoning under inconsistency, it is implicitly assumed that the formulae from the belief base are connected using a weak form of conjunction. When it is consistent, a belief base B  ..., n, where the i are propositional formulae, is logically equivalent to the base   ...  n. However, when it is not consistent, both bases typically lead to different conclusions. This illustrates the fact that the comma used in base B has to be considered as an additional, genuine connective, and not as a simple conjunction. In this work we define and investigate a propositional framework with such a \"comma connective\". We give it a semantics and show how it generalizes several approaches for reasoning from inconsistent beliefs.|S√©bastien Konieczny,J√©r√¥me Lang,Pierre Marquis","16055|IJCAI|2005|Propositional Argumentation and Causal Reasoning|The paper introduces a number of propositional argumentation systems obtained by gradually extending the underlying language and associated monotonic logics. An assumption-based argumentation framework Bondarenko et al.,  will constitute a special case of this construction. In addition, a stronger argumentation system in a full classical language will be shown to be equivalent to a system of causal reasoning Giunchiglia et al., . The implications of this correspondence for the respective nonmonotonic theories of argumentation and causal reasoning are discussed.|Alexander Bochman","16150|IJCAI|2005|Reasoning with Inconsistent Ontologies|In this paper we present a framework of reasoning with inconsistent ontologies, in which pre-defined selection functions are used to deal with concept relevance. We examine how the notion of \"concept relevance\" can be used for reasoning with inconsistent ontologies. We have implemented a prototype called PION (Processing Inconsistent ONtologies), which is based on a syntactic relevance-based selection function. In this paper, we also report the experiments with PION.|Zhisheng Huang,Frank van Harmelen,Annette ten Teije","16227|IJCAI|2005|Temporal Context Representation and Reasoning|This paper demonstrates how a model for temporal context reasoning can be implemented. The approach is to detect temporally related events in natural language text and convert the events into an enriched logical representation. Reasoning is provided by a first order logic theorem prover adapted to text. Results show that temporal context reasoning boosts the performance of a Question Answering system.|Dan I. Moldovan,Christine Clark,Sanda M. Harabagiu","16283|IJCAI|2005|Probabilistic Reasoning for Plan Robustness|A planning system must reason about the uncertainty of continuous variables in order to accurately project the possible system state over time. A method is devised for directly reasoning about the uncertainty in continuous activity duration and resource usage for planning problems. By representing random variables as parametric distributions, computing projected system state can be simplified. Common approximations and novel methods are compared for over-constrained and lightly constrained domains within an iterative repair planner. Results show improvements in robustness over the conventional non-probabilistic representation by reducing the number of constraint violations during execution. The improvement is more significant for larger problems and those with higher resource subscription levels but diminishes as the system is allowed to accept higher risk levels.|Steve R. Schaffer,Bradley J. Clement,Steve A. Chien","16216|IJCAI|2005|Cognitive Modelling of Event Ordering Reasoning in Imagistic Domains|The inference of temporal information from past event occurences in imagistic domains is relevant in several applications in knowledge engineering. In such applications, the order in which events have happened is imprinted in the domain as visual-spatial relations among its elements. Therefore, the interpretation of the relative ordering in which those events have occured is essential for understanding the domain evolution. We propose a cognitive model for event ordering reasoning within domains whose elements have been modified by past events. From the analysis of cognitive abilities of experts we propose new ontology constructs for knowledge modelling associated to Problem-Solving Methods. We illustrate the effectiveness of the model by means of an applications to an imagistic domain.|Laura S. Mastella,Mara Abel,Lu√≠s C. Lamb,Luis Fernando De Ros","16156|IJCAI|2005|Data Complexity of Reasoning in Very Expressive Description Logics|Data complexity of reasoning in description logics (DLs) estimates the performance of reasoning algorithms measured in the size of the ABox only. We show that, even for the very expressive DL SHIQ, satisfiability checking is data complete for NP. For applications with large ABoxes, this can be a more accurate estimate than the usually considered combined complexity, which is EXPTIME-complete. Furthermore, we identify an expressive fragment, Horn-SHIQ, which is data complete for P, thus being very appealing for practical usage.|Ullrich Hustadt,Boris Motik,Ulrike Sattler","16316|IJCAI|2005|Ordering Heuristics for Description Logic Reasoning|We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.|Dmitry Tsarkov,Ian Horrocks","16197|IJCAI|2005|From knowledge-based programs to graded belief-based programs part II off-line reasoning|Belief-based programs generalize knowledgebased programs Fagin et al.,  by allowing for incorrect beliefs, unreliable observations, and branching conditions that refer to implicit graded beliefs, such as in \"while my belief about the direction to the railway station is not strong enough do ask someone\". We show how to reason off-line about the possible executions of a belief-based program, which calls for introducing second-order uncertainty in the model.|No√´l Laverny,J√©r√¥me Lang"],["16117|IJCAI|2005|Automatic learning of domain model for personalized hypermedia applications|This paper deals with the automatic building of personalized hypermedia. We build upon ideas developed for educational hypermedia the definition of a domain model and the use of overlay user models. Since much work has been done on learning user models and adapting hypermedia based on such models, we tackle the core problem the automatic definition of a domain model for a static hypermedia.|Hermine Njike Fotzo,Thierry Arti√®res,Patrick Gallinari,Julien Blanchard,Guillaume Letellier","16030|IJCAI|2005|Language Learning in Multi-Agent Systems|We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.|Martin Allen,Claudia V. Goldman,Shlomo Zilberstein","16253|IJCAI|2005|ROCCER An Algorithm for Rule Learning Based on ROC Analysis|We introduce a rule selection algorithm called ROCCER, which operates by selecting classification rules from a larger set of rules - for instance found by Apriori - using ROC analysis. Experimental comparison with rule induction algorithms shows that ROCCER tends to produce considerably smaller rule sets with compatible Area Under the ROC Curve (AUC) values. The individual rules that compose the rule set also have higher support and stronger association indexes.|Ronaldo C. Prati,Peter A. Flach","16183|IJCAI|2005|Using Neutral Examples for Learning Polarity|Sentiment analysis is an example of polarity learning. Most research on learning to identify sentiment ignores \"neutral\" examples and instead performs training and testing using only examples of significant polarity. We show that it is crucial to use neutral examples in learning polarity for a variety of reasons and show how neutral examples help us obtain superior classification results in two sentiment analysis test-beds.|Moshe Koppel,Jonathan Schler","16046|IJCAI|2005|A language for functional interpretation of model based simulation|Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.|Jonathan Bell,Neal Snooke,Chris Price","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","16040|IJCAI|2005|Model Compilation for Real-Time Planning and Diagnosis with Feedback|This paper describes MEXEC, an implemented micro executive that compiles a device model that can have feedback into a structure for subsequent evaluation. This system computes both the most likely current device mode from n sets of sensor measurements and the n- step reconfiguration plan that is most likely to result in reaching a target mode - if such a plan exists. A user tunes the system by increasing n to improve system capability at the cost of real-time performance.|Anthony Barrett","16112|IJCAI|2005|A Simple-Transition Model for Relational Sequences|We use \"nearly sound\" logical constraints to infer hidden states of relational processes. We introduce a simple-transition cost model, which is parameterized by weighted constraints and a statetransition cost. Inference for this model, i.e. finding a minimum-cost state sequence, reduces to a single-state minimization (SSM) problem. For relational Horn constraints, we give a practical approach to SSM based on logical reasoning and bounded search. We present a learning method that discovers relational constraints using CLAUDIEN De Raedt and Dehaspe,  and then tunes their weights using perceptron updates. Experiments in relational video interpretation show that our learned models improve on a variety of competitors.|Alan Fern","16100|IJCAI|2005|A Probabilistic Model of Redundancy in Information Extraction|Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness This paper introduces a combinatorial \"balls-andurns\" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are  times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression.|Doug Downey,Oren Etzioni,Stephen Soderland","16162|IJCAI|2005|Model minimization by linear PSR|Predictive state representation (PSR), proposed by Littman et al.,  Singh et al., , are a general representation for controlled dynamical systems. We present a sufficient condition under which a linear PSR compresses a POMDP representation.|Masoumeh T. Izadi,Doina Precup"],["16062|IJCAI|2005|A Study of Selection Noise in Collaborative Web Search|Collaborative Web search uses the past search behaviour (queries and selections) of a community of users to promote search results that are relevant to the community. The extent to which these promotions are likely to be relevant depends on how reliably past search behaviour can be captured. We consider this issue by analysing the results of collaborative Web search in circumstances where the behaviour of searchers is unreliable.|Ois√≠n Boydell,Barry Smyth,Cathal Gurrin,Alan F. Smeaton","16277|IJCAI|2005|Efficient belief-state AND-OR search with application to Kriegspiel|The paper reports on new algorithms for solving partially observable games. Whereas existing algorithms apply AND-OR search to a tree of blackbox belief states, our \"incremental\" versions treat uncertainty as a new search dimension, examining the physical states within a belief state to construct solution trees incrementally. On a newly created database of checkmate problems for Kriegspiel (a partially observable form of chess), incrementalization yields speedups of two or more orders of magnitude on hard instances.|Stuart J. Russell,Jason Wolfe","16087|IJCAI|2005|Explaining Search Results|In this paper we argue that it may be possible to help searchers to better understand the relevance of search results by generating explanations that highlight how other users have interacted with such results under similar search conditions in the past. We propose the use of the search histories of a community of online users as a source of these explanations. We describe the results of a recent study to examine the use of such explanation-based techniques to help Web searchers better appreciate the relevancy of search results. We highlight shortcomings of this approach in its current form and offer suggestions as to how it may be improved in future work.|Maurice Coyle,Barry Smyth","16124|IJCAI|2005|Limited Discrepancy Beam Search|Beam search reduces the memory consumption of best-first search at the cost of finding longer paths but its memory consumption can still exceed the given memory capacity quickly. We therefore develop BULB (Beam search Using Limited discrepancy Backtracking), a complete memory-bounded search method that is able to solve more problem instances of large search problems than beam search and does so with a reasonable runtime. At the same time, BULB tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory. We demonstrate these properties of BULB experimentally for three standard benchmark domains.|David Furcy,Sven Koenig","16265|IJCAI|2005|CSP Search with Responsibility Sets and Kernels|We introduce data structures called responsibility set and kernel. We present an algorithm FCRK, which is a modification of FC that maintains these structures and uses them for pruning of the search space. According to our experimental evaluation, FC-RK outperforms FC-CBJ on constraint networks encoding graph k-coloring instances and on non-dense random binary constraint networks.|Igor Razgon,Amnon Meisels","16045|IJCAI|2005|Improved Knowledge Acquisition for High-Performance Heuristic Search|We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.|J. P. Bekmann,Achim G. Hoffmann","16079|IJCAI|2005|Towards More Intelligent Mobile Search|As the mobile Internet continues to grow there is an increasing need to provide users with effective search facilities. In this paper we argue that the standard Web search approach of providing snippet text alongside each result is not appropriate given the interface limitations of mobile devices. Instead we evaluate an alternative approach involving the use of related queries in place of snippet text for result gisting.|Karen Church,Mark T. Keane,Barry Smyth","16191|IJCAI|2005|Complete MCS-Based Search Application to Resource Constrained Project Scheduling|This paper describes a simple complete search for cumulative scheduling based on the detection and resolution of minimal critical sets (MCS). The heuristic for selecting MCSs relies on an estimation of the related reduction of the search space. An extension of the search procedure using self-adapting shaving is proposed. The approach was implemented on top of classical constraint propagation algorithms and tested on resource constrained project scheduling problems (RCPSP). We were able to close more than % of the previously open problems of the PSPLIB Kolisch and Sprecher,  and improve more than % of the best known lower bounds on those heavily studied problems. Other new results on open-shop and cumulative job-shop scheduling are reported.|Philippe Laborie","16158|IJCAI|2005|Efficient Stochastic Local Search for MPE Solving|Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.|Frank Hutter,Holger H. Hoos,Thomas St√ºtzle","16058|IJCAI|2005|Viewing Referring Expression Generation as Search|Almost all natural language generation (NLG) systems are faced with the problem of the generation of referring expressions (GRE) given a symbol corresponding to an intended referent, how do we work out the semantic content of a referring expression that uniquely identifies the entity in question This is now one of the most widely explored problems in NLG over the last  years, a number of algorithms have been proposed for addressing different aspects of this problem, but the different approaches taken make it very difficult to compare and contrast the algorithms provided in any meaningful way. In this paper, we show how viewing the problem of referring expression generation as a search problem allows us to recast existing algorithms in a way that makes their similarities and differences clear.|Bernd Bohnet,Robert Dale"],["16247|IJCAI|2005|Phase Transitions within Grammatical Inference|It is now well-known that the feasibility of inductive learning is ruled by statistical properties linking the empirical risk minimization principle and the \"capacity\" of the hypothesis space. The discovery, a few years ago, of a phase transition phenomenon in inductive logic programming proves that other fundamental characteristics of the learning problems may similarly affect the very possibility of learning under very general conditions. Our work examines the case of grammatical inference. We show that while there is no phase transition when considering the whole hypothesis space, there is a much more severe \"gap\" phenomenon affecting the effective search space of standard grammatical induction algorithms for deterministic finite automata (DFA). Focusing on the search heuristics of the RPNI and RED-BLUE algorithms, we show that they overcome this problem to some extent, but that they are subject to overgeneralization. The paper last suggests some directions for new generalization operators, suited to this Phase Transition phenomenon.|Nicolas Pernot,Antoine Cornu√©jols,Mich√®le Sebag","16052|IJCAI|2005|Optimal and Suboptimal Singleton Arc Consistency Algorithms|Singleton arc consistency (SAC) enhances the pruning capability of arc consistency by ensuring that the network cannot become arc inconsistent after the assignment of a value to a variable. Algorithms have already been proposed to enforce SAC, but they are far from optimal time complexity. We give a lower bound to the time complexity of enforcing SAC, and we propose an algorithm that achieves this complexity, thus being optimal. However, it can be costly in space on large problems. We then propose another SAC algorithm that trades time optimality for a better space complexity. Nevertheless, this last algorithm has a better worst-case time complexity than previously published SAC algorithms. An experimental study shows the good performance of the new algorithms.|Christian Bessi√®re,Romuald Debruyne","16059|IJCAI|2005|Reconstructing an Agents Epistemic State from Observations|We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a \"reverse engineering\" approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that \"best explains\" the observation. Further considerations on this best-explaining model then allow inferences about the agent's epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.|Richard Booth,Alexander Nittka","16257|IJCAI|2005|Learning and Inference over Constrained Output|We study learning structured output in a discriminative framework where values of the output variables are estimated by local classifiers. In this framework, complex dependencies among the output variables are captured by constraints and dictate which global labels can be inferred. We compare two strategies, learning independent classifiers and inference based training, by observing their behaviors in different conditions. Experiments and theoretical justification lead to the conclusion that using inference based learning is superior when the local classifiers are difficult to learn but may require many examples before any discernible difference can be observed.|Vasin Punyakanok,Dan Roth,Wen-tau Yih,Dav Zimak","16279|IJCAI|2005|Affine Algebraic Decision Diagrams AADDs and their Application to Structured Probabilistic Inference|We propose an affine extension to ADDs (AADD) capable of compactly representing context-specific, additive, and multiplicative structure. We show that the AADD has worst-case time and space performance within a multiplicative constant of that of ADDs, but that it can be linear in the number of variables in cases where ADDs are exponential in the number of variables. We provide an empirical comparison of tabular, ADD, and AADD representations used in standard Bayes net and MDP inference algorithms and conclude that the AADD performs at least as well as the other two representations, and often yields an exponential performance improvement over both when additive or multiplicative structure can be exploited. These results suggest that the AADD is likely to yield exponential time and space improvements for a variety of probabilistic inference algorithms that currently use tables or ADDs.|Scott Sanner,David A. McAllester","16131|IJCAI|2005|The computational complexity of dominance and consistency in CP-nets|We investigate the computational complexity of testing dominance and consistency in CP-nets. Previously, the complexity of dominance has been determined for restricted classes in which the dependency graph of the CP-net is acyclic. However, there are preferences of interest that define cyclic dependency graphs these are modeled with general CP-nets. In our main results, we show here that both dominance and consistency for general CP-nets are PSPACE-complete. We then consider the concept of strong dominance, dominance equivalence and dominance incomparability, and several notions of optimality, and identify the complexity of the corresponding decision problems. The reductions used in the proofs are from STRIPS planning, and thus reinforce the earlier established connections between both areas.|Judy Goldsmith,J√©r√¥me Lang,Miroslaw Truszczynski,Nic Wilson","16063|IJCAI|2005|Lifted First-Order Probabilistic Inference|Most probabilistic inference algorithms are specified and processed on a propositional level. In the last decade, many proposals for algorithms accepting first-order specifications have been presented, but in the inference stage they still operate on a mostly propositional representation level. Poole,  presented a method to perform inference directly on the first-order level, but this method is limited to special cases. In this paperwe present the first exact inference algorithm that operates directly on a first-order level, and that can be applied to any first-order model (specified in a language that generalizes undirected graphical models). Our experiments show superior performance in comparison with propositional exact inference.|Rodrigo de Salvo Braz,Eyal Amir,Dan Roth","16258|IJCAI|2005|PsychSim Modeling Theory of Mind with Decision-Theoretic Agents|Agent-based modeling of human social behavior is an increasingly important research area. A key factor in human social interaction is our beliefs about others, a theory of mind. Whether we believe a message depends not only on its content but also on our model of the communicator. How we act depends not only on the immediate effect but also on how we believe others will react. In this paper, we discuss PsychSim, an implemented multiagent-based simulation tool for modeling interactions and influence. While typical approaches to such modeling have used first-order logic, Psych-Sim agents have their own decision-theoretic model of the world, including beliefs about its environment and recursive models of other agents. Using these quantitative models of uncertainty and preferences, we have translated existing psychological theories into a decision-theoretic semantics that allow the agents to reason about degrees of believability in a novel way. We discuss PsychSim's underlying architecture and describe its application to a school violence scenario for illustration.|David V. Pynadath,Stacy Marsella","16078|IJCAI|2005|Attribution of Knowledge to Artificial Agents and their Principals|We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.|Samir Chopra,Laurence White","16199|IJCAI|2005|A Greedy Approach to Establish Singleton Arc Consistency|In this paper, we propose a new approach to establish Singleton Arc Consistency (SAC) on constraint networks. While the principle of existing SAC algorithms involves performing a breadth-first search up to a depth equal to , the principle of the two algorithms introduced in this paper involves performing several runs of a greedy search (where at each step, arc consistency is maintained). It is then an original illustration of applying inference (i.e. establishing singleton arc consistency) by search. Using a greedy search allows benefiting from the incrementality of arc consistency, learning relevant information from conflicts and, potentially finding solution(s) during the inference process. Further-more, both space and time complexities are quite competitive.|Christophe Lecoutre,St√©phane Cardon"],["16313|IJCAI|2005|Temporal-Difference Networks with History|Temporal-difference (TD) networks are a formalism for expressing and learning grounded world knowledge in a predictive form Sutton and Tanner, . However, not all partially observable Markov decision processes can be efficiently learned with TD networks. In this paper, we extend TD networks by allowing the network-update process (answer network) to depend on the recent history of previous actions and observations rather than only on the most recent action and observation. We show that this extension enables the solution of a larger class of problems than can be solved by the original TD networks or by history-based methods alone. In addition, we apply TD networks to a problem that, while still simple, is significantly larger than has previously been considered. We show that history-extended TD networks can learn much of the common-sense knowledge of an egocentric gridworld domain with a single bit of perception.|Brian Tanner,Richard S. Sutton","16071|IJCAI|2005|Sensitivity Analysis in Markov Networks|This paper explores the topic of sensitivity analysis in Markov networks, by tackling questions similar to those arising in the context of Bayesian networks the tuning of parameters to satisfy query constraints, and the bounding of query changes when perturbing network parameters. Even though the distribution induced by a Markov network corresponds to ratios of multi-linear functions, whereas the distribution induced by a Bayesian network corresponds to multi-linear functions, the results we obtain for Markov networks are as effective computationally as those obtained for Bayesian networks. This similarity is due to the fact that conditional probabilities have the same functional form in both Bayesian and Markov networks, which turns out to be the more influential factor. The major difference we found, however, is in how changes in parameter values should be quantified, as such parameters are interpreted differently in Bayesian networks and Markov networks.|Hei Chan,Adnan Darwiche","16234|IJCAI|2005|Robust Ontology Acquisition from Machine-Readable Dictionaries|In this paper, we outline the development of a system that automatically constructs ontologies by extracting knowledge from dictionary definition sentences using Robust Minimal Recursion Semantics (RMRS), a semantic formalism that permits underspecification. We show that by combining deep and shallow parsing resources through the common formalism of RMRS, we can extract ontological relations in greater quality and quantity. Our approach also has the advantages of requiring a very small amount of rules and being easily adaptable to any language with RMRS resources.|Eric Nichols,Francis Bond,Dan Flickinger","16137|IJCAI|2005|Shallow Semantics for Relation Extraction|This paper presents a new method for extracting meaningful relations from unstructured natural language sources. The method is based on information made available by shallow semantic parsers. Semantic information was used () to enhance a dependency tree kernel and () to build semantic dependency structures used for enhanced relation extraction for several semantic classifiers. In our experiments the quality of the extracted relations surpassed the results of kernel-based models employing only semantic class information.|Sanda M. Harabagiu,Cosmin Adrian Bejan,Paul Morarescu","16263|IJCAI|2005|Dependency Calculus Reasoning in a General Point Relation Algebra|The point algebra is a fundamental formal calculus for spatial and temporal reasoning. We present a new generalization that meets all requirements to describe dependencies on networks. Applications range from traffic networks to medical diagnostics. We investigate satisfaction problems, tractable subclassses, embeddings into other relation algebras, and the associated interval algebra.|Marco Ragni,Alexander Scivos","16224|IJCAI|2005|Semantic annotation of unstructured and ungrammatical text|There are vast amounts of free text on the internet that are neither grammatical nor formally structured, such as item descriptions on Ebay or internet classifieds like Craig's list. These sources of data, called \"posts,\" are full of useful information for agents scouring the Semantic Web, but they lack the semantic annotation to make them searchable. Annotating these posts is difficult since the text generally exhibits little formal grammar and the structure of the posts varies. However, by leveraging collections of known entities and their common attributes, called \"reference sets,\" we can annotate these posts despite their lack of grammar and structure. To use this reference data, we align a post to a member of the reference set, and then exploit this matched member during information extraction. We compare this extraction approach to more traditional information extraction methods that rely on structural and grammatical characteristics, and we show that our approach outperforms traditional methods on this type of data.|Matthew Michelson,Craig A. Knoblock","16309|IJCAI|2005|The Ontology Revision|An ontology consists of a set of concepts, a set of constraints imposing on instances of concepts, and the subsumption relation. It is assumed that an ontology is a tree under the subsumption relation between concepts. To preserve structural properties of ontologies, the ontology revision is not only contracting ontologies by discarding statements inconsistent with a revising statement, but also extracting statements consistent with the revising statement and adding some other statements. In the ontology revision, the consistency of a revising statement with the theory of the logical closure of the ontology under the closed world assumption is discussed. The basic postulates of the ontology revision are proposed and a concrete ontology revision is given based on the consistence or inconsistence of an ontology and a revising statement.|Yu Sun,Yuefei Sui","16081|IJCAI|2005|Unsupervised Learning of Semantic Relations between Concepts of a Molecular Biology Ontology|In this paper we present an unsupervised model for learning arbitrary relations between concepts of a molecular biology ontology for the purpose of supporting text mining and manual ontology building. Relations between named-entities are learned from the GENIA corpus by means of several standard natural language processing techniques. An in-depth analysis of the output of the system shows that the model is accurate and has good potentials for text mining and ontology building applications.|Massimiliano Ciaramita,Aldo Gangemi,Esther Ratsch,Jasmin Saric,Isabel Rojas","16287|IJCAI|2005|Aspects of Distributed and Modular Ontology Reasoning|We investigate a formalism for reasoning with multiple local ontologies, connected by directional semantic mappings. We propose () a relatively small change of semantics which localizes inconsistency (thereby making unnecessary global satisfiability checks), and preserves directionality of \"knowledge import\" () a characterization of inferences using a fixed-point operator, which can form the basis of a cache-based implementation for local reasoners () a truly distributed tableaux algorithm for cases when the local reasoners use subsets of SHIQ. Throughout, we indicate the applicability of the results to several recent proposals for knowledge representation and reasoning that support modularity, scalability and distributed reasoning.|Luciano Serafini,Alexander Borgida,Andrei Tamilin","16280|IJCAI|2005|Supervaluation Semantics for an Inland Water Feature Ontology|This paper describes an ontology for inland water features built using formal concept analysis and supervaluation semantics. The first is used to generate a complete lattice of the water domain, whereas supervaluation semantics is used to model the variability of the concepts in terms of threshold parameters. We also present an algorithm for a mechanism of individuation and classification of water features, from snapshots of river networks, according to the proposed ontology.|Paulo Santos,Brandon Bennett,Georgios Sakellariou"],["16272|IJCAI|2005|Bounded Search and Symbolic Inference for Constraint Optimization|Constraint optimization underlies many problems in AI. We present a novel algorithm for finite domain constraint optimization that generalizes branch-and-bound search by reasoning about sets of assignments rather than individual assignments. Because in many practical cases, sets of assignments can be represented implicitly and compactly using symbolic techniques such as decision diagrams, the set-based algorithm can compute bounds faster than explicitly searching over individual assignments, while memory explosion can be avoided by limiting the size of the sets. Varying the size of the sets yields a family of algorithms that includes known search and inference algorithms as special cases. Furthermore, experiments on random problems indicate that the approach can lead to significant performance improvements.|Martin Sachenbacher,Brian C. Williams","16230|IJCAI|2005|Networked Distributed POMDPs A Synergy of Distributed Constraint Optimization and POMDPs|In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.|Ranjit Nair,Pradeep Varakantham,Milind Tambe,Makoto Yokoo","16250|IJCAI|2005|A Scalable Method for Multiagent Constraint Optimization|We present in this paper a new, complete method for distributed constraint optimization, based on dynamic programming. It is a utility propagation method, inspired by the sum-product algorithm, which is correct only for tree-shaped constraint networks. In this paper, we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. Our algorithm requires a linear number of messages, whose maximal size depends on the induced width along the particular pseudotree chosen. We compare our algorithm with backtracking algorithms, and present experimental results. For some problem types we report orders of magnitude fewer messages, and the ability to deal with arbitrarily large problems. Our algorithm is formulated for optimization problems, but can be easily applied to satisfaction problems as well.|Adrian Petcu,Boi Faltings","16086|IJCAI|2005|Feature Selection Based on the Shapley Value|We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.|Shay Cohen,Eytan Ruppin,Gideon Dror","16262|IJCAI|2005|InterActive Feature Selection|We study the effects of feature selection and human feedback on features in active learning settings. Our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features. Consistent with previous findings, we find that feature selection based on the labeled training set has little effect. But our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion (%) of the most relevant features. Furthermore, these experiments show that feature labeling takes much less (about th) time than document labeling. We propose an algorithm that interleaves labeling features and documents which significantly accelerates active learning.|Hema Raghavan,Omid Madani,Rosie Jones","16317|IJCAI|2005|Sequential Genetic Search for Ensemble Feature Selection|Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on  data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.|Alexey Tsymbal,Mykola Pechenizkiy,Padraig Cunningham","16051|IJCAI|2005|Bounded Policy Iteration for Decentralized POMDPs|We present a bounded policy iteration algorithm for infinite-horizon decentralized POMDPs. Policies are represented as joint stochastic finite-state controllers, which consist of a local controller for each agent. We also let a joint controller include a correlation device that allows the agents to correlate their behavior without exchanging information during execution, and show that this leads to improved performance. The algorithm uses a fixed amount of memory, and each iteration is guaranteed to produce a controller with value at least as high as the previous one for all possible initial state distributions. For the case of a single agent, the algorithm reduces to Poupart and Boutilier's bounded policy iteration for POMDPs.|Daniel S. Bernstein,Eric A. Hansen,Shlomo Zilberstein","16106|IJCAI|2005|Reinforcement Learning in POMDPs Without Resets|We consider the most realistic reinforcement learning setting in which an agent starts in an unknown environment (the POMDP) and must follow one continuous and uninterrupted chain of experience with no access to \"resets\" or \"offline\" simulation. We provide algorithms for general connected POMDPs that obtain near optimal average reward. One algorithm we present has a convergence rate which depends exponentially on a certain horizon time of an optimal policy, but has no dependence on the number of (unobservable) states. The main building block of our algorithms is an implementation of an approximate reset strategy, which we show always exists in every POMDP. An interesting aspect of our algorithms is how they use this strategy when balancing exploration and exploitation.|Eyal Even-Dar,Sham M. Kakade,Yishay Mansour","16135|IJCAI|2005|The COMPSET Algorithm for Subset Selection|Subset selection problems are relevant in many domains. Unfortunately, their combinatorial nature prohibits solving them optimally in most cases. Local search algorithms have been applied to subset selection with varying degrees of success. This work presents COMPSET, a general algorithm for subset selection that invokes an existing local search algorithm from a random subset and its complementary set, exchanging information between the two runs to help identify wrong moves. Preliminary results on complex SAT, Max Clique,  Multidimensional Knapsack and Vertex Cover problems show that COMPSET improves the efficient stochastic hill climbing and tabu search algorithms by up to two orders of magnitudes.|Yaniv Hamo,Shaul Markovitch","16287|IJCAI|2005|Aspects of Distributed and Modular Ontology Reasoning|We investigate a formalism for reasoning with multiple local ontologies, connected by directional semantic mappings. We propose () a relatively small change of semantics which localizes inconsistency (thereby making unnecessary global satisfiability checks), and preserves directionality of \"knowledge import\" () a characterization of inferences using a fixed-point operator, which can form the basis of a cache-based implementation for local reasoners () a truly distributed tableaux algorithm for cases when the local reasoners use subsets of SHIQ. Throughout, we indicate the applicability of the results to several recent proposals for knowledge representation and reasoning that support modularity, scalability and distributed reasoning.|Luciano Serafini,Alexander Borgida,Andrei Tamilin"],["16073|IJCAI|2005|Compiling Bayesian Networks with Local Structure|Recent work on compiling Bayesian networks has reduced the problem to that of factoring CNF encodings of these networks, providing an expressive framework for exploiting local structure. For networks that have local structure, large CPTs, yet no excessive determinism, the quality of the CNF encodings and the amount of local structure they capture can have a significant effect on both the offline compile time and online inference time. We examine the encoding of such Bayesian networks in this paper and report on new findings that allow us to significantly scale this compilation approach. In particular, we obtain order-of-magnitude improvements in compile time, compile some networks successfully for the first time, and obtain ordersof-magnitude improvements in online inference for some networks with local structure, as compared to baseline jointree inference, which does not exploit local structure.|Mark Chavira,Adnan Darwiche","16181|IJCAI|2005|A Fast Normalized Maximum Likelihood Algorithm for Multinomial Data|Stochastic complexity of a data set is defined as the shortest possible code length for the data obtainable by using some fixed set of models. This measure is of great theoretical and practical importance as a tool for tasks such as model selection or data clustering. In the case of multinomial data, computing the modern version of stochastic complexity, defined as the Normalized Maximum Likelihood (NML) criterion, requires computing a sum with an exponential number of terms. Furthermore, in order to apply NML in practice, one often needs to compute a whole table of these exponential sums. In our previous work, we were able to compute this table by a recursive algorithm. The purpose of this paper is to significantly improve the time complexity of this algorithm. The techniques used here are based on the discrete Fourier transformand the convolution theorem.|Petri Kontkanen,Petri Myllym√§ki","16170|IJCAI|2005|A Novel Approach to Model Generation for Heterogeneous Data Classification|Ensemble methods such as bagging and boosting have been successfully applied to classification problems. Two important issues associated with an ensemble approach are how to generate models to construct an ensemble, and how to combine them for classification. In this paper, we focus on the problem of model generation for heterogeneous data classification. If we could partition heterogeneous data into a number of homogeneous partitions, we will likely generate reliable and accurate classification models over the homogeneous partitions. We examine different ways of forming homogeneous subsets and propose a novel method that allows a data point to be assigned multiple times in order to generate homogeneous partitions for ensemble learning. We present the details of the new algorithm and empirical studies over the UCI benchmark datasets and datasets of image classification, and show that the proposed approach is effective for heterogeneous data classification.|Rong Jin,Huan Liu","16034|IJCAI|2005|Learning Partially Observable Deterministic Action Models|We present the first tractable, exact solution for the problem of identifying actions' effects in partially observable STRIPS domains. Our algorithms resemble Version Spaces and Logical Filtering, and they identify all the models that are consistent with observations. They apply in other deterministic domains (e.g., with conditional effects), but are inexact (may return false positives) or inefficient (we could not bound the representation size). Our experiments verify the theoretical guarantees, and show that we learn STRIPS actions efficiently, with time that is significantly better than approaches for HMMs and Reinforcement Learning (which are inexact). Our results are especially surprising because of the inherent intractability of the general deterministic case. These results have been applied to an autonomous agent in a virtual world, facilitating decision making, diagnosis, and exploration.|Eyal Amir","16156|IJCAI|2005|Data Complexity of Reasoning in Very Expressive Description Logics|Data complexity of reasoning in description logics (DLs) estimates the performance of reasoning algorithms measured in the size of the ABox only. We show that, even for the very expressive DL SHIQ, satisfiability checking is data complete for NP. For applications with large ABoxes, this can be a more accurate estimate than the usually considered combined complexity, which is EXPTIME-complete. Furthermore, we identify an expressive fragment, Horn-SHIQ, which is data complete for P, thus being very appealing for practical usage.|Ullrich Hustadt,Boris Motik,Ulrike Sattler","16342|IJCAI|2005|Learning Global Models Based on Distributed Data Abstractions|Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.|Xiaofeng Zhang,William K. Cheung","16340|IJCAI|2005|Question Classification by Structure Induction|In this article we introduce a new approach (and several implementations) to the task of question classification. The approach extracts structural information using machine learning techniques and the patterns found are used to classify the questions. The approach fits in between the machine learning and handcrafting of regular expressions (as it was done in the past) and combines the best of both classifiers can be generated automatically and the output can be investigated and manually optimised if needed.|Menno van Zaanen,Luiz Augusto Sangoi Pizzato,Diego Moll√°","16102|IJCAI|2005|Updating Action Domain Descriptions|How can an intelligent agent update her knowledge base about an action domain, relative to some conditions (possibly obtained from earlier observations) We study this question in a formal framework for reasoning about actions and change, in which the meaning of an action domain description can be represented by a directed graph whose nodes correspond to states and whose edges correspond to action occurrences. We define the update of an action domain description in this framework, and show among other results that a solution to this problem can be obtained by a divide-and-conquer approach in some cases. We also introduce methods to compute a solution and an approximate solution to this problem, and analyze the computational complexity of these problems. Finally, we discuss techniques to improve the quality of solutions.|Thomas Eiter,Esra Erdem,Michael Fink,J√°n Senko","16118|IJCAI|2005|Abstraction-based Action Ordering in Planning|Many planning problems contain collections of symmetric objects, actions and structures which render them difficult to solve efficiently. It has been shown that the detection and exploitation of symmetric structure in planning problems can dramatically reduce the size of the search space and the time taken to find a solution. We present the idea of using an abstraction of the problem domain to reveal symmetric structure and guide the navigation of the search space. We show that this is effective even in domains in which there is little accessible symmetric structure available for pruning. Proactive exploitation represents a flexible and powerful alternative to the symmetry-breaking strategies exploited in earlier work in planning and CSPs. The notion of almost symmetry is defined and results are presented showing that proactive exploitation of almost symmetry can improve the performance of a heuristic forward search planner.|Maria Fox,Derek Long,Julie Porteous","16332|IJCAI|2005|Mining Spatial Object Associations for Scientific Data|In this paper, we present efficient algorithms to discover spatial associations among features extracted from scientific datasets. In contrast to previous work in this area, features are modeled as geometric objects rather than points. We define multiple distance metrics that take into account objects' extent. We have developed algorithms to discover two types of spatial association patterns in scientific data. We present experimental results to demonstrate the efficacy of our approach on real datasets drawn from the bioinformatic domain. We also highlight the importance of the discovered patterns by integrating the underlying domain knowledge.|Hui Yang,Srinivasan Parthasarathy,Sameep Mehta"],["16159|IJCAI|2005|Combining Structural Descriptions and Image-based Representations for Image Object and Scene Recognition|Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.|Nicolas Do Huu,Williams Paquier,Raja Chatila","16221|IJCAI|2005|D Shape Classification and Retrieval|We present a novel correspondence-based technique for efficient shape classification and retrieval. Shape boundaries are described by a set of (ad hoc) equally spaced points - avoiding the need to extract \"landmark points\". By formulating the correspondence problem in terms of a simple generative model, we are able to efficiently compute matches that incorporate scale, translation, rotation and reflection invariance. A hierarchical scheme with likelihood cut-off provides additional speed-up. In contrast to many shape descriptors, the concept of a mean (prototype) shape follows naturally in this setting. This enables model based classification, greatly reducing the cost of the testing phase. Equal spacing of points can be defined in terms of either perimeter distance or radial angle. It is shown that combining the two leads to improved classification retrieval performance.|Graham McNeill,Sethu Vijayakumar","16121|IJCAI|2005|Image Retrieval and Disambiguation for Encyclopedic Web Search|To produce multimedia encyclopedic content, we propose a method to search the Web for images associated with a specific word sense. We use text in an HTML file which links to an image as a pseudocaption for the image and perform text-based indexing and retrieval. We use term descriptions in a Web search site called \"CYCLONE\" as queries and correspond images and texts based on word senses.|Atsushi Fujii,Tetsuya Ishikawa","16029|IJCAI|2005|Exploiting Informative Priors for Bayesian Classification and Regression Trees|A general method for defining informative priors on statistical models is presented and applied specifically to the space of classification and regression trees. A Bayesian approach to learning such models from data is taken, with the Metropolis-Hastings algorithm being used to approximately sample from the posterior. By only using proposal distributions closely tied to the prior, acceptance probabilities are easily computable via marginal likelihood ratios, whatever the prior used. Our approach is empirically tested by varying (i) the data, (ii) the prior and (iii) the proposal distribution. A comparison with related work is given.|Nicos Angelopoulos,James Cussens","16168|IJCAI|2005|Semantic Argument Classification Exploiting Argument Interdependence|This paper describes our research on automatic semantic argument classification, using the PropBank data Kingsbury et al., . Previous research employed features that were based either on a full parse or shallow parse of a sentence. These features were mostly based on an individual semantic argument and the relation between the predicate and a semantic argument, but they did not capture the interdependence among all arguments of a predicate. In this paper, we propose the use of the neighboring semantic arguments of a predicate as additional features in determining the class of the current semantic argument. Our experimental results show significant improvement in the accuracy of semantic argument classification after exploiting argument interdependence. Argument classification accuracy on the standard Section  test set improves to .%, representing a relative error reduction of %.|Zheng Ping Jiang,Jia Li,Hwee Tou Ng","16340|IJCAI|2005|Question Classification by Structure Induction|In this article we introduce a new approach (and several implementations) to the task of question classification. The approach extracts structural information using machine learning techniques and the patterns found are used to classify the questions. The approach fits in between the machine learning and handcrafting of regular expressions (as it was done in the past) and combines the best of both classifiers can be generated automatically and the output can be investigated and manually optimised if needed.|Menno van Zaanen,Luiz Augusto Sangoi Pizzato,Diego Moll√°","16210|IJCAI|2005|Relational Object Maps for Mobile Robots|Mobile robot map building is the task of generating a model of an environment from sensor data. Most existing approaches to mobile robot mapping either build topological representations or generate accurate, metric maps of an environment. In this paper we introduce relational object maps, a novel approach to building metric maps that represent individual objects such as doors or walls. We show how to extend relational Markov networks in order to reason about a hierarchy of objects and the spatial relationships between them. Markov chain Monte Carlo is used for efficient inference and to learn the parameters of the model. We show that the spatial constraints modeled by our mapping technique yield drastic improvements for labeling line segments extracted from laser range-finders.|Benson Limketkai,Lin Liao,Dieter Fox","16238|IJCAI|2005|Capturing and Reusing Case-Based Context for Image Retrieval|Like many other application areas, task-based domains that employ digital imagery are faced with the problem of information overload. Modeling the relationship between images and the tasks being performed is an important step in addressing this problem. We have developed an interactive approach for the capture and reuse of image context information that leverages a measure of a user's intentions with regard to tasks that they address. We analyze aspects of human-computer interaction information that enables us to infer why image contents are important in a particular context and how specific images have been used to address particular domain goals.|Dympna O'Sullivan,Eoin McLoughlin,Michela Bertolotto,David C. Wilson","16332|IJCAI|2005|Mining Spatial Object Associations for Scientific Data|In this paper, we present efficient algorithms to discover spatial associations among features extracted from scientific datasets. In contrast to previous work in this area, features are modeled as geometric objects rather than points. We define multiple distance metrics that take into account objects' extent. We have developed algorithms to discover two types of spatial association patterns in scientific data. We present experimental results to demonstrate the efficacy of our approach on real datasets drawn from the bioinformatic domain. We also highlight the importance of the discovered patterns by integrating the underlying domain knowledge.|Hui Yang,Srinivasan Parthasarathy,Sameep Mehta","16095|IJCAI|2005|Inferring Image Templates from Classification Decisions|Assuming human image classification decisions are based on estimating the degree of match between a small number of stored internal templates and certain regions of the input images, we present an algorithm which infers observers classification templates from their classification decisions on a set of test images. The problem is formulated as learning prototypes from labeled data under an adjustable, prototype-specific elliptical metric. The matrix of the elliptical metric indicates the pixels that the template responds to. The model was applied to human psychophysical data collected in a simple image classification experiment.|Arnab Dhua,Florin Cutzu"],["16092|IJCAI|2005|View Learning for Statistical Relational Learning With an Application to Mammography|Statistical relational learning (SRL) constructs probabilistic models from relational databases. A key capability of SRL is the learning of arcs (in the Bayes net sense) connecting entries in different rows of a relational table, or in different tables. Nevertheless, SRL approaches currently are constrained to use the existing database schema. For many database applications, users find it profitable to define alternative \"views\" of the database, in effect defining new fields or tables. Such new fields or tables can also be highly useful in learning. We provide SRL with the capability of learning new views.|Jesse Davis,Elizabeth S. Burnside,In√™s de Castro Dutra,David Page,Raghu Ramakrishnan,V√≠tor Santos Costa,Jude W. Shavlik","16169|IJCAI|2005|Learning with Labeled Sessions|Traditional supervised learning deals with labeled instances. In many applications such as physiological data modeling and speaker identification, however, training examples are often labeled objects and each of the labeled objects consists of multiple unlabeled instances. When classifying a new object, its class is determined by the majority of its instance classes. As a consequence of this decision rule, one challenge to learning with labeled objects (or sessions) is to determine during training which subset of the instances inside an object should belong to the class of the object. We call this type of learning 'session-based learning' to distinguish it from the traditional supervised learning. In this paper, we introduce session-based learning problems, give a formal description of session-based learning in the context of related work, and propose an approach that is particularly designed for session-based learning. Empirical studies with UCI datasets and real-world data show that the proposed approach is effective for session-based learning.|Rong Jin,Huan Liu","16187|IJCAI|2005|Transfer in Learning by Doing|We develop two related themes, learning procedures and knowledge transfer. This paper introduces two methods for learning procedures and one for transferring previously-learned knowledge to a slightly different task. We demonstrate by experiment that transfer accelerates learning.|William Krueger,Tim Oates,Tom Armstrong,Paul R. Cohen,Carole R. Beal","16096|IJCAI|2005|Learning Web Page Scores by Error Back-Propagation|In this paper we present a novel algorithm to learn a score distribution over the nodes of a labeled graph (directed or undirected). Markov Chain theory is used to define the model of a random walker that converges to a score distribution which depends both on the graph connectivity and on the node labels. A supervised learning task is defined on the given graph by assigning a target score for some nodes and a training algorithm based on error backpropagation through the graph is devised to learn the model parameters. The trained model can assign scores to the graph nodes generalizing the criteria provided by the supervisor in the examples. The proposed algorithm has been applied to learn a ranking function for Web pages. The experimental results show the effectiveness of the proposed technique in reorganizing the rank accordingly to the examples provided in the training set.|Michelangelo Diligenti,Marco Gori,Marco Maggini","16093|IJCAI|2005|Learning Forward Models for Robots|Forward models enable a robot to predict the effects of its actions on its own motor system and its environment. This is a vital aspect of intelligent behaviour, as the robot can use predictions to decide the best set of actions to achieve a goal. The ability to learn forward models enables robots to be more adaptable and autonomous this paper describes a system whereby they can be learnt and represented as a Bayesian network. The robot's motor system is controlled and explored using 'motor babbling'. Feedback about its motor system comes from computer vision techniques requiring no prior information to perform tracking. The learnt forward model can be used by the robot to imitate human movement.|Anthony M. Dearden,Yiannis Demiris","16233|IJCAI|2005|A Machine Learning Approach to Identification and Resolution of One-Anaphora|We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.|Hwee Tou Ng,Yu Zhou,Robert Dale,Mary Gardiner","16082|IJCAI|2005|Stacked Sequential Learning|We describe a new sequential learning scheme called \"stacked sequential learning\". Stacked sequential learning is a meta-learning algorithm, in which an arbitrary base learner is augmented so as to make it aware of the labels of nearby examples. We evaluate the method on several \"sequential partitioning problems\", which are characterized by long runs of identical labels. We demonstrate that on these problems, sequential stacking consistently improves the performance of nonsequential base learners that sequential stacking often improves performance of learners (such as CRFs) that are designed specifically for sequential tasks and that a sequentially stacked maximum-entropy learner generally outperforms CRFs.|William W. Cohen,Vitor Rocha de Carvalho","16138|IJCAI|2005|fMRI Analysis via One-class Machine Learning Techniques|We show how one-class compression Neural Networks and one-class SVM can be applied to fMRI data to learn the classification of brain activity associated with a specific motor activity. For comparison purposes, we use two labeled data and see what degree of classification ability is lost compared with the usual two-class SVM.|David R. Hardoon,Larry M. Manevitz","16139|IJCAI|2005|Learning Coordination Classifiers|We present a new approach to ensemble classification that requires learning only a single base classifier. The idea is to learn a classifier that simultaneously predicts pairs of test labels--as opposed to learning multiple predictors for single test labels-- then coordinating the assignment of individual labels by propagating beliefs on a graph over the data. We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data. In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers. Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination.|Yuhong Guo,Russell Greiner,Dale Schuurmans","16085|IJCAI|2005|Learning to Understand Web Site Update Requests|Although Natural Language Processing (NLP) for requests for information has been well-studied, there has been little prior work on understanding requests to update information. In this paper, we propose an intelligent system that can process natural language website update requests semi-automatically. In particular, this system can analyze requests, posted via email, to update the factual content of individual tuples in a database-backed website. Users' messages are processed using a scheme decomposing their requests into a sequence of entity recognition and text classification tasks. Using a corpus generated by human-subject experiments, we experimentally evaluate the performance of this system, as well as its robustness in handling request types not seen in training, or user-specific language styles not seen in training.|William W. Cohen,Einat Minkov,Anthony Tomasic"],["16122|IJCAI|2005|Feature Generation for Text Categorization Using World Knowledge|We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.|Evgeniy Gabrilovich,Shaul Markovitch","16183|IJCAI|2005|Using Neutral Examples for Learning Polarity|Sentiment analysis is an example of polarity learning. Most research on learning to identify sentiment ignores \"neutral\" examples and instead performs training and testing using only examples of significant polarity. We show that it is crucial to use neutral examples in learning polarity for a variety of reasons and show how neutral examples help us obtain superior classification results in two sentiment analysis test-beds.|Moshe Koppel,Jonathan Schler","16173|IJCAI|2005|Signal-to-Score Music Transcription using Graphical Models|We present a transcription system that takes a music signal as input and returns its musical score. Two stages of processing are used. The first employs a fundamental frequency detector and an onset detector to transform input signals into a sequence of sound events. The onset detection is inherently noisy. This paper focuses on the second stage, going from sound events to a notated score. We use a family of graphical models for this task. We allow the results of onset detection to be noisy, necessitating a search over possible segmentations of the sound events. We use a large corpus of monophonic vocal music to evaluate our system. Our results show that our approach is well-suited to the problem of music transcription. The initial onset detection reduces the number of observations and makes the system less instrument specific. The search over segmentations corrects the errors in the onset detection. Without such reasoning, these errors are magnified in subsequent rhythm transcription.|Emir Kapanci,Avi Pfeffer","16206|IJCAI|2005|Location-Based Activity Recognition using Relational Markov Networks|In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.|Lin Liao,Dieter Fox,Henry A. Kautz","16142|IJCAI|2005|Real-Time Path Planning for Humanoid Robot Navigation|We present a data structure and an algorithm for real-time path planning of a humanoid robot. Due to the many degrees of freedom, the robots shape and available actions are approximated for finding solutions efficiently. The resulting  dimensional configuration space is searched by the A* algorithm finding solutions in tenths of a second on lowperformance, embedded hardware. Experimental results demonstrate our solution for a robot in a world containing obstacles with different heights, stairs and a higher-level platform.|Jens-Steffen Gutmann,Masaki Fukuchi,Masahiro Fujita","16246|IJCAI|2005|Multi-Agent Assumption-Based Planning|The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.|Damien Pellier,Humbert Fiorino","16165|IJCAI|2005|Path-Planning for Autonomous Training on Robot Manipulators in Space|This paper describes the integration of robot path-planning and spatial task modeling into a software system that teaches the operation of a robot manipulator deployed on International Space Station (ISS). The system addresses the complexity of the manipulator, the limited direct view of the ISS exterior and the unpredictability of lighting conditions in the workspace. Robot path planning is used not for controlling the manipulator, but for automatically checking errors of a student learning to operate the manipulator and for automatically producing illustrations of good and bad motions in training.|Froduald Kabanza,Roger Nkambou,Khaled Belghith","16110|IJCAI|2005|Multi-agent Coordination using Local Search|We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.|Boi Faltings,Quang Huy Nguyen 0003","16163|IJCAI|2005|Using core beliefs for point-based value iteration|Recent research on point-based approximation algorithms for POMDPs demonstrated that good solutions to POMDP problems can be obtained without considering the entire belief simplex. For instance, the Point Based Value Iteration (PBVI) algorithm Pineau et al.,  computes the value function only for a small set of belief states and iteratively adds more points to the set as needed. A key component of the algorithm is the strategy for selecting belief points, such that the space of reachable beliefs is well covered. This paper presents a new method for selecting an initial set of representative belief points, which relies on finding first the basis for the reachable belief simplex. Our approach has better worst-case performance than the original PBVI heuristic, and performs well in several standard POMDP tasks.|Masoumeh T. Izadi,Ajit V. Rajwade,Doina Precup","16118|IJCAI|2005|Abstraction-based Action Ordering in Planning|Many planning problems contain collections of symmetric objects, actions and structures which render them difficult to solve efficiently. It has been shown that the detection and exploitation of symmetric structure in planning problems can dramatically reduce the size of the search space and the time taken to find a solution. We present the idea of using an abstraction of the problem domain to reveal symmetric structure and guide the navigation of the search space. We show that this is effective even in domains in which there is little accessible symmetric structure available for pruning. Proactive exploitation represents a flexible and powerful alternative to the symmetry-breaking strategies exploited in earlier work in planning and CSPs. The notion of almost symmetry is defined and results are presented showing that proactive exploitation of almost symmetry can improve the performance of a heuristic forward search planner.|Maria Fox,Derek Long,Julie Porteous"]]}}