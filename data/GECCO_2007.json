{"abstract":{"entropy":5.716431034084034,"topics":["particle swarm, optimization problem, optimization algorithm, evolutionary algorithm, hierarchical bayesian, genetic gas, multi-objective algorithm, building blocks, swarm optimization, particle optimization, multiobjective optimization, algorithm problem, multi-objective optimization, multi-objective evolutionary, hierarchical algorithm, algorithm gas, scheduling problem, evolutionary optimization, swarm pso, particle pso","genetic algorithm, genetic programming, evolutionary algorithm, describe algorithm, estimation distribution, real world, algorithm applied, describe genetic, distribution algorithm, use algorithm, paper describe, evolutionary programming, crossover mutation, paper algorithm, crossover, estimation algorithm, genetic problem, genetic crossover, hybrid algorithm, concept evolutionary","learning classifier, artificial immune, immune systems, systems, classifier systems, novel approach, learning systems, problem detection, use design, artificial systems, describe use, learning, systems control, presents artificial, classifier approach, novel algorithm, presents approach, artificial problem, use learning, artificial","data mining, evolutionary computation, genetic approaches, problem function, presents, genetic network, methods genetic, work presents, presents framework, presents algorithm, presents evolutionary, work, presents genetic, data, important, methods, effort, information, genetic problem, network","genetic gas, hierarchical bayesian, hierarchical optimization, hierarchical algorithm, algorithm gas, bayesian optimization, solve problem, algorithm solve, solve optimization, hierarchical problem, bayesian algorithm, optimization algorithm, genetic problem, algorithm problem, evolution","search, heuristics, robust, field, last, consider, optimal, dynamic","genetic crossover, algorithm crossover, analyze algorithm, genetic applied, algorithm applied, crossover, class, random, operators","real world, selection, introduced, mutation, parameters, strategies, recently, evolution","xcs, introduces, model, population, extension, performance, called","novel approach, novel algorithm, approach, evolution, presented, presents, evaluation, evolutionary, function, use","problem function, presents, function, important, domain","data, data mining, information, dna, interaction, analysis, large"],"ranking":[["58046|GECCO|2007|Obtaining ground states of ising spin glasses via optimizing bonds instead of spins|Frustrated Ising spin glasses represent a rich class of challenging optimization problems that share many features with other complex, highly multimodal optimization and combinatorial problems. This paper shows that transforming candidate solutions to an alternative representation that is strongly tied to the energy function simplifies the exploration of the space of potential spin configurations and that it significantly improves performance of evolutionary algorithms with simple variation operators on Ising spin glasses. The proposed techniques are incorporated into the simple genetic algorithm, the univariate marginal distribution algorithm, and the hierarchical Bayesian optimization algorithm.|Martin Pelikan,Alexander K. Hartmann","58190|GECCO|2007|Multi-objective hybrid PSO using -fuzzy dominance|This paper describes a PSO-Nelder Mead Simplex hybrid multi-objective optimization algorithm based on a numerical metric called  -fuzzy dominance. Within each iteration of this approach, in addition to the position and velocity update of each particle using PSO, the k-means algorithm is applied to divide the population into smaller sized clusters. The Nelder-Mead simplex algorithm is used separately within each cluster for added local search. The proposed algorithm is shown to perform better than MOPSO on several test problems as well as for the optimization of a genetic model for flowering time control in Arabidopsis. Adding the local search achieves faster convergence, an important feature in computationally intensive optimization of gene networks.|Praveen Koduru,Sanjoy Das,Stephen Welch","58025|GECCO|2007|A heuristic particle swarm optimization|A heuristic version of the particle swarm optimization (PSO) is introduced in this paper. In this new method called \"The heuristic particle swarm optimization(HPSO)\", we use heuristics to choose the next particle to update its velocity and position. By using heuristics , the convergence rate to local minimum is faster. To avoid premature convergence of the swarm, the particles are re-initialized with random velocity when moving too close to the global best position. The combination of heuristics and re-initialization mechanism make HPSO outperform the basic PSO and recent versions of PSO.|Hoang Thanh Lam,Popova Nina Nicolaevna,Nguyen Thoi Minh Quan","58085|GECCO|2007|MRPSO MapReduce particle swarm optimization|In optimization problems involving large amounts of data, Particle Swarm Optimization (PSO) must be parallelized because individual function evaluations may take minutes or even hours. However, large-scale parallelization is difficult because programs must communicate efficiently, balance workloads and tolerate node failures. To address these issues, we present Map Reduce Particle Swarm Optimization(MRPSO), a PSO implementation based on Google's Map Reduce parallel programming model.|Andrew W. McNabb,Christopher K. Monson,Kevin D. Seppi","57994|GECCO|2007|Particle swarm guided evolution strategy|Evolution strategy (ES) and particle swarm optimization (PSO) are two of the most popular research topics for tackling real-parameter optimization problems in evolutionary computation. Both of them have strengths and weaknesses for their different search behaviors and methodologies. In ES, mutation, as the main operator, tries to find good solutions around each individual. While in PSO, particles are moving toward directions determined by certain global information, such as the global best particle. In order to leverage the specialties offered by both sides to our advantage, this paper combines the essential mechanism of ES and the key concept of PSO to develop a new hybrid optimization methodology, called particle swarm guided evolution strategy. We introduce swarm intelligence to the ES mutation framework to create a new mutation operator, called guided mutation, and integrate the guided mutation operator into ES. Numerical experiments are conducted on a set of benchmark functions, and the experimental results indicate that PSGES is a promising optimization methodology as well as an interesting research direction.|Chang-Tai Hsieh,Chih-Ming Chen,Ying-Ping Chen","58032|GECCO|2007|Applying particle swarm optimization to software testing|Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with  small artificial test objects and  more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.|Andreas Windisch,Stefan Wappler,Joachim Wegener","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","58203|GECCO|2007|Hybrid evolutionary algorithms on minimum vertex cover for random graphs|This paper analyzes the hierarchical Bayesian optimization algorithm (hBOA) on minimum vertex cover for standard classes of random graphs and transformed SAT instances. The performance of hBOA is compared with that of the branch-and-bound problem solver (BB), the simple genetic algorithm (GA) and the parallel simulated annealing (PSA). The results indicate that BB is significantly outperformed by all the other tested methods, which is expected as BB is a complete search algorithm and minimum vertex cover is an NP-complete problem. The best performance is achieved with hBOA nonetheless, the performance differences between hBOA and other evolutionary algorithms are relatively small, indicating that mutation-based search and recombination-based search lead to similar performance on the tested problem instances.|Martin Pelikan,Rajiv Kalapala,Alexander K. Hartmann","58186|GECCO|2007|A multi-objective imaging scheduling approach for earth observing satellites|EOSs (Earth Observing Satellites) circle the earth to take shotswhich are requested by customers. To make replete use of resourcesof EOSs, it is required to deal with the problem of united imagingscheduling of EOSs in a given scheduling horizon, which is acomplicated multi-objective combinatorial optimization problem. Inthis paper, we construct a mathematical model for the problem byabstracting imaging constraints of different EOSs. Then we propose anovel multi-objective EOSs imaging scheduling method, which is basedon the Strength Pareto Evolutionary Algorithm . The specialencoding technique and imaging constraint control are applied toguarantee feasibility of solutions. The approach is tested upon fourreal application problems of CBERS EOSs series. From the results, itis confirmed that the proposed approach is effective in solvingmulti-objective EOSs imaging scheduling problems.|Jun Wang,Ning Jing,Jun Li,Zhong Hui Chen","57996|GECCO|2007|Why is parity hard for estimation of distribution algorithms|We describe a k-bounded and additively separable test problem on which the hierarchical Bayesian Optimization Algorithm (hBOA) scales exponentially.|David Jonathan Coffin,Robert Elliott Smith"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","58046|GECCO|2007|Obtaining ground states of ising spin glasses via optimizing bonds instead of spins|Frustrated Ising spin glasses represent a rich class of challenging optimization problems that share many features with other complex, highly multimodal optimization and combinatorial problems. This paper shows that transforming candidate solutions to an alternative representation that is strongly tied to the energy function simplifies the exploration of the space of potential spin configurations and that it significantly improves performance of evolutionary algorithms with simple variation operators on Ising spin glasses. The proposed techniques are incorporated into the simple genetic algorithm, the univariate marginal distribution algorithm, and the hierarchical Bayesian optimization algorithm.|Martin Pelikan,Alexander K. Hartmann","57887|GECCO|2007|An application of EDA and GA to dynamic pricing|E-commerce has transformed the way firms develop their pricing strategies, producing shift away from fixed pricing to dynamic pricing. In this paper, we use two different Estimation of distribution algorithms (EDAs), a Genetic Algorithm (GA) and a Simulated Annealing (SA) algorithm for solving two different dynamic pricing models. Promising results were obtained for an EDA confirming its suitability for resource management in the proposed model. Our analysis gives interesting insights into the application of population based optimization techniques for dynamic pricing.|Siddhartha Shakya,Fernando Oliveira,Gilbert Owusu","57893|GECCO|2007|A data parallel approach to genetic programming using programmable graphics hardware|In recent years the computing power of graphics cards has increased significantly. Indeed, the growth in the computing power of these graphics cards is now several orders of magnitude greater than the growth in the power of computer processor units. Thus these graphics cards are now beginning to be used by the scientific community aslow cost, high performance computing platforms. Traditional genetic programming is a highly computer intensive algorithm but due to its parallel nature it can be distributed over multiple processors to increase the speed of the algorithm considerably. This is not applicable for single processor architectures but graphics cards provide a mechanism for developing a data parallel implementation of genetic programming. In this paper we will describe the technique of general purpose computing using graphics cards and how to extend this technique to genetic programming. We will demonstrate the improvement in the performance of genetic programming on single processor architectures which can be achieved by harnessing the computing power of these next generation graphics cards.|Darren M. Chitty","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","57932|GECCO|2007|Genetically designed multiple-kernels for improving the SVM performance|Classical kernel-based classifiers only use a single kernel, butthe real world applications have emphasized the need to con-sider a combination of kernels also known as a multiple kernel in order to boost the performance. Our purpose isto automatically find the mathematical expression of a multiple kernel by evolutionary means. In order to achieve this purpose we propose a hybrid model that combines a Genetic Programming (GP) algorithm and a kernel-based Support Vector Machine (SVM) classifier. Each GP chromosome isa tree encoding the mathematical expression of a multiple kernel. Numerical experiments show that the SVM embedding the evolved multiple kernel performs better than the standard kernels for the considered classification problems.|Laura Diosan,Mihai Oltean,Alexandrina Rogozan,Jean-Pierre Pécuchet","57939|GECCO|2007|Peer-to-peer evolutionary algorithms with adaptive autonomous selection|In this paper we describe and evaluate a fully distributed PP evolutionary algorithm (EA) with adaptive autonomous selection. Autonomous selection means that decisions regarding survival and reproduction are taken by the individuals themselves independently, without any central control.This allows for a fully distributed EA, where not only reproduction (crossover and mutation) but also selection is performed at local level. An unwanted consequence of adding and removing individuals in a non-synchronized manner is that the population size gets out of control too. This problem is resolved by addingan adaptation mechanism allowing individuals to regulate their own selection pressure. The key tothis is a gossiping algorithm that enables individuals to maintain estimates on the size andthe fitness of the population. The algorithm is experimentally evaluated on a test problem to show the viability of the idea and to gain insight into the run-time dynamics of such an algorithm. The results convincingly demonstrate the feasibility of a fully decentralized EA in which the population size can be kept stable.|W. R. M. U. K. Wickramasinghe,Maarten van Steen,A. E. Eiben","57885|GECCO|2007|Empirical analysis of ideal recombination on random decomposable problems|This paper analyzes the behavior of a selectorecombinative genetic algorithm (GA) with an ideal crossover on a class of random additively decomposable problems (rADPs). Specifically, additively decomposable problems of order k whose subsolution fitnesses are sampled from the standard uniform distribution U, are analyzed. The scalability of the selectorecombinative GA is investigated for , rADP instances. The validity of facetwise models in bounding the population size, run duration, and the number of function evaluations required to successfully solve the problems is also verified. Finally, rADP instances that are easiest and most difficult are also investigated.|Kumara Sastry,Martin Pelikan,David E. Goldberg","58010|GECCO|2007|Global multiobjective optimization via estimation of distribution algorithm with biased initialization and crossover|Multiobjective optimization problems with many local Pareto fronts is a big challenge to evolutionary algorithms. In this paper, two operators, biased initialization and biased crossover, are proposed to improve the global search ability of RM-MEDA, a recently proposed multiobjective estimation of distribution algorithm. Biased initialization inserts several globally Pareto optimal solutions into the initial population biased crossover combines the location information of some best solutions found so far and globally statistical information extracted from current population. Experiments have been conducted to study the effects of these two operators.|Aimin Zhou,Qingfu Zhang,Yaochu Jin,Bernhard Sendhoff,Edward P. K. Tsang","57969|GECCO|2007|Dependency trees permutations and quadratic assignment problem|This paper describes and analyzes an estimation of distribution algorithm based on dependency tree models (dtEDA), which can explicitly encode probabilistic models for permutations. dtEDA is tested on deceptive ordering problems and a number of instances of the quadratic assignment problem. The performance of dtEDA is compared to that of the standard genetic algorithm with the partially matched crossover (PMX) and the linear order crossover (LOX). In the quadratic assignment problem, the robust tabu search is also included in the comparison.|Martin Pelikan,Shigeyoshi Tsutsui,Rajiv Kalapala"],["57958|GECCO|2007|Dendritic cells for SYN scan detection|Artificial immune systems have previously been applied to the problem of intrusion detection. The aim of this research is to develop an intrusion detection system based on the function of Dendritic Cells (DCs). DCs are antigen presenting cells and key to the activation of the human immune system, behaviour which has been abstracted to form the Dendritic Cell Algorithm (DCA). In algorithmic terms, individual DCs perform multi-sensor data fusion, asynchronously correlating the fused data signals with a secondary data stream. Aggregate output of a population of cells is analysed and forms the basis of an anomaly detection system. In this paper the DCA is applied to the detection of outgoing port scans using TCP SYN packets. Results show that detection can be achieved with the DCA, yet some false positives can be encountered when simultaneously scanning and using other network services. Suggestions are made for using adaptive signals to alleviate this uncovered problem.|Julie Greensmith,Uwe Aickelin","58163|GECCO|2007|Artificial ecosystems for creative discovery|This paper discusses the concept of an artificial ecosystem for use in machine-assisted creative discovery. Properties and processes from natural ecosystems are abstracted and applied to the design of creative systems, in a similar way that evolutionary computing methods use the metaphor of Darwinian evolution to solve problems in search and optimisation. The paper examines some appropriate mechanisms and metaphors when applying artificial ecosystems to problems in creative design. General properties and processes of evolutionary artificial ecosystems are presented as a basis for developing individual systems that automate the discovery of novelty without explicit teleological goals. The adaptation of species to fit their environment drives the creative solutions, so the role of the designer shifts to the design of environments. This allows a variety of creative solutions to emerge in simulation without the need for explicit or human-evaluated fitness measures, such as those used in interactive evolution. Two example creative ecosystems are described to highlight the effectiveness of the method presented.|Jon McCormack","58133|GECCO|2007|MILCS a mutual information learning classifier system|This paper introduces a new variety of learning classifier system (LCS), called MILCS, which utilizes mutual information as fitness feedback. Unlike most LCSs, MILCS is specifically designed for supervised learning. MILCS's design draws on an analogy to the structural learning approach of cascade correlation networks. We present preliminary results, and contrast them to results from XCS. We discuss the explanatory power of the resulting rule sets, and introduce a new technique for visualizing explanatory power. Final comments include future directions for this research, including investigations in neural networks and other systems.|Robert Elliott Smith,Max Kun Jiang","58189|GECCO|2007|Extended thymus action for reducing false positives in ais based network intrusion detection systems|One of the major problems faced by anomaly based Network Intrusion Detection (NID) systems is the high number of false positives. False positives refer to the false detection of normal behavior as malicious behavior. Artificial Immune Systems (AISs) also fall under the category of anomaly based-NID systems. AIS presented in this paper is as a victim-end filter, consisting of detectors distributed on the network, which distinguishes normal traffic from malicious traffic. In this work, we focus on TCP-SYN flood based Distributed Denial of Services (DDoS) attacks. Light Weight Intrusion Detection System (LISYS) provides the basic framework for AIS based NID systems. AISs normally utilize the negative selection algorithm in thymus action to tolerize the detectors to normal traffic so they may not detect normal traffic as malicious traffic. We propose and implement extended thymus action' model to improve this characteristic of AIS. Results verify that our model significantly reduces false positives which is a major concern in anomaly-based NID systems.|M. Zubair Shafiq,Mehrin Kiani,Bisma Hashmi,Muddassar Farooq","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","57971|GECCO|2007|Towards clustering with XCS|This paper presents a novel approach to clustering using an accuracy-based Learning Classifier System. Our approach achieves this by exploiting the generalization mechanisms inherent to such systems. The purpose of the work is to develop an approach to learning rules which accurately describe clusters without prior assumptions as to their number within a given dataset. Favourable comparisons to the commonly used k-means algorithm are demonstrated on a number of synthetic datasets.|Kreangsak Tamee,Larry Bull,Ouen Pinngern","58016|GECCO|2007|An artificial immune system with partially specified antibodies|Artificial Immune System algorithms use antibodies which fully specify the solution of an optimization, learning, or pattern recognition problem. By being restricted to fully specified antibodies, an AIS algorithm can not make use of schemata or classes of partial solutions. This paper presents a symbiotic artificial immune system (SymbAIS) algorithm which is an extension of CLONALG algorithm. It uses partially specified antibodies and gradually builds up building blocks of suitable sub-antibodies. The algorithm is compared with CLONALG on multimodal function optimization and combinatorial optimization problems and it is shown that it can solve problems that CLONALG is unable to solve.|Ramin Halavati,Saeed Bagheri Shouraki,Mojdeh Jalali Heravi,Bahareh Jafari Jashmi","58017|GECCO|2007|Procreating V-detectors for nonself recognition an application to anomaly detection in power systems|The artificial immune system approach for self-nonself discrimination and its application to anomaly detection problems in engineering is showing great promise. A seminal contribution in this area is the V-detectors algorithm that can very effectively cover the nonself region of the feature space with a set of detectors. The detector set can be used to detect anomalous inputs. In this paper, a multistage approach to create an effective set of V-detectors is considered. The first stage of the algorithm generates an initial set of V-detectors. In subsequent stage, new detectors are grown from existing ones, by means of a mechanism called procreation. Procreating detectors can more effectively fill hard-to-reach interstices in the nonself region, resulting in better coverage. The effectiveness of the algorithm is first illustrated by applying it to a well-known fractal, the Koch curve. The algorithm is then applied to the problem of detecting anomalous behavior in power distribution systems, and can be of much use for maintenance-related decision-making in electrical utility companies.|Min Gui,Sanjoy Das,Anil Pahwa","58183|GECCO|2007|Keyword extraction using an artificial immune system|This paper presents a model for keyword extraction which combines an artificial immune system with a mathematical background based on information theory. The proposed approach does not need any domain knowledge, neither the use of a stopword list. The output is a set of keywords for each of the categories into the corpus used.|Andres Romero,Fernando Niño","58230|GECCO|2007|Mixing independent classifiers|In this study we deal with the mixing problem, which concerns combining the prediction of independently trained local models to form a global prediction. We deal with it from the perspective of Learning Classifier Systems where a set of classifiers provide the local models. Firstly, we formalise the mixing problem and provide both analytical and heuristic approaches to solving it. The analytical approaches are shown to not scale well with the number of local models, but are nevertheless compared to heuristic models in a set of function approximation tasks. These experiments show that we can design heuristics that exceed the performance of the current state-of-the-art Learning Classifier System XCS, and are competitive when compared to analytical solutions. Additionally, we provide an upper bound on the prediction errors for the heuristic mixing approaches.|Jan Drugowitsch,Alwyn Barry"],["57912|GECCO|2007|Using genetic programming for information retrieval local and global query expansion|This poster presents results for two approaches using Genetic Programming (GP) to overcome the problem of term mismatch in Information Retrieval (IR). We use automatic query expansion techniques which add terms to a user's initial query in the hope that these words better describe the information need and ultimately return more relevant documents to the user.|Ronan Cummins,Colm O'Riordan","58157|GECCO|2007|Towards billion-bit optimization via a parallel estimation of distribution algorithm|This paper presents a highly efficient, fully parallelized implementation of the compact genetic algorithm (cGA) to solve very large scale problems with millions to billions of variables. The paper presents principled results demonstrating the scalable solution of a difficult test function on instances over a billion variables using a parallel implementation of cGA. The problem addressed is a noisy, blind problem over a vector of binary decision variables. Noise is added equaling up to a tenth of the deterministic objective function variance of the problem, thereby making it difficult for simple hillclimbers to find the optimal solution. The compact GA, on the other hand, is able to find the optimum in the presence of noise quickly, reliably, and accurately, and the solution scalability follows known convergence theories. These results on noisy problem together with other results on problems involving varying modularity, hierarchy, and overlap foreshadow routine solution of billion-variable problems across the landscape of search problems.|Kumara Sastry,David E. Goldberg,Xavier Llorà","58060|GECCO|2007|Volatility forecasting using time series data mining and evolutionary computation techniques|Traditional parametric methods have limited success in estimating and forecasting the volatility of financial securities. Recent advance in evolutionary computation has provided additional tools to conduct data mining effectively. The current work applies the genetic programming in a Time Series Data Mining framework to characterize the S&P high frequency data in order to forecast the one step ahead integrated volatility. Results of the experiment have shown to be superior to those derived by the traditional methods.|Irwin Ma,Tony Wong,Thiagas Sankar","57948|GECCO|2007|Automated trading on financial instruments with evolved neural networks|This paper presents an approach to single-position, intraday automated trading based on a neuro-genetic algorithm.An artificial neural network is evolved which provides trading signals to a very unsophisticated automated trading agent.|Antonia Azzini,Andrea Tettamanzi","58057|GECCO|2007|Synthesis of analog filters on an evolvable hardware platform using a genetic algorithm|This work presents a novel approach to filter synthesis on a fieldprogrammable analog array (FPAA) architecture using a genetic algorithm (GA). First, a Matlab model of the FPAA is created and verified for compliance with transistor-level simulations of the FPAA. Using this model, differentfilter structures are built using an active-RC approach and evaluated. Secondly, a robust genetic algorithm is implemented in Matlab, which allows synthesis of analog filters on the given structure. Optimal parameters and operators of the genetic algorithm are identified by gradual adaptation andperformance evaluation, and the general feasibility is shown. Finally, the GA is used to overcome quantization-limitations of the FPAA structure and find configurations of filters, which would not have been achievable with traditional synthesis methods. The system is not only a platform for theoretical investigation offilter structures on the given chip structure but also provides aframework for evolution and instantiation of filters on actual chiphardware.|Joachim Becker,Stanis Trendelenburg,Fabian Henrici,Yiannos Manoli","57947|GECCO|2007|A NSGA-II web-enabled parallel optimization framework for NLP and MINLP|Engineering design increasingly uses computer simulation models coupled with optimization algorithms to find the best design that meets the customer constraints within a time constrained deadline. The continued application of Moore's law combined with linear speedups of coarse grained parallelization will allow more designs to be evaluated in shorter periods of time. This paper presents a scalable, standards based framework that uses web services and grid services with a multiple objective genetic algorithm to solve continuous, mixed integer, single objective or multiple objective nonlinear, constrained design problems. Test data is provided to validate a linear speedup based on the number of processors and to show the robustness of the genetic algorithm on a set of  design problems.|David J. Powell,Joel K. Hollingsworth","58240|GECCO|2007|Symbiotic tabu search|Recombination in the Genetic Algorithm (GA) is supposed to extract the component characteristics from two parents and reassemble them in different combinations hopefully producing an offspring that has the good characteristics of both parents. Symbiotic Combination is formerly introduced as an alternative for sexual recombination operator to overcome the need of explicit design of recombination operators in GA all. This paper presents an optimization algorithm based on using this operator in Tabu Search. The algorithm is benchmarked on two problem sets and is compared with standard genetic algorithm and symbiotic evolutionary adaptation model, showing success rates higher than both cited algorithms.|Ramin Halavati,Saeed Bagheri Shouraki,Bahareh Jafari Jashmi,Mojdeh Jalali Heravi","58247|GECCO|2007|Evolving virtual creatures revisited|Thirteen years have passed since Karl Sims published his work on evolving virtual creatures. Since then,several novel approaches to neural network evolution and genetic algorithms have been proposed. The aim of our work is to apply recent results in these areas to the virtual creatures proposed by Karl Sims, leading to creatures capable of solving more complex tasks. This paper presents our success in reaching the first milestone -a new and complete implementation of the original virtual creatures. All morphological and control properties of the original creatures were implemented. Laws of physics are simulated using ODE library. Distributed computation is used for CPU-intensive tasks, such as fitness evaluation.Experiments have shown that our system is capable of evolving both morphology and control of the creatures resulting in a variety of non-trivial swimming and walking strategies.|Peter Krcah","58205|GECCO|2007|The multi-objective next release problem|This paper is concerned with the Multi-Objective Next Release Problem (MONRP), a problem in search-based requirements engineering. Previous work has considered only single objective formulations. In the multi-objective formulation, there are at least two (possibly conflicting) objectives that the software engineer wishes to optimize. It is argued that the multi-objective formulation is more realistic, since requirements engineering is characterised by the presence of many complex and conflicting demands, for which the software engineer must find a suitable balance. The paper presents the results of an empirical study into the suitability of weighted and Pareto optimal genetic algorithms, together with the NSGA-II algorithm, presenting evidence to support the claim that NSGA-II is well suited to the MONRP. The paper also provides benchmark data to indicate the size above which the MONRP becomes non--trivial.|Yuanyuan Zhang,Mark Harman,S. Afshin Mansouri","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao"],["58129|GECCO|2007|A chain-model genetic algorithm for Bayesian network structure learning|Bayesian Networks are today used in various fields and domains due to their inherent ability to deal with uncertainty. Learning Bayesian Networks, however is an NP-Hard task . The super exponential growth of the number of possible networks given the number of factors in the studied problem domain has meant that more often, approximate and heuristic rather than exact methods are used. In this paper, a novel genetic algorithm approach for reducing the complexity of Bayesian network structure discovery is presented. We propose a method that uses chain structures as a model for Bayesian networks that can be constructed from given node orderings. The chain model is used to evolve a small number of orderings which are then injected into a greedy search phase which searches for an optimal structure. We present a series of experiments that show a significant reduction can be made in computational cost although with some penalty in success rate.|Ratiba Kabli,Frank Herrmann,John McCall","58046|GECCO|2007|Obtaining ground states of ising spin glasses via optimizing bonds instead of spins|Frustrated Ising spin glasses represent a rich class of challenging optimization problems that share many features with other complex, highly multimodal optimization and combinatorial problems. This paper shows that transforming candidate solutions to an alternative representation that is strongly tied to the energy function simplifies the exploration of the space of potential spin configurations and that it significantly improves performance of evolutionary algorithms with simple variation operators on Ising spin glasses. The proposed techniques are incorporated into the simple genetic algorithm, the univariate marginal distribution algorithm, and the hierarchical Bayesian optimization algorithm.|Martin Pelikan,Alexander K. Hartmann","57879|GECCO|2007|Adopting dynamic operators in a genetic algorithm|Genetic Algorithms have been used to solve difficult optimization problems in a number of fields. However, in order to solve a problem with GA, the user has to specify a number of parameters.allThis parameter tuning is a difficult task as different genetic operators are suitable in different application areas. This paper proposes a scheme for genetic algorithms where the genetic operators are changed randomly. The information of gender and age is also incorporated in this approach to maintain population diversity. The experimental result of the proposed algorithm based on a mechanical design problem shows promising result.|Khadiza Tahera,Raafat N. Ibrahim,Paul B. Lochert","58243|GECCO|2007|Analyzing probabilistic models in hierarchical BOA on traps and spin glasses|The hierarchical Bayesian optimization algorithm (hBOA) can solve nearly decomposable and hierarchical problems of bounded difficulty in a robust and scalable manner by building and sampling probabilistic models of promising solutions. This paper analyzes probabilistic models in hBOA on two common test problems concatenated traps and D Ising spin glasses with periodic boundary conditions. We argue that although Bayesian networks with local structures can encode complex probability distributions, analyzing these models in hBOA is relatively straightforward and the results of such analyses may provide practitioners with useful information about their problems. The results show that the probabilistic models in hBOA closely correspond to the structure of the underlying optimization problem, the models do not change significantly in subsequent iterations of BOA, and creating adequate probabilistic models by hand is not straightforward even with complete knowledge of the optimization problem.|Mark Hauschild,Martin Pelikan,Cláudio F. Lima,Kumara Sastry","58203|GECCO|2007|Hybrid evolutionary algorithms on minimum vertex cover for random graphs|This paper analyzes the hierarchical Bayesian optimization algorithm (hBOA) on minimum vertex cover for standard classes of random graphs and transformed SAT instances. The performance of hBOA is compared with that of the branch-and-bound problem solver (BB), the simple genetic algorithm (GA) and the parallel simulated annealing (PSA). The results indicate that BB is significantly outperformed by all the other tested methods, which is expected as BB is a complete search algorithm and minimum vertex cover is an NP-complete problem. The best performance is achieved with hBOA nonetheless, the performance differences between hBOA and other evolutionary algorithms are relatively small, indicating that mutation-based search and recombination-based search lead to similar performance on the tested problem instances.|Martin Pelikan,Rajiv Kalapala,Alexander K. Hartmann","58197|GECCO|2007|Order or not does parallelization of model building in hBOA affect its scalability|It has been shown that model building in the hierarchical Bayesian optimization algorithm (hBOA) can be efficiently parallelized by randomly generating an ancestral ordering of the nodes of the network prior to learning the network structure and allowing only dependencies consistent with the generated ordering. However, it has not been thoroughly shown that this approach to restricting probabilistic models does not affect scalability of hBOA on important classes of problems. This paper demonstrates that although the use of a random ancestral ordering restricts the structure of considered models to allow efficient parallelization of model building, its effects on hBOA performance and scalability are negligible.|Martin Pelikan,James D. Laury Jr.","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","58003|GECCO|2007|Overcoming hierarchical difficulty by hill-climbing the building block structure|The Building Block Hypothesis suggests that Genetic Algorithms (GAs) are well-suited for hierarchical problems, where efficient solving requires proper problem decomposition and assembly of solution from sub-solution with strong non-linear interdependencies. The paper proposes a hill-climber operating over the building block (BB) space that can efficiently address hierarchical problems. The new Building Block Hill-Climber (BBHC) uses hill-climb search experience to learn the problem structure. The neighborhood structure is adapted whenever new knowledge about the underlaying BB structure is incorporated into the search. This allows the method to climb the hierarchical structure by revealing and solving consecutively the hierarchical levels. It is expected that for fully non-deceptive hierarchical BB structures the BBHC can solve hierarchical problems in linearithmic time. Empirical results confirm that the proposed method scales almost linearly with the problem size thus clearly outperforms population based recombinative methods.|David Iclanzan,Dan Dumitrescu","57996|GECCO|2007|Why is parity hard for estimation of distribution algorithms|We describe a k-bounded and additively separable test problem on which the hierarchical Bayesian Optimization Algorithm (hBOA) scales exponentially.|David Jonathan Coffin,Robert Elliott Smith","58016|GECCO|2007|An artificial immune system with partially specified antibodies|Artificial Immune System algorithms use antibodies which fully specify the solution of an optimization, learning, or pattern recognition problem. By being restricted to fully specified antibodies, an AIS algorithm can not make use of schemata or classes of partial solutions. This paper presents a symbiotic artificial immune system (SymbAIS) algorithm which is an extension of CLONALG algorithm. It uses partially specified antibodies and gradually builds up building blocks of suitable sub-antibodies. The algorithm is compared with CLONALG on multimodal function optimization and combinatorial optimization problems and it is shown that it can solve problems that CLONALG is unable to solve.|Ramin Halavati,Saeed Bagheri Shouraki,Mojdeh Jalali Heravi,Bahareh Jafari Jashmi"],["58176|GECCO|2007|A study on metamodeling techniques ensembles and multi-surrogates in evolutionary computation|Surrogate-Assisted Memetic Algorithm (SAMA) is a hybrid evolutionary algorithm, particularly a memetic algorithm that employs surrogate models in the optimization search. Since most of the objective function evaluations in SAMA are approximated, the search performance of SAMA is likely to be affected by the characteristics of the models used. In this paper, we study the search performance of using different meta modeling techniques, ensembles, and multi-surrogates in SAMA. In particular, we consider the SAMA-TRF, a SAMA model management framework that incorporates a trust region scheme for interleaving use of exact objective function with computationally cheap local meta models during local searches. Four different metamodels, namely Gaussian Process (GP), Radial Basis Function (RBF), Polynomial Regression (PR), and Extreme Learning Machine (ELM) neural network are used in the study. Empirical results obtained show that while some metamodeling techniques perform best on particular benchmark problems, ensemble of metamodels and multisurrogates yield robust and improved solution quality on the benchmark problems in general, for the same computational budget.|Dudy Lim,Yew-Soon Ong,Yaochu Jin,Bernhard Sendhoff","58076|GECCO|2007|On the scalability of evolution strategies in the optimization of dynamic molecular alignment|We consider the numerical optimization of dynamic molecular alignment by shaped femtosecond pulses, and study the scalability of the electric field subject to optimization by Evolution Strategies.The trade-off between fine-tuning of the electric field versus the evolutionary optimization feasibility is investigated.|Ofer M. Shir,Thomas Bäck,Marc J. J. Vrakking","58081|GECCO|2007|A multi-objective approach to search-based test data generation|There has been a considerable body of work on search-based test data generation for branch coverage. However, hitherto, there has been no work on multi-objective branch coverage. In many scenarios a single-objective formulation is unrealistic testers will want to find test sets that meet several objectives simultaneously in order to maximize the value obtained from the inherently expensive process of running the test cases and examining the output they produce. This paper introduces multi-objective branch coverage.The paper presents results from a case study of the twin objectives of branch coverage and dynamic memory consumption for both real and synthetic programs. Several multi-objective evolutionary algorithms are applied. The results show that multi-objective evolutionary algorithms are suitable for this problem, and illustrates the way in which a Pareto optimal search can yield insights into the trade-offs between the two simultaneous objectives.|Kiran Lakhotia,Mark Harman,Phil McMinn","58070|GECCO|2007|Convergence phases variance trajectories and runtime analysis of continuous EDAs|Considering the available body of literature on continuous EDAs, one must state that many important questions are still unanswered, e.g. How do continuous EDAs really work, and how can we increase their efficiency further The first question must be answered on the basis of formal models, but despite some recent results, the majority of contributions to the field is experimental. The second questionshould be answered by exploiting the insights that have been gained from formal models. We contribute to the theoretical literature on continuous EDAs by focussing on a simple, yet important, question How should the variances used tosample offspring from change over an EDA run To answer this question, the convergence process is separated into three phases and it is shown that for each phase, a preferable strategy exists for setting the variances. It is highly likely that the use of variances that have been estimated with maximum likelihood is not optimal. Thus, variance modification policies are not just a nice add-on. In the light of our findings, they become an integral component of continuous EDAs, and they should consider the specific requirements of all phases of the optimization process.|Jörn Grahl,Peter A. N. Bosman,Stefan Minner","58074|GECCO|2007|The effects of solution density in the search space on finding spatially robust solutions|The common definition for robust solutions considers a solution robust if it remains optimal (or near optimal) when the parameters defining the fitness function are perturbed. We call this parameter robustness or temporal robustness. In this paper we propose an alternate definition for robustness, which we call spatial or solution robustness, if both the solution and the neighbourhood around the solution has high fitness. With this definition, we created a set of functions with useful properties to allow for the testing of solution robustness. We then focus on the effect of the precision (density) of the search space and find that it has a drastic effect on both the number of solutions and their quality.|Grzegorz Drzadzewski,Mark Wineberg","57920|GECCO|2007|A study of mutational robustness as the product of evolutionary computation|This paper investigates the ability of a tournament selection based genetic algorithm to find mutationally robust solutions to a simple combinatorial optimization problem. Two distinct algorithms (a stochastic hill climber and a tournament selection based GA) were used to search for optimal walks in several variants of the self avoiding walk problem. The robustness of the solutions obtained by the algorithms were compared, both with each other and with solutions obtained by a random sampling of the optimal solution space. The solutions found by the GA were, for most of the problem variants, significantly more robust than those found by either the hill climbing algorithm or random sampling. The solutions found by the hill climbing algorithm were often significantly less robust than those obtained through random sampling. .|Justin Schonfeld","58229|GECCO|2007|On the runtime analysis of the -ANT ACO algorithm|The runtime analysis of randomized search heuristics is a growing field where, in the last two decades, many rigorous results have been obtained. These results, however, apply particularly to classical search heuristics such as Evolutionary Algorithms (EAs) and Simulated Annealing. First runtime analyses of modern search heuristics have been conducted only recently w.r.t a simple Ant Colony Optimization (ACO) algorithm called -ANT. In particular, the influence of the evaporation factor in the pheromone update mechanism and the robustness of this parameter w.r.t the runtime behavior have been determined for the example function OneMax.This paper puts forward the rigorous runtime analysis of the -ANT on example functions, namely on the functions LeadingOnes and BinVal. With respect to EAs, such analyses have been essential to develop methods for the analysis on more complicated problems. The proof techniques required for the -ANT, unfortunately, differ significantly from those for EAs, which means that a new reservoir of methods has to be built up. Again, the influence of the evaporation factor is analyzed rigorously, and it is proved that its choice can be very crucial to allow efficient runtimes. Moreover, the analyses provide insight into the working principles of ACO algorithms and, in terms of their robustness, describe essential differences to other randomized search heuristics.|Benjamin Doerr,Frank Neumann,Dirk Sudholt,Carsten Witt","57989|GECCO|2007|Sex and death towards biologically inspired heuristics for constraint handling|Constrained continuous optimization is still an interesting field of research. Many heuristics have been proposed in the last decade. Most of them are based on penalty functions. Here, we experimentally investigate the two constraint handling heuristics proposed by Kramer and Schwefel. The two sexes evolution strategy (TSES) is inspired by the biological concept of sexual selection and pairing. The death penalty step control evolution strategy (DSES) is based on the controlled reduction of a minimum step size depending on the distance to the infeasible search space. These two methods are able to overcome the problem of premature mutation strength reduction, a result of the self-adaptation mechanism of evolution strategies in constrained environments. All methods are experimentally evaluated on a couple of typical constrained test problems. These experiments offer recommendations for the TSES population ratios and the speed of the -reduction process of the DSES.|Oliver Kramer,Stephan Brügger,Dejan Lazovic","57964|GECCO|2007|Binary ant algorithm|When facing dynamic optimization problems the goal is no longer to find the extrema, but to track their progression through the space as closely as possible. Over these kind of over changing, complex and ubiquitous real-world problems, the explorative-exploitive subtle counterbalance character of our current state-of-the-art search algorithms should be biased towards an increased explorative behavior. While counterproductive in classic problems, the main and obvious reason of using it in severe dynamic problems is simple while we engage ourselves in exploiting the extrema, the extrema moves elsewhere. In order to tackle this subtle compromise, we propose a novel algorithm for optimization in dynamic binary landscapes, stressing the role of negative feedback mechanisms. The Binary Ant Algorithm (BAA) mimics some aspects of social insects' behavior. Like Ant Colony Optimization (ACO), BAA acts by building pheromone maps over a graph of possible trails representing pseudo-solutions of increasing quality to a specific optimization problem. Main differences rely on the way this search space is represented and provided to the colony in order to exploreexploit it, while and more important, we enrol in providing strong evaporation to the problem-habitat. By a process of pheromone reinforcement and evaporation the artificial insect's trails over the graph converge to regions near the ideal solution of the optimization problem. Over each generation, positive feedbacks made available by pheromone reinforcement consolidate the best solutions found so far, while enhanced negative feedbacks given by the evaporation mechanism provided the system with population diversity and fast self-adaptive characteristics, allowing BAA to be particularly suitable for severe complex dynamic optimization problems. Experiments made with some well known test functions frequently used in the Evolutionary Algorithms' research field illustrate the efficiency of the proposed method. BAA was also compared with other algorithms, proving to be more able to track fast moving extrema on several test problems.|Carlos Fernandes,Agostinho C. Rosa,Vitorino Ramos","58235|GECCO|2007|Approximating covering problems by randomized search heuristics using multi-objective models|The main aim of randomized search heuristics is to produce good approximations of optimal solutions within a small amount of time. In contrast to numerous experimental results, there are only a few theoretical ones on this subject. We consider the approximation ability of randomized search heuristics for the class of covering problems and compare single-objective and multi-objective models for such problems. For the Vertex-Cover problem, we point out situations where the multi-objective model leads to a fast construction of optimal solutions while in the single-objective case even no good approximation can be achieved within expected polynomial time. Examining the more general Set-Cover problem we show that optimal solutions can be approximated within a factor of log n, where n is the problem dimension, using the multi-objective approach while the approximation quality obtainable by the single-objective approach in expected polynomial time may be arbitrarily bad.|Tobias Friedrich,Nils Hebbinghaus,Frank Neumann,Jun He,Carsten Witt"],["58146|GECCO|2007|A synthesis of optimal stopping time in compact genetic algorithm based on real options approach|This paper introduces the real options approach, which is an evaluation tool for investment under uncertainty, to analyze optimal stopping time in genetic algorithms. This paper focuses on the simple model of EDAs named the compact genetic algorithm. This algorithm employs the probability vector as a model that scales well with the problem size. We analyze optimal stopping time of trap problems and propose an optimal stopping criterion as a decision contour. The proposed criterion also provides a stopping boundary, where termination is optimal on one side and continuation is on the other. This region suggests when it is worth continuing the algorithm and helps save computational effort by stopping early. Moreover, when the reset method is applied, the algorithm can reach a higher solution quality. The proposed technique can also be applied to analyze other problems.|Sunisa Rimcharoen,Daricha Sutivong,Prabhas Chongstitvatana","57935|GECCO|2007|On the constructiveness of context-aware crossover|Crossover in Genetic Programming is mostly a destructive operator, generally producing children worse than the parents and occasionally producing those who are better. A recently introduced operator, Context-Aware Crossover, which implicitly discovers the best possible crossover site for a subtree has been shown to consistently attain higher fitnesses while processing fewer individuals.It has been observed that context-aware crossover is similar to Brood Crossover in that multiple children are produced during each crossover event. This paper performs a thorough analysis of these crossover operators and compares the performance of the two and demonstrates that, although they do work similarly, context-aware crossover performs a far better sampling of the search space and thus performs much better.We also demonstrate that context-aware crossover benefits from a speed up of almost an order of magnitude when using a simple and very small cache, which is over two orders of magnitute smaller than caches typically used.|Hammad Majeed,Conor Ryan","58122|GECCO|2007|Lets get ready to rumble redux crossover versus mutation head to head on exponentially scaled problems|This paper analyzes the relative advantages between crossover and mutation on a class of deterministic and stochastic additively separable problems with substructures of non-uniform salience. This study assumes that the recombination and mutation operators have the knowledge of the building blocks (BBs) and effectively exchange or search among competing BBs. Facetwise models of convergence time and population sizing have been used to determine the scalability of each algorithm. The analysis shows that for deterministic exponentially-scaled additively separable, problems, the BB-wise mutation is more efficient than crossover yielding a speedup of o(llogl), where l is the problem size. For the noisy exponentially-scaled problems, the outcome depends on whether scaling on noise is dominant. When scaling dominates, mutation is more efficient than crossover yielding a speedup of o(llogl). On the other hand, when noise dominates, crossover is more efficient than mutation yielding a speedup of o(l).|Kumara Sastry,David E. Goldberg","57960|GECCO|2007|A new crossover technique for Cartesian genetic programming|Genetic Programming was first introduced by Koza using tree representation together with a crossover technique in which random sub-branches of the parents' trees are swapped to create the offspring. Later Miller and Thomson introduced Cartesian Genetic Programming, which uses directed graphs as a representation to replace the tree structures originally introduced by Koza. Cartesian Genetic Programming has been shown to perform better than the traditional Genetic Programming but it does not use crossover to create offspring, it is implemented using mutation only. In this paper a new crossover method in Genetic Programming is introduced. The new technique is based on an adaptation of the Cartesian Genetic Programming representation and is tested on two simple regression problems. It is shown that by implementing the new crossover technique, convergence is faster than that of using mutation only in the Cartesian Genetic Programming method.|Janet Clegg,James Alfred Walker,Julian Francis Miller","58175|GECCO|2007|Learning building block structure from crossover failure|In the classical binary genetic algorithm, although crossover within a building block (BB) does not always cause a decrease in fitness, any decrease in fitness results from the destruction of some building blocks, in problems where such structures are well defined, such as those considered here. Those crossovers that cause both offspring to be worse, or one to be worse and one unchanged, are here designated as failed crossovers. Counting the failure frequency of single-point crossovers performed at each locus reveals something of the BB structure. Guided by the failure record, GA operators could choose appropriate points for crossover, in order to work moreefficiently and effectively. Experiments on test functions RoyalRoad R and R, Holland's Royal Road Challenge function and H-IFF functions show that such a guided operator improves performance. While many methods exist to discover building blocks, this \"quick-and-dirty\" method can sketch the linkage nearly \"for free\", requiring very little extra computation.|Zhenhua Li,Erik D. Goodman","57885|GECCO|2007|Empirical analysis of ideal recombination on random decomposable problems|This paper analyzes the behavior of a selectorecombinative genetic algorithm (GA) with an ideal crossover on a class of random additively decomposable problems (rADPs). Specifically, additively decomposable problems of order k whose subsolution fitnesses are sampled from the standard uniform distribution U, are analyzed. The scalability of the selectorecombinative GA is investigated for , rADP instances. The validity of facetwise models in bounding the population size, run duration, and the number of function evaluations required to successfully solve the problems is also verified. Finally, rADP instances that are easiest and most difficult are also investigated.|Kumara Sastry,Martin Pelikan,David E. Goldberg","58010|GECCO|2007|Global multiobjective optimization via estimation of distribution algorithm with biased initialization and crossover|Multiobjective optimization problems with many local Pareto fronts is a big challenge to evolutionary algorithms. In this paper, two operators, biased initialization and biased crossover, are proposed to improve the global search ability of RM-MEDA, a recently proposed multiobjective estimation of distribution algorithm. Biased initialization inserts several globally Pareto optimal solutions into the initial population biased crossover combines the location information of some best solutions found so far and globally statistical information extracted from current population. Experiments have been conducted to study the effects of these two operators.|Aimin Zhou,Qingfu Zhang,Yaochu Jin,Bernhard Sendhoff,Edward P. K. Tsang","58095|GECCO|2007|Efficiency updates for the restricted growth function GA for grouping problems|Problems that require the partitioning of a set of variables in order to compute a solution such as bin packing or line balancing are typically NP-hard. Hence, researchers have focused on producing heuristic methods for finding appropriate partitions. Many of the representations used in optimisation algorithms including those in GA methods suffer from degeneracy . Furthermore, Falkenauer has found that representations with less degeneracy result in more efficient GAs with respect to grouping problems . Previously we developed a new representation for grouping genetic algorithms called the Restricted Growth Function GA (RGFGA) . The RGFGA effectively removes all degeneracy, resulting in a more efficient search. However, one flaw of the RGFGA is that it converges too quickly resulting in a population with very little diversity. We exploit visualistion techniques, which can be used in conjunction with the Hamming distance, as well as introducing a novel population generator and a crossover operator which exploits the notion of extrema within grouping problems, to ensure diversity within the population. A restricted growth function is a function f  n  n such that f()  , f(i + ) - max f(), . . . , f(i)+. Note that there is a one-to-one correspondence between the set of RGFs and the set of partitions of n. In particular, the RGF represents a partition into m - n groups, where  by convention belongs to the first group, i belongs to the f(i)th group, and max f(), . . . , f(n)  m. The one-to-one correspondence means that there is no degeneracy in the representation of a partition using an RGF. We introduce a new random RGF generator to create a better coverage of the search space, and a new crossover operator for the RGFGA in order to prevent premature convergence. The grouping problem search space contains two extrema one occurs when all elements belong to a single group the other when each group contains a single element. We choose two distinct RGFs as parents as in the original RGFGA, f and g. However, one child (rather than two) is chosen using an existing path linking method  between f and g. The other child is generated from the path generated between one extremum chosen at random and one of the parents chosen at random. It is hoped that this modified crossover will ensure that a subset of children will be 'pulled away' from any local maxima toward the extrema in order to prevent premature convergence. A visualisation of this new crossover with the extrema points along with the old crossover used in  can be plotted within the search space using multidimensional scaling with Hamming distance between RGFs. The original RGF generator in  meant that at each iteration, the probability of a new group being generated decreases as the number of groups increases. Visualisation shows how the RGF generator biases individuals to be closer to the extrema with only one group.Therefore, we propose a new algorithm for generating RGFs that ensures an equal probability of creating a new group or using existing groups, whenever a new variable is assigned. Visualisation illustrates the resulting distribution of RGFs with individuals less clustered around one extremum than before. We tested the old RGFGA crossover with different combinations of the new one and the new random population generator as well as testing straw men approaches on a binpacking dataset and a multivariate time-series dataset that were outlined in . Our hypothesis was that the two updates to our previous RGFGA would reduce the premature convergence of the algorithm. The results appear to suggest that either new update to the RGFGA improves upon the original in terms of controlling premature convergence, resulting in a more efficient search. However, the combination does not appear to add any further improvement. Future work will involve applying the RGFGA to consensus clustering algorithms for gene expression data which currently use simple heuristic search techniques in order to cluster data without the biases of standard clustering techniques. We also intend to explore the parallelisation of the RGFGA using different distributed GA architectures.|Allan Tucker,Stephen Swift,Jason Crampton","57908|GECCO|2007|Variable discrimination of crossover versus mutation using parameterized modular structure|Recent work has provided functions that can be used to prove a principled distinction between the capabilities of mutation-based and crossover-based algorithms. However, prior functions are isolated problem instances that do not provide much intuition about the space of possible functions that is relevant to this distinction or the characteristics of the problem class that affect the relative success of these operators. Modularity is a ubiquitous and intuitive concept in design, engineering and optimisation, and can be used to produce functions that discriminate the ability of crossover from mutation. In this paper, we present a new approach to representing modular problems, which parameterizes the amount of modular structure that is present in the epistatic dependencies of the problem. This adjustable level of modularity can be used to give rise to tuneable discrimination of the ability of genetic algorithms with crossover versus mutation-only algorithms.|Rob Mills,Richard A. Watson","57969|GECCO|2007|Dependency trees permutations and quadratic assignment problem|This paper describes and analyzes an estimation of distribution algorithm based on dependency tree models (dtEDA), which can explicitly encode probabilistic models for permutations. dtEDA is tested on deceptive ordering problems and a number of instances of the quadratic assignment problem. The performance of dtEDA is compared to that of the standard genetic algorithm with the partially matched crossover (PMX) and the linear order crossover (LOX). In the quadratic assignment problem, the robust tabu search is also included in the comparison.|Martin Pelikan,Shigeyoshi Tsutsui,Rajiv Kalapala"],["58031|GECCO|2007|Option pricing model calibration using a real-valued quantum-inspired evolutionary algorithm|Quantum effects are a natural phenomenon and just like evolution, or immune processes, can serve as an inspiration for the design of computing algorithms. This study illustrates how a real-valued quantum-inspired evolutionary algorithm(QEA) can be constructed and examines the utility of the resulting algorithm on an important real-world problem, namely the calibration of an Option Pricing model. The results from the algorithm are shown to be robust and sensitivity analysis is carried out on the algorithm parameters, suggesting that there is useful potential to apply QEA to this domain.|Kai Fan,Anthony Brabazon,Conall O'Sullivan,Michael O'Neill","57993|GECCO|2007|Context-aware mutation a modular context aware mutation operator for genetic programming|This paper introduces a new type of mutation, Context-Aware Mutation, which is inspired by the recently introduced context-aware crossover. Context-Aware mutation operates by replacing existing sub-trees with modules from a previously construct repository of possibly useful sub-trees. We describe an algorithmic way to produce the repository from an initial, exploratory run and test various GP set ups for producing the repository. The results show that when the exploratory run uses context-aware crossover and the main run uses context-aware mutation, not only is the final result significantly better, the overall cost of the runs in terms of individuals evaluated is significantly lower.|Hammad Majeed,Conor Ryan","57913|GECCO|2007|Using feedback to regulate gene expression in a developmental control architecture|We present what we believe is the first attempt to physically reconstruct the exploratory mechanism of genetic regulatory networks. Feedback plays a crucial role during developmental processes and its mechanisms have recently become much clearer due to evidence from evolutionary developmental biology. We believe that without similar mechanisms of interaction and feedback, digital genomes cannot guide themselves across functional search spaces in a way that fully exploits a domain's resources, particularly in the complex search domains of real-world physics. Our architecture is designed to let evolution utilise feedback as part of its mechanism of exploration.|Kester Clegg,Susan Stepney,Tim Clarke","57877|GECCO|2007|An extended mutation concept for the local selection based differential evolution algorithm|A new mutation concept is proposed to generalize local selection based Differential Evolution algorithm to work in general multi-modal problems. Three variations of the proposed method are compared with classic Differential Evolution algorithm using a set of five well known test functions and their variants. The general idea of the new mutation operation is to divide the mutation into two parts the local and global mutation. The global mutation works as a migration operator allowing the algorithm perform global search efficiently, while the local mutation improves the efficiency of local search. The results show that the concept of global mutation is able to generalize the good performance of local selection based Differential Evolution from convex uni-modal functions to general non-convex and multi-modal problems. Among the tested functions, the new method was able to outperform the classic Differential Evolution in all butone. A limited analysis of the effects of control parameters to the performance of the algorithm is also done.|Jani Rönkkönen,Jouni Lampinen","57933|GECCO|2007|Adaptive strategies for a semantically driven tree optimizer to control code growth|In genetic programming many methods to fight growth exist. Butmost of these methods require one or multiple parameters to beset. Unfortunately performance strongly depends on a correct setting of each of those parameters. Recently a semantically driven tree optimizer has been developed. In this paper two adaptive strategies to choose a reasonable parameter setting forthis growth limiter are presented.|Bart Wyns,Luc Boullart","58021|GECCO|2007|GARS an improved genetic algorithm with reserve selection for global optimization|This paper investigates how genetic algorithms (GAs) can be improved to solve large-scale and complex problems more efficiently. First of all, we review premature convergence, one of the challenges confronted with when applying GAs to real-world problems. Next, some of the methods now available to prevent premature convergence and their intrinsic defects are discussed. A qualitative analysis is then done on the cause of premature convergence that is the loss of building blocks hosted in less-fit individuals during the course of evolution. Thus, we propose a new improver - GAs with Reserve Selection (GARS), where a reserved area is set up to save potential building blocks and a selection mechanism based on individual uniqueness is employed to activate the potentials. Finally, case studies are done in a few standard problems well known in the literature, where the experimental results demonstrate the effectiveness and robustness of GARS in suppressing premature convergence, and also an enhancement is found in global optimization capacity.|Yang Chen,Jinglu Hu,Kotaro Hirasawa,Songnian Yu","57989|GECCO|2007|Sex and death towards biologically inspired heuristics for constraint handling|Constrained continuous optimization is still an interesting field of research. Many heuristics have been proposed in the last decade. Most of them are based on penalty functions. Here, we experimentally investigate the two constraint handling heuristics proposed by Kramer and Schwefel. The two sexes evolution strategy (TSES) is inspired by the biological concept of sexual selection and pairing. The death penalty step control evolution strategy (DSES) is based on the controlled reduction of a minimum step size depending on the distance to the infeasible search space. These two methods are able to overcome the problem of premature mutation strength reduction, a result of the self-adaptation mechanism of evolution strategies in constrained environments. All methods are experimentally evaluated on a couple of typical constrained test problems. These experiments offer recommendations for the TSES population ratios and the speed of the -reduction process of the DSES.|Oliver Kramer,Stephan Brügger,Dejan Lazovic","57953|GECCO|2007|Hill climbing on discrete HIFF exploring the role of DNA transposition in long-term artificial evolution|We show how a random mutation hill climber that does multi-level selection utilizes transposition to escape local optima on the discrete Hierarchical-If-And-Only-If (HIFF) problem. Although transposition is often deleterious to an individual, we outline two population models where recently transposed individuals can survive. In these models, transposed individuals survive selection through cooperation with other individuals. In the multi-population model, individuals were allowed a maturation stage to realize their potential fitness. In the genetic algorithm model, transposition helped maintain genetic diversity even within small populations. However, the results for transposition on the discrete Hierarchical-Exclusive-Or (HXOR) problem were less positive. Unlike HIFF, HXOR does not benefit from random drift. This led us to hypothesize that two conditions necessary for transposition to enhance evolvability are (i) the presence of local optima and (ii) susceptibility to random drift. This hypothesis is supported by further experiments. The findings of this paper suggest that epistasis and large mutations can sustain artificial evolution in the long-term by providing a way for individuals and populations to escape evolutionary dead ends. Paradoxically, epistasis creates local optima and holds a key to its resolution, while deleterious mutations such as transposition enhance evolvability. However, not all large mutations are equal.|Susan Khor","57894|GECCO|2007|Self-adaptive ant colony optimisation applied to function allocation in vehicle networks|Modern vehicles possess an increasing number of softwareand hardware components that are integrated in electroniccontrol units (ECUs). Finding an optimal allocation forall components is a multi-objective optimisation problem,since every valid allocation can be rated according to multipleobjectives like costs, busload, weight, etc. Additionally,several constraints mainly regarding the availability of resourceshave to be considered. This paper introduces a newvariant of the well-known ant colony optimisation, whichhas been applied to the real-world problem described above.Since it concerns a multi-objective optimisation problem,multiple ant colonies are employed. In the course of thiswork, pheromone updating strategies specialised on constrainthandling are developed. To reduce the effort neededto adapt the algorithm to the optimisation problem by tuningstrategic parameters, self-adaptive mechanisms are establishedfor most of them. Besides the reduction of theeffort, this step also improves the algorithm's convergencebehaviour.|Manuel Förster,Bettina Bickel,Bernd Hardung,Gabriella Kókai","57929|GECCO|2007|The second harmonic generation case-study as a gateway for es to quantum control problems|The Second Harmonic Generation (SHG), a process that turns out to be a good test case in the physics lab, can also be considered as a fairly simple theoretical test function for global optimization. Despite its symmetry properties, that will be derived here analytically, it seems to capture the complexity of the Fourier transform between the decision space to the evaluation space, and by that to challenge optimization routines. And indeed, counter-intuitively to some extent, locating its global maximum seems to be not an easy task for Evolutionary Algorithms (EAs). Although this research originates from the real-world applications domain, it aims to introduce a theoretical test case to Evolution Strategies (ES), being a possible theoretical gateway to the real-world physics regime of quantum control problems. After presenting some theoretical results, this paper introduces the study of the scalability of the decision space subject to optimization by specific variants of Derandomized Evolution Strategies. We show that the Evolution Strategy in use requires a quasi-quadratic increase of function evaluations for locating the global maximum as the dimensionality increases.|Ofer M. Shir,Thomas Bäck"],["57883|GECCO|2007|XCS for adaptive user-interfaces|We outline our context learning framework that harnesses information from a user's environment to learn user preferences for application actions. Within this framework, we employ XCS in a real world application for personalizing user-interface actions to individual users. Sycophant, our context aware calendaring application and research test-bed, uses XCS to adaptively generate user-preferred alarms for ten users in our study. Our results show that XCS' alarm prediction performance equals or surpasses the performance of One-R and a decision tree algorithm for all the users. XCS' average performance is close to $$ percent on the alarm prediction task for all ten users. These encouraging results further highlight the feasibility of using XCS for predictive data mining tasks and the promise of a classifier systems based approach to personalize user interfaces.|Anil Shankar,Sushil J. Louis,Sergiu Dascalu,Ramona Houmanfar,Linda J. Hayes","58133|GECCO|2007|MILCS a mutual information learning classifier system|This paper introduces a new variety of learning classifier system (LCS), called MILCS, which utilizes mutual information as fitness feedback. Unlike most LCSs, MILCS is specifically designed for supervised learning. MILCS's design draws on an analogy to the structural learning approach of cascade correlation networks. We present preliminary results, and contrast them to results from XCS. We discuss the explanatory power of the resulting rule sets, and introduce a new technique for visualizing explanatory power. Final comments include future directions for this research, including investigations in neural networks and other systems.|Robert Elliott Smith,Max Kun Jiang","58056|GECCO|2007|A new evolutionary model for detecting multiple optima|Multimodal optimization problems consist in detecting all global and local optima of a problem. A new evolutionary approach to multimodal optimization called Roaming technique (RO) is presented. Roaming uses two original concepts in order to detect multiple optima a stability measure for subpopulations and an external population called archive to store detected optima. Individuals in the archive are refined by evolving them independently. Performance of Roaming is compared by means of numerical experiments with two other evolutionary techniques.|Rodica Ioana Lung,D. Dumitrescu","58190|GECCO|2007|Multi-objective hybrid PSO using -fuzzy dominance|This paper describes a PSO-Nelder Mead Simplex hybrid multi-objective optimization algorithm based on a numerical metric called  -fuzzy dominance. Within each iteration of this approach, in addition to the position and velocity update of each particle using PSO, the k-means algorithm is applied to divide the population into smaller sized clusters. The Nelder-Mead simplex algorithm is used separately within each cluster for added local search. The proposed algorithm is shown to perform better than MOPSO on several test problems as well as for the optimization of a genetic model for flowering time control in Arabidopsis. Adding the local search achieves faster convergence, an important feature in computationally intensive optimization of gene networks.|Praveen Koduru,Sanjoy Das,Stephen Welch","58014|GECCO|2007|Distribution replacement how survival of the worst can out perform survival of the fittest|A new family of \"Distribution Replacement\" operators for use in steady state genetic algorithms is presented. Distribution replacement enforces the members of the population to conform to an arbitrary statistical distribution, defined by its Cumulative Distribution Frequency, relative to the current best individual. As new superior individuals are discovered, the distribution \"stretches\" to accommodate the increased diversity, the exact opposite of convergence. Decoupling the maintenance of an optimal set of parents from the production of superior children allows the search to be freed from the traditional overhead of evolving a population of maximal fitness and, more significantly, avoids premature convergence. The population distribution has a significant effect on performance for a given problem, and in turn, the type of problem affects the performance of different distributions. Keeping mainly good individuals naturally does well on simple problems (as do distributions that exclude \"median\" individuals). With deceptive problems however, distributions which keep mainly bad individuals are shown to be superior to other replacement operators and also outperform classical generational genetic algorithms. In all cases, the uniform distribution proves suboptimal. This paper explains the details of distribution replacement, simulation experiments and discussions on the extension of this idea to a dynamic distribution.|Howard Tripp,Phil Palmer","58011|GECCO|2007|Introducing fault tolerance to XCS|In this paper, we introduce fault tolerance to XCS and propose a new XCS framework called XCS with Fault Tolerance (XCSFT). As an important branch of learning classifier systems, XCS has been proven capable of evolving maximally accurate, maximally general problem solutions. However, in practice, it oftentimes generates a lot of rules, which lower the readability of the evolved classification model, and thus, people may not be able to get the desired knowledge or useful information out of the model. Inspired by the fault tolerance mechanism proposed in field of data mining, we devise a new XCS framework by integrating the concept and mechanism of fault tolerance into XCS in order to reduce the number of classification rules and therefore to improve the readability of the generated prediction model. A series of $N$-multiplexer experiments, including -bit, -bit, -bit, and -bit multiplexers, are conducted to examine whether XCSFT can accomplish its goal of design. According to the experimental results, XCSFT can offer the same level of prediction accuracy on the test problems as XCS can, while the prediction model evolved by XCSFT consists of significantly fewer classification rules.|Hong-Wei Chen,Ying-Ping Chen","58201|GECCO|2007|Empirical analysis of generalization and learning in XCS with gradient descent|We analyze generalization and learning in XCS with gradient descent. At first, we show that the addition of gradient in XCS may slow down learning because it indirectly decreases the learning rate. However, in contrast to what was suggested elsewhere, gradient descent has no effect on the achieved generalization. We also show that when gradient descent is combined with roulette wheel selection, which is known to be sensitive to small values of the learning rate, the learning speed can slow down dramatically. Previous results reported no difference in the performance of XCS with gradient descent when roulette wheel selection or tournament selection were used. In contrast, we suggest that gradient descent should always be combined with tournament selection, which is not sensitive to the value of the learning rate. When gradient descent is used in combination with tournament selection, the results show that (i) the slowdown in learning is limited and (ii) the generalization capabilities of XCS are not affected.|Pier Luca Lanzi,Martin V. Butz,David E. Goldberg","57981|GECCO|2007|Modeling XCS in class imbalances population size and parameter settings|This paper analyzes the scalability of the population size required in XCS to maintain nichesthat are infrequently activated.Facetwise models have been developed to predict the effect of the imbalance ratio--ratio betweenthe number of instances of the majority class and the minority class that are sampled to XCS--on population initialization, andon the creation and deletion of classifiers of the minority class. While theoretical models show that, ideally, XCS scales linearly with the imbalance ratio, XCS with standard configuration scales exponentially. The causes that are potentially responsible for this deviation from the ideal scalability are also investigated. Specifically, the inheritance procedure of classifiers' parameters, mutation, and subsumption are analyzed, and improvements in XCS's mechanisms are proposed to effectively and efficiently handle imbalanced problems. Once the recommendations are incorporated to XCS, empirical results show that the population size in XCS indeed scales linearly with the imbalance ratio.|Albert Orriols-Puig,David E. Goldberg,Kumara Sastry,Ester Bernadó-Mansilla","57917|GECCO|2007|XCSF with computed continuous action|Wilson introduced XCSF as a successor to XCS. The major development of XCSF is the concept of a computed prediction. The efficiency of XCSF in dealing with numerical input and continuous payoff has been demonstrated. However, the possible actions must always be determined in advance. Yet domains such as robot control require numerical actions, so that neither XCS nor XCSF with their discrete actions can yield high performance. This paper studies computed action in XCSF, where the action is continuous with respect to the input state. In comparison with Wilson's architecture for continuous action, our XCSF version, called XCSFCA, proves to be more efficient.|Trung Hau Tran,Cédric Sanza,Yves Duthen,Thuc Dinh Nguyen","58005|GECCO|2007|Preliminary investigations into the evolution of cooperative strategies in a minimally spatial model|In this paper we outline a simple model of spatially structured populations that is an extension of the replicator dynamics approach used in evolutionary game theory. Using this model, we are able to investigate issues such as how the degree of spatial localisation affects the evolution of cooperative and selfish genotypes in a resource sharing scenario.|Simon T. Powers,Richard A. Watson"],["58071|GECCO|2007|A novel generative encoding for exploiting neural network sensor and output geometry|A significant problem for evolving artificial neural networks is that the physical arrangement of sensors and effectors is invisible to the evolutionary algorithm. For example, in this paper, directional sensors and effectors are placed around the circumference of a robot in analogous arrangements. This configuration ensures that there is a useful geometric correspondence between sensors and effectors. However, if sensors are mapped to a single input layer and the effectors to a single output layer (as is typical), evolution has no means to exploit this fortuitous arrangement. To address this problem, this paper presents a novel generative encoding called connective Compositional Pattern Producing Networks (connective CPPNs) that can effectively detect and capitalize on geometric relationships among sensors and effectors. The key insight is that sensors and effectors with consistent geometric relationships can be exploited by a repeating motif in the neural architecture. Thus, by employing an encoding that can discover such motifs as a function of network geometry, it becomes possible to exploit it. In this paper, a method for evolving connective CPPNs called Hypercube-based Neuroevolution of Augmenting Topologies (HyperNEAT) discovers sensible repeating motifs that take advantage of two different placement schemes, demonstrating the utility of such an approach.|David B. D'Ambrosio,Kenneth O. Stanley","58180|GECCO|2007|Alternative techniques to solve hard multi-objective optimization problems|In this paper, we propose the combination of different optimization techniques in order to solve \"hard\" two- and three-objective optimization problems at a relatively low computational cost. First, we use the -constraint method in order to obtain a few points over (or very near of) the true Pareto front, and then we use an approach based on rough sets to spread these solutions, so that the entire Pareto front can be covered. The constrained single-objective optimizer required by the -constraint method, is the cultured differential evolution, which is an efficient approach for approximating the global optimum of a problem with a low number of fitness function evaluations. The proposed approach is validated using several difficult multi-objective test problems, and our results are compared with respect to a multi-objective evolutionary algorithm representative of the state-of-the-art in the area the NSGA-II.|Ricardo Landa Becerra,Carlos A. Coello Coello,Alfredo García Hernández-Díaz,Rafael Caballero,Julián Molina Luque","58057|GECCO|2007|Synthesis of analog filters on an evolvable hardware platform using a genetic algorithm|This work presents a novel approach to filter synthesis on a fieldprogrammable analog array (FPAA) architecture using a genetic algorithm (GA). First, a Matlab model of the FPAA is created and verified for compliance with transistor-level simulations of the FPAA. Using this model, differentfilter structures are built using an active-RC approach and evaluated. Secondly, a robust genetic algorithm is implemented in Matlab, which allows synthesis of analog filters on the given structure. Optimal parameters and operators of the genetic algorithm are identified by gradual adaptation andperformance evaluation, and the general feasibility is shown. Finally, the GA is used to overcome quantization-limitations of the FPAA structure and find configurations of filters, which would not have been achievable with traditional synthesis methods. The system is not only a platform for theoretical investigation offilter structures on the given chip structure but also provides aframework for evolution and instantiation of filters on actual chiphardware.|Joachim Becker,Stanis Trendelenburg,Fabian Henrici,Yiannos Manoli","58152|GECCO|2007|Estimation of fitness landscape contours in EAs|Evolutionary algorithms applied in real domain should profit from information about the local fitness function curvature. This paper presents an initial study of an evolutionary strategy with a novel approach for learning the covariance matrix of a Gaussian distribution. The learning method is based one stimation of the fitness landscape contour line between the selected and discarded individuals. The distribution learned this way is then used to generate new population members. The algorithm presented here is the first attempt to construct the Gaussian distribution this way and should beconsidered only a proof of concept nevertheless, the empirical comparison on low-dimensional quadratic functions shows that our approach is viable and with respect to the number of evaluations needed to find a solution of certain quality, it is comparable to the state-of-the-art CMA-ES incase of sphere function and outperforms the CMA-ES in case of elliptical function.|Petr Posík,Vojtech Franc","57971|GECCO|2007|Towards clustering with XCS|This paper presents a novel approach to clustering using an accuracy-based Learning Classifier System. Our approach achieves this by exploiting the generalization mechanisms inherent to such systems. The purpose of the work is to develop an approach to learning rules which accurately describe clusters without prior assumptions as to their number within a given dataset. Favourable comparisons to the commonly used k-means algorithm are demonstrated on a number of synthetic datasets.|Kreangsak Tamee,Larry Bull,Ouen Pinngern","58054|GECCO|2007|Scalable estimation-of-distribution program evolution|I present a new estimation-of-distribution approach to program evolution where distributions are not estimated over the entire space of programs. Rather, a novel representation-building procedure that exploits domain knowledge is used to dynamically select program subspaces for estimation over. This leads to a system of demes consisting of alternative rep-resentations (i.e. program subspaces) that are maintained simultaneously and managed by the overall system. Meta-optimizing semantic evolutionary search (MOSES), a program evolution system based on this approach, is described, and its representation-building subcomponent is analyzed in depth. Experimental results are also provided for the overall MOSES procedure that demonstrate good scalability.|Moshe Looks","58209|GECCO|2007|Evolving distributed agents for managing air traffic|Air traffic management offers an intriguing real world challenge to designing large scale distributed systems using evolutionary computation. The ability to evolve effective air traffic flow strategies depends not only on evolving good local strategies, but also on ensuring that those local strategies result in good global solutions. While traditional, direct evolutionary strategies can be highly effective in certain combinatorial domains, they are not well-suited to complex air traffic flow problems because of the large interdependencies among the local subsystems. In this paper, we propose an evolutionary agent-based solution to the air traffic flow problem. In this approach, we evolve agents both to learn the right local flow strategies to alleviate congestion in their immediate surroundings, and to prevent the creation of congestion \"downstream\" from their local areas. The agent-based approach leads to better and more fault-tolerant solutions. To validate this approach, we use FACET, an air traffic simulator developed at NASA and used extensively by the FAA and industry. On a scenario composed of three hundred aircraft and two points of congestion, our results show that an agent based evolutionary computation method, where each agent uses the system evaluation function, achieves % improvement over a direct evolutionary algorithm. In addition by creating agent-specific \"difference evaluation functions\" we achieve an additional % improvement over agents using the system evaluation.|Adrian K. Agogino,Kagan Tumer","58101|GECCO|2007|An online implementable differential evolution tuned optimal guidance law|This paper proposes a novel application of differential evolution to solve a difficult dynamic optimisation or optimal control problem. The miss distance in a missile-target engagement is minimised using differential evolution. The difficulty of solving it by existing conventional techniques in optimal control theory is caused by the nonlinearity of the dynamic constraint equation, inequality constraint on the control input and inequality constraint on another parameter that enters problem indirectly. The optimal control problem of finding the minimum miss distance has an analytical solution subject to several simplifying assumptions. In the approach proposed in this paper, the initial population is generated around the seed value given by this analytical solution. Thereafter, the algorithm progresses to an acceptable final solution within a few generations, satisfying the constraints at every iteration. Since this solution or the control input has to be obtained in real time to be of any use in practice, the feasibility of online implementation is also illustrated.|Raghunathan Thangavelu,S. Pradeep","58156|GECCO|2007|A genetic algorithm with exon shuffling crossover for hard bin packing problems|A novel evolutionary approach for the bin packing problem (BPP) is presented. A simple steady-state genetic algorithm is developed that produces results comparable to other approaches in the literature, without the need for any additional heuristics. The algorithm's design makes maximum use of the principle of natural selection to evolve valid solutions without the explicit need to verify constraint violations. Our algorithm is based upon a biologically inspired group encoding which allows for a modularisation of the search space in which individual sub-solutions may be assigned independent cost values. These values are subsequently utilised in a crossover event modelled on the theory of exon shuffling to produce a single offspring that inherits the most promising segments from its parents. The algorithm is tested on a set of hard benchmark problems and the results indicate that the method has a very high degree of accuracy and reliability compared to other approaches in the literature.|Philipp Rohlfshagen,John A. Bullinaria","58195|GECCO|2007|ICSPEA evolutionary five-axis milling path optimisation|ICSPEA is a novel multi-objective evolutionary algorithm which integrates aspects from the powerful variation operators of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and the well proven multi-objective Strength Pareto Evaluation Scheme of the SPEA . The CMA-ES has already shown excellent performance on various kinds of complex single-objective problems. The evaluation scheme of the SPEA  selects individuals with respect to their current position in the objective space using a scalar index in order to form proper Pareto front approximations. These indices can be used by the CMA-part of ICSPEA for learning and guiding the search towards better Pareto front approximations. The ICSPEA is applied to complex benchmark functions such as an extended n-dimensional Schaffer's function or Quagliarella's problem. The results show that the CMA operator allows ICSPEA to find the Pareto set of the generalised Schaffer's function faster than SPEA . Furthermore, this concept is tested on the complex real-world application of the multi-objective optimization of five-axis milling NC-paths. An application of ICSPEA to the milling-path optimisation problem yielded efficient sets of five-axis NC-paths.|Jörn Mehnen,Rajkumar Roy,Petra Kersting,Tobias Wagner"],["58157|GECCO|2007|Towards billion-bit optimization via a parallel estimation of distribution algorithm|This paper presents a highly efficient, fully parallelized implementation of the compact genetic algorithm (cGA) to solve very large scale problems with millions to billions of variables. The paper presents principled results demonstrating the scalable solution of a difficult test function on instances over a billion variables using a parallel implementation of cGA. The problem addressed is a noisy, blind problem over a vector of binary decision variables. Noise is added equaling up to a tenth of the deterministic objective function variance of the problem, thereby making it difficult for simple hillclimbers to find the optimal solution. The compact GA, on the other hand, is able to find the optimum in the presence of noise quickly, reliably, and accurately, and the solution scalability follows known convergence theories. These results on noisy problem together with other results on problems involving varying modularity, hierarchy, and overlap foreshadow routine solution of billion-variable problems across the landscape of search problems.|Kumara Sastry,David E. Goldberg,Xavier Llorà","58071|GECCO|2007|A novel generative encoding for exploiting neural network sensor and output geometry|A significant problem for evolving artificial neural networks is that the physical arrangement of sensors and effectors is invisible to the evolutionary algorithm. For example, in this paper, directional sensors and effectors are placed around the circumference of a robot in analogous arrangements. This configuration ensures that there is a useful geometric correspondence between sensors and effectors. However, if sensors are mapped to a single input layer and the effectors to a single output layer (as is typical), evolution has no means to exploit this fortuitous arrangement. To address this problem, this paper presents a novel generative encoding called connective Compositional Pattern Producing Networks (connective CPPNs) that can effectively detect and capitalize on geometric relationships among sensors and effectors. The key insight is that sensors and effectors with consistent geometric relationships can be exploited by a repeating motif in the neural architecture. Thus, by employing an encoding that can discover such motifs as a function of network geometry, it becomes possible to exploit it. In this paper, a method for evolving connective CPPNs called Hypercube-based Neuroevolution of Augmenting Topologies (HyperNEAT) discovers sensible repeating motifs that take advantage of two different placement schemes, demonstrating the utility of such an approach.|David B. D'Ambrosio,Kenneth O. Stanley","58031|GECCO|2007|Option pricing model calibration using a real-valued quantum-inspired evolutionary algorithm|Quantum effects are a natural phenomenon and just like evolution, or immune processes, can serve as an inspiration for the design of computing algorithms. This study illustrates how a real-valued quantum-inspired evolutionary algorithm(QEA) can be constructed and examines the utility of the resulting algorithm on an important real-world problem, namely the calibration of an Option Pricing model. The results from the algorithm are shown to be robust and sensitivity analysis is carried out on the algorithm parameters, suggesting that there is useful potential to apply QEA to this domain.|Kai Fan,Anthony Brabazon,Conall O'Sullivan,Michael O'Neill","58140|GECCO|2007|On the behavioral diversity of random programs|Generating a random sampling of program trees with spec-ified function and terminal sets is the initial step of many program evolution systems. I present a theoretical and experimental analysis of the expected distribution of uniformly sampled programs, guided by algorithmic information theory. This analysis demonstrates that increasing the sample size is often an inefficient means of increasing the overall diversity of program behaviors (outputs). A novel sampling scheme (semantic sampling) is proposed that exploits semantics to heuristically increase behavioral diversity. An important property of the scheme is that no calls of the problem-specific fitness function are required. Its effective-ness at increasing behavioral diversity is demonstrated empirically for Boolean formulae. Furthermore, it is found to lead to statistically significant improvements in performance for genetic programming on parity and multiplexer problems.|Moshe Looks","58041|GECCO|2007|Extended probe method for linkage discovery over high-cardinality alphabets|The work addresses the problem of identifying the epistatic linkage of a function from high cardinality alphabets to the real numbers. It is a generalization of Heckendorn and Wright's work that restricts problem representation into the binary-string domain. Discrete Fourier transform is used to analyze underlying structure in high-cardinality alphabets space. Boolean operators are replaced with new operators such as , ,  and so on in high cardinality alphabets. The \"probe\" formulation is redesigned to determine epistatic properties of non-binary function. Theoretical analysis shows the close relationship between probe value and problem structure. A deterministic and a stochastic algorithm based on properties of probes are proposed to completely identify the linkage structure and rigourously compute all Fourier coefficients. Some discussion about linkage detection for continuous problems is given.|Shude Zhou,Zengqi Sun,Robert B. Heckendorn","58152|GECCO|2007|Estimation of fitness landscape contours in EAs|Evolutionary algorithms applied in real domain should profit from information about the local fitness function curvature. This paper presents an initial study of an evolutionary strategy with a novel approach for learning the covariance matrix of a Gaussian distribution. The learning method is based one stimation of the fitness landscape contour line between the selected and discarded individuals. The distribution learned this way is then used to generate new population members. The algorithm presented here is the first attempt to construct the Gaussian distribution this way and should beconsidered only a proof of concept nevertheless, the empirical comparison on low-dimensional quadratic functions shows that our approach is viable and with respect to the number of evaluations needed to find a solution of certain quality, it is comparable to the state-of-the-art CMA-ES incase of sphere function and outperforms the CMA-ES in case of elliptical function.|Petr Posík,Vojtech Franc","57919|GECCO|2007|Parallel skeleton for multi-objective optimization|Many real-world problems are based on the optimization of more than one objective function. This work presents a tool for the resolution of multi-objective optimization problems based on the cooperation of a set of algorithms. The invested time in the resolution is decreased by means of a parallel implementation of an evolutionary team algorithm. This model keeps the advantages of heterogeneous island models but also allows to assign more computational resources to the algorithms with better expectations. The elitist scheme applied aims to improve the results obtained with single executions of independent evolutionary algorithms. The user solves the problem without the need of knowing the internal operation details of the used evolutionary algorithms. The computational results obtained on a cluster of PCs for some tests available in the literature are presented.|Coromoto León,Gara Miranda,Carlos Segura","58160|GECCO|2007|Fitness calculation approach for nested if-else construct in evolutionary testing|This poster paper addresses the fitness calculation problem fornested if-else constructs. A new term \"optimism level\" is incorporated into the fitness function to assess the branch distance of nested branches for a given test data.|Xiyang Liu,Lei Wang,Xiubin Zhu,Zhiwen Bai,Miao Zhang,Hehui Liu","58016|GECCO|2007|An artificial immune system with partially specified antibodies|Artificial Immune System algorithms use antibodies which fully specify the solution of an optimization, learning, or pattern recognition problem. By being restricted to fully specified antibodies, an AIS algorithm can not make use of schemata or classes of partial solutions. This paper presents a symbiotic artificial immune system (SymbAIS) algorithm which is an extension of CLONALG algorithm. It uses partially specified antibodies and gradually builds up building blocks of suitable sub-antibodies. The algorithm is compared with CLONALG on multimodal function optimization and combinatorial optimization problems and it is shown that it can solve problems that CLONALG is unable to solve.|Ramin Halavati,Saeed Bagheri Shouraki,Mojdeh Jalali Heravi,Bahareh Jafari Jashmi","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao"],["57927|GECCO|2007|Improving the human readability of features constructed by genetic programming|The use of machine learning techniques to automatically analyse data for information is becoming increasingly widespread. In this paper we examine the use of Genetic Programming and a Genetic Algorithm to pre-process data before it is classified by an external classifier. Genetic Programming is combined with a Genetic Algorithm to construct and select new features from those available in the data, a potentially significant process for data mining since it gives consideration to hidden relationships between features. We then examine techniques to improve the human readability of these new features and extract more information about the domain.|Matthew Smith,Larry Bull","58119|GECCO|2007|Multiobjective clustering with automatic k-determination for large-scale data|Web mining - data mining for web data - is a key factor of web technologies. Especially, web behavior mining has attracted a great deal of attention recently. Behavior mining involves analyzing the behavior of users, finding patterns of user behavior, and predicting their subsequent behaviors or interests. Web behavior mining is used in web advertising systems or content recommendation systems. To analyze huge amounts of data, such as web data, data-clustering techniques are usually used. Data clustering is a technique involving the separation of data into groups according to similarity, and is usually used in the first step of data mining. In the present study, we developed a scalable data-clustering algorithm for web mining based on existent evolutionary multiobjective clustering algorithm. To derive clusters, we applied multiobjective clustering with automatic k-determination (MOCK). It has been reported that MOCK shows better performance than k-means, agglutination methods, and other evolutionary clustering algorithms. MOCK can also find the appropriate number of clusters using the information of the trade-off curve. The k-determination scheme of MOCK is powerful and strict. However the computational costs are too high when applied to clustering huge data. In this paper, we propose a scalable automatic k-determination scheme. The proposed scheme reduces Pareto-size and the appropriate number of clusters can usually be determined.|Nobukazu Matake,Tomoyuki Hiroyasu,Mitsunori Miki,Tomoharu Senda","58060|GECCO|2007|Volatility forecasting using time series data mining and evolutionary computation techniques|Traditional parametric methods have limited success in estimating and forecasting the volatility of financial securities. Recent advance in evolutionary computation has provided additional tools to conduct data mining effectively. The current work applies the genetic programming in a Time Series Data Mining framework to characterize the S&P high frequency data in order to forecast the one step ahead integrated volatility. Results of the experiment have shown to be superior to those derived by the traditional methods.|Irwin Ma,Tony Wong,Thiagas Sankar","57883|GECCO|2007|XCS for adaptive user-interfaces|We outline our context learning framework that harnesses information from a user's environment to learn user preferences for application actions. Within this framework, we employ XCS in a real world application for personalizing user-interface actions to individual users. Sycophant, our context aware calendaring application and research test-bed, uses XCS to adaptively generate user-preferred alarms for ten users in our study. Our results show that XCS' alarm prediction performance equals or surpasses the performance of One-R and a decision tree algorithm for all the users. XCS' average performance is close to $$ percent on the alarm prediction task for all ten users. These encouraging results further highlight the feasibility of using XCS for predictive data mining tasks and the promise of a classifier systems based approach to personalize user interfaces.|Anil Shankar,Sushil J. Louis,Sergiu Dascalu,Ramona Houmanfar,Linda J. Hayes","58097|GECCO|2007|Mining breast cancer data with XCS|In this paper, we describe the use of a modern learning classifier system to a data mining task. In particular, in collaboration with a medical specialist, we apply XCS to a primary breast cancer data set. Our results indicate more effective knowledge discovery than with C..|Faten Kharbat,Larry Bull,Mohammed Odeh","58145|GECCO|2007|Induction of fuzzy rules with artificial immune systems in acgh based er status breast cancer characterization|Genomic DNA copy number aberrations are frequent in solid tumours although their underlying causes remain obscure. In this paper we show how Artificial Immune System (AIS) paradigm can be successfully employed in the elucidation of biological dynamics of cancerous processes using a novel fuzzy rule induction system for data mining (IFRAIS). Competitive results have been obtained using IFRAIS. A biological interpretation of the results, carried out using Gene Ontology, followed the statistical assessment and put in evidence interesting patterns that are currently under investigation.|Filippo Menolascina,Roberto Teixeira Alves,Stefania Tommasi,Patrizia Chiarappa,Myriam Regattieri Delgado,Giuseppe Mastronardi,Angelo Paradiso,Alex Alves Freitas,Vitoantonio Bevilacqua","57984|GECCO|2007|Discrimination of metabolic flux profiles using a hybrid evolutionary algorithm|Studying metabolic fluxes is a crucial aspect of understanding biological phenotypes. However, it is often not possible to measure these fluxes directly. As an alternative, fluxome profiling provides indirect information about fluxes in a high-throughput setting. In this paper, we consider a scenario where fluxome profiling is used to investigate characteristic differences between a number of bacterial mutant strains. The goal is to identify groups of mutants that show maximally different fluxome profiles. We propose an evolutionary algorithm for this optimization problem and demonstrate that it outperforms alternative methods based on principle component analysis and independent component analysis on both real and synthetic data sets.|Stefan Bleuler,Eckart Zitzler","58082|GECCO|2007|Parallel genetic algorithm assessment of performance in multidimensional scaling|Visualization of multidimensional data by means of Multidimensional Scaling (MDS) is a popular technique of exploratory data analysis widely usable, e.g. in analysis of bio-medical data, behavioral science, marketing research, etc. Implementations of MDS methods include a subroutine for an auxiliary global optimization problem. The latter is difficult because of high dimensionality, absence of overall smoothness, and a large number of local minima. In such a situation application of a genetic algorithm (GA) seems reasonable. A favorable assessment of application of GAs in MDS in previous publications is based on heuristic arguments without estimating quantitatively the precision of GA while applied to the solution of corresponding global optimization problems. Indeed, the estimation of precision is difficult because of complexity to find the actual global minimum not only in routine use but also in unique research experiments. Quantitatively the precision of GA was estimated, at least in the experimental problems of modest dimensionality, using global minima found by means of the developed parallel version of explicit enumeration algorithm. To cope with high complexity of the minimization problem a parallel version of GA is developed, and its efficiency for problem of higher dimensionality is investigated.|Antanas Zilinskas,Julius Zilinskas","58166|GECCO|2007|Hardware acceleration of multi-deme genetic algorithm for the application of DNA codeword searching|A large and reliable DNA codeword library is key to the success of DNA based computing. Searching for sets of reliable DNA codewords is an NP-hard problem, which can take days on state-of-art high performance cluster computers. This work presents a hybrid architecture that consists of a general purpose microprocessor and a hardware accelerator for accelerating the multi-deme genetic algorithm (GA) for the application of DNA codeword searching. The presented architecture provides more than X speed-up compared to a software only implementation. A code extender that uses exhaustive search to produce locally optimum codes in about . hours for the case of length  codes is also described. The experimental results demonstrate that the GA can find % of the words in locally optimum libraries. Finally, we investigate the performance impact of migration, mating and mutation functions in the hardware accelerator. The analysis shows that a modified GA without mating is the most effective for DNA codeword searching.|Qinru Qiu,Daniel J. Burns,Prakash Mukre,Qing Wu","57902|GECCO|2007|Towards better than human capability in diagnosing prostate cancer using infrared spectroscopic imaging|Cancer diagnosis is essentially a human task. Almost universally, the process requires the extraction of tissue (biopsy) and examination of its microstructure by a human. To improve diagnoses based on limited and inconsistent morphologic knowledge, a new approach has recently been proposed that uses molecular spectroscopic imaging to utilize microscopic chemical composition for diagnoses. In contrast to visible imaging, the approach results in very large data sets as each pixel contains the entire molecular vibrational spectroscopy data from all chemical species. Here, we propose data handling and analysis strategies to allow computer-based diagnosis of human prostate cancer by applying a novel genetics-based machine learning technique (tt NAX). We apply this technique to demonstrate both fast learning and accurate classification that, additionally, scales well with parallelization. Preliminary results demonstrate that this approach can improve current clinical practice in diagnosing prostate cancer.|Xavier Llorà,Rohith Reddy,Brian Matesic,Rohit Bhargava"]]},"title":{"entropy":5.196670368652298,"topics":["the effects, the, and evolutionary, the and, evolution strategies, building block, optimization and, evolutionary study, the evolution, evolutionary computation, evolution for, the dynamic, analysis the, analysis and, differential evolution, analysis problem, and, and its, using multi-objective, evolution","genetic programming, genetic algorithm, genetic for, using genetic, genetic and, genetic network, using algorithm, using programming, mutation operator, for network, programming for, programming and, operator for, cartesian programming, strategies for, for using, and for, network programming, genetic problem, genetic with","automatic generation, artificial immune, data using, immune systems, gene using, evolving for, automatic for, neural network, artificial systems, classification using, with evolutionary, rule with, and selection, for classification, with xcs, with and, selection using, with, learning with, for selection","particle swarm, algorithm for, for problem, evolutionary algorithm, for optimization, optimization algorithm, for the, particle optimization, swarm optimization, estimation distribution, evolutionary for, algorithm problem, the problem, algorithm the, multiobjective optimization, evolutionary approach, hybrid algorithm, optimization problem, estimation algorithm, multi-objective approach","and evolutionary, the evolutionary, evolutionary study, evolutionary computation, the study, the and, and diversity, and computation, and, multiobjective, with, case, solution","the effects, analysis the, analysis and, and its, the its, distribution and, algorithm the, analysis algorithm, the and, convergence, particle, program, swarm, optimiser","and for, for tree, for parameter, for, code, novel","genetic programming, using genetic, genetic for, genetic network, programming for, using programming, genetic and, programming and, network programming, cartesian programming, cartesian genetic, parallel genetic","for selection, and selection, continuous, selection, adaptive, eda, variance, scaling, xcs, analysis","data using, gene using, classification using, using, ensemble, genetic, evolutionary","algorithm for, for optimization, evolutionary algorithm, optimization algorithm, optimization problem, algorithm the, estimation distribution, the optimization, algorithm problem, evolutionary optimization, algorithm with, hybrid for, evolutionary problem, hybrid evolutionary, hybrid algorithm, distribution algorithm, estimation algorithm, optimization with, evolutionary for, multi-objective","for problem, the problem, algorithm problem, for the, for scheduling, algorithm for, guided, binary"],"ranking":[["57962|GECCO|2007|Two adaptive mutation operators for optima tracking in dynamic optimization problems with evolution strategies|The dynamic optimization problem concerns finding an optimum in a changing environment. In the tracking problem, the optimizer should be able to follow the optimum's changes over time.In this paper we present two adaptive mutation operators designed to improve the following of a time-changing optimum, under the assumption that the changes follow a non-random law. Such law can be estimated in order to improve the optimum tracking capabilities of the algorithm. For experimental assessment, a (,) evolution strategy has been applied to a dynamic version of the sphere problem.|Claudio Rossi,Antonio Barrientos,Jaime del Cerro","58076|GECCO|2007|On the scalability of evolution strategies in the optimization of dynamic molecular alignment|We consider the numerical optimization of dynamic molecular alignment by shaped femtosecond pulses, and study the scalability of the electric field subject to optimization by Evolution Strategies.The trade-off between fine-tuning of the electric field versus the evolutionary optimization feasibility is investigated.|Ofer M. Shir,Thomas Bäck,Marc J. J. Vrakking","58013|GECCO|2007|Analysis of evolutionary algorithms for the longest common subsequence problem|In the longest common subsequence problem the task is to find the longest sequence of letters that can be found as a subsequence in all members of a given finite set of sequences. The problem is one of the fundamental problems in computer science with the task of finding a given pattern in a text as an important special case. It has applications in bioinformatics problem-specific algorithms and facts about its complexity are known. Motivated by reports about good performance of evolutionary algorithms for some instances of this problem a theoretical analysis of a generic evolutionary algorithm is performed. The general algorithmic framework encompasses EAs as different as steady state GAs with uniform crossover and randomized hill-climbers. For all these algorithms it is proved that even rather simple special cases of the longest common subsequence problem can neither be solved to optimality nor approximately be solved up to an approximation factor arbitrarily close to&xa.|Thomas Jansen,Dennis Weyland","57985|GECCO|2007|Differential evolution and non-separability using selective pressure to focus search|Recent results show that the Differential Evolution algorithm has significant difficulty on functions that are not linearly separable. On such functions, the algorithm must rely primarily on its differential mutation procedure which, unlike its recombination strategy, is rotationally invariant. We conjecture that this mutation strategy lacks sufficient selective pressure when appointing parent and donor vectors to have satisfactory exploitative power on non-separable functions. We find that imposing pressure in the form of rank-based differential mutation results in a significant improvement of exploitation on rotated benchmarks.|Andrew M. Sutton,Monte Lunacek,L. Darrell Whitley","58024|GECCO|2007|A discrete differential evolution algorithm for the permutation flowshop scheduling problem|In this paper, a novel discrete differential evolution (DDE) algorithm is presented to solve the permutation flowhop scheduling problem with the makespan criterion. The DDE algorithm is simple in nature such that it first mutates a target population to produce the mutant population. Then the target population is recombined with the mutant population in order to generate a trial population. Finally, a selection operator is applied to both target and trial populations to determine who will survive for the next generation based on fitness evaluations. As a mutation operator in the discrete differential evolution algorithm, a destruction and construction procedure is employed to generate the mutant population. We propose a referenced local search, which is embedded in the discrete differential evolution algorithm to further improve the solution quality. Computational results show that the proposed DDE algorithm with the referenced local search is very competitive to the iterated greedy algorithm which is one of the best performing algorithms for the permutation flowshop scheduling problem in the literature.|Quan-Qe Pan,Mehmet Fatih Tasgetiren,Yun-Chia Liang","57881|GECCO|2007|Evolution of non-uniform cellular automata using a genetic algorithm diversity and computation|We used a genetic algorithm to evaluate the cost  benefit of diversity in evolving sets of rules for non-uniform cellular automata solving the density classification problem.|Forrest Sondahl,William Rand","57877|GECCO|2007|An extended mutation concept for the local selection based differential evolution algorithm|A new mutation concept is proposed to generalize local selection based Differential Evolution algorithm to work in general multi-modal problems. Three variations of the proposed method are compared with classic Differential Evolution algorithm using a set of five well known test functions and their variants. The general idea of the new mutation operation is to divide the mutation into two parts the local and global mutation. The global mutation works as a migration operator allowing the algorithm perform global search efficiently, while the local mutation improves the efficiency of local search. The results show that the concept of global mutation is able to generalize the good performance of local selection based Differential Evolution from convex uni-modal functions to general non-convex and multi-modal problems. Among the tested functions, the new method was able to outperform the classic Differential Evolution in all butone. A limited analysis of the effects of control parameters to the performance of the algorithm is also done.|Jani Rönkkönen,Jouni Lampinen","57945|GECCO|2007|An experimental analysis of evolution strategies and particle swarm optimisers using design of experiments|The success of evolutionary algorithms (EAs) depends crucially on finding suitable parameter settings. Doing this by hand is a very time consuming job without the guarantee to finally find satisfactory parameters. Of course, there exist various kinds of parameter control techniques, but not for parameter tuning. The Design of Experiment (DoE) paradigm offers a way of retrieving optimal parameter settings. It is still a tedious task, but it is known to be a robust and well tested suite, which can be beneficial for giving reason to parameter choices besides human experience. In this paper we analyse evolution strategies (ES) and particle swarm optimisation (PSO) with and without optimal parameters gathered with DoE. Reasonable improvements have been observed for the two ES variants.|Oliver Kramer,Bartek Gloger,Andreas Goebels","57886|GECCO|2007|Evolutionary computation-based kernel optimal component analysis for pattern recognition|Kernel methods are mathematical tools that provide higher dimensional representation of given data set in feature space for pattern recognition and data analysis problems. Optimal Component Analysis (OCA)  poses the problem of finding an optimal linear representation. In this paper we present the results of six kernel functions and their respective performance for Evolutionary Computation-based kernel OCA on the Pima Indian Diabetes database. Empirical results show that we outperform existing techniques on this database.|Jason C. Isaacs,Simon Y. Foo,Anke Meyer-Bäse","58101|GECCO|2007|An online implementable differential evolution tuned optimal guidance law|This paper proposes a novel application of differential evolution to solve a difficult dynamic optimisation or optimal control problem. The miss distance in a missile-target engagement is minimised using differential evolution. The difficulty of solving it by existing conventional techniques in optimal control theory is caused by the nonlinearity of the dynamic constraint equation, inequality constraint on the control input and inequality constraint on another parameter that enters problem indirectly. The optimal control problem of finding the minimum miss distance has an analytical solution subject to several simplifying assumptions. In the approach proposed in this paper, the initial population is generated around the seed value given by this analytical solution. Thereafter, the algorithm progresses to an acceptable final solution within a few generations, satisfying the constraints at every iteration. Since this solution or the control input has to be obtained in real time to be of any use in practice, the feasibility of online implementation is also illustrated.|Raghunathan Thangavelu,S. Pradeep"],["58132|GECCO|2007|Self-modifying cartesian genetic programming|In nature, systems with enormous numbers of components (i.e. cells) are evolved from a relatively small genotype. It has not yet been demonstrated that artificial evolution is sufficient to make such a system evolvable. Consequently researchers have been investigating forms of computational development that may allow more evolvable systems. The approaches taken have largely used re-writing, multi- cellularity, or genetic regulation. In many cases it has been difficult to produce general purpose computation from such systems.In this paper we introduce computational development using a form of Cartesian Genetic Programming that includes self-modification operations. One advantage of this approach is that ab initio the system can be used to solve computational problems. We present results on a number of problems and demonstrate the characteristics and advantages that self-modification brings.|Simon Harding,Julian Francis Miller,Wolfgang Banzhaf","57904|GECCO|2007|Association rule mining for continuous attributes using genetic network programming|Most association rule mining algorithms make use of discretization algorithms for handling continuous attributes. However, by means of methods of discretization, it is difficult to get highest attribute interdependency and at the same time to get lowest number of intervals. We propose a method using a new graph-based evolutionary algorithm named \"Genetic Network Programming (GNP)\" that can deal with continues values directly, that is, without using any discretization method as a preprocessing step. GNP is one of the evolutionary optimization techniques, which uses directed graph structures as solutions and is composed of three kinds of nodes start node, judgment node and processing node. Once GNP is booted up, firstly the execution starts from the start node, secondly the next node to be executed is determined according to the judgment and connection from the current activated node. The features of GNP are described as follows. First, it is possible to reuse nodes because of this, the structure is compact. Second, GNP can find solutions of problems without bloat, which can be sometimes found in Genetic Programming (GP), because of the fixed number of nodes in GNP. Third, nodes that are not used at the current program executions will be used for future evolution. Fourth, GNP is able to cope with partially observable Markov processes. In this paper, we propose a method that can deal with continuous attributes, where attributes in databases correspond to judgment nodes in GNP and each continuous attribute is checked whether its value is greater than a threshold value and the association rules are represented as the connections of the judgment nodes. Threshold ai is firstly determined by calculating the mean i and standard deviation si of all attribute values of Ai. Then, initial threshold ai is selected randomly between the interval i - aisi, i + aisi where ai is a parameter to determine the range of the interval. Once the threshold ai is selected for all attributes, each value of the attribute Ai is checked if it is greater than the threshold ai in the judgment nodes of the proposed method. In addition to that, the threshold ai is also evolved by mutation between i - aisi, i + aisi in every generation in order to obtain as many association rules as possible. The features of the proposed method are as follows compared with other methods ) Extracts rules without identifying frequent itemsets used in Apriori-like mining methods. ) Stores extracted important association rules in a pool all together through generations. ) Measures the significance of associations via the chi-squared test. ) Extracts important rules sufficient enough for user's purpose in a short time. ) The pool is updated in every generation and only important association rules with higher chi-squared value are stored when the identical rules are stored. We have evaluated the proposed method by doing two simulations. Simulation  uses fixed threshold values that is, they remain fixed at initial thresholds during evolution. In simulation ,thresholds are evolved by mutation in every generation. Fig.  shows the number of rules extracted in the pool in simulation . It is found that the number of rules extracted has been increased, which means simulation  outperforms simulation .|Karla Taboada,Kaoru Shimada,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu","57993|GECCO|2007|Context-aware mutation a modular context aware mutation operator for genetic programming|This paper introduces a new type of mutation, Context-Aware Mutation, which is inspired by the recently introduced context-aware crossover. Context-Aware mutation operates by replacing existing sub-trees with modules from a previously construct repository of possibly useful sub-trees. We describe an algorithmic way to produce the repository from an initial, exploratory run and test various GP set ups for producing the repository. The results show that when the exploratory run uses context-aware crossover and the main run uses context-aware mutation, not only is the final result significantly better, the overall cost of the runs in terms of individuals evaluated is significantly lower.|Hammad Majeed,Conor Ryan","58049|GECCO|2007|The genetic programming collaboration network and its communities|Useful information about scientific collaboration structures and patterns can be inferred from computer databases of published papers. The genetic programming bibliography is the most complete reference of papers on GP. In addition to locating publications, it contains coauthor and coeditor relationships from which a more complete picture of the field emerges. We treat these relationships as undirected small world graphs whose study reveals the community structure of the GP collaborative social network. Automatic analysis discovers new communities and highlights new facets of them. The investigation reveals many similarities between GP and coauthorship networks in other scientific fields but also some subtle differences such as a smaller central network component and a high clustering.|Leslie Luthi,Marco Tomassini,Mario Giacobini,William B. Langdon","58114|GECCO|2007|Coevolution of intelligent agents using cartesian genetic programming|A coevolutionary competitive learning environment for two antagonistic agents is presented. The agents are controlled by a new kind of computational network based on a compartmentalised model of neurons. We have taken the view that the genetic basis of neurons is an important  and neglected aspect of previous approaches. Accordingly, we have defined a collection of chromosomes representing various aspects of the neuron soma, dendrites and axon branches, and synaptic connections. Chromosomes are represented and evolved using a form of genetic programming known as Cartesian Genetic Programming. The network formed by running the chromosomal programs has a highly dynamic morphology in which neurons grow, and die, and neurite branches together with synaptic connections form and change in response to environmental interactions. The idea of this paper is to demonstrate the importance of the genetic transfer of learned experience and life time learning. The learning is a consequence of the complex dynamics produced as a result of interaction (coevolution) between two intelligent agents. Our results show that both agents exhibit interesting learning capabilities.|Gul Muhammad Khan,Julian Francis Miller,David M. Halliday","57965|GECCO|2007|Effects of passengers arrival distribution to double-deck elevator group supervisory control systems using genetic network programming|The Elevator Group Supervisory Control Systems (EGSCS) are the control systems that systematically manage three or more elevators in order to efficiently transport the passengers in buildings. Double-deck elevators, where two cages are connected with each other, are expected to be the next generation elevator systems. Meanwhile, Destination Floor Guidance Systems (DFGS) are also expected in Double-Deck Elevator Systems (DDES). With these, the passengers could be served at two consecutive floors and could input their destinations at elevator halls instead of conventional systems without DFGS. Such systems become more complex than the traditional systems and require new control methods Genetic Network Programming (GNP), a graph-based evolutionary method, has been applied to EGSCS and its advantages are shown in some previous papers. GNP can obtain the strategy of a new hall call assignment to the optimal elevator because it performs crossover and mutation operations to judgment nodes and processing nodes. In studies so far, the passenger's arrival has been assumed to take Exponential distribution for many years. In this paper, we have applied Erlang distribution and Binomial distribution in order to study how the passenger's arrival distribution affects EGSCS. We have found that the passenger's arrival distribution has great influence on EGSCS. It has been also clarified that GNP makes good performances under different conditions.|Lu Yu,Jin Zhou,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu,Sandor Markon","57974|GECCO|2007|Trading rules on stock markets using genetic network programming with sarsa learning|In this paper, the Genetic Network Programming (GNP) for creating trading rules on stocks is described. GNP is an evolutionary computation, which represents its solutions using graph structures and has some useful features inherently. It has been clarified that GNP works well especially in dynamic environments since GNP can create quite compact programs and has an implicit memory function. In this paper, GNP is applied to creating a stock trading model. There are three important points The first important point is to combine GNP with Sarsa Learning which is one of the reinforcement learning algorithms. Evolution-based methods evolve their programs after task execution because they must calculate fitness values, while reinforcement learning can change programs during task execution, therefore the programs can be created efficiently. The second important point is that GNP uses candlestick chart and selects appropriate technical indices to judge the buying and selling timing of stocks. The third important point is that sub-nodes are used in each node to determine appropriate actions (buyingselling) and to select appropriate stock price information depending on the situation. In the simulations, the trading model is trained using the stock prices of  brands in ,  and . Then the generalization ability is tested using the stock prices in . From the simulation results, it is clarified that the trading rules of the proposed method obtain much higher profits than Buy&Hold method and its effectiveness has been confirmed.|Yan Chen,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu","57893|GECCO|2007|A data parallel approach to genetic programming using programmable graphics hardware|In recent years the computing power of graphics cards has increased significantly. Indeed, the growth in the computing power of these graphics cards is now several orders of magnitude greater than the growth in the power of computer processor units. Thus these graphics cards are now beginning to be used by the scientific community aslow cost, high performance computing platforms. Traditional genetic programming is a highly computer intensive algorithm but due to its parallel nature it can be distributed over multiple processors to increase the speed of the algorithm considerably. This is not applicable for single processor architectures but graphics cards provide a mechanism for developing a data parallel implementation of genetic programming. In this paper we will describe the technique of general purpose computing using graphics cards and how to extend this technique to genetic programming. We will demonstrate the improvement in the performance of genetic programming on single processor architectures which can be achieved by harnessing the computing power of these next generation graphics cards.|Darren M. Chitty","57895|GECCO|2007|Peptide detectability following ESI mass spectrometry prediction using genetic programming|The accurate quantification of proteins is important in several areas of cell biology, biotechnology and medicine. Both relative and absolute quantification of proteins is often determined following mass spectrometric analysis of one or more of their constituent peptides. However, in order for quantification to be successful, it is important that the experimenter knows which peptides are readily detectable under the mass spectrometric conditions used for analysis. In this paper, genetic programming is used to develop a function which predicts the detectability of peptides from their calculated physico-chemical properties. Classification is carried out in two stages the selection of a good classifier using the AUROC objective function and the setting of an appropriate threshold. This allows the user to select the balance point between conflicting priorities in an intuitive way. The success of this method is found to be highly dependent on the initial selection of input parameters. The use of brood recombination and a modified version of the multi-objective FOCUS method are also investigated. While neither has a significant effect on predictive accuracy, the use of the FOCUS method leads to considerably more compact solutions.|David C. Wedge,Simon J. Gaskell,Simon J. Hubbard,Douglas B. Kell,King Wai Lau,Claire Eyers","57990|GECCO|2007|Solving real-valued optimisation problems using cartesian genetic programming|Classical Evolutionary Programming (CEP) and Fast Evolutionary Programming (FEP) have been applied to real-valued function optimisation. Both of these techniques directly evolve the real-values that are the arguments of the real-valued function. In this paper we have applied a form of genetic programming called Cartesian Genetic Programming (CGP) to a number of real-valued optimisation benchmark problems. The approach we have taken is to evolve a computer program that controls a writing-head, which moves along and interacts with a finite set of symbols that are interpreted as real numbers, instead of manipulating the real numbers directly. In other studies, CGP has already been shown to benefit from a high degree of neutrality. We hope to exploit this for real-valued function optimisation problems to avoid being trapped on local optima. We have also used an extended form of CGP called Embedded CGP (ECGP) which allows the acquisition, evolution and re-use of modules. The effectiveness of CGP and ECGP are compared and contrasted with CEP and FEP on the benchmark problems. Results show that the new techniques are very effective.|James Alfred Walker,Julian Francis Miller"],["58040|GECCO|2007|Variable selection for wind power prediction using particle swarm optimization|Wind energy has an increasing influence on the energy supply in many countries, but in contrast to conventional power plants it is a fluctuating energy source. For its integration in the electricity supply structure it is necessary to predict the wind power hours or days ahead. There are models based on physical, statistical or artificial intelligence approaches for the prediction of wind power. In this paper a new short-term prediction method is described based on variable selection using particle swarm optimization and nearest neighbour search. As input variables for this prediction method weather data of a numerical weather prediction model and measured power data from wind farms of several locations in a spread area are used. Additionally a prediction model based on neural networks is described and the results of the new method are compared to the results of the neural network approach. As a result we get a reduction of the prediction error by using the new prediction method. An additional error reduction is possible by using the mean model output of the neural network model and of the nearest neighbour search based prediction approach.|René Jursa","57954|GECCO|2007|Using group selection to evolve leadership in populations of self-replicating digital organisms|This paper describes a study in the evolution of distributed cooperative behavior, specifically leader election, through digital evolution and group selection. In digital evolution, a population of self-replicating computer programs exists in a user-defined computational environment and is subject to instruction-level mutations and natural selection. Group selection is the theory that the survival of the individual is linked to the survival of the group, thus encouraging cooperation. The results of experiments using the Avida digital evolution platform demonstrate that group selection can produce populations capable of electing a leader and, when that leader is terminated, electing a new leader. This result serves as an existence proof that group selection and digital evolution can produce complex cooperative behaviors, and therefore have promise in the design of robust distributed computing systems.|David B. Knoester,Philip K. McKinley,Charles Ofria","58066|GECCO|2007|Automatic generation of benchmarks for plagiarism detection tools using grammatical evolution|Student plagiarism is a mayor problem in universities worldwide. In this paper,we focus on plagiarism in answers to computer programming assignments,where student mix andor modify one or more original solutions to obtain counterfeits. Although several software tools have been implemented to help the tedious and time consuming task of detecting plagiarism, little has been done to assess their quality, because, in fact, determining the original subset of the whole solutionset is practically impossible for graders. In this article we present a Grammatical Evolution technique which generates benchmarks. Given a programming language, our technique generates a set of original solutions to an assignment, together with a set of plagiarisms of the former set which mimic the way in which students act. The phylogeny of the coded solutions is predefined, providing a base for the evaluationof the performance of copy-catching tools. We give empirical evidence of the suitability of our approach by studying the behavior of one state-of-the-art detection tool (AC) on four benchmarks coded in APL, generated with this technique.|Manuel Cebrián,Manuel Alfonseca,Alfonso Ortega","58145|GECCO|2007|Induction of fuzzy rules with artificial immune systems in acgh based er status breast cancer characterization|Genomic DNA copy number aberrations are frequent in solid tumours although their underlying causes remain obscure. In this paper we show how Artificial Immune System (AIS) paradigm can be successfully employed in the elucidation of biological dynamics of cancerous processes using a novel fuzzy rule induction system for data mining (IFRAIS). Competitive results have been obtained using IFRAIS. A biological interpretation of the results, carried out using Gene Ontology, followed the statistical assessment and put in evidence interesting patterns that are currently under investigation.|Filippo Menolascina,Roberto Teixeira Alves,Stefania Tommasi,Patrizia Chiarappa,Myriam Regattieri Delgado,Giuseppe Mastronardi,Angelo Paradiso,Alex Alves Freitas,Vitoantonio Bevilacqua","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","58223|GECCO|2007|Modelling danger and anergy in artificial immune systems|Artificial Immune Systems are engineering systems which have been inspired from the functioning of the biological immune system. We present an immune system model which incorporates two biologically motivated mechanisms to protect against autoimmune reactions, or false positives. The first, anergy, has been subject to the intense focus of immunologists as a possible key to autoimmune disease. The second is danger theory, which has attracted much interest as a possible alternative to traditional self-nonself selection models.We adopt a published immunological model, validate and extend it. Using the same calculations and assumptions as the original model, we integrate danger theory into the software.Without anergy, both models - the original and the danger model - produce similar results. When anergy is added, both models' performance improves. However, there seems to be some synergy between the mechanisms anergy has a greater effect on the danger model than the original model. These findings should be of interest both to AIS practitioners and to the immunological community.|Steve Cayzer,Julie Sullivan","58034|GECCO|2007|Clustering gene expression data via mining ensembles of classification rules evolved using moses|A novel approach, model-based clustering, is described foridentifying complex interactions between genes or gene-categories based on static gene expression data. The approach deals with categorical data, which consists of a set of gene expressionprofiles belonging to one category, and a set belonging to anothercategory. An evolutionary algorithm (Meta-Optimizing Semantic Evolutionary Search, or MOSES) is used to learn an ensemble of classification models distinguishing the two categories, based on inputs that are features corresponding to gene expression values. Each feature is associated with a model-based vector, which encodes quantitative information regarding the utilization of the feature across the ensembles of models. Two different ways of constructing these vectors are explored. These model-based vectors are then clustered using a variant of hierarchical clustering called Omniclust. The result is a set of model-based clusters, in which features are gathered together if they are often considered together by classification models -- which may be because they're co-expressed, or may be for subtler reasons involving multi-gene interactions. The method is illustrated by applying it to two datasets regarding human gene expression, one drawn from brain cells and pertinent to the neurogenetics of aging, and the other drawn from blood cells and relating to differentiating between types of lymphoma. We find that, compared to traditional expression-based clustering, the new method often yields clusters that have higher mathematical quality (in the sense of homogeneity and separation) and also yield novel and meaningful insights into the underlying biological processes.|Moshe Looks,Ben Goertzel,Lúcio de Souza Coelho,Mauricio Mudado,Cassio Pennachin","57934|GECCO|2007|Evolutionary selection of minimum number of features for classification of gene expression data using genetic algorithms|Selecting the most relevant factors from genetic profiles that can optimally characterize cellular states is of crucial importance in identifying complex disease genes and biomarkers for disease diagnosis and assessing drug efficiency. In this paper, we present an approach using a genetic algorithm for a feature subset selection problem that can be used in selecting the near optimum set of genes for classification of cancer data. In substantial improvement over existing methods, we classified cancer data with high accuracy with less features.|Alper Küçükural,Reyyan Yeniterzi,Süveyda Yeniterzi,Osman Ugur Sezerman","58183|GECCO|2007|Keyword extraction using an artificial immune system|This paper presents a model for keyword extraction which combines an artificial immune system with a mathematical background based on information theory. The proposed approach does not need any domain knowledge, neither the use of a stopword list. The output is a set of keywords for each of the categories into the corpus used.|Andres Romero,Fernando Niño","58075|GECCO|2007|A platform for the selection of genes in DNA microarraydata using evolutionary algorithms|This paper presents a flexible framework to the task of featureselection in classification of DNA microarray data. Theuser can select a number of filter methods in the preprocessingstage and choose from a wide set of classifiers (models and algorithms from WEKA  are available) and accuracy estimation methods. This approach implements wrapper methods, where Evolutionary Algorithms, with variable sized set based representations are used to reduce the number of attributes. Two case studies were used to validate the approach, with three distinct classifiers (-nearest neighbour, decision trees, SVMs), a filter method based on discriminant fuzzy patterns and k-fold cross-validation to estimate the generalization error.|Miguel Rocha,Rui Mendes,Paulo Maia,Daniel Glez-Peña,Florentino Fdez-Riverola"],["58157|GECCO|2007|Towards billion-bit optimization via a parallel estimation of distribution algorithm|This paper presents a highly efficient, fully parallelized implementation of the compact genetic algorithm (cGA) to solve very large scale problems with millions to billions of variables. The paper presents principled results demonstrating the scalable solution of a difficult test function on instances over a billion variables using a parallel implementation of cGA. The problem addressed is a noisy, blind problem over a vector of binary decision variables. Noise is added equaling up to a tenth of the deterministic objective function variance of the problem, thereby making it difficult for simple hillclimbers to find the optimal solution. The compact GA, on the other hand, is able to find the optimum in the presence of noise quickly, reliably, and accurately, and the solution scalability follows known convergence theories. These results on noisy problem together with other results on problems involving varying modularity, hierarchy, and overlap foreshadow routine solution of billion-variable problems across the landscape of search problems.|Kumara Sastry,David E. Goldberg,Xavier Llorà","57951|GECCO|2007|An estimation of distribution algorithm with guided mutation for a complex flow shop scheduling problem|An Estimation of Distribution Algorithm (EDA) is proposed toapproach the Hybrid Flow Shop with Sequence Dependent Setup Times and Uniform Machines in parallel (HFS-SDST-UM) problem. The latter motivated by the needs of a real world company. The proposed EDA implements a fairly new mechanism to improve the search of more traditional EDAs. This is the Guided Mutation (GM). EDA-GM generates new solutions by using the information from a probability model, as all EDAs, and the local information from a good known solution. The approach is tested on several instances of HFS-SDST-UM and compared with adaptations of meta-heuristics designed for very similarproblems. Encouraging results are reported.|Abdellah Salhi,José Antonio Vázquez Rodríguez,Qingfu Zhang","58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Suárez,Manuel Valenzuela-Rendón,Hugo Terashima-Marín,Eduardo Uresti-Charre","58126|GECCO|2007|A genetic algorithm for privacy preserving combinatorial optimization|We propose a protocol for a local search and a genetic algorithm for the distributed traveling salesman problem (TSP). In the distributed TSP, information regarding the cost function such as traveling costs between cities and cities to be visited are separately possessed by distributed parties and both are kept private each other. We propose a protocol that securely solves the distributed TSP by means of a combination of genetic algorithms and a cryptographic technique, called the secure multiparty computation. The computation time required for the privacy preserving optimization is practical at some level even when the city-size is more than a thousand.|Jun Sakuma,Shigenobu Kobayashi","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57972|GECCO|2007|Kernel based automatic clustering using modified particle swarm optimization algorithm|This paper introduces a method for clustering complex and linearly non-separable datasets, without any prior knowledge of the number of naturally occurring clusters. The proposed method is based on an improved variant of the Particle Swarm Optimization (PSO) algorithm. In addition, it employs a kernel-induced similarity measure instead of the conventional sum-of-squares distance. Use of the kernel function makes it possible to cluster data that is linearly non-separable in the original input space into homogeneous groups in a transformed high-dimensional feature space. Computer simulations have been undertaken with a test bench of five synthetic and three real life datasets, in order to compare the performance of the proposed method with a few state-of-the-art clustering algorithms. The results reflect the superiority of the proposed algorithm in terms of accuracy, convergence speed and robustness.|Ajith Abraham,Swagatam Das,Amit Konar","58208|GECCO|2007|Two-level of nondominated solutions approach to multiobjective particle swarm optimization|In multiobjective particle swarm optimization (MOPSO) methods, selecting the local best and the global best for each particle of the population has a great impact on the convergence and diversity of solutions, especially when optimizing problems with high number of objectives. This paper presents a two-level of nondominated solutions approach to MOPSO. The ability of the proposed approach to detect the true Pareto optimal solutions and capture the shape of the Pareto front is evaluated through experiments on well-known non-trivial test problems. The diversity of the nondominated solutions obtained is demonstrated through different measures. The proposed approach has been assessed through a comparative study with the reported results in the literature.|M. A. Abido","58018|GECCO|2007|Investigation of mutation operators for the bayesian optimization algorithm|Although BOA is effective at finding solutions for optimization problems, small population sizes in a model can result in premature convergence to a sub-optimal solution. One way of avoiding premature convergence is to increase population diversity with a mutation operator. In our experiments, we compare several mutation operators for use with BOA. We examine in detail the probabilistic model utilizing (PMU) bit flipping mutation operator. We compare the effectiveness of the PMU operator with standard BOA, self-adaptive evolution and local search of substructural neighborhoods.|Eric Martin Heien,Tomoyuki Hiroyasu,Noriyuki Fujimoto","58010|GECCO|2007|Global multiobjective optimization via estimation of distribution algorithm with biased initialization and crossover|Multiobjective optimization problems with many local Pareto fronts is a big challenge to evolutionary algorithms. In this paper, two operators, biased initialization and biased crossover, are proposed to improve the global search ability of RM-MEDA, a recently proposed multiobjective estimation of distribution algorithm. Biased initialization inserts several globally Pareto optimal solutions into the initial population biased crossover combines the location information of some best solutions found so far and globally statistical information extracted from current population. Experiments have been conducted to study the effects of these two operators.|Aimin Zhou,Qingfu Zhang,Yaochu Jin,Bernhard Sendhoff,Edward P. K. Tsang"],["58176|GECCO|2007|A study on metamodeling techniques ensembles and multi-surrogates in evolutionary computation|Surrogate-Assisted Memetic Algorithm (SAMA) is a hybrid evolutionary algorithm, particularly a memetic algorithm that employs surrogate models in the optimization search. Since most of the objective function evaluations in SAMA are approximated, the search performance of SAMA is likely to be affected by the characteristics of the models used. In this paper, we study the search performance of using different meta modeling techniques, ensembles, and multi-surrogates in SAMA. In particular, we consider the SAMA-TRF, a SAMA model management framework that incorporates a trust region scheme for interleaving use of exact objective function with computationally cheap local meta models during local searches. Four different metamodels, namely Gaussian Process (GP), Radial Basis Function (RBF), Polynomial Regression (PR), and Extreme Learning Machine (ELM) neural network are used in the study. Empirical results obtained show that while some metamodeling techniques perform best on particular benchmark problems, ensemble of metamodels and multisurrogates yield robust and improved solution quality on the benchmark problems in general, for the same computational budget.|Dudy Lim,Yew-Soon Ong,Yaochu Jin,Bernhard Sendhoff","58060|GECCO|2007|Volatility forecasting using time series data mining and evolutionary computation techniques|Traditional parametric methods have limited success in estimating and forecasting the volatility of financial securities. Recent advance in evolutionary computation has provided additional tools to conduct data mining effectively. The current work applies the genetic programming in a Time Series Data Mining framework to characterize the S&P high frequency data in order to forecast the one step ahead integrated volatility. Results of the experiment have shown to be superior to those derived by the traditional methods.|Irwin Ma,Tony Wong,Thiagas Sankar","58004|GECCO|2007|Dimensionality reduction in evolutionary multiobjective design case study|Real-world applications of Pareto-based optimisation commonly involve many objectives. It causes difficulties because of reduced selection pressure for better solutions. Dimensionality Reduction (DR) is a very appealing approach to overcome this problem. A case study of multiobjective Electric Machine (EM) design based on DR of the novel model  is considered.|Piotr Wozniak","58036|GECCO|2007|Characteristic determination for solid state devices with evolutionary computation a case study|In this paper, we develop a new optimization framework that consists of the extended compact genetic algorithm (ECGA) and split-on-demand (SoD), an adaptive discretization technique, to tackle the characteristic determination problem for solid state devices. As most decision variables of characteristic determination problems are real numbers due to the modeling of physical phenomena, and ECGA is designed for handling discrete-type problems, a specific mechanism to transform the variable types of the two ends is in order. In the proposed framework, ECGA is used as a back-end optimization engine, and SoD is adopted as the interface between the engine and the problem. Moreover, instead of one mathematical model with various parameters, characteristic determination is in fact a set of problems of which the mathematical formulations may be very different. Therefore, in this study, we employ the proposed framework on three study cases to demonstrate that the technique proposed in the domain of evolutionary computation can provide not only the high quality optimization results but also the flexibility to handle problems of different formulations.|Ping-Chu Hung,Ying-Ping Chen,Hsiao Wen Zan","57920|GECCO|2007|A study of mutational robustness as the product of evolutionary computation|This paper investigates the ability of a tournament selection based genetic algorithm to find mutationally robust solutions to a simple combinatorial optimization problem. Two distinct algorithms (a stochastic hill climber and a tournament selection based GA) were used to search for optimal walks in several variants of the self avoiding walk problem. The robustness of the solutions obtained by the algorithms were compared, both with each other and with solutions obtained by a random sampling of the optimal solution space. The solutions found by the GA were, for most of the problem variants, significantly more robust than those found by either the hill climbing algorithm or random sampling. The solutions found by the hill climbing algorithm were often significantly less robust than those obtained through random sampling. .|Justin Schonfeld","58198|GECCO|2007|Using evolutionary computation and local search to solve multi-objective flexible job shop problems|Finding realistic schedules for Flexible Job Shop Problems has attracted many researchers recently due to its NP-hardness. In this paper, we present an efficient approach for solving the multi-objective flexible job shop by combining Evolutionary Algorithm and Guided Local Search. Instead of applying random local search to find neighborhood solutions, we introduce a guided local search procedure to accelerate the process of convergence to Pareto-optimal solutions. The main improvement of this combination is to help diversify the population towards the Pareto-front. Empirical studies show that ) the gaps between the obtained results and known lower bounds are small, and ) the multi-objective solutions of our algorithms dominate previous designs for solving the same benchmarks while incurring less computational time.|Nhu Binh Ho,Joc Cing Tay","57886|GECCO|2007|Evolutionary computation-based kernel optimal component analysis for pattern recognition|Kernel methods are mathematical tools that provide higher dimensional representation of given data set in feature space for pattern recognition and data analysis problems. Optimal Component Analysis (OCA)  poses the problem of finding an optimal linear representation. In this paper we present the results of six kernel functions and their respective performance for Evolutionary Computation-based kernel OCA on the Pima Indian Diabetes database. Empirical results show that we outperform existing techniques on this database.|Jason C. Isaacs,Simon Y. Foo,Anke Meyer-Bäse","58125|GECCO|2007|An informed convergence accelerator for evolutionary multiobjective optimiser|A novel optimisation accelerator deploying neural network predictions and objective space direct manipulation strategies is presented. The concept of directing the search through the use of 'mirage' solutions is introduced and investigated. The accelerator is meant to be a portable component that can be plugged into any stochastic optimisation algorithm, such as genetic algorithms. The purpose of the new component termed as the Informed Convergence Accelerator (ICA) is to enhance the search capability, convergence extent and most especially the speed of convergence of the hosting stochastic global optimisation technique. ICA was hybridized with the Non-Dominated Sorting Genetic Algorithm (NSGA-II). Enhanced results were achieved demonstrating the utility of the introduced component.|Salem F. Adra,Ian Griffin,Peter J. Fleming","57977|GECCO|2007|On the roles of redundancy and neutrality in evolutionary optimization an experimental study|An experimental study was performed to explore whether it is neutrality itself or simply the larger neighborhoods associated with neutral representations that influence the results achieved by evolutionary algorithms on NK fitness landscape problems.Markov chains were used to model the behaviour of a stochastic hill-climber on NK fitness landscapes, using two different types of representation a neutral network representation which exhibits neutrality and a redundant representation without neutrality which implements the same neighborhood induced by the corresponding neutral representation.|Marisol B. Correia,Carlos M. Fonseca","58099|GECCO|2007|Automatic analog IC layout generation based on a evolutionary computation approach|This paper describes an innovative analog IC layout generation approach based on evolutionary computation techniques.|Nuno C. Lourenço,Nuno C. G. Horta"],["57916|GECCO|2007|Exact analysis of the sampling distribution for the canonical particle swarm optimiser and its convergence during stagnation|Several theoretical analyses of the dynamics of particle swarms have been offered in the literature over the last decade. Virtually all rely on substantial simplifications, including the assumption that the particles are deterministic. This has prevented the exact characterisation of the sampling distribution of the PSO. In this paper we introduce a novel method, which allows one to exactly determine all the characteristics of a PSO's sampling distribution and explain how they change over any number of generations, in the presence stochasticity. The only assumption we make is stagnation, i.e., we study the sampling distribution produced by particles in search for a better personal best. We apply the analysis to the PSO with inertia weight, but the analysis is also valid for the PSO with constriction.|Riccardo Poli,David S. Broomhead","57982|GECCO|2007|Generalisation of the limiting distribution of program sizes in tree-based genetic programming and analysis of its effects on bloat|Recent research  has found that standard sub-tree crossover with uniform selection of crossover points, in the absence of fitness pressure, pushes a population of GP trees towards a Lagrange distribution of tree sizes. However, the result applied to the case of single arity function plus leaf node combinations, e.g., unary, binary, ternary, etc trees only. In this paper we extend those findings and show that the same distribution is also applicable to the more general case where the function set includes functions of mixed arities. We also provide empirical evidence that strongly corroborates this generalisation. Both predicted and observed results show a distinct bias towards the sampling of shorter programs irrespective of the mix of function arities used. Practical applications and implications of this knowledge are investigated with regard to search efficiency and program bloat. Work is also presented regarding the applicability of the theory to the traditional %-function %-terminal crossover node selection policy.|Stephen Dignum,Riccardo Poli","58103|GECCO|2007|An analysis of the effects of population structure on scalable multiobjective optimization problems|Multiobjective evolutionary algorithms (MOEA) are an effective tool for solving search and optimization problems containing several incommensurable and possibly conflicting objectives. Unfortunately, many MOEAs face difficulties in solving problems when the number of objectives increases. In this paper, we investigate the efficacy of spatially structured MOEAs for scalable multiobjective problems. The algorithm is an extension of the standard cellular evolutionary algorithm, where the population is mapped to nodes of alternative complex networks. A selection regime based on a non-dominance rating and a crowding mechanism guides the evolutionary trajectory and an -dominance external archive is used to maintain a spread of solutions across the Pareto-optimal front. An important outcome of this work is the classification of the network models based on their impact on convergence speed and solution quality as the number of objectives increases for a given problem.|Michael Kirley,Robert L. Stewart","57909|GECCO|2007|Enhanced forma analysis of permutation problems|Forma analysis provides an approach to formally derive domain specific operators based on domain-independent operator templates by manipulating a set of equivalence relations (i.e., the basis), which is used to describe the search space. In the case of permutation problems, where the basis is highly constrained, the declarative nature of forma analysis encounters some difficulties which give rise to some additional issues, such as the interpretation of declarative constraints and the complexity of the application of operator. This paper aims to address these issues by introducing Enhanced Forma Analysis that explores a broader view of forma analysis by using ideas from constraint satisfaction.|Tao Gong,Andrew Tuson","58070|GECCO|2007|Convergence phases variance trajectories and runtime analysis of continuous EDAs|Considering the available body of literature on continuous EDAs, one must state that many important questions are still unanswered, e.g. How do continuous EDAs really work, and how can we increase their efficiency further The first question must be answered on the basis of formal models, but despite some recent results, the majority of contributions to the field is experimental. The second questionshould be answered by exploiting the insights that have been gained from formal models. We contribute to the theoretical literature on continuous EDAs by focussing on a simple, yet important, question How should the variances used tosample offspring from change over an EDA run To answer this question, the convergence process is separated into three phases and it is shown that for each phase, a preferable strategy exists for setting the variances. It is highly likely that the use of variances that have been estimated with maximum likelihood is not optimal. Thus, variance modification policies are not just a nice add-on. In the light of our findings, they become an integral component of continuous EDAs, and they should consider the specific requirements of all phases of the optimization process.|Jörn Grahl,Peter A. N. Bosman,Stefan Minner","58224|GECCO|2007|EcoPS a particle swarm algorithm to model group-foraging|Recent work has introduced a simulation model of ecological processes in terms of a very simple Particle Swarm algorithm. This abstract model produced qualitatively realistic behaviours, but do these results hold up in a model constrained by more plausible biological assumptions The objective of this paper is to answer this question.|Cecilia Di Chio,Riccardo Poli,Paolo Di Chio","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","58229|GECCO|2007|On the runtime analysis of the -ANT ACO algorithm|The runtime analysis of randomized search heuristics is a growing field where, in the last two decades, many rigorous results have been obtained. These results, however, apply particularly to classical search heuristics such as Evolutionary Algorithms (EAs) and Simulated Annealing. First runtime analyses of modern search heuristics have been conducted only recently w.r.t a simple Ant Colony Optimization (ACO) algorithm called -ANT. In particular, the influence of the evaporation factor in the pheromone update mechanism and the robustness of this parameter w.r.t the runtime behavior have been determined for the example function OneMax.This paper puts forward the rigorous runtime analysis of the -ANT on example functions, namely on the functions LeadingOnes and BinVal. With respect to EAs, such analyses have been essential to develop methods for the analysis on more complicated problems. The proof techniques required for the -ANT, unfortunately, differ significantly from those for EAs, which means that a new reservoir of methods has to be built up. Again, the influence of the evaporation factor is analyzed rigorously, and it is proved that its choice can be very crucial to allow efficient runtimes. Moreover, the analyses provide insight into the working principles of ACO algorithms and, in terms of their robustness, describe essential differences to other randomized search heuristics.|Benjamin Doerr,Frank Neumann,Dirk Sudholt,Carsten Witt","57945|GECCO|2007|An experimental analysis of evolution strategies and particle swarm optimisers using design of experiments|The success of evolutionary algorithms (EAs) depends crucially on finding suitable parameter settings. Doing this by hand is a very time consuming job without the guarantee to finally find satisfactory parameters. Of course, there exist various kinds of parameter control techniques, but not for parameter tuning. The Design of Experiment (DoE) paradigm offers a way of retrieving optimal parameter settings. It is still a tedious task, but it is known to be a robust and well tested suite, which can be beneficial for giving reason to parameter choices besides human experience. In this paper we analyse evolution strategies (ES) and particle swarm optimisation (PSO) with and without optimal parameters gathered with DoE. Reasonable improvements have been observed for the two ES variants.|Oliver Kramer,Bartek Gloger,Andreas Goebels","57983|GECCO|2007|A framework of quantum-inspired multi-objective evolutionary algorithms and its convergence condition|A general framework of quantum-inspired multi-objective evolutionary algorithms as well as one of its sufficient convergence conditions to Pareto optimal set is proposed.|Zhiyong Li,Günter Rudolph"],["58071|GECCO|2007|A novel generative encoding for exploiting neural network sensor and output geometry|A significant problem for evolving artificial neural networks is that the physical arrangement of sensors and effectors is invisible to the evolutionary algorithm. For example, in this paper, directional sensors and effectors are placed around the circumference of a robot in analogous arrangements. This configuration ensures that there is a useful geometric correspondence between sensors and effectors. However, if sensors are mapped to a single input layer and the effectors to a single output layer (as is typical), evolution has no means to exploit this fortuitous arrangement. To address this problem, this paper presents a novel generative encoding called connective Compositional Pattern Producing Networks (connective CPPNs) that can effectively detect and capitalize on geometric relationships among sensors and effectors. The key insight is that sensors and effectors with consistent geometric relationships can be exploited by a repeating motif in the neural architecture. Thus, by employing an encoding that can discover such motifs as a function of network geometry, it becomes possible to exploit it. In this paper, a method for evolving connective CPPNs called Hypercube-based Neuroevolution of Augmenting Topologies (HyperNEAT) discovers sensible repeating motifs that take advantage of two different placement schemes, demonstrating the utility of such an approach.|David B. D'Ambrosio,Kenneth O. Stanley","58115|GECCO|2007|Learning recursive programs with cooperative coevolution of genetic code mapping and genotype|The Probabilistic Adaptive Mapping Developmental Genetic Programming (PAM DGP) algorithm that cooperatively coevolves a population of adaptive mappings and associated genotypes is used to learn recursive solutions given a function set consisting of general (not implicitly recursive) machine-language instructions. PAM DGP using redundant encodings to model the evolution of the biological genetic code is found to more efficiently learn nd and rd order recursive Fibonacci functions than related developmental systems and traditional linear GP. PAM DGP using redundant encoding is also demonstrated to produce the semantically highest quality solutions for all three recursive functions considered (Factorial, nd and rd order Fibonacci). PAM DGP is then shown to have produced such solutions by evolving redundant mappings to select and emphasize appropriate subsets of the function set useful for producing the naturally recursive solutions.|Garnett Carl Wilson,Malcolm I. Heywood","58142|GECCO|2007|A novel ab-initio genetic-based approach for protein folding prediction|In this paper, a model based on genetic algorithms for protein folding prediction is proposed. The most important features of the proposed approach are i) Heuristic secondary structure information is used in the initialization of the genetic algorithm ii) An enhanced D spatial representation called cube-octahedron is used, also, an expansion technique is proposed in order to reduce the computational complexity and spatial constraints iii) Data preprocessing of geometric features to characterize the cube-octahedron using twelve basic vectors to define the nodes. Additionally, biological information (torsion angles, bond angles and secondary structure conformations) was pre-processed through an analysis of all possible combinations of the basic vectors which satisfy the biological constrains defined by the spatial representation and iv) Hashing techniques were used to improve the computational efficiency. The pre-processed information was stored in hash tables, which are intensively used by the genetic algorithm. Some experiments were carried out to validate the proposed model obtaining very promising results.|Sergio Raul Duarte Torres,David Camilo Becerra Romero,Luis Fernando Niño Vasquez,Yoan José Pinzón Ardila","58162|GECCO|2007|Genetic parameter tuning for reliable segmentation of colored visual tags|This paper reports on a case study on segmentation of colored visual tags for object identification. Lighting variations result in uncertainty in color thresholds leading to unreliable overall system behavior. We describe an experiment with a genetic algorithm (GA) approach for generating reliable thresholds for color identification. We compare it with a maximum distance (MD) approach, and demonstrate that the genetic approach is far more accurate and reliable.|Audrey J. W. Mbogho,Lori L. Scarlatos","58042|GECCO|2007|Novel ways of improving cooperation and performance in ensemble classifiers|There are two common methods of evolving teams of genetic programs. Research suggests Island approaches produce teams of strong individuals that cooperate poorly and Team approaches produce teams of weak individuals that cooperate strongly. Ideally, teams should be composed of strong individuals that cooperate well. In this paper we present a new class of algorithms called Orthogonal Evolution of Teams (OET) that overcomes the weaknesses of current Island and Team approaches by applying evolutionary pressure at both the level of teams and individuals during selection and replacement. We present four novel algorithms in this new class and compare their performance to Island and Team approaches as well as multi-class Adaboost on a number of classification problems.|Russell Thomason,Terence Soule","57933|GECCO|2007|Adaptive strategies for a semantically driven tree optimizer to control code growth|In genetic programming many methods to fight growth exist. Butmost of these methods require one or multiple parameters to beset. Unfortunately performance strongly depends on a correct setting of each of those parameters. Recently a semantically driven tree optimizer has been developed. In this paper two adaptive strategies to choose a reasonable parameter setting forthis growth limiter are presented.|Bart Wyns,Luc Boullart","58117|GECCO|2007|Comparison of tree and graph encodings as function of problem complexity|In this paper, we analyze two general-purpose encoding types, trees and graphs systematically, focusing on trends over increasingly complex problems. Tree and graph encodings are similar in application but offer distinct advantages and disadvantages in genetic programming. We describe two implementations and discuss their evolvability. We then compare performance using symbolic regression on hundreds of random nonlinear target functions of both -dimensional and -dimensional cases. Results show the graph encoding has less bias for bloating solutions but is slower to converge and deleterious crossovers are more frequent. The graph encoding however is found to have computational benefits, suggesting it to be an advantageous trade-off between regression performance and computational effort.|Michael D. Schmidt,Hod Lipson","57981|GECCO|2007|Modeling XCS in class imbalances population size and parameter settings|This paper analyzes the scalability of the population size required in XCS to maintain nichesthat are infrequently activated.Facetwise models have been developed to predict the effect of the imbalance ratio--ratio betweenthe number of instances of the majority class and the minority class that are sampled to XCS--on population initialization, andon the creation and deletion of classifiers of the minority class. While theoretical models show that, ideally, XCS scales linearly with the imbalance ratio, XCS with standard configuration scales exponentially. The causes that are potentially responsible for this deviation from the ideal scalability are also investigated. Specifically, the inheritance procedure of classifiers' parameters, mutation, and subsumption are analyzed, and improvements in XCS's mechanisms are proposed to effectively and efficiently handle imbalanced problems. Once the recommendations are incorporated to XCS, empirical results show that the population size in XCS indeed scales linearly with the imbalance ratio.|Albert Orriols-Puig,David E. Goldberg,Kumara Sastry,Ester Bernadó-Mansilla","58083|GECCO|2007|Limiting code growth to improve robustness in tree-based genetic programming|In this paper we analyze the composition of the function set ofthe artificial ant problem to define new training and testing trails similar to the Santa Fe trail. Cross-validation is used inapplications where large amounts of data are available. We alsouse a semantically driven growth limiter to reduce program sizeand check if growth reduction could lead to increased testperformance.|Bart Wyns,Luc Boullart,Pieter Jan De Smedt","58147|GECCO|2007|Some novel locality results for the blob code spanning tree representation|The Blob Code is a bijective tree code that represents each tree on n labelled vertices as a string of n- vertex labels. In recent years, several researchers have deployed the Blob Code as a GA representation, and have reported promising results across a range of tree-based optimization problems. In this paper, we exploit a recently discovered linear-time decoding algorithm for the Blob Code to develop some novel locality results, extending previous work by Julstrom. Let  be the random variable representing the number of tree edges that are changed by a random single-element string mutation. Under the Blob Code, we demonstrate that pessimal mutations (i.e., mutations for which n-) can arise for any n  . However, as n grows, the probability of perfect mutation P() approaches one, following a power-law relationship, and E() approaches two. These results show that the locality of the Blob Code is high, but not as high as that of Dandelion-like codes. We also show that the choice of mutation position places restrictions on the range of , and therefore influences the distribution of . In particular, mutating the kth element of a Blob string alters at most n-k tree edges.|Tim Paulden,David K. Smith"],["58132|GECCO|2007|Self-modifying cartesian genetic programming|In nature, systems with enormous numbers of components (i.e. cells) are evolved from a relatively small genotype. It has not yet been demonstrated that artificial evolution is sufficient to make such a system evolvable. Consequently researchers have been investigating forms of computational development that may allow more evolvable systems. The approaches taken have largely used re-writing, multi- cellularity, or genetic regulation. In many cases it has been difficult to produce general purpose computation from such systems.In this paper we introduce computational development using a form of Cartesian Genetic Programming that includes self-modification operations. One advantage of this approach is that ab initio the system can be used to solve computational problems. We present results on a number of problems and demonstrate the characteristics and advantages that self-modification brings.|Simon Harding,Julian Francis Miller,Wolfgang Banzhaf","57904|GECCO|2007|Association rule mining for continuous attributes using genetic network programming|Most association rule mining algorithms make use of discretization algorithms for handling continuous attributes. However, by means of methods of discretization, it is difficult to get highest attribute interdependency and at the same time to get lowest number of intervals. We propose a method using a new graph-based evolutionary algorithm named \"Genetic Network Programming (GNP)\" that can deal with continues values directly, that is, without using any discretization method as a preprocessing step. GNP is one of the evolutionary optimization techniques, which uses directed graph structures as solutions and is composed of three kinds of nodes start node, judgment node and processing node. Once GNP is booted up, firstly the execution starts from the start node, secondly the next node to be executed is determined according to the judgment and connection from the current activated node. The features of GNP are described as follows. First, it is possible to reuse nodes because of this, the structure is compact. Second, GNP can find solutions of problems without bloat, which can be sometimes found in Genetic Programming (GP), because of the fixed number of nodes in GNP. Third, nodes that are not used at the current program executions will be used for future evolution. Fourth, GNP is able to cope with partially observable Markov processes. In this paper, we propose a method that can deal with continuous attributes, where attributes in databases correspond to judgment nodes in GNP and each continuous attribute is checked whether its value is greater than a threshold value and the association rules are represented as the connections of the judgment nodes. Threshold ai is firstly determined by calculating the mean i and standard deviation si of all attribute values of Ai. Then, initial threshold ai is selected randomly between the interval i - aisi, i + aisi where ai is a parameter to determine the range of the interval. Once the threshold ai is selected for all attributes, each value of the attribute Ai is checked if it is greater than the threshold ai in the judgment nodes of the proposed method. In addition to that, the threshold ai is also evolved by mutation between i - aisi, i + aisi in every generation in order to obtain as many association rules as possible. The features of the proposed method are as follows compared with other methods ) Extracts rules without identifying frequent itemsets used in Apriori-like mining methods. ) Stores extracted important association rules in a pool all together through generations. ) Measures the significance of associations via the chi-squared test. ) Extracts important rules sufficient enough for user's purpose in a short time. ) The pool is updated in every generation and only important association rules with higher chi-squared value are stored when the identical rules are stored. We have evaluated the proposed method by doing two simulations. Simulation  uses fixed threshold values that is, they remain fixed at initial thresholds during evolution. In simulation ,thresholds are evolved by mutation in every generation. Fig.  shows the number of rules extracted in the pool in simulation . It is found that the number of rules extracted has been increased, which means simulation  outperforms simulation .|Karla Taboada,Kaoru Shimada,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu","58113|GECCO|2007|Best SubTree genetic programming|The result of the program encoded into a Genetic Programming(GP) tree is usually returned by the root of that tree. However, this is not a general strategy. In this paper we present and investigate a new variant where the best subtree is chosen to provide the solution of the problem. The other nodes (not belonging to the best subtree) are deleted. This will reduce the size of the chromosome in those cases where its best subtree is different from the entire tree. We have tested this strategy on a wide range of regression and classification problems. Numerical experiments have shown that the proposed approach can improve both the search speed and the quality of results.|Oana Muntean,Laura Diosan,Mihai Oltean","58049|GECCO|2007|The genetic programming collaboration network and its communities|Useful information about scientific collaboration structures and patterns can be inferred from computer databases of published papers. The genetic programming bibliography is the most complete reference of papers on GP. In addition to locating publications, it contains coauthor and coeditor relationships from which a more complete picture of the field emerges. We treat these relationships as undirected small world graphs whose study reveals the community structure of the GP collaborative social network. Automatic analysis discovers new communities and highlights new facets of them. The investigation reveals many similarities between GP and coauthorship networks in other scientific fields but also some subtle differences such as a smaller central network component and a high clustering.|Leslie Luthi,Marco Tomassini,Mario Giacobini,William B. Langdon","58114|GECCO|2007|Coevolution of intelligent agents using cartesian genetic programming|A coevolutionary competitive learning environment for two antagonistic agents is presented. The agents are controlled by a new kind of computational network based on a compartmentalised model of neurons. We have taken the view that the genetic basis of neurons is an important  and neglected aspect of previous approaches. Accordingly, we have defined a collection of chromosomes representing various aspects of the neuron soma, dendrites and axon branches, and synaptic connections. Chromosomes are represented and evolved using a form of genetic programming known as Cartesian Genetic Programming. The network formed by running the chromosomal programs has a highly dynamic morphology in which neurons grow, and die, and neurite branches together with synaptic connections form and change in response to environmental interactions. The idea of this paper is to demonstrate the importance of the genetic transfer of learned experience and life time learning. The learning is a consequence of the complex dynamics produced as a result of interaction (coevolution) between two intelligent agents. Our results show that both agents exhibit interesting learning capabilities.|Gul Muhammad Khan,Julian Francis Miller,David M. Halliday","57974|GECCO|2007|Trading rules on stock markets using genetic network programming with sarsa learning|In this paper, the Genetic Network Programming (GNP) for creating trading rules on stocks is described. GNP is an evolutionary computation, which represents its solutions using graph structures and has some useful features inherently. It has been clarified that GNP works well especially in dynamic environments since GNP can create quite compact programs and has an implicit memory function. In this paper, GNP is applied to creating a stock trading model. There are three important points The first important point is to combine GNP with Sarsa Learning which is one of the reinforcement learning algorithms. Evolution-based methods evolve their programs after task execution because they must calculate fitness values, while reinforcement learning can change programs during task execution, therefore the programs can be created efficiently. The second important point is that GNP uses candlestick chart and selects appropriate technical indices to judge the buying and selling timing of stocks. The third important point is that sub-nodes are used in each node to determine appropriate actions (buyingselling) and to select appropriate stock price information depending on the situation. In the simulations, the trading model is trained using the stock prices of  brands in ,  and . Then the generalization ability is tested using the stock prices in . From the simulation results, it is clarified that the trading rules of the proposed method obtain much higher profits than Buy&Hold method and its effectiveness has been confirmed.|Yan Chen,Shingo Mabu,Kotaro Hirasawa,Jinglu Hu","57893|GECCO|2007|A data parallel approach to genetic programming using programmable graphics hardware|In recent years the computing power of graphics cards has increased significantly. Indeed, the growth in the computing power of these graphics cards is now several orders of magnitude greater than the growth in the power of computer processor units. Thus these graphics cards are now beginning to be used by the scientific community aslow cost, high performance computing platforms. Traditional genetic programming is a highly computer intensive algorithm but due to its parallel nature it can be distributed over multiple processors to increase the speed of the algorithm considerably. This is not applicable for single processor architectures but graphics cards provide a mechanism for developing a data parallel implementation of genetic programming. In this paper we will describe the technique of general purpose computing using graphics cards and how to extend this technique to genetic programming. We will demonstrate the improvement in the performance of genetic programming on single processor architectures which can be achieved by harnessing the computing power of these next generation graphics cards.|Darren M. Chitty","57960|GECCO|2007|A new crossover technique for Cartesian genetic programming|Genetic Programming was first introduced by Koza using tree representation together with a crossover technique in which random sub-branches of the parents' trees are swapped to create the offspring. Later Miller and Thomson introduced Cartesian Genetic Programming, which uses directed graphs as a representation to replace the tree structures originally introduced by Koza. Cartesian Genetic Programming has been shown to perform better than the traditional Genetic Programming but it does not use crossover to create offspring, it is implemented using mutation only. In this paper a new crossover method in Genetic Programming is introduced. The new technique is based on an adaptation of the Cartesian Genetic Programming representation and is tested on two simple regression problems. It is shown that by implementing the new crossover technique, convergence is faster than that of using mutation only in the Cartesian Genetic Programming method.|Janet Clegg,James Alfred Walker,Julian Francis Miller","58106|GECCO|2007|Linear genetic programming of metaheuristics|We suggest a flavour of linear Genetic Programming indomain-specific languages that acts as a hyperheuristic (HH).|Robert E. Keller,Riccardo Poli","57990|GECCO|2007|Solving real-valued optimisation problems using cartesian genetic programming|Classical Evolutionary Programming (CEP) and Fast Evolutionary Programming (FEP) have been applied to real-valued function optimisation. Both of these techniques directly evolve the real-values that are the arguments of the real-valued function. In this paper we have applied a form of genetic programming called Cartesian Genetic Programming (CGP) to a number of real-valued optimisation benchmark problems. The approach we have taken is to evolve a computer program that controls a writing-head, which moves along and interacts with a finite set of symbols that are interpreted as real numbers, instead of manipulating the real numbers directly. In other studies, CGP has already been shown to benefit from a high degree of neutrality. We hope to exploit this for real-valued function optimisation problems to avoid being trapped on local optima. We have also used an extended form of CGP called Embedded CGP (ECGP) which allows the acquisition, evolution and re-use of modules. The effectiveness of CGP and ECGP are compared and contrasted with CEP and FEP on the benchmark problems. Results show that the new techniques are very effective.|James Alfred Walker,Julian Francis Miller"],["58105|GECCO|2007|Modeling selection pressure in XCS for proportionate and tournament selection|In this paper, we derive models of the selection pressure in XCS for proportionate (roulette wheel) selection and tournament selection. We show that these models can explain the empirical results that have been previously presented in the literature. We validate the models on simple problems showing that, (i) when the model assumptions hold, the theory perfectly matches the empirical evidence (ii) when the model assumptions do not hold, the theory can still provide qualitative explanations of the experimental results.|Albert Orriols-Puig,Kumara Sastry,Pier Luca Lanzi,David E. Goldberg,Ester Bernadó-Mansilla","58222|GECCO|2007|Cross entropy and adaptive variance scaling in continuous EDA|This paper deals with the adaptive variance scaling issue incontinuous Estimation of Distribution Algorithms. A phenomenon is discovered that current adaptive variance scaling method in EDA suffers from imprecise structure learning. A new type of adaptation method is proposed to overcome this defect. The method tries to measure the difference between the obtained population and the prediction of the probabilistic model, then calculate the scaling factor by minimizing the cross entropy between these two distributions. This approach calculates the scaling factor immediately rather than adapts it incrementally. Experiments show that this approach extended the class of problems that can be solved, and improve the search efficiency in some cases. Moreover, the proposed approach features in that each decomposed subspace can be assigned an individual scaling factor, which helps to solve problems with special dimension property.|Yunpeng Cai,Xiaomin Sun,Hua Xu,Peifa Jia","57968|GECCO|2007|An analysis of constructive crossover and selection pressure in genetic programming|A common problem in genetic programming search algorithms is destructive crossover in which the offspring of good parents generally has worse performance than the parents. Designing constructive crossover operators and integrating some local search techniques into the breeding process have been suggested as solutions. This paper reports on experiments demonstrating that premature convergence may happen more often when using these techniques in combination with standard parent selection. It shows that modifying the selection pressure in the parent selection process is necessary to obtain a significant performance improvement.|Huayang Xie,Mengjie Zhang,Peter Andreae","58070|GECCO|2007|Convergence phases variance trajectories and runtime analysis of continuous EDAs|Considering the available body of literature on continuous EDAs, one must state that many important questions are still unanswered, e.g. How do continuous EDAs really work, and how can we increase their efficiency further The first question must be answered on the basis of formal models, but despite some recent results, the majority of contributions to the field is experimental. The second questionshould be answered by exploiting the insights that have been gained from formal models. We contribute to the theoretical literature on continuous EDAs by focussing on a simple, yet important, question How should the variances used tosample offspring from change over an EDA run To answer this question, the convergence process is separated into three phases and it is shown that for each phase, a preferable strategy exists for setting the variances. It is highly likely that the use of variances that have been estimated with maximum likelihood is not optimal. Thus, variance modification policies are not just a nice add-on. In the light of our findings, they become an integral component of continuous EDAs, and they should consider the specific requirements of all phases of the optimization process.|Jörn Grahl,Peter A. N. Bosman,Stefan Minner","57946|GECCO|2007|SDR a better trigger for adaptive variance scaling in normal EDAs|Recently, advances have been made in continuous, normal-distribution-based Estimation-of-DistributionAlgorithms (EDAs) by scaling the variance upfrom the maximum-likelihood estimate. When doneproperly, such scaling has been shown to preventpremature convergence on slope-like regions ofthe search space. In this paper we specificallyfocus on one way of scaling that was previouslyintroduced as Adaptive Variance Scaling (AVS). It wasfound that when using AVS, the average number offitness evaluations grows subquadratically withthe dimensionality on a wide range of unimodaltest-problems, competitively with the CMA-ES.Still, room for improvement exists because thevariance doesn't always have to be scaled. Apreviously introduced trigger based on correlationthat determines when to apply scaling was shownto fail on higher dimensional problems. Here weprovide a new solution called the Standard-DeviationRatio (SDR) trigger that is integrated with theIterated Density-Estimation Evolutionary Algorithm(IDEA). Intuitively put, scaling istriggered with SDR only if improvements are foundto be far away from the mean. SDR works even inhigh dimensions as a result of factorizing thedecision rule behind the trigger according to theestimated Bayesian factorization. We evaluateSDR-AVS-IDEA on the same set ofbenchmark problems and compare it with AVS-IDEAand CMA-ES. We find that the addition of SDR givesAVS-IDEA an important extra edgefor it to be used in future research and inapplications both in single-objective optimizationas well as in multi-objective and dynamicoptimization. In addition, we provide practical rulesof thumb for parameter settings for usingSDR-AVS-IDEA that result in anasymptotic scale-up behavior that is sublinearfor the population size (O(l.)) andsubquadratic (O(l.)) for thenumber of evaluations.|Peter A. N. Bosman,Jörn Grahl,Franz Rothlauf","57936|GECCO|2007|Another investigation on tournament selection modelling and visualisation|Tournament selection has been widely used and studied in evolutionary algorithms. To supplement the study of tournament selection, this paper provides several models describing the probabilities that a program of a particular rank is sampled and is selected in the standard tournament selection in a simple situation and a complex situation. This paper discovers that, with the same tournament size, trends of sampling probability of a program and selection probability distributions of a population are the same regardless ofthe population size. This paper also models and investigates an alternative tournament selection method which eliminates one of the drawbacks in the standard tournament selection. Finally, this paper proposes a new fitness evaluation saving algorithm via the use of not-sampled individuals, which is a special property of tournament selection.|Huayang Xie,Mengjie Zhang,Peter Andreae","57939|GECCO|2007|Peer-to-peer evolutionary algorithms with adaptive autonomous selection|In this paper we describe and evaluate a fully distributed PP evolutionary algorithm (EA) with adaptive autonomous selection. Autonomous selection means that decisions regarding survival and reproduction are taken by the individuals themselves independently, without any central control.This allows for a fully distributed EA, where not only reproduction (crossover and mutation) but also selection is performed at local level. An unwanted consequence of adding and removing individuals in a non-synchronized manner is that the population size gets out of control too. This problem is resolved by addingan adaptation mechanism allowing individuals to regulate their own selection pressure. The key tothis is a gossiping algorithm that enables individuals to maintain estimates on the size andthe fitness of the population. The algorithm is experimentally evaluated on a test problem to show the viability of the idea and to gain insight into the run-time dynamics of such an algorithm. The results convincingly demonstrate the feasibility of a fully decentralized EA in which the population size can be kept stable.|W. R. M. U. K. Wickramasinghe,Maarten van Steen,A. E. Eiben","58232|GECCO|2007|Autonomous selection in evolutionary algorithms|This work introduces Autonomous selection in EAs to escape the need for some central control during the selection phases of an EA. The results demonstrate that this is a viable idea that needs further investigation.|A. E. Eiben,Marc Schoenauer,D. W. F. van Krevelen,M. C. Hobbelman,M. A. ten Hagen,R. C. van het Schip","58218|GECCO|2007|Adaptive variance scaling in continuous multi-objective estimation-of-distribution algorithms|Recent research into single-objective continuous Estimation-of-Distribution Algorithms (EDAs)has shown that when maximum-likelihood estimationsare used for parametric distributions such as thenormal distribution, the EDA can easily suffer frompremature convergence. In this paper we argue thatthe same holds for multi-objective optimization.Our aim in this paper is to transfer a solutioncalled Adaptive Variance Scaling (AVS) from thesingle-objective case to the multi-objectivecase. To this end, we zoom in on an existing EDAfor continuous multi-objective optimization, theMIDEA, which employs mixturedistributions. We propose a means to combine AVSwith the normal mixture distribution, as opposedto the single normal distribution for which AVS wasintroduced. In addition, we improve the AVS schemeusing the Standard-Deviation Ratio(SDR) trigger. Intuitively put, variance scalingis triggered by the SDR trigger only ifimprovements are found to be far awayfrom the mean. For the multi-objective case,this addition is important to keep the variancefrom being scaled to excessively large values.From experiments performed on five well-knownbenchmark problems, the addition of SDR andAVS is found to enlarge the class of problems thatcontinuous multi-objective EDAs can solve reliably.|Peter A. N. Bosman,Dirk Thierens","57956|GECCO|2007|Linear selection|We investigate a form of selection, linear selection, where parents are not selected independently. One form of dependent selection, semi-linear selection, where the parents are jointly selected with a probability proportional to the average of their selection probabilities, leads the GA to behave half-way between an algorithm driven by crossover and one driven by mutation.|Mario Graff,Riccardo Poli,Alberto Moraglio"],["57966|GECCO|2007|Discovering structures in gene regulatory networks using genetic programming and particle swarms|In this paper, we describe a Genetic Programming and Particle Swarm Hybrid algorithm for Gene Network discovery.|Xinye Cai,Stephen Welch,Praveen Koduru,Sanjoy Das","58060|GECCO|2007|Volatility forecasting using time series data mining and evolutionary computation techniques|Traditional parametric methods have limited success in estimating and forecasting the volatility of financial securities. Recent advance in evolutionary computation has provided additional tools to conduct data mining effectively. The current work applies the genetic programming in a Time Series Data Mining framework to characterize the S&P high frequency data in order to forecast the one step ahead integrated volatility. Results of the experiment have shown to be superior to those derived by the traditional methods.|Irwin Ma,Tony Wong,Thiagas Sankar","58114|GECCO|2007|Coevolution of intelligent agents using cartesian genetic programming|A coevolutionary competitive learning environment for two antagonistic agents is presented. The agents are controlled by a new kind of computational network based on a compartmentalised model of neurons. We have taken the view that the genetic basis of neurons is an important  and neglected aspect of previous approaches. Accordingly, we have defined a collection of chromosomes representing various aspects of the neuron soma, dendrites and axon branches, and synaptic connections. Chromosomes are represented and evolved using a form of genetic programming known as Cartesian Genetic Programming. The network formed by running the chromosomal programs has a highly dynamic morphology in which neurons grow, and die, and neurite branches together with synaptic connections form and change in response to environmental interactions. The idea of this paper is to demonstrate the importance of the genetic transfer of learned experience and life time learning. The learning is a consequence of the complex dynamics produced as a result of interaction (coevolution) between two intelligent agents. Our results show that both agents exhibit interesting learning capabilities.|Gul Muhammad Khan,Julian Francis Miller,David M. Halliday","57893|GECCO|2007|A data parallel approach to genetic programming using programmable graphics hardware|In recent years the computing power of graphics cards has increased significantly. Indeed, the growth in the computing power of these graphics cards is now several orders of magnitude greater than the growth in the power of computer processor units. Thus these graphics cards are now beginning to be used by the scientific community aslow cost, high performance computing platforms. Traditional genetic programming is a highly computer intensive algorithm but due to its parallel nature it can be distributed over multiple processors to increase the speed of the algorithm considerably. This is not applicable for single processor architectures but graphics cards provide a mechanism for developing a data parallel implementation of genetic programming. In this paper we will describe the technique of general purpose computing using graphics cards and how to extend this technique to genetic programming. We will demonstrate the improvement in the performance of genetic programming on single processor architectures which can be achieved by harnessing the computing power of these next generation graphics cards.|Darren M. Chitty","58051|GECCO|2007|Generating classification trees for small disjuncts using incremental gas|In this paper an Incremental GA techniques is proposed tosolve the problem of small disjuncts in classification trees. It is once applied on the disjuncts sorted in ascending orderand once in descending order with respect to their coverage. Both versions of the technique have been tested using benchmark datasets and the results are compared with thoseof other hybrid techniques.|Magda Bahaa Eldin Fayek,Amira Samy Talaat,Nevin Mahmoud Darwish","58034|GECCO|2007|Clustering gene expression data via mining ensembles of classification rules evolved using moses|A novel approach, model-based clustering, is described foridentifying complex interactions between genes or gene-categories based on static gene expression data. The approach deals with categorical data, which consists of a set of gene expressionprofiles belonging to one category, and a set belonging to anothercategory. An evolutionary algorithm (Meta-Optimizing Semantic Evolutionary Search, or MOSES) is used to learn an ensemble of classification models distinguishing the two categories, based on inputs that are features corresponding to gene expression values. Each feature is associated with a model-based vector, which encodes quantitative information regarding the utilization of the feature across the ensembles of models. Two different ways of constructing these vectors are explored. These model-based vectors are then clustered using a variant of hierarchical clustering called Omniclust. The result is a set of model-based clusters, in which features are gathered together if they are often considered together by classification models -- which may be because they're co-expressed, or may be for subtler reasons involving multi-gene interactions. The method is illustrated by applying it to two datasets regarding human gene expression, one drawn from brain cells and pertinent to the neurogenetics of aging, and the other drawn from blood cells and relating to differentiating between types of lymphoma. We find that, compared to traditional expression-based clustering, the new method often yields clusters that have higher mathematical quality (in the sense of homogeneity and separation) and also yield novel and meaningful insights into the underlying biological processes.|Moshe Looks,Ben Goertzel,Lúcio de Souza Coelho,Mauricio Mudado,Cassio Pennachin","57997|GECCO|2007|Feature selection and classification in noisy epistatic problems using a hybrid evolutionary approach|A hybrid evolutionary approach is proposed for the combined problem of feature selection (using a genetic algorithm with IntersectionUnion recombination and a fitness function based on a counter-propagation artificial neural network) and subsequent classifier construction (using strongly-typed genetic programming), for use in nonlinear association studies with relatively large potential feature sets and noisy class data. The method was tested using synthetic data with various degrees of injected noise, based on a proposed mental health database.allResults show the algorithm has good potential for feature selection, classification and function characterization.|Drew DeHaas,Jesse Craig,Colin Rickert,Margaret J. Eppstein,Paul Haake,Kirsten Stor","57913|GECCO|2007|Using feedback to regulate gene expression in a developmental control architecture|We present what we believe is the first attempt to physically reconstruct the exploratory mechanism of genetic regulatory networks. Feedback plays a crucial role during developmental processes and its mechanisms have recently become much clearer due to evidence from evolutionary developmental biology. We believe that without similar mechanisms of interaction and feedback, digital genomes cannot guide themselves across functional search spaces in a way that fully exploits a domain's resources, particularly in the complex search domains of real-world physics. Our architecture is designed to let evolution utilise feedback as part of its mechanism of exploration.|Kester Clegg,Susan Stepney,Tim Clarke","58159|GECCO|2007|Investigating data-flow coverage of classes using evolutionary algorithms|It is not unusual for a software development organization to expend % of total project effort on testing, which can be a very laborious and time-consuming process. Therefore, there is a big necessity for test automation. This paper describes an approach to automatically generate test-data for OO software exploiting a Genetic Algorithm (GA) to achieve high levels of data-flow (d-u) coverage. A proof-of-concept tool is presented. The experimental results from testing six Java classes helped us identify three categories of problematic test targets, and suggest that in the future full d-u coverage with a reasonable computational cost may be possible if we overcome these obstacles.|Konstantinos Liaskos,Marc Roper,Murray Wood","57934|GECCO|2007|Evolutionary selection of minimum number of features for classification of gene expression data using genetic algorithms|Selecting the most relevant factors from genetic profiles that can optimally characterize cellular states is of crucial importance in identifying complex disease genes and biomarkers for disease diagnosis and assessing drug efficiency. In this paper, we present an approach using a genetic algorithm for a feature subset selection problem that can be used in selecting the near optimum set of genes for classification of cancer data. In substantial improvement over existing methods, we classified cancer data with high accuracy with less features.|Alper Küçükural,Reyyan Yeniterzi,Süveyda Yeniterzi,Osman Ugur Sezerman"],["58157|GECCO|2007|Towards billion-bit optimization via a parallel estimation of distribution algorithm|This paper presents a highly efficient, fully parallelized implementation of the compact genetic algorithm (cGA) to solve very large scale problems with millions to billions of variables. The paper presents principled results demonstrating the scalable solution of a difficult test function on instances over a billion variables using a parallel implementation of cGA. The problem addressed is a noisy, blind problem over a vector of binary decision variables. Noise is added equaling up to a tenth of the deterministic objective function variance of the problem, thereby making it difficult for simple hillclimbers to find the optimal solution. The compact GA, on the other hand, is able to find the optimum in the presence of noise quickly, reliably, and accurately, and the solution scalability follows known convergence theories. These results on noisy problem together with other results on problems involving varying modularity, hierarchy, and overlap foreshadow routine solution of billion-variable problems across the landscape of search problems.|Kumara Sastry,David E. Goldberg,Xavier Llorà","57951|GECCO|2007|An estimation of distribution algorithm with guided mutation for a complex flow shop scheduling problem|An Estimation of Distribution Algorithm (EDA) is proposed toapproach the Hybrid Flow Shop with Sequence Dependent Setup Times and Uniform Machines in parallel (HFS-SDST-UM) problem. The latter motivated by the needs of a real world company. The proposed EDA implements a fairly new mechanism to improve the search of more traditional EDAs. This is the Guided Mutation (GM). EDA-GM generates new solutions by using the information from a probability model, as all EDAs, and the local information from a good known solution. The approach is tested on several instances of HFS-SDST-UM and compared with adaptations of meta-heuristics designed for very similarproblems. Encouraging results are reported.|Abdellah Salhi,José Antonio Vázquez Rodríguez,Qingfu Zhang","58086|GECCO|2007|A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design|This paper presents a hybrid evolutionary programming algorithm to solve the spread spectrum radar polyphase code design problem. The proposed algorithm uses an Evolutionary Programming (EP) approach as global search heuristic. This EP is hybridized with a gradient-based local search procedure which includes a dynamic step adaptation procedure to perform accurate and efficient local search for better solutions. Numerical examples demonstrate that the algorithm outperforms existing approaches for this problem.|?ngel M. Pérez-Bellido,Sancho Salcedo-Sanz,Emilio G. Ortíz-García,Antonio Portilla-Figueras","58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Suárez,Manuel Valenzuela-Rendón,Hugo Terashima-Marín,Eduardo Uresti-Charre","58092|GECCO|2007|Guided hyperplane evolutionary algorithm|A new evolutionary technique for multicriteria optimization called Guiding Hyper-plane Evolutionary Algorithm (GHEA) is proposed. The originality of the approach consists in the fact that the fitness assignment is realized by using a guiding hyperplane and a new non Pareto optimality concept. Numerical experiments illustrate the performance of GHEA compared with the popular NSGA-II and SPEA.|Corina Rotar,D. Dumitrescu,Rodica Ioana Lung","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","57984|GECCO|2007|Discrimination of metabolic flux profiles using a hybrid evolutionary algorithm|Studying metabolic fluxes is a crucial aspect of understanding biological phenotypes. However, it is often not possible to measure these fluxes directly. As an alternative, fluxome profiling provides indirect information about fluxes in a high-throughput setting. In this paper, we consider a scenario where fluxome profiling is used to investigate characteristic differences between a number of bacterial mutant strains. The goal is to identify groups of mutants that show maximally different fluxome profiles. We propose an evolutionary algorithm for this optimization problem and demonstrate that it outperforms alternative methods based on principle component analysis and independent component analysis on both real and synthetic data sets.|Stefan Bleuler,Eckart Zitzler","58018|GECCO|2007|Investigation of mutation operators for the bayesian optimization algorithm|Although BOA is effective at finding solutions for optimization problems, small population sizes in a model can result in premature convergence to a sub-optimal solution. One way of avoiding premature convergence is to increase population diversity with a mutation operator. In our experiments, we compare several mutation operators for use with BOA. We examine in detail the probabilistic model utilizing (PMU) bit flipping mutation operator. We compare the effectiveness of the PMU operator with standard BOA, self-adaptive evolution and local search of substructural neighborhoods.|Eric Martin Heien,Tomoyuki Hiroyasu,Noriyuki Fujimoto","58010|GECCO|2007|Global multiobjective optimization via estimation of distribution algorithm with biased initialization and crossover|Multiobjective optimization problems with many local Pareto fronts is a big challenge to evolutionary algorithms. In this paper, two operators, biased initialization and biased crossover, are proposed to improve the global search ability of RM-MEDA, a recently proposed multiobjective estimation of distribution algorithm. Biased initialization inserts several globally Pareto optimal solutions into the initial population biased crossover combines the location information of some best solutions found so far and globally statistical information extracted from current population. Experiments have been conducted to study the effects of these two operators.|Aimin Zhou,Qingfu Zhang,Yaochu Jin,Bernhard Sendhoff,Edward P. K. Tsang"],["57951|GECCO|2007|An estimation of distribution algorithm with guided mutation for a complex flow shop scheduling problem|An Estimation of Distribution Algorithm (EDA) is proposed toapproach the Hybrid Flow Shop with Sequence Dependent Setup Times and Uniform Machines in parallel (HFS-SDST-UM) problem. The latter motivated by the needs of a real world company. The proposed EDA implements a fairly new mechanism to improve the search of more traditional EDAs. This is the Guided Mutation (GM). EDA-GM generates new solutions by using the information from a probability model, as all EDAs, and the local information from a good known solution. The approach is tested on several instances of HFS-SDST-UM and compared with adaptations of meta-heuristics designed for very similarproblems. Encouraging results are reported.|Abdellah Salhi,José Antonio Vázquez Rodríguez,Qingfu Zhang","58185|GECCO|2007|On the relativity in the assessment of blind optimization algorithms and the problem-algorithm coevolution|Considering as an optimization problem the one of knowing what is hard for a blind optimization algorithm, the usefulness of absolute algorithm-independent hardness measures is called into question, establishing as a working hypothesis the relativity in the assessment of blind search. The results of the implementation of an incremental coevolutionary algorithm for coevolving populations of tunings of a simple genetic algorithm and simulated annealing, random search and -bit problems are presented, showing how these results are related to two popular views of hardness for genetic search deception and rugged fitness landscapes.|Carlos D. Toledo-Suárez,Manuel Valenzuela-Rendón,Hugo Terashima-Marín,Eduardo Uresti-Charre","57921|GECCO|2007|A memetic algorithm for the low autocorrelation binary sequence problem|Finding binary sequences with low auto correlation is a very hard problem with many practical applications. In this paper we analyze several meta heuristic approaches to tackle the construction of this kind of sequences. We focus on two different local search strategies, steepest descent local search (SDLS) and tabu search (TS), and their use both as stand-alone techniques and embedded within a memetic algorithm (MA). Plain evolutionary algorithms are shown to perform worse than stand-alone local search strategies. However, a MA endowed with TS turns out to be a state-of-the-art algorithm it consistently finds optimal sequences in considerably less time than previous approaches reported in the literature.|José E. Gallardo,Carlos Cotta,Antonio J. Fernández","58024|GECCO|2007|A discrete differential evolution algorithm for the permutation flowshop scheduling problem|In this paper, a novel discrete differential evolution (DDE) algorithm is presented to solve the permutation flowhop scheduling problem with the makespan criterion. The DDE algorithm is simple in nature such that it first mutates a target population to produce the mutant population. Then the target population is recombined with the mutant population in order to generate a trial population. Finally, a selection operator is applied to both target and trial populations to determine who will survive for the next generation based on fitness evaluations. As a mutation operator in the discrete differential evolution algorithm, a destruction and construction procedure is employed to generate the mutant population. We propose a referenced local search, which is embedded in the discrete differential evolution algorithm to further improve the solution quality. Computational results show that the proposed DDE algorithm with the referenced local search is very competitive to the iterated greedy algorithm which is one of the best performing algorithms for the permutation flowshop scheduling problem in the literature.|Quan-Qe Pan,Mehmet Fatih Tasgetiren,Yun-Chia Liang","57923|GECCO|2007|Hybrid quantum particle swarm optimization algorithm for combinatorial optimization problem|In this paper, a framework of hybrid PSO is proposed by reasonablycombining the Q-bit evolutionary search of quantum PSO and binary bit evolutionary search of genetic PSO.|Jiahai Wang,Yalan Zhou","57976|GECCO|2007|A discrete particle swarm optimization algorithm for the generalized traveling salesman problem|Dividing the set of nodes into clusters in the well-known traveling salesman problem results in the generalized traveling salesman problem which seeking a tour with minimum cost passing through only a single node from each cluster. In this paper, a discrete particle swarm optimization is presented to solve the problem on a set of benchmark instances. The discrete particle swarm optimization algorithm exploits the basic features of its continuous counterpart. It is also hybridized with a local search, variable neighborhood descend algorithm, to further improve the solution quality. In addition, some speed-up methods for greedy node insertions are presented. The discrete particle swarm optimization algorithm is tested on a set of benchmark instances with symmetric distances up to  nodes from the literature. Computational results show that the discrete particle optimization algorithm is very promising to solve the generalized traveling salesman problem.|Mehmet Fatih Tasgetiren,Ponnuthurai N. Suganthan,Quan-Qe Pan","58182|GECCO|2007|ExGA II an improved exonic genetic algorithm for the multiple knapsack problem|ExGA I, a previously presented genetic algorithm, successfully solved numerous instances of the multiple knapsack problem (MKS) by employing an adaptive repair function that made use of the algorithm's modular encoding. Here we present ExGA II, an extension of ExGA I that implements additional features which allow the algorithm to perform more reliably across a larger set of benchmark problems. In addition to some basic modifications of the algorithm's framework, more specific extensions include the use of a biased mutation operator and adaptive control sequences which are used to guide the repair procedure. The success rate of ExGA II is superior to its predecessor, and other algorithms in the literature, without an overall increase in the number of function evaluations required to reach the global optimum. In fact, the new algorithm exhibits a significant reduction in the number of function evaluations required for the largest problems investigated. We also address the computational cost of using a repair function and show that the algorithm remains highly competitive when this cost is accounted for.|Philipp Rohlfshagen,John A. Bullinaria","57964|GECCO|2007|Binary ant algorithm|When facing dynamic optimization problems the goal is no longer to find the extrema, but to track their progression through the space as closely as possible. Over these kind of over changing, complex and ubiquitous real-world problems, the explorative-exploitive subtle counterbalance character of our current state-of-the-art search algorithms should be biased towards an increased explorative behavior. While counterproductive in classic problems, the main and obvious reason of using it in severe dynamic problems is simple while we engage ourselves in exploiting the extrema, the extrema moves elsewhere. In order to tackle this subtle compromise, we propose a novel algorithm for optimization in dynamic binary landscapes, stressing the role of negative feedback mechanisms. The Binary Ant Algorithm (BAA) mimics some aspects of social insects' behavior. Like Ant Colony Optimization (ACO), BAA acts by building pheromone maps over a graph of possible trails representing pseudo-solutions of increasing quality to a specific optimization problem. Main differences rely on the way this search space is represented and provided to the colony in order to exploreexploit it, while and more important, we enrol in providing strong evaporation to the problem-habitat. By a process of pheromone reinforcement and evaporation the artificial insect's trails over the graph converge to regions near the ideal solution of the optimization problem. Over each generation, positive feedbacks made available by pheromone reinforcement consolidate the best solutions found so far, while enhanced negative feedbacks given by the evaporation mechanism provided the system with population diversity and fast self-adaptive characteristics, allowing BAA to be particularly suitable for severe complex dynamic optimization problems. Experiments made with some well known test functions frequently used in the Evolutionary Algorithms' research field illustrate the efficiency of the proposed method. BAA was also compared with other algorithms, proving to be more able to track fast moving extrema on several test problems.|Carlos Fernandes,Agostinho C. Rosa,Vitorino Ramos","57910|GECCO|2007|A genetic algorithm for resident physician scheduling problem|This paper formally presents the resident physician scheduling problem, which is one of the most important scheduling problems in hospital. The resident physician scheduling problem is characterized as satisfying the fair schedule constraint, the physician specification constraint and the safe schedule constraint simultaneously. To minimize the penalties from violating the constraints, this study adopts the evolutionary approach to propose a genetic algorithm for solving the problems. In addition the well-known genetic operators, this study proposed a new mutation operator called dynamic mutation for solving the resident physician scheduling problem. The experimental results show that the proposed algorithm performs well in searching optimal schedules.|Chi-Way Wang,Lei-Ming Sun,Ming-Hui Jin,Chung-Jung Fu,Li Liu,Chen-hsiung Chan,Cheng-Yan Kao","58219|GECCO|2007|A fuzzy genetic algorithm for the dynamic cell formation problem|This paper deals with a fuzzy genetic algorithm applied to a manufacturing cell formation problem. We discuss the importance of taking into account the dynamic aspect of the problem that has been poorly studied in the related literature. Using a multi-periodic planning horizon modeling, two strategies are considered passive and active. The first strategy consists of maintaining the same composition of machines during the overall planning horizon, while the second allows performing a different composition for each period. When the decision maker wants to choose the most adequate strategy for its environment, there is a need to control the proposed evolutionary solving approach, due to the complexity of the model. For that purpose, we propose an off-line fuzzy logic enhancement. The results, using this enhancement, are better than those obtained using the GA alone.|Menouar Boulif,Karim Atif"]]}}